TheThirty-FifthAAAIConferenceonArtificialIntelligence(AAAI-21)
Conversational Neuro-Symbolic Commonsense Reasoning
ForoughArabshahi1*,JenniferLee1,MikaylaGawarecki2
KathrynMazaitis2,AmosAzaria3,TomMitchell2
1Facebook,
2CarnegieMellonUniversity,
3ArielUniversity
fforough,jenniferlee98g@fb.com,fmgawarec,krivardg@cs.cmu.edu,
amos.azaria@ariel.ac.il,tom.mitchell@cs.cmu.edu
Abstract Astudy,inwhichwecollectedsuchif(state)-then(action)
commandsfromhumansubjects,revealedthathumansoften
InorderforconversationalAIsystemstoholdmorenatural
under-specifyconditionsintheirstatements;perhapsbecause
andbroad-rangingconversations,theywillrequiremuchmore
theyareusedtospeakingwithotherhumanswhopossessthe
commonsense,includingtheabilitytoidentifyunstatedpre-
commonsenseneededtoinfertheirmorespecificintentby
sumptionsoftheirconversationalpartners.Forexample,in
the command “If it snows at night then wake me up early makingpresumptionsabouttheirstatement.
becauseIdon’twanttobelateforwork”thespeakerrelieson Theinabilitytomakethesepresumptionsmakesitchal-
commonsensereasoningofthelistenertoinfertheimplicitpre- lengingforcomputerstoengageinnaturalsoundingconver-
sumptionthattheywishtobewokenonlyifitsnowsenough
sationswithhumans.WhileconversationalAIsystemssuch
tocausetrafficslowdowns.Weconsiderheretheproblemof
asSiri,Alexa,andothersareenteringourdailylives,their
understandingsuchimpreciselystatednaturallanguagecom-
conversationswithushumansremainslimitedtoasetofpre-
mandsgivenintheformofif-(state),then-(action),because-
programmedtasks.Weproposethathandlingunseentasks
(goal)statements.Moreprecisely,weconsidertheproblem
ofidentifyingtheunstatedpresumptionsofthespeakerthat requiresconversationalagentstodevelopcommonsense.
allowtherequestedactiontoachievethedesiredgoalfrom Therefore, we propose a new commonsense reasoning
thegivenstate(perhapselaboratedbymakingtheimplicitpre- benchmark for conversational agents where the task is to
sumptionsexplicit).Wereleaseabenchmarkdatasetforthis infercommonsensepresumptionsincommandsoftheform
task,collectedfromhumansandannotatedwithcommonsense
“If state holds Then perform action Because I want to
presumptions.Wepresentaneuro-symbolictheoremprover
achieve goal.” The if-(state), then-(action) clause arises
thatextractsmulti-hopreasoningchains,andapplyittothis
whenhumansinstructnewconditionaltaskstoconversational
problem.Furthermore,toaccommodatetherealitythatcurrent
AIcommonsensesystemslackfullcoverage,wealsopresent agents(Azaria,Krishnamurthy,andMitchell2016;Labutov,
aninteractiveconversationalframeworkbuiltonourneuro- Srivastava,andMitchell2018).Thereasonforincludingthe
symbolicsystem,thatconversationallyevokescommonsense because-(goal) clause in the commands is that some pre-
knowledgefromhumanstocompleteitsreasoningchains. sumptions are ambiguous without knowing the user’s pur-
pose, or goal. For instance, if Alice’s goal in the previous
Introduction examplewastoseesnowforthefirsttime,Bobwouldhave
presumedthatevenasnowflurrywouldbeexcuseenoughto
Despitetheremarkablesuccessofartificialintelligence(AI)
wakeherup.Sincehumansfrequentlyomitdetailswhenstat-
andmachinelearninginthelastfewdecades,commonsense
ingsuchcommands,acomputerpossessingcommonsense
reasoning remains an unsolved problem at the heart of AI
shouldbeabletoinferthehiddenpresumptions;thatis,the
(Levesque, Davis, and Morgenstern 2012; Davis and Mar-
additionalunstatedconditionsontheIfand/orThenportion
cus2015;Sakaguchietal.2020).Commonsenseallowsus
ofthecommand.PleaserefertoTab.1forsomeexamples.In
humanstoengageinconversationswithoneanotherandto
thispaper,inadditiontotheproposalofthisnoveltaskand
convey our thoughts efficiently, without the need to spec-
thereleaseofanewdatasettostudyit,weproposeanovel
ify much detail (Grice 1975). For example, if Alice asks
initialapproachthatinferssuchmissingpresumptions,byex-
Bobto“wakeherupearlywheneveritsnowsatnight”so
tractingachainofreasoningthatshowshowthecommanded
that she can get to work on time, Alice assumes that Bob
actionwillachievethedesiredgoalwhenthestateholds.
will wake her up only if it snows enough to cause traffic
Wheneveranyadditionalreasoningstepsappearinthisrea-
slowdowns,andonlyifitisaworkingday.Alicedoesnot
soning chain, they are output by our system as assumed
explicitlystatetheseconditionssinceBobmakessuchpre-
implicitpresumptionsassociatedwiththecommand.Forour
sumptionswithoutmucheffortthankstohiscommonsense.
reasoningmethodweproposeaneuro-symbolicinteractive,
conversationalapproach,inwhichthecomputercombinesits
*workdonewhenFAandJLwereatCarnegieMellonUniversity.
Copyright©2021,AssociationfortheAdvancementofArtificial owncommonsenseknowledgewithconversationallyevoked
Intelligence(www.aaai.org).Allrightsreserved. knowledgeprovidedbyahumanuser.Thereasoningchain
4902
if then because Annotation:
Domain clause clause clause Example CommonsensePresumptions Count
Ifit’sgoingtorainintheafternoon((cid:1)#)
(8,andIamoutside)
Restricteddomain state action goal thenremindmetobringanumbrella((cid:1)#)
(15,beforeIleavethehouse)
76
becauseIwanttoremaindry
IfIhaveanupcomingbillpayment((cid:1)#)
(7,inthenextfewdays)
Restricteddomain state action anti-goal thenremindmetopayit((cid:1)#)
(13,beforethebillpaymentdeadline)
3
becauseIdon’twanttopayalatefee
Ifmyflight((cid:1)#)isfrom2amto4am (3,takeofftime)
Restricteddomain state action modifier thenbookmeasupershuttle((cid:1)#) (13,for2hoursbefore 2
becauseitwillbedifficulttofindubers. myflighttakeofftime)
IfIreceiveemailsaboutsales
onbasketballshoes((cid:1)#) (9,mysize)
Restricteddomain state action conjunction 2
thenletmeknow((cid:1)#) (13,thereisasale)
becauseIneedthemandIwanttosavemoney.
SUM 83
Ifthereisanupcomingelection((cid:1)#) (6,inthenextfewmonths)
(6,andIameligibletovote)
Everydaydomain state action goal thenremindmetoregister((cid:1)#)andvote((cid:1)#)
(11,tovote)
55
becauseIwantmyvoicetobeheard. (13,intheelection)
Ifit’sbeentwoweeks
sincemylastcallwithmymentee
(21,inthenextfewdays)
andIdon’thaveanupcoming
Everydaydomain state action anti-goal appointmentwithher((cid:1)#) (29,toscheduleour 4
nextappointment)
thenremindmetosendheranemail((cid:1)#)
becauseweforgottoscheduleournextchat
IfIhavedifficultysleeping((cid:1)#)
Everydaydomain state action modifier thenplayalullaby (5,atnight) 12
becauseitsoothesme.
Ifthepowergoesout((cid:1)#)
thenwhenitcomesbackon
Everydaydomain state action conjunction remindmetorestartthehousefurnace (5,intheWinter) 6
becauseitdoesn’tcomebackonbyitself
andIwanttostaywarm
SUM 77
Table1:Statisticsofif-(state),then-(action),because-(goal)commandscollectedfromapoolofhumansubjects.Thetableshows
fourdistincttypesofbecause-clauseswefound,thecountofcommandsofeachtype,examplesofeachandtheircorresponding
commonsense presumption annotations. Restricted domain includes commands whose stateis limited to checking email,
calendar, maps, alarms, and weather. Everyday domain includes commands concerning more general day-to-day activities.
Annotationsaretuplesof(index,presumption)whereindexshowsthestartingwordindexofwherethemissingpresumption
shouldbeinthecommand,highlightedwitharedarrow.Indexstartsat0andiscalculatedfortheoriginalcommand.
isextractedusingourneuro-symbolictheoremproverthat studiedtasks1.
learnssub-symbolicrepresentations(embeddings)forlogical
statements,makingitrobusttovariationsofnaturallanguage RelatedWork
encounteredinaconversationalinteractionsetting.
Theliteratureoncommonsensereasoningdatesbacktothe
verybeginningofthefieldofAI(Winograd1972;Mueller
Contributions This paper presents three main contribu- 2014;DavisandMarcus2015)andisstudiedinseveralcon-
tions. 1) We propose a benchmark task for commonsense texts.Oneaspectfocusesonbuildingalargeknowledgebase
reasoninginconversationalagentsandreleaseadatasetcon- (KB)ofcommonsensefacts.ProjectslikeCYC(Lenatetal.
tainingif-(state),then-(action),because-(goal)commands, 1990),ConceptNet(LiuandSingh2004;Havasi,Speer,and
annotatedwithcommonsensepresumptions.2)Wepresent Alonso2007;Speer,Chin,andHavasi2017)andATOMIC
CORGI(COmmonsenseReasoninGbyInstruction),asystem (Sapetal.2019;Rashkinetal.2018)areexamplesofsuch
that performs soft logical inference. CORGI uses our pro- KBs(see(DavisandMarcus2015)foracomprehensivelist).
posedneuro-symbolictheoremproverandappliesittoextract Recently,Bosselutetal.(2019)proposedCOMET,aneural
amulti-hopreasoningchainthatrevealscommonsensepre- knowledgegraphthatgeneratesknowledgetuplesbylearning
sumptions.3)WeequipCORGIwithaconversationalinter- onexamplesofstructuredknowledge.TheseKBsprovide
actionmechanismthatenablesittocollectjust-in-timecom- backgroundknowledgefortasksthatrequirecommonsense.
monsenseknowledgefromhumans.Ouruser-studyshows(a) However,itisknownthatknowledgebasesareincomplete,
theplausibilityofrelyingonhumanstoevokecommonsense
knowledgeand(b)theeffectivenessofourtheoremprover, 1The code and data are available here:
enablingustoextractreasoningchainsforupto45%ofthe https://github.com/ForoughA/CORGI
4903
andmosthaveambiguitiesandinconsistencies(Davisand differentiablestrategyforbeliefpropagationoverthegraph.
Marcus2015)thatmustbeclarifiedforparticularreasoning DeepProbLog (Manhaeve et al. 2018) developed a proba-
tasks.Therefore,wearguethatreasoningenginescanbenefit bilisticlogicprogramminglanguagethatissuitableforap-
greatlyfromaconversationalinteractionstrategytoaskhu- plicationscontainingcategoricalvariables.Contrarytoour
mansabouttheirmissingorinconsistentknowledge.Closest approach,boththesemethodsdonotlearnembeddingsfor
innaturetothisproposalistheworkbyHixon,Clark,andHa- logicalrulesthatareneededtomakeCORGIrobusttonatural
jishirzi(2015)onrelationextractionthroughconversationfor language variations. Therefore, we propose an end-to-end
questionansweringandWuetal.(2018)’ssystemthatlearns differentiablesolutionthatusesaProlog(Colmerauer1990)
toformsimpleconceptsthroughinteractivedialoguewitha prooftracetolearnruleembeddingsfromdata.Ourproposal
user.Theadventofintelligentagentsandadvancementsin is closest to the neural programmer interpreter (Reed and
naturallanguageprocessinghavegivenlearningfromcon- DeFreitas2015)thatusesthetraceofalgorithmssuchasad-
versational interactions a good momentum in the last few ditionandsorttolearntheirexecution.TheuseofPrologfor
years(Azaria,Krishnamurthy,andMitchell2016;Labutov, performingmulti-hoplogicalreasoninghasbeenstudiedin
Srivastava,andMitchell2018;Srivastava2018;Goldwasser Rockta¨schelandRiedel(2017)andWeberetal.(2019).These
andRoth2014;Christmannetal.2019;Guoetal.2018;Li methodsperformInductiveLogicProgrammingtolearnrules
etal.2018,2017;Li,Azaria,andMyers2017). fromdata,andarenotapplicabletoourproblem.DeepLogic
A current challenge in commonsense reasoning is lack (CingilliogluandRusso2018),Rockta¨scheletal.(2014),and
ofbenchmarks(DavisandMarcus2015).Benchmarktasks WangandCohen(2016)alsolearnrepresentationsforlogi-
in commonsense reasoning include the Winograd Schema calrulesusingneuralnetworks.Veryrecently,transformers
Challenge(WSC)(Levesque,Davis,andMorgenstern2012), were used for temporal logic (Finkbeiner et al. 2020) and
itsvariations(Kocijanetal.2020),anditsrecentlyscaledup todomulti-hopreasoning(Clark,Tafjord,andRichardson
counterpart,Winogrande(Sakaguchietal.2020);ROCSto- 2020)usinglogicalfactsandrulesstatedinnaturallanguage.
ries(Mostafazadehetal.2017),COPA(Roemmele,Bejan, Apurelyconnectionistapproachtoreasoningsuffersfrom
andGordon2011),TriangleCOPA(Maslan,Roemmele,and somelimitations.Forexample,theinputtokensizelimitof
Gordon 2015), and ART (Bhagavatula et al. 2020), where transformersrestrictsClark,Tafjord,andRichardson(2020)
thetaskistochooseaplausibleoutcome,causeorexplana- tosmallknowledgebases.Moreover,generalizingtoarbitrary
tion for an input scenario; and the TimeTravel benchmark numberofvariablesoranarbitraryinferencedepthisnottriv-
(Qin et al. 2019) where the task to revise a story to make ialforthem.Sincesymbolicreasoningcaninherentlyhandle
itcompatiblewithagivencounterfactualevent.Otherthan allthesechallenges,ahybridapproachtoreasoningtakesthe
TimeTravel,mostofthesebenchmarkshaveamultiplechoice burdenofhandlingthemoffoftheneuralcomponent.
designformat.However,intherealworldthecomputeris
usuallynotgivenmultiplechoicequestions.Noneofthese ProposedCommonsenseReasoning
benchmarkstargetstheextractionofunspokendetailsina
Benchmark
naturallanguagestatement,whichisachallengingtaskfor
computersknownsincethe1970’s(Grice1975).Notethan Thebenchmarktaskthatweproposeinthisworkisthatof
inferring commonsense presumptions is different from in- uncoveringhiddencommonsensepresumptionsgivencom-
tent understanding (Jan´ıcˇek 2010; Tur and De Mori 2011) mandsthatfollowthegeneralformat“ifhstateholdsithen
wherethegoalistounderstandtheintentofaspeakerwhen hperformactionibecausehIwanttoachievegoali”.Were-
they say, e.g., “pick up the mug”. It is also different from fer to these as if-then-because commands. We refer to the
implicatureandpresupposition(Sbisa` 1999;Simons2013; if-clauseasthestate,thethen-clauseastheactionand
SakamaandInoue2016)whichareconcernedwithwhatcan thebecause-clauseasthegoal.Thesenaturallanguagecom-
bepresupposedorimplicatedbyatext. mandswerecollectedfromapoolofhumansubjects(more
CORGIhasaneuro-symboliclogictheoremprover.Neuro- detailsintheAppendix).Thedataisannotatedwithunspoken
symbolicsystemsarehybridmodelsthatleveragetherobust- commonsensepresumptionsbyateamofannotators.Tab.1
ness of connectionist methods and the soundness of sym- showsthestatisticsofthedataandannotatedexamplesfrom
bolicreasoningtoeffectivelyintegratelearningandreason- thedata.Wecollectedtwosetsofif-then-becausecommands.
ing(Garcezetal.2015;Besoldetal.2017).Theyhaveshown Thefirstsetcontains83commandstargetedatastatethat
promiseindifferentareasoflogicalreasoningrangingfrom canbeobservedbyacomputer/mobilephone(e.g.checking
classicallogictopropositionallogic,probabilisticlogic,ab- emails, calendar, maps, alarms, and weather). The second
ductivelogic,andinductivelogic(Maoetal.2019;Manhaeve setcontains77commandswhosestateisaboutday-to-day
etal.2018;Dongetal.2019;Marraetal.2019;Zhou2019; eventsandactivities.81%ofthecommandsoverbothsets
Evans and Grefenstette 2018). To the best of our knowl- qualify as “if hstatei then hactioni because hgoali”.
edge,neuro-symbolicsolutionsforcommonsensereasoning The remaining 19% differ in the categorization of the be-
havenotbeenproposedbefore.Examplesofcommonsense cause-clause (see Tab. 1); common alternate clause types
reasoning engines are: AnalogySpace (Speer, Havasi, and included anti-goals (“...because I don’t want to be late”),
Lieberman2008;Havasietal.2009)thatusesdimensionality modificationsofthestateoraction(“...becauseitwillbedif-
reduction and Mueller (2014) that uses the event calculus ficulttofindanUber”),orconjunctionsincludingatleastone
formallanguage.TensorLog(Cohen2016)convertsafirst- non-goaltype.Notethatwedidnotinstructthesubjectsto
order logical database into a factor graph and proposes a giveusdatafromthesecategories,ratherweuncoveredthem
4904
input:If-(state),then-(action),because-(goal)
Doesthe
ParseStatement: Isthere
S(X) state IsGin goalStack Neuro-Symbolic aproof proof
GA( (Y Z)) ga oc at lion K? Y empty? Y T Prh oe vo ere Gm (ZPr )over: Gf (o Zr
)?
Y Sc ( Ao X (n Y)ta a )i ?n nd Y S pu rc oc oe fed
N N Ruleand
Variable N
Fail Y i>n? AddanewruletoK embeddings discard the rules N
added in the knowl-
N goalStack:top()‘G(Z) edge base update
G(Z)=goalStack:pop() loop
userfeedbackloop Asktheuserfor
knowledgebaseupdateloop
moreinformation
G0(Z). Fail
i=i+1
goalStack:push(G(Z))
G(Z)=G0(Z)
Figure 1: CORGI’s flowchart. The input is an if-then-because command e.g., “if it snows tonight then wake me up early
because I want to get to work on time”. The input is parsed into its logical form representation (for this example, S(X)
= weather(snow, Precipitation)). If CORGI succeeds, it outputs a proof tree for the because-clause or goal(parsed into
G(Z)=get(i,work,on time)).Theoutputprooftreecontainscommonsensepresumptionsfortheinputstatement(Fig2showsan
example).IfthepredicateGdoesnotexistintheknowledgebase,K,(IsGinK?),wehavemissingknowledgeandcannotfind
aproof.Therefore,weextractitfromahumanintheuserfeedbackloop.AttheheartofCORGIisaneuro-symbolictheorem
proverthatlearnsruleandvariableembeddingstoperformaproof(Appendix).goalStackandtheloopvariableiareinitialized
toemptyand0respectively,andn=3.italictextinthefigurerepresentsdescriptionsthatarereferredtointhemaintext.
afterdatacollection.Also,commonsensebenchmarkssuch andappropriatecommonsenseknowledge(seetheAppendix
astheWinogradSchemaChallenge(Levesque,Davis,and -PrologBackground)).
Morgenstern2012)includedasimilarnumberofexamples
(100)whenfirstintroduced(Kocijanetal.2020). CORGI:COmmonsenseReasoningbyInstruction
Lastly, the if-then-because commands given by humans
canbecategorizedintoseveraldifferentlogictemplates.The CORGItakesasinputanaturallanguagecommandofthe
discoveredlogictemplatesaregivenintheAppendix2.Our form“ifhstateithenhactionibecausehgoali”andin-
neuro-symbolic theorem prover uses a general reasoning fers commonsense presumptions by extracting a chain of
strategythatcanaddressallreasoningtemplates.However, commonsenseknowledgethatexplainshowthecommanded
inanextendeddiscussionintheAppendix,weexplainhowa actionachievesthegoalwhenthestateholds.Forexam-
reasoningsystem,includingours,couldpotentiallybenefit ple from a high level, for the command in Fig. 2 CORGI
fromtheselogictemplates. outputs(1)ifitsnowsmorethantwoinches,thentherewill
be traffic, (2) if there is traffic, then my commute time to
Method workincreases,(3)ifmycommutetimetoworkincreases
thenIneedtoleavethehouseearliertoensureIgettowork
Background and notation The system’s commonsense
ontime(4)ifIwakeupearlierthenIwillleavethehouse
knowledge is a KB, denoted K, programmed in a Prolog-
earlier.Formally,thisreasoningchainisaprooftree(proof
likesyntax.WehavedevelopedamodifiedversionofProlog,
trace)showninFig.2.Asshown,theprooftreeincludesthe
which has been augmented to support several special fea-
commonsensepresumptions.
tures(types,soft-matchedpredicatesandatoms,etc).Prolog
CORGI’sarchitectureisdepictedinFigure1.Inthefirst
(Colmerauer1990)isadeclarativelogicprogramminglan-
step,theif-then-becausecommandgoesthroughaparserthat
guagethatconsistsofasetofpredicateswhoseargumentsare
extractsthestate,actionandgoalfromitandconverts
atoms,variablesorpredicates.Apredicateisdefinedbyaset
themtotheirlogicalformrepresentationsS(X),A(Y)and
ofrules(Head:(cid:0)Body:)andfacts(Head:),whereHeadisa
G(Z),respectively.Forexample,theaction“wakemeup
predicate,Bodyisaconjuctionofpredicates,and:(cid:0)islogical
early” is converted to wake(me, early). The parser is pre-
implication.WeusethenotationS(X),A(Y)andG(Z)to
sentedintheAppendix(Sec.Parsing).
representthelogicalformofthestate,actionandgoal,
TheprooftraceisobtainedbyfindingaproofforG(Z),
respectivelywhereS,AandGarepredicatenamesandX;Y
using K and the context of the input if-then-because com-
andZ indicatethelistofargumentsofeachpredicate.For
mand. In other words, S(X)\A(Y)\K ! G(Z): One
example,forgoal=“Iwanttogettoworkontime”,wehave
challengeisthateventhelargestknowledgebasesgatheredto
G(Z) =get(i, work, on time). Prolog can be used to logi-
dateareincomplete,makingitvirtuallyinfeasibletoprovean
cally“prove”aquery(e.g.,toproveG(Z)fromS(X);G(Z)
arbitraryinputG(Z).Therefore,CORGIisequippedwitha
2Theappendixisavailableathttps://arxiv.org/abs/2006.10022 conversationalinteractionstrategy,whichenablesittoprove
4905
aquerybycombiningitsowncommonsenseknowledgewith theprooftrace(Fig.2)returnedbyitstheoremproverandsuc-
conversationally evoked knowledge provided by a human ceeds.Inthenextsection,weexplainourtheoremproverin
userinresponsetoaquestionfromCORGI(userfeedback detail.WerevisitscenariosA(cid:0)Dindetailinthediscussion
loopinFig.1).Thereare4possiblescenariosthatcanoccur sectionandshowrealexamplesfromouruserstudy.
whenCORGIaskssuchquestions:
A Theuserunderstandsthequestion,butdoesnotknowthe Neuro-SymbolicTheoremProving
answer.
OurNeuro-Symbolictheoremproverisaneuralmodification
B Theusermisunderstandsthequestionandrespondswith
ofbackwardchainingandusesthevectorsimilaritybetween
anundesiredanswer.
ruleandvariableembeddingsforunification.Inordertolearn
C Theuserunderstandsthequestionandprovidesacorrect theseembeddings,ourtheoremproverlearnsageneralprov-
answer,butthesystemfailstounderstandtheuserdueto: ingstrategybytrainingonprooftracesofsuccessfulproofs.
Fromahighlevel,foragivenqueryourmodelmaximizes
C:1 limitationsofnaturallanguageunderstanding.
theprobabilityofchoosingthecorrectruletopickineach
C:2 variationsinnaturallanguage,whichresultinmisalign-
step of the backward chaining algorithm. This proposal is
mentofthedataschemaintheknowledgebaseandthe
anadaptationofReedetal.’sNeuralProgrammer-Interpreter
dataschemaintheuser’smind.
(ReedandDeFreitas2015)thatlearnstoexecutealgorithms
D Theuserunderstandsthequestionandprovidesthecorrect suchasadditionandsort,bytrainingontheirexecutiontrace.
answerandthesystemsuccessfullyparsesandunderstands Inwhatfollows,werepresentscalarswithlowercaselet-
it. ters,vectorswithboldlowercaselettersandmatriceswith
CORGI’sdifferentcomponentsaredesignedsuchthatthey bolduppercaseletters.Mrule 2Rn1(cid:2)m1 denotestheembed-
addresstheabovechallenges,asexplainedbelow.Sinceour ding matrix for the rules and facts, where n 1 is the num-
benchmark data set deals with day-to-day activities, it is berofrulesandfactsandm 1 istheembeddingdimension.
unlikelyforscenarioAtooccur.Ifthetaskrequiredmore Mvar 2 Rn2(cid:2)m2 denotes the variable embedding matrix,
specificdomainknowledge,Acouldhavebeenaddressedby where n 2 is the number of all the atoms and variables in
choosingapoolofdomainexperts.ScenarioBisaddressed the knowledge base and m 2 is the variable embedding di-
byaskinginformativequestionsfromusers.ScenarioC:1is mension. Our knowledge base is type coerced, therefore
addressed by trying to extract small chunks of knowledge the variable names are associated with their types (e.g.,
from the users piece-by-piece. Specifically, the choice of alarm(Person,Time))
whattoasktheuserintheuserfeedbackloopisdeterministi-
callycomputedfromtheuser’sgoal.Thefirststepistoask
howtoachievetheuser’sstatedgoal,andCORGIexpects Learning Themodel’scoreconsistsofanLSTMnetwork
ananswerthatgivesasub-goal.Inthenextstep,CORGI whosehiddenstateindicatesthenextruleintheprooftrace
asks how to achieve the sub-goalthe user just mentioned. andaproofterminationprobability,givenaqueryasinput.
Thereasonforthispiece-by-pieceknowledgeextractionis Themodelhasafeedforwardnetworkthatmakesvariable
to ensure that the language understanding component can bindingdecisions.Themodel’strainingisfullysupervised
correctly parse the user’s response. CORGI then adds the bytheprooftraceofaquerygiveninadepth-first-traversal
extracted knowledge from the user to K in the knowledge order from left to right (Fig. 2). The trace is sequentially
updateloopshowninFig.1.Missingknowledgeoutsidethis inputtothemodelinthetraversalorderasexplainedinwhat
goal/sub-goalpathisnothandled,althoughitisaninterest- follows.Instept2[0;T]oftheproof,themodel’sinputis
ingfuturedirection.Moreover,themodelisuserspecificand (cid:15)inp = (cid:0) q ;r ;(v1;:::;v‘)(cid:1) and T is the total number of
t t t t t
theknowledgeextractedfromdifferentusersarenotshared proof steps. q is the query’s embedding and is computed
t
amongthem.Sharingknowledgeraisesinterestingprivacy byfeedingthepredicatenameofthequeryintoacharacter
issuesandrequireshandlingpersonalizedconflictsandfalls RNN.r istheconcatenatedembeddingsoftherulesinthe
t
outofthescopeofourcurrentstudy. parentandtheleftsisternodesintheprooftrace,lookedup
ScenarioC:2,causedbythevariationsofnaturallanguage, fromMrule.ForexampleinFig.2,q representsthenodeat
3
resultsinsemanticallysimilarstatementstogetmappedinto proofstept=3,r representstherulehighlightedingreen
3
different logical forms, which is unwanted. For example, (parent rule), and r represents the fact alarm(i, 8). The
4
“make sure I am awake early morning” vs. “wake me up reasonforincludingtheleftsisternodeinr isthattheproof
t
early morning” will be parsed into different logical forms isconductedinaleft-to-rightdepthfirstorder.Therefore,the
awake(i,early morning) and wake(me, early morning), re- decisionofwhatnextruletochooseineachnodeisdependent
spectivelyalthoughtheyaresemanticallysimilar.Thismis- onboththeleftsistersandtheparent(e.g.theparentandthe
match prevents a logical proof from succeeding since the leftsistersofthenodeatstept=8inFig.2aretherulesat
proofstrategyreliesonexactmatchintheunificationopera- nodest=1,t=2,andt=6,respectively).Thearguments
tion(seeAppendix).Thisisaddressedbyourneuro-symbolic of the query are presented in (v1;:::;v‘) where ‘ is the
t t
theoremprover(Fig.1)thatlearnsvectorrepresentations(em- arityofthequerypredicate.Forexample,v1inFig2isthe
3
beddings) for logical rules and variables and uses them to embedding of the variable Person. Each vi for i 2 [0;‘],
t
performalogicalproofthroughsoftunification.Ifthetheo- islookedupfromtheembeddingmatrixMvar.Theoutput
remprovercanprovetheuser’sgoal,G(Z),CORGIoutputs ofthemodelinsteptis(cid:15)out =(cid:0) c ;r ;(v1 ;:::;v‘ ))
t t t+1 t+1 t+1
4906
t=0 get(Person,ToPlace,ontime)
t=1 arrive(Person, , ,ToPlace,ArriveAt) t=13 calendarEntry(Person,ToPlace,ArriveAt)
t=2 ready(Person,LeaveAt,PrepTime) t=14 calendarEntry(i,work,9)
t=3 alarm(Perosn,Time)
ArriveAt=LeaveAt+
t=4 alarm(i,8) t=5 LeaveAt=Time+PrepTime. t=12 CommuteTime+TrTime
t=6 commute(Person,FromPlace,ToPlace,With,CommuteTime)
t=8 traffic(LeaveAt,ToPlace,With,TrTime)
t=7 commute(i,home,work,car,1)
t=9 weather(snow,Precipitation) t=10 Precipitation>=2 t=11 TrTime=1
Figure 2: Sample proof tree for the because-clause of the statement: “If it snows tonight then wake me up early because
I want to get to work on time”. Proof traversal is depth-first from left to right (t gives the order). Each node in the tree
indicates a rule’s head, and its children indicate the rule’s body. For example, the nodes highlighted in green indicate the
ruleready(Person,LeaveAt,PrepTime) :(cid:0) alarm(Person, Time) ^ LeaveAt = Time+PrepTime.Thegoalwewanttoprove,
G(Z)=get(Person, ToPlace, on time),isinthetree’sroot.Ifaproofissuccessful,thevariablesinG(Z)getgrounded(here
PersonandToPlacearegroundedtoiandwork,respectively).Thehighlightedorangenodesaretheuncoveredcommonsense
presumptions.
andiscomputedthroughthefollowingequations ExperimentDesign
s =f (q ;); h =f (s ;r ;h ); (1) Theknowledgebase,K,usedforallexperimentsisasmall
t enc t t lstm t t t(cid:0)1
handcraftedsetofcommonsenseknowledgethatreflectsthe
c =f (h ); r =f (h ); vi =f (vi); (2)
t end t t+1 rule t t+1 var t incompleteness of SOTA KBs. Some examples of our KB
wherevi isaprobabilityvectoroverallthevariablesand entries are available in the Appendix. K includes general
t+1
atomsfortheithargument,r isaprobabilityvectorover informationabouttime,restricted-domainssuchassetting
t+1
alltherulesandfactsandc isascalarprobabilityoftermi- alarmsandnotifications,emails,andsoon,aswellascom-
t
natingtheproofatstept.f ,f ,f andf arefeed
monsenseknowledgeaboutday-to-dayactivities.Kcontains
enc end rule var
forwardnetworkswithtwofullyconnectedlayers,andf a total of 228 facts and rules. Among these, there are 189
lstm
everyday-domainand39restricteddomainfactsandrules.
isanLSTMnetwork.Thetrainableparametersofthemodel
Weobservedthatmostoftheif-then-becausecommandsre-
aretheparametersofthefeedforwardneuralnetworks,the
LSTMnetwork,thecharacterRNNthatembedsq andthe quireeveryday-domainknowledgeforreasoning,evenifthey
t
ruleandvariableembeddingmatricesMruleandMvar. arerestricted-domaincommands(seeTable3forexample).
OurNeuro-Symbolictheoremproveristrainedonproof
Ourmodelistrainedend-to-end.Inordertotrainthemodel
traces (proof trees similar to Fig. 2) collected by proving
parametersandtheembeddings,wemaximizetheloglikeli-
automaticallygeneratedqueriestoKusingsPyrolog3.Mrule
hoodprobabilitygivenbelow
and Mvar are initialized randomly and with GloVe embed-
X
(cid:18)(cid:3) =argmax log(P((cid:15)outj(cid:15)in;(cid:18))); (3) dings(Pennington,Socher,andManning2014),respectively,
(cid:18)
(cid:15)out;(cid:15)in wherem 1 = 256andm 2 = 300.SinceK istype-coerced
(e.g.Time,Location,:::),initializingthevariableswithpre-
wherethesummationisoveralltheprooftracesinthetrain-
trainedwordembeddingshelpscapturetheirsemanticsand
ingsetand(cid:18) isthetrainableparametersofthemodel.We
improves the performance. The neural components of the
have
theorem prover are implemented in PyTorch (Paszke et al.
T
X 2017)andtheproverisbuiltontopofsPyrolog.
log(P((cid:15)outj(cid:15)in;(cid:18)))= logP((cid:15)outj(cid:15)in:::(cid:15)in ;(cid:18)); (4)
t 1 t(cid:0)1
t=1 UserStudy
logP((cid:15)outj(cid:15)in:::(cid:15)in ;(cid:18))=logP((cid:15)outj(cid:15)in ;(cid:18)) InordertoassessCORGI’sperformance,weranauserstudy.
t 1 t(cid:0)1 t t(cid:0)1
Weselected10goal-typeif-then-becausecommandsfrom
=logP(c jh )+
t t thedatasetinTable1andusedeachasthepromptforarea-
logP(r t+1jh t)+ soningtask.Wehad28participantsinthestudy,4ofwhich
X wereexpertscloselyfamiliarwithCORGIanditscapabilities.
log P(vi jvi): (5)
t+1 t Therestwereundergraduateandgraduatestudentswiththe
i majoritybeinginengineeringorcomputersciencefieldsand
Where the probabilities in Equation (5) are given in Equa- somethatmajoredinbusinessadministrationorpsychology.
tions(2).Theinferencealgorithmforporvingisgiveninthe
Appendix,sectionInference. 3https://github.com/leonweber/spyrolog
4907
CORGIvariations NoviceUser ExpertUser Successfultask
No-feedback 0% 0% Ifit’sgoingtorainintheafternoonthenremindmetobring
Softunification 15.61% 35.00% anumbrellabecauseIwanttoremaindry.
Oracleunification 21.62% 45.71% HowdoIknowif“Iremaindry”?
IfIhavemyumbrella.
Table2:percentageofsuccessfulreasoningtasksfordifferent
HowdoIknowif“Ihavemyumbrella”?
usertypes.Inno-feedback,userresponsesarenotconsidered
Ifyouremindmetobringanumbrella.
intheproofattempt.insoftunificationCORGIusesourpro-
Okay,Iwillperform“remindmetobringanumbrella”
posedneuro-symbolictheoremprover.IntheOraclescenario,
inordertoachieve“Iremaindry”.
thetheoremproverhasaccesstooracleembeddingsandsoft
unificationis100%accurate.
Failedtask
Ifit’sgoingtorainintheafternoonthenremindmetobring
TheseusershadneverinteractedwithCORGIpriorto the anumbrellabecauseIwanttoremaindry.
study(noviceusers).Eachpersonwasissuedthe10reason- HowdoIknowif“Iremaindry”?
ingtasks,takingonaverage20minutestocompleteall10. IfIhavemyumbrella.
Solvingareasoningtaskconsistsofparticipatinginadialog HowdoIknowif“Ihavemyumbrella”?
withCORGIasthesystemattemptstocompleteaprooffor Ifit’sinmyoffice.
thegoalofthecurrenttask;seesampledialogsinTab.3.The HowdoIknowif“it’sinmyoffice”?
tasksucceedsifCORGIisabletousetheanswersprovided ...
bytheparticipanttoconstructareasoningchain(proof)lead-
Table 3: Sample dialogs of 2 novice users in our study.
ingfromthegoaltothestateandaction.Wecollected
CORGI’sresponsesarenotedinitalics.
469dialoguesinourstudy.
The user study was run with the architecture shown in
Fig.1.Weusedtheparticipantresponsesfromthestudyto
Sec.).Therefore,oneinterestingfuturedirectionistodevelop
run a few more experiments. We (1) Replace our theorem
adynamiccontext-dependentNaturalLanguageGeneration
proverwithanoracleproverthatselectstheoptimalruleat
methodforaskingmoreeffectivequestions.
eachproofstepinourinferenceAlgorithm(Appendix)and
We would like to emphasize that although it seems to
(2)attempttoprovethegoalwithoutusinganyparticipant
us,humans,thatthepreviousexamplerequiresverysimple
responses (no-feedback). Tab. 2 shows the success rate in
backgroundknowledgethatlikelyexistsinSOTAlargecom-
eachsetting.
monsenseknowledgegraphssuchasConcepNet4,ATOMIC5
orCOMET(Bosselutetal.2019),thisisnotthecase(ver-
Discussion
ifiablebyqueryingthemonline).Forexample,forqueries
In this section, we analyze the results from the study and
suchas“thewindowsareclosed”,COMET-ConceptNetgen-
provideexamplesofthe4scenariosinSection thatween- erative model6 returns knowledge about blocking the sun,
countered.Ashypothesized,scenarioAhardlyoccurredas andCOMET-ATOMICgenerativemodel7returnsknowledge
thecommandsareaboutday-to-dayactivitiesthatallusers
aboutkeepingthehousewarmoravoidingtogethot;which
are familiar with. We did encounter scenario B, however.
while being correct, is not applicable in this context. For
The study’s dialogs show that some users provided means
“myhomeisdry”,bothCOMET-ConceptNetandCOMET-
ofsensingthegoalratherthanthecauseofthegoal.For
ATOMICgenerativemodelsreturnknowledgeabouthouse
example,forthereasoningtask“Iftherearethunderstorms
cleaningorhousecomfort.Ontheotherhand,thefactthat
intheforecastwithinafewhoursthenremindmetoclosethe
40%ofthenoviceusersinourstudywereabletohelpCORGI
windowsbecauseIwanttokeepmyhomedry”,inresponse
reasonaboutthisexamplewithresponsessuchas“IfIclose
tothesystem’sprompt“HowdoIknowif‘Ikeepmyhome
thewindows” toCORGI’s prompt, isaninterestingresult.
dry’?”auserresponded“ifthefloorisnotwet”asopposed
This tells us that conversational interactions with humans
to an answer such as “if the windows are closed”. More-
couldpavethewayforcommonsensereasoningandenable
over,someusersdidnotpayattentiontothecontextofthe
computerstoextractjust-in-timecommonsenseknowledge,
reasoningtask.Forexample,anotheruserrespondedtothe
whichwouldlikelyeithernotexistinlargeknowledgebases
aboveprompt(samereasoningtask)with“ifthetemperature
or be irrelevant in the context of the particular reasoning
isabove80”!Overall,wenoticedthatCORGI’sabilityto
task.Lastly,were-iteratethatasconversationalagents(such
successfullyreasonaboutanif-then-becausestatementwas
asSiriandAlexa)enterpeople’slives,leveragingconversa-
heavily dependent on whether the user knew how to give
tionalinteractionsforlearninghasbecomeamorerealistic
thesystemwhatitneeded,andnotnecessarilywhatitasked
opportunitythaneverbefore.
for;seeTable3foranexample.AsitcanbeseeninTable
In order to address scenario C:1, the conversational
2,expertusersareabletomoreeffectivelyprovideanswers
thatcompleteCORGI’sreasoningchain,likelybecausethey 4http://conceptnet.io/
knowthatregardlessofwhatCORGIasks,theobjectofthe 5https://mosaickg.apps.allenai.org/kg atomic
dialogistoconnectthebecausegoalbacktotheknowledge 6https://mosaickg.apps.allenai.org/comet conceptnet
baseinsomeseriesofif-thenrules(goal/sub-goalpathin 7https://mosaickg.apps.allenai.org/comet atomic
4908
promptsofCORGIaskforspecificsmallpiecesofknowl- Besold,T.R.;Garcez,A.d.;Bader,S.;Bowman,H.;Domin-
edgethatcanbeeasilyparsedintoapredicateandasetof gos,P.;Hitzler,P.;Ku¨hnberger,K.-U.;Lamb,L.C.;Lowd,
arguments.However,someusersinourstudytriedtoprovide D.; Lima, P. M. V.; et al. 2017. Neural-symbolic learning
additional details, which challenged CORGI’s natural lan- andreasoning:Asurveyandinterpretation. arXivpreprint
guageunderstanding.Forexample,forthereasoningtask“If arXiv:1711.03902.
Ireceiveanemailaboutwatershutoffthenremindmeabout
Bhagavatula,C.;Bras,R.L.;Malaviya,C.;Sakaguchi,K.;
itadaybeforebecauseIwanttomakesureIhaveaccessto
Holtzman,A.;Rashkin,H.;Downey,D.;Yih,S.W.-t.;and
waterwhenIneedit.”,inresponsetothesystem’sprompt
Choi,Y.2020. Abductivecommonsensereasoning. InInter-
“HowdoIknowif‘IhaveaccesstowaterwhenIneedit.’?”
nationalConferenceonLearningRepresentations(ICLR).
oneuserresponded“IfIamremindedaboutawatershutoff
Bosselut,A.;Rashkin,H.;Sap,M.;Malaviya,C.;Celikyil-
I can fill bottles”. This is a successful knowledge transfer.
maz,A.;andChoi,Y.2019. COMET:CommonsenseTrans-
However, the parser expected this to be broken down into
formersforAutomaticKnowledgeGraphConstruction.arXiv
twosteps.Ifthisuserrespondedtothepromptwith“IfIfill
preprintarXiv:1906.05317.
bottles” first, CORGI would have asked “How do I know
if ‘I fill bottles’?” and if the user then responded “if I am Christmann,P.;SahaRoy,R.;Abujabal,A.;Singh,J.;and
remindedaboutawatershutoff”CORGIwouldhavesuc- Weikum, G. 2019. Look before you Hop: Conversational
ceeded.Thesuccessfromsuchconversationalinteractions Question Answering over Knowledge Graphs Using Judi-
arenotreflectedintheoverallperformancemainlyduetothe ciousContextExpansion. InProceedingsofthe28thACM
limitationsofnaturallanguageunderstanding. International Conference on Information and Knowledge
Table2evaluatestheeffectivenessofconversationalinter- Management,729–738.
actionsforprovingcomparedtotheno-feedbackmodel.The
Cingillioglu,N.;andRusso,A.2018. DeepLogic:Towards
0%successratetherereflectstheincompletenessofK.The
End-to-EndDifferentiableLogicalReasoning.arXivpreprint
improvementintasksuccessratebetweentheno-feedback
arXiv:1805.07433.
caseandtheotherrowsindicatesthatwhenitispossiblefor
userstocontributeusefulcommon-senseknowledgetothe Clark, P.; Tafjord, O.; and Richardson, K. 2020. Trans-
system,performanceimproves.Theuserscontributedatotal formers as soft reasoners over language. arXiv preprint
numberof96rulestoourknowledgebase,31ofwhichwere
arXiv:2002.05867.
uniquerules.ScenarioC:2occurswhenthereisvariationin Cohen,W.W.2016. Tensorlog:Adifferentiabledeductive
theuser’snaturallanguagestatementandisaddressedwith database. arXivpreprintarXiv:1605.06523.
our neuro-symbolic theorem prover. Rows 2-3 in Table 2
Colmerauer, A. 1990. An introduction to Prolog III. In
evaluateourtheoremprover(softunification).Havingaccess
ComputationalLogic,37–79.Springer.
to the optimal rule for unification does still better, but the
tasksuccessrateisnot100%,mainlyduetothelimitations Davis,E.;andMarcus,G.2015. Commonsensereasoning
ofnaturallanguageunderstandingexplainedearlier. andcommonsenseknowledgeinartificialintelligence. Com-
municationsoftheACM58(9):92–103.
Conclusions Dong,H.;Mao,J.;Lin,T.;Wang,C.;Li,L.;andZhou,D.
2019. Neurallogicmachines. InInternationalConference
Inthispaper,weintroducedabenchmarktaskforcommon-
onLearningRepresentations(ICLR).
sensereasoningthataimsatuncoveringunspokenintentsthat
humanscaneasilyuncoverinagivenstatementbymaking Evans,R.;andGrefenstette,E.2018. Learningexplanatory
presumptionssupportedbytheircommonsense.Inorderto rulesfromnoisydata. JournalofArtificialIntelligenceRe-
solvethistask,weproposeCORGI(COmmon-senseReason- search61:1–64.
inGbyInstruction),aneuro-symbolictheoremproverthat
Finkbeiner, B.; Hahn, C.; Rabe, M. N.; and Schmitt, F.
performscommonsensereasoningbyinitiatingaconversa-
2020. TeachingTemporalLogicstoNeuralNetworks. arXiv
tion with a user. CORGI has access to a small knowledge
preprintarXiv:2003.04218.
baseofcommonsensefactsandcompletesitassheinteracts
withtheuser.Wefurtherconductauserstudythatindicates Garcez,A.d.;Besold,T.R.;DeRaedt,L.;Fo¨ldiak,P.;Hitzler,
thepossibilityofusingconversationalinteractionswithhu- P.;Icard,T.;Ku¨hnberger,K.-U.;Lamb,L.C.;Miikkulainen,
mansforevokingcommonsenseknowledgeandverifiesthe R.; and Silver, D. L. 2015. Neural-symbolic learning and
effectivenessofourproposedtheoremprover. reasoning:contributionsandchallenges.In2015AAAISpring
SymposiumSeries.
Acknowledgements Goldwasser,D.;andRoth,D.2014. Learningfromnatural
instructions. Machinelearning94(2):205–232.
ThisworkwassupportedinpartbyAFOSRunderresearch
contractFA9550201. Grice,H.P.1975. Logicandconversation. InSpeechacts,
41–58.Brill.
References
Guo, D.; Tang, D.; Duan, N.; Zhou, M.; and Yin, J. 2018.
Azaria, A.; Krishnamurthy, J.; and Mitchell, T. M. 2016. Dialog-to-action:Conversationalquestionansweringovera
Instructable intelligent personal agent. In Thirtieth AAAI large-scaleknowledgebase. InAdvancesinNeuralInforma-
ConferenceonArtificialIntelligence. tionProcessingSystems,2942–2951.
4909
Havasi, C.; Speer, R.; and Alonso, J. 2007. ConceptNet scenes,words,andsentencesfromnaturalsupervision. InIn-
3: a flexible, multilingual semantic network for common ternationalConferenceonLearingRepresentations(ICLR).
senseknowledge. InRecentadvancesinnaturallanguage
Marra, G.; Giannini, F.; Diligenti, M.; and Gori, M. 2019.
processing,27–29.Citeseer.
IntegratingLearningandReasoningwithDeepLogicModels.
Havasi, C.; Speer, R.; Pustejovsky, J.; and Lieberman, H. arXivpreprintarXiv:1901.04195.
2009. Digitalintuition:Applyingcommonsenseusingdi- Maslan,N.;Roemmele,M.;andGordon,A.S.2015. One
mensionalityreduction. IEEEIntelligentsystems24(4):24– hundred challenge problems for logical formalizations of
35. commonsensepsychology. InAAAISpringSymposiumSe-
Hixon,B.;Clark,P.;andHajishirzi,H.2015.Learningknowl- ries.
edgegraphsforquestionansweringthroughconversational Mostafazadeh,N.;Roth,M.;Louis,A.;Chambers,N.;and
dialog. InProceedingsofthe2015ConferenceoftheNorth Allen,J.2017. Lsdsem2017sharedtask:Thestorycloze
AmericanChapteroftheAssociationforComputationalLin- test. InProceedingsofthe2ndWorkshoponLinkingModels
guistics:HumanLanguageTechnologies,851–861. ofLexical,SententialandDiscourse-levelSemantics,46–51.
Jan´ıcˇek,M.2010.Abductivereasoningforcontinualdialogue Mueller, E. T. 2014. Commonsense reasoning: an event
understanding. InNewDirectionsinLogic,Languageand calculusbasedapproach. MorganKaufmann.
Computation,16–31.Springer. Paszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.;
Kocijan,V.;Lukasiewicz,T.;Davis,E.;Marcus,G.;andMor- DeVito,Z.;Lin,Z.;Desmaison,A.;Antiga,L.;andLerer,A.
genstern,L.2020. AReviewofWinogradSchemaChallenge 2017. AutomaticdifferentiationinPyTorch. InNIPS2017
DatasetsandApproaches. arXivpreprintarXiv:2004.13831. WorkshoponAutodiff.
Pennington,J.;Socher,R.;andManning,C.2014. Glove:
Labutov, I.; Srivastava, S.; and Mitchell, T. 2018. LIA: A
Globalvectorsforwordrepresentation. InProceedingsofthe
naturallanguageprogrammablepersonalassistant. InPro-
2014conferenceonempiricalmethodsinnaturallanguage
ceedingsofthe2018ConferenceonEmpiricalMethodsin
processing(EMNLP),1532–1543.
NaturalLanguageProcessing:SystemDemonstrations,145–
150. Qin,L.;Bosselut,A.;Holtzman,A.;Bhagavatula,C.;Clark,
E.;andChoi,Y.2019. CounterfactualStoryReasoningand
Lenat,D.B.;Guha,R.V.;Pittman,K.;Pratt,D.;andShep-
Generation. InProceedingsofthe2019ConferenceonEm-
herd,M.1990. Cyc:towardprogramswithcommonsense.
piricalMethodsinNaturalLanguageProcessingandthe9th
CommunicationsoftheACM33(8):30–49.
International Joint Conference on Natural Language Pro-
Levesque, H.; Davis, E.; and Morgenstern, L. 2012. The cessing(EMNLP-IJCNLP),5046–5056.
winograd schema challenge. In Thirteenth International
Rashkin,H.;Sap,M.;Allaway,E.;Smith,N.A.;andChoi,
ConferenceonthePrinciplesofKnowledgeRepresentation
Y. 2018. Event2mind: Commonsense inference on events,
andReasoning.
intents,andreactions. arXivpreprintarXiv:1805.06939.
Li,T.J.-J.;Azaria,A.;andMyers,B.A.2017. SUGILITE:
Reed, S.; and De Freitas, N. 2015. Neural programmer-
creatingmultimodalsmartphoneautomationbydemonstra-
interpreters. arXivpreprintarXiv:1511.06279.
tion. InProceedingsofthe2017CHIConferenceonHuman
Rockta¨schel,T.;Bosˇnjak,M.;Singh,S.;andRiedel,S.2014.
FactorsinComputingSystems,6038–6049.ACM.
Low-dimensionalembeddingsoflogic. InProceedingsof
Li,T.J.-J.;Labutov,I.;Li,X.N.;Zhang,X.;Shi,W.;Ding, theACL2014WorkshoponSemanticParsing,45–49.
W.; Mitchell, T. M.; and Myers, B. A. 2018. APPINITE:
Rockta¨schel,T.;andRiedel,S.2017. End-to-enddifferen-
AMulti-ModalInterfaceforSpecifyingDataDescriptions
tiableproving.InAdvancesinNeuralInformationProcessing
inProgrammingbyDemonstrationUsingNaturalLanguage
Systems,3788–3800.
Instructions. In2018IEEESymposiumonVisualLanguages
andHuman-CentricComputing(VL/HCC),105–114.IEEE. Roemmele,M.;Bejan,C.A.;andGordon,A.S.2011.Choice
of plausible alternatives: An evaluation of commonsense
Li,T.J.-J.;Li,Y.;Chen,F.;andMyers,B.A.2017. Program-
causalreasoning. In2011AAAISpringSymposiumSeries.
mingIoTdevicesbydemonstrationusingmobileapps. In
Sakaguchi, K.; Le Bras, R.; Bhagavatula, C.; and Choi, Y.
InternationalSymposiumonEndUserDevelopment,3–17.
2020. Winogrande:Anadversarialwinogradschemachal-
Springer.
lengeatscale. InProceedingsoftheAAAIConferenceon
Liu,H.;andSingh,P.2004. ConceptNet—apracticalcom- ArtificialIntelligence,volume34,8732–8740.
monsensereasoningtool-kit. BTtechnologyjournal22(4):
Sakama,C.;andInoue,K.2016. Abduction,conversational
211–226.
implicatureandmisleadinginhumandialogues. LogicJour-
Manhaeve,R.;Dumancic,S.;Kimmig,A.;Demeester,T.;and naloftheIGPL24(4):526–541.
DeRaedt,L.2018. Deepproblog:Neuralprobabilisticlogic
Sap,M.;LeBras,R.;Allaway,E.;Bhagavatula,C.;Lourie,
programming.InAdvancesinNeuralInformationProcessing
N.;Rashkin,H.;Roof,B.;Smith,N.A.;andChoi,Y.2019.
Systems,3749–3759.
Atomic:Anatlasofmachinecommonsenseforif-thenrea-
Mao, J.; Gan, C.; Kohli, P.; Tenenbaum, J. B.; and Wu, J. soning. InProceedingsoftheAAAIConferenceonArtificial
2019. The neuro-symbolic concept learner: Interpreting Intelligence,volume33,3027–3035.
4910
Sbisa`, M. 1999. Presupposition, implicature and context
in text understanding. In International and Interdisci-
plinary Conference on Modeling and Using Context, 324–
338.Springer.
Simons,M.2013.Ontheconversationalbasisofsomepresup-
positions. InPerspectivesonlinguisticpragmatics,329–348.
Springer.
Speer, R.; Chin, J.; and Havasi, C. 2017. Conceptnet 5.5:
Anopenmultilingualgraphofgeneralknowledge. InPro-
ceedingsoftheAAAIConferenceonArtificialIntelligence,
volume31.
Speer, R.; Havasi, C.; and Lieberman, H. 2008. Analo-
gySpace:ReducingtheDimensionalityofCommonSense
Knowledge. InAAAI,volume8,548–553.
Srivastava, S. 2018. Teaching Machines to Classify from
NaturalLanguageInteractions. Ph.D.thesis,SamsungElec-
tronics.
Tur,G.;andDeMori,R.2011. Spokenlanguageunderstand-
ing:Systemsforextractingsemanticinformationfromspeech.
JohnWiley&Sons.
Wang,W.Y.;andCohen,W.W.2016. LearningFirst-Order
LogicEmbeddingsviaMatrixFactorization. InIJCAI,2132–
2138.
Weber, L.; Minervini, P.; Mu¨nchmeyer, J.; Leser, U.; and
Rockta¨schel,T.2019. NLprolog:ReasoningwithWeakUni-
fication for Question Answering in Natural Language. In
Proceedingsofthe57thAnnualMeetingoftheAssociation
for Computational Linguistics, ACL 2019, Florence, Italy,
Volume1:LongPapers,volume57.ACL(Associationfor
ComputationalLinguistics).
Winograd,T.1972. Understandingnaturallanguage. Cogni-
tivepsychology3(1):1–191.
Wu,B.;Russo,A.;Law,M.;andInoue,K.2018. Learning
CommonsenseKnowledgeThroughInteractiveDialogue. In
TechnicalCommunicationsofthe34thInternationalConfer-
enceonLogicProgramming(ICLP2018).SchlossDagstuhl-
Leibniz-ZentrumfuerInformatik.
Zhou, Z.-H. 2019. Abductive learning: towards bridging
machinelearningandlogicalreasoning. ScienceChinaInfor-
mationSciences62(7):76101.
4911
