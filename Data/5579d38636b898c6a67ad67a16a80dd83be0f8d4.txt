Towards Multilingual Automatic Open-Domain Dialogue Evaluation
JohnMendonça1,2,∗,AlonLavie3,4 and IsabelTrancoso1,2
1 INESC-ID,Lisbon
2 InstitutoSuperiorTécnico,UniversityofLisbon
3 CarnegieMellonUniversity,Pittsburgh
4 Phrase,Pittsburgh
{john.mendonca, isabel.trancoso}@inesc-id.pt
alavie@cs.cmu.edu
Abstract
EN
LANG
T r uo ah b te iu osm nta m min u ell tti rim il cini st gi in u sg a tl hfa o ec p lt e ao n cr - ki dn o ot m fh mae i ud n le d tv ii le a il nlo o gp g um u aee ln e dt v aao talf - (( 𝑐𝑐 &! ,, 𝑟𝑟 &! )) (𝑐",𝑟")(𝑐# (, 𝑐𝑟# %) ,𝑟%(𝑐 )$,𝑟$) (( 𝑐𝑐 &! ,, 𝑟𝑟 &! )) (𝑐",𝑟")(𝑐# (, 𝑐𝑟# %) ,𝑟%(𝑐 )$,𝑟$)
and the limited availability of open-sourced
multilingual dialogue systems. In this work,
weproposeaworkaroundforthislackofdata MT Quality Estimation
byleveragingastrongmultilingualpretrained
encoder-basedLanguageModelandaugment-
ing existing English dialogue data using Ma-
LANG
chine Translation. We empirically show that
thenaiveapproachoffinetuningapretrained Dialogue Submetric top 𝑘 1 2. . 𝑐 𝑐# ’,, 𝑟𝑟 ’#
multilingualencodermodelwithtranslateddata ...
isinsufficienttooutperformthestrongbaseline
𝑁. 𝑐%,𝑟%
of finetuning a multilingual model with only
Figure 1: Proposed architecture. The original dia-
sourcedata. Instead,thebestapproachconsists
loguedatasetistransformedintocontext-responsepairs
inthecarefulcurationoftranslateddatausing
(c ,r ) and translated using MT. The final dialogue
MTQualityEstimationmetrics,excludinglow n n
submetricistrainedusingacombinationoftheoriginal
qualitytranslationsthathinderitsperformance.
Englishdataandthetopk sentencesor(c ,r )from n n
1 Introduction eachlanguage,dependingonthesubmetric.
Open-domain dialogue systems have gained sub-
stantial attention in the NLP (Natural Language selectfewlanguages. Word-overlapbasedmetrics
Processing) and ML (Machine Learning) fields, from NLG (Natural Language Generation) such
thankstotheirincreasinglyhuman-likebehaviour as BLEU (Papineni et al., 2002) and METEOR
(Thoppilanetal.,2022;Shusteretal.,2022). Their (Banerjee and Lavie, 2005) are agnostic to lan-
impressivegenerationcapabilitiescanbeattributed guage,onlyrequiringareferenceresponse. How-
tonewmilestonesinmodeldevelopmentandscal- ever, these metrics are known to correlate poorly
ing(Adiwardanaetal.,2020),andtheamountof withhumanjudgmentsduetothemultifacetedna-
data used during training. Despite this research tureofdialogue(Liuetal.,2016). Reference-free
anddevelopmenteffort,advertisedgenerationca- metricssuchasUSR(MehriandEskenazi,2020)
pabilitieswereonlyattainableinaselectfewlan- and USL-H (Phy et al., 2020), however, require
guages (typically English or Chinese) due to low dialoguedatafortraining. Consideringmostopen-
resourcesindialogueforotherlanguages(Zhang source dialogue data is in English, these models
etal.,2022b). Morerecently,however,theadvent areexpectedtounderperformsignificantlyinother
ofLLMs(LargeLanguageModels)finetunedwith languages. Additionally, most open sourced dia-
Reinforcement Learning from Human Feedback loguesystemsarealsolimitedtoEnglish,further
suchasChatGPT(Ouyangetal.,2022)hasopened disincentivisingmultilingualresearch.
thepathforhigh-qualityandeasilyaccessiblemul- Onesolutiontotheissuespreviouslymentioned
tilingualdialoguegeneration. istoleverageMT(MachineTranslation). WithMT
Similarly,automatedopen-domaindialogueeval- servicesbecomingmoreaffordableandconsistent,
uationhasalsobeenlargelylimitedtoevaluatinga someauthorsresorttotranslationwhendeveloping
∗WorkconductedasavisitingscholaratCMU. theirmultilingualdialoguesystems(Schusteretal.,
3202
guA
13
]LC.sc[
1v59761.8032:viXra
2019; Anastasiou et al., 2022). This can either ing with subsets consisting of only the best
be included as a module in the system’s pipeline translations. Wefoundthat,dependingonthe
– allowing the use of proven English generation subquality and target language, the optimal
models for other languages; or as a cross-lingual amountoftranslateddatacanbeaslowas5%
transfermethod–bytranslatingtrainingdata. andashighas75%.
Inthispaper,weextendtheapproachoftraining
• We translate and release DailyDialog and a
usingdatageneratedbyMTforthedevelopmentof
corresponding test set of human quality an-
multilingualmodelsforevaluationofopen-domain
notations in 6 languages to facilitate future
dialogueresponses. Weexperimentwithandevalu-
benchmarkingofmultilingualdialogueevalu-
ateseveraldifferentpossibleworkaroundsforthis
ationmetrics1.
problem. Namely,weleveragetheavailabilityof
strongpretrainedmultilingualencodersasafoun-
2 Background
dation for training multilingual dialogue evalua-
tionmodels. Asafirststep, wetranslateexisting 2.1 Open-DomainDialogueEvaluation
publicly-available English dialogue data into the Metrics
targetlanguages. Wethenexploremultiplealterna-
The recent trend in open-domain dialogue evalu-
tivewaystoleveragethistranslateddatainorderto
ation is to train dialogue submetrics using well-
finetuneandtrainmonolingualandmultilingualdi-
definedself-supervisedtaskswhichcorrelatewell
alogueevaluationmodelsfortwospecificdialogue
with their corresponding subqualities. The most
submetrics. To address the impact of low quality
usedself-supervisedtaskisNextSentencePredic-
translations,weproposeusinganMTQualityEs-
tion (NSP), as it is known to correlate well with
timation (QE) model to rank the translations and
subqualitiesthatevaluate"ContextAwareness". Ex-
investigate the impact of finetuning models with
amples of this include: Uses Context (Mehri and
varyingamountsofquality-rankeddata. Figure1
Eskenazi, 2020), Sensibleness (Phy et al., 2020;
illustratestheproposedapproach.
Mendoncaetal.,2022)andRelevance(Zhaoetal.,
Theperformanceofthesealternativemodelsis
2020;Zhangetal.,2022a). Othersubqualitiesin-
evaluatedonacuratedtestsetofdialogueswhich
clude: Fluency,GrammaticallyCorrectorUnder-
werehuman-annotatedwithdialoguequalityscores
standability, which use word-level noising tech-
for two subqualities. The original English test
niques to generate negative samples (Phy et al.,
setwastranslatedusingMTandthenpost-edited
2020;Mendoncaetal.,2022;Zhangetal.,2022a);
by editors into six different target languages (PT-
and Specificity, which uses an MLM (Masked
Portuguese,DE-German,FR-French,ZH-Chinese,
LanguageModelling)score(MehriandEskenazi,
ES-SpanishandJA-Japanese). Thequalityscores
2020; Phy et al., 2020; Zhang et al., 2022a). For
from the human annotations of the original En-
overallquality,thesesubmetricsaretypicallycom-
glishdialogueswerethencarriedovertothetarget-
binedusingdifferentmethods(e.g. empiricalob-
languagedialogues. Ourfinetunedmultilingualdia-
servation,trainedLinearRegressionormultilayer
logueevaluationmodelsexhibitstrongcorrelations
perceptrons).
withhumanjudgements,comparabletoLLMs,in-
Tothebestofourknowledge,therehasnotbeen
dicating it is possible to leverage multilingual di-
any published research on cross-lingual transfer
alogueevaluationmetricswithouttheconstraints
and/ordevelopmentoftrainedmultilingualmetrics
LLMscurrentlypossess(costs,latency,etc.). We
foropen-domaindialogueevaluation.
hopethiswillencourageotherresearcherstoupdate
existing metrics using our proposed multilingual 2.2 MultilingualTextClassification
finetuningapproach.
Despite the lack of research on multilingual dia-
In summary, the primary contributions of this
logue evaluation, extending text classification to
workareasfollow:
other languages is a well established subfield of
research in NLP. The main constraint for mul-
• Weevaluatecross-lingualtransferandtransla-
tilingual performance parity is the lack of task-
tionaugmentedtrainingapproachesusingMT
specific resources in the vast majority of written
forthetaskoftrainingmultilingualdialogue
languages. Giventhecreationoftheseresourcesis
evaluationmodels,showingthat,onaverage,
the best performance is achieved by finetun- 1github.com/johndmendonca/DialEvalML
bothtimeconsumingandexpensive,mostresearch • Understandability An understandable re-
effort has been geared towards general-purpose sponseisonethatcanbeunderstoodwithout
cross-lingual representations that are learned in context. Such responses may contain minor
anunsupervisedway,thereforeleveragingtheun- typosthatdonothinderthecomprehensionof
structured data available in the wild. Large mul- theresponse.
tilingualTransformer-basedmodels(e.gmBERT,
XLM-RoBERTa,andmT5)havebeensuccessfully • SensiblenessAsensibleresponseisonethat
usedinavarietyofclassificationtasks(Conneau takesintoaccountitsprecedingcontext.
et al., 2020; Pires et al., 2019; Xue et al., 2021).
Mostautomaticevaluationmetricsreformulate
Thestandardapproachforcross-lingualtransferis
the problem as regression. Performance is then
tofinetuneonexistingdomaindatainasourcelan-
evaluatedusingPearsonandSpearmancorrelations
guageandperforminferenceinatargetlanguage.
withhumanannotations.
However,thisapproachtypicallylagsbehindmod-
elsspecificallytrainedwithin-domain(bothtask
3.1 AutomaticDialogueEvaluationMetrics
andlanguage)data.
As a solution to this problem, Pfeiffer et al. The majority of competitive metrics for dia-
(2020)proposelearninglanguage-specificadapter logueevaluationincludemodelstrainedinaself-
modulesviaMLMonunlabelledtarget-language supervised way for Valid Sentence Prediction
datafollowedbytask-specificadaptermodulesby (VSP) and Next Sentence Prediction (NSP) (Yeh
optimising a target task on labelled data in the etal.,2021;Zhangetal.,2021). Assuch,thefocus
sourcelanguage. Taskandlanguageadaptersare ofthisworkwastoevaluatemultilingualdynamics
stacked,allowingcross-lingualtransfertothetar- forthesemodels,whichcanthenbeemployedon
get language by substituting the target-language existingmetrics.
adapteratinference.
VSP: Valid Sentence Prediction In this paper,
Bornea et al. (2021) propose an augmentation
wefollowedtheapproachusedbyPhyetal.(2020)
strategy where a corpus of multilingual silver-
andinitiallyproposedbySinhaetal.(2020). Are-
labelled QA pairs is generated by combining the
gressionmodelwastrainedtodifferentiatebetween
originalEnglishtrainingdatawithMT-generated
positive samples and synthetic negative samples.
data. A language adversarial training and arbi-
Positivesamplesareperturbedbyrandomlyapply-
trationframeworkbringtheembeddingscloserto
ing one of the following: (1) no perturbation, (2)
eachother,makingthemodellanguageinvariant.
punctuationremoval,(3)stop-wordremoval. Neg-
Tothebestofourknowledge,therehasnotbeen
ativesamplesaregeneratedbyrandomlyapplying
anyresearchontheutilizationofMTQualityEs-
oneofthefollowingrules: (1)wordreorder(shuf-
timation (QE) scoring as a means for identifying
flingtheorderingofthewords);(2)word-drop;and
anddemotingorexcludingpoorlytranslateddata
(3)word-repeat(randomlyrepeatingwords).
insuchcross-languagetrainingscenarios.
NSP:NextSentencePrediction Thetaskofpre-
3 ProblemFormulation dicting sensibleness can be considered a binary
(NSP)task,distinguishingapositiveexamplefrom
Thegoalofreference-freeturn-leveldialogueeval-
asemanticallynegativeone,givenacontext. Adis-
uationis,givenadialoguehistory(frequentlyde-
criminativeregressionmodelwastrainedusingthe
notedascontext)cofvaryingamountofturns,and
followingsamplingstrategy: positiveresponsesare
aresponser,tolearnascoringfunctionthatassigns
drawndirectlyfromthedialog;negativeresponses
ascoref(c,r) → s. Thisscoringfunctioniscom-
arerandomlyselectedandatokencoveragetestdis-
paredagainsthumanjudgements,whichannotate
cardssemanticallysimilarsentences. Allresponses
thesamecontext-responsepairs. Theseresponses
areprocessedusingthepositive-sampleheuristic
areevaluatedusingascalingmethod,forinstance,
usedbyVSP.
a binary (0,1) judgement or a [1,5] scale, where
the lowest value means lowest quality and high-
4 Cross-lingualTransferLearning
estvaluemaximumquality. Thenotionofquality
varieswildlydependingontheannotation. Inthis Thegoaloftheexperimentsdescribedinthissec-
work,weevaluatedialogueintwodimensions: tionwastoevaluatedifferentbasicapproachesof
cross-lingualtransferforthetaskofautomaticdia- For both the VSP and NSP models, we added a
logueevaluation. Forencodermodeltraining,we regressionheadontopoftheencodermodel.
leveragedMachineTranslation(MT)byfullytrans-
EN–Zero-shotinference Asabaselineforour
latinganEnglishsourcedialoguedatasetandthen
results, we conducted zero-shot inference on the
finetuning monolingual and multilingual models
targetlanguagesusingamodelfinetunedonlyon
usingthesetranslations.
theoriginalEnglishdata.
4.1 ExperimentalSetup LANG–Target-LanguageFinetuning Wefine-
tunedtheencoderwithtarget-languagetranslated
4.1.1 Dataset
dialoguedataonly. Thedownsideofthisapproach
AllexperimentsinthispaperwerebasedontheDai-
isthatauniquemodelneedstobetrainedforeach
lyDialog (Li et al., 2017) dataset, a high-quality
target language. However, this method can be
human-human open-domain dialogue dataset fo-
scaledtoeverylanguage,includingnewones,and
cusedonday-to-dayconversations. Afterprocess-
isoptimisedtoperformbestinthatlanguage.
ing,weobtainedtrain/devsplitsof58,515/25,078
and89,707/38,449perlanguagefortheVSPand ML–MultilingualFinetuning Insteadoffine-
NSPmodels,respectively. Fortrainingandevalua- tuninganewmodelforeachtargetlanguage,one
tion,thepost-processeddatasetwastranslatedinto canfinetuneasinglemultilingualmodelbycombin-
the target languages using MBART50 (Liu et al., ingallofthetranslateddata. Inthiscase,theresult-
2020). We opted for using MBART50 as it is a ingsingletrainedmodelisthenusedtoevaluatere-
relativelylightweightopensourcedmodelwitha sponsesinalllanguages. However,itsperformance
largelanguagecoverage. maysufferinlanguagesithasnotseenduringfine-
For the test set, we leveraged the annotations tuning,eveniftheyaresupportedbytheencoder
fromPhyetal.(2020). Thesehumanannotations model. Furthermore, unlike target-language fine-
evaluatefiveresponsesfromtworetrievalmethods, tuned,themultilingualmodelisoptimisedjointly
twogenerativemethods,andonehuman-generated forallincludedlanguages.
response for 50 contexts. These responses were
MAD-X Inthisapproach,wetrainedaVSPand
annotatedintermsofUnderstandabilityandSensi-
NSPtaskadapterusingtheoriginalEnglishdataby
bleness2. WetranslatedthissetusingUnbabel’s3
stackingthetaskadapterwithapretrainedEnglish
translationservice. Atotalof300sentenceswere
languageadapter(keptfrozenduringtraining). For
translated,correspondingtothe50sharedcontexts
zero-shotinference,theEnglishlanguageadapter
and 250 responses. The translations were then
was replaced by the target-language counterpart,
split into smaller tasks and were corrected by ed-
whilekeepingthetrainedtaskadapterinplace.
itors from a commercial provider. Editors were
specificallyaskedtoretainanysourcedisfluencies 4.1.3 LargeLanguageModel
or hallucinations stemming from low quality re- As an additional strong baseline, we leveraged
sponsegeneration(e.g. "I’mafraidyoucan’t. I’m gpt-3.5-turbo(colloquiallyknownasChatGPT)
afraidyoucan’t.";"Aucontraire,youneedtobea asanevaluatorofUnderstandabilityandSensible-
bahn."). Thisensuredtheoriginalhumanquality ness. The context (exclusively for Sensibleness)
annotations remained valid for the translation. A andresponsewasprovidedasinput,togetherwith
secondarysenioreditorreviewedtheeditedcontent theprompt"{Giventhecontext,}evaluatefrom1-
asawhole. 5 the response in terms of {dimension}. Provide
thescoreandnothingelse.". Thisprompt,paired
4.1.2 FinetunedEncoders
withatemperaturesettingof0.0attemptedtomin-
WeusedXLM-RoBERTa(Conneauetal.,2020)as imisesthevariabilityoftheoutput. Nevertheless,
theencodermodelfortheexperiments. Thismodel wereportastandarddeviationof(.003,.003)and
isthemultilingualversionofRoBERTa,pretrained (.001,.001)forUnderstandabilityandSensibleness
onCommonCrawldatacontaining100languages. correlations,respectively,across3runs.
2AnnotationsforSpecificityandOverallQualitywerealso 4.2 Results
conducted,butwereexcludedsincetheydonotmaptothe
Thecorrelationresultsforallsubqualitiesandthe
learnedmetricsunderstudy.
3unbabel.com overallqualityarepresentedinTable1.
EN PT DE FR ZH ES JA AVG
Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp.
Understandability
EN .376 .187 .366 .167 .328 .172 .351 .120 .318 .202 .342 .204 .204 .176 .327 .194
LANG - - .176 .164 .214 .138 .052 .034 .274 .156 .219 .144 .185 .132 .214 .146
ML .336 .117 .176 .167 .262 .150 .012 .015 .225 .138 .117 .158 .091 .092 .174 .126
MAD-X .363 .166 .189 .103 .237 .122 .168 .078 .305 .168 .217 .119 .119 .129 .228 .126
ChatGPT .397 .334 .365 .230 .332 .263 .369 .273 .276 .182 .394 .263 .228 .223 .337 .263
Sensibleness
EN .658 .676 .636 .651 .657 .655 .646 .656 .640 .656 .646 .657 .590 .599 .639 .649
LANG - - .649 .661 .669 .699 .635 .655 .634 .671 .629 .669 .617 .640 .642 .664
ML .651 .691 .606 .675 .634 .680 .605 .669 .642 .667 .596 .676 .599 .637 .619 .664
MAD-X .660 .681 .614 .604 .664 .652 .624 .624 .608 .647 .688 .661 .558 .595 .631 .638
ChatGPT .746 .724 .636 .626 .683 .675 .695 .666 .655 .645 .680 .677 .625 .610 .674 .662
Table 1: Average correlation results across 3 runs with different seeds. Pr. denotes Pearson and Sp. denotes
Spearman. Bolddenotesbestperformance,Italicp<0.05.
Understandability Theresultsshowthat,onav- EN:Yes,I’dliketoseethereceipt.
Oh!Iseeyouboughtthewatchlastweek.
erage, the best performing encoder approach is
PT:Sim,gostavadeveroreceio.
the zero-shot inference using the English model Oh!Vejo-teafazerorelógionasemanapassada.
(EN).Boththetarget-languagefinetuning(LANG) QEscore:-0.670
andmultilingualfinetuningapproaches(ML)have EN:Justlookaround?Ah,that’sboring.
ES:¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡
muchlowerperformances,indicatingthattransla-
QEscore:-1.481
tionaugmentationisdetrimentalforthistask. We
EN:Eighttens,sixonesandlargesilverforothers.
alsonotethattheMAD-Xapproach,althoughper- ZH:八个十个,六个十个,其他十个十个十个十个十...
forming slightly better than ML and LANG, still QEScore:-1.312
lagsbehindENconsiderably. Inanycase,ChatGPT
Table2: Examplesoflowqualitytranslationswithcor-
largelyoutperformsothermodelsonbothmetrics.
responding QE score. Red denotes MT error, with
underlineinthesourcesentenceindicatingtheclosest
Sensibleness The best performing encoder ap-
alignmentoftheerror. Bluedenoteskeywordsthatrefer
proach for this subquality is LANG. Intuitively topriorcontext.
thismakessense,giventhatduringfinetuningthe
model is exposed to target-language data for the
thequalityoftheresponsebydisruptingkeywords
language it is being evaluated on. Furthermore,
that point to the context (which is important for
theperformancedifferencebetweenthedifferent
Sensibleness), or even more subtle quality cues
approachesisrelativelymuchsmaller,whichindi-
(e.g. loss of empathy, inconsistency with named
catestheSensiblenesssubqualityislesssensitive
entities). However, the NSP model is trained to
toMTquality. Whencomparingtheseresultswith
discriminatebetweentheoriginalresponseandran-
ChatGPT,weobserveamuchsmallerperformance
domlyselectedresponsefromthecorpus. Assuch,
gap,withthebestencodermodelsslightlyoutper-
themodel’spredictionwillremaininvarianttomost
formingonSpearman.
translationerrors.
Theseobservations,pairedwiththefactencoder
5 MTQuality-awarefinetuning
models only slightly underperform ChatGPT (a
Theeffectsofnoiseintroducedtothetrainingdata much larger and expensive model), motivate the
is a subject of intense research in the literature work described in this section. We hypothesise
(Zhangetal.,2017;Huetal.,2020;Swayamdipta that,byamelioratingtheMTnoiseviaidentifying
etal.,2020). Itisexpectedthat,forthistask,noise andfilteringlowqualitytranslations,theencoder
isintroducedbylowqualitytranslations,reducing modelperformancecanoutperformLLMssuchas
theperformanceoftrainedmodels. Thisissuewas ChatGPT,atafractionofthecost.
identifiedinSection4, wherefortheVSPmodel Sincetherearenoavailablereferences,anMT
inparticular,themodelstrainedusingtranslations QE(Speciaetal.,2018)automaticmetricisused
performedmuchworsethanthebaselineapproach. forthispurpose. Formally,anMTQEmodelisa
Ourhypothesisisthatsometranslationsheavilydis- scoringfunctionthatassignsascoregivenasource
ruptmorphosyntacticcuesusedtoinferresponse sentenceandhypothesistranslation. Theunbound-
fluency, as shown in Table 2. We acknowledge ednessanduncalibratednatureofthisscoreacross
thattheselowqualitytranslationsmayalsoreduce languages results in the need for a cumbersome
Pearson Correlation for Understandability Spearman Correlation for Understandability
1.0 1.0
0.8 0.8
0.6 0.6
PT PT
0.4 DE 0.4 DE
FR FR
ZH ZH
0.2 ES 0.2 ES
JA JA
0.0 0.0
0.05 0.10 0.20 0.50 0.751.00 0.05 0.10 0.20 0.50 0.751.00
Amount of Translations Amount of Translations
(a)PearsonCorrelation,Understandability. (b)SpearmanCorrelation,Understandability.
Pearson Correlation for Sensibleness Spearman Correlation for Sensibleness
1.10 1.10
PT
1.05 DE 1.05
FR
ZH
1.00 1.00
ES
JA
0.95 0.95 PT
DE
0.90 0.90 FR
ZH
0.85 0.85 ES
JA
0.80 0.80
0.05 0.10 0.20 0.50 0.751.00 0.05 0.10 0.20 0.50 0.751.00
Amount of Translations Amount of Translations
(c)PearsonCorrelation,Sensibleness. (d)SpearmanCorrelation,Sensibleness.
Figure2: NormalisedPearsonandSpearmancorrelationfortheUnderstandabilityandSensiblenesssubmetricwith
varyingamountoftranslatedtrainingdata. NumericresultsavailableinAppendixB.
analysis for each individual language in order to 2020). FortheVSPmodel,werankedtheindivid-
determineathresholdforfiltering. Instead,wepro- ualsentences,andthenappliednegativesampling.
pose to use QE scores for response ranking, for For the NSP model, we ranked the positive and
eachtargetlanguage. Thisensuresastandardised negativesamplesseparatelyandthenmergedthem
method for filtering, improving the scalability of together. Figure3presentstheunnormalisedscore
thismethodtonewlanguages. boxplotperlanguageforallsentences(contextand
responses)forDailyDialog.
5.1 Experimentalsetup One of the things we noticed when finetuning
themonolingualmodelswasthattheVSPmodels
had large variations in performance. This can be
MT QE score distributions
attributedto(1)thelowamountoftrainingdata,es-
PT
peciallywhenusingveryfewexamples(5%,10%),
DE
and (2) low quality translations, which is the re-
FR
searchquestionthisexperimentattemptstoanswer.
ZH Sincethetrueimpactoflowqualitytranslationsis
ES obfuscatedbyotherfactors,wedecidedtofinetune
theLANGmodelsstartingfromtheENcheckpoint
JA
2.5 2.0 1.5 1.0 0.5 0.0 0.5 1.0 insteadofthepretrainedXLM-RoBERTa,andin-
MT QE
cludethezero-shotresultsas0%.
Figure3: MTQEunnormalisedscoreboxplotperlan-
5.2 Results
guage.
LANG Forthemonolingualmodels,weplotnor-
Inordertoconfirmourhypothesis,weretrained malisedcorrelationresultswiththeamountofMT
all models using different amounts of translated data used during finetuning in Figure 2. The Un-
data(100,75,50,20,10and5%). Therankingof derstandability correlation results show that the
thetranslationswasconductedbyscoringthemus- optimalamountoftranslateddataislanguagede-
ingtheWMT20COMET-QE-DAmodel(Reietal., pendent,butwithaclearindicationthattheinclu-
egaugnaL
noitalerroC
desilamroN
noitalerroC
desilamroN
noitalerroC
desilamroN
noitalerroC
desilamroN
EN PT DE FR ZH ES JA AVG
Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp.
Understandability
0(EN) .376 .187 .366 .167 .328 .172 .351 .120 .318 .202 .342 .204 .204 .176 .327 .194
5 .403 .182 .490 .219 .344 .172 .385 .091 .320 .235 .429 .236 .230 .179 .372 .211
10 .377 .180 .514 .227 .381 .193 .294 .091 .338 .214 .385 .212 .216 .175 .358 .206
20 .384 .177 .478 .236 .333 .203 .153 .087 .318 .219 .315 .214 .174 .168 .308 .202
50 .413 .201 .481 .242 .381 .213 .103 .053 .310 .200 .315 .221 .219 .149 .317 .200
75 .311 .145 .247 .211 .320 .195 .047 .048 .163 .149 .111 .198 .108 .127 .187 .158
100 .336 .117 .176 .167 .262 .150 .012 .015 .225 .138 .117 .158 .091 .092 .174 .126
ChatGPT .397 .334 .365 .230 .332 .263 .369 .273 .276 .182 .394 .263 .228 .223 .337 .263
Sensibleness
0(EN) .658 .676 .636 .651 .657 .655 .646 .656 .640 .656 .646 .657 .590 .599 .639 .649
5 .637 .674 .629 .632 .627 .648 .637 .656 .629 .646 .626 .647 .567 .596 .621 .640
10 .642 .675 .639 .664 .661 .669 .636 .661 .637 .656 .635 .668 .575 .604 .632 .654
20 .650 .689 .627 .670 .649 .681 .627 .666 .621 .661 .637 .673 .568 .614 .626 .660
50 .667 .691 .642 .687 .650 .672 .621 .662 .652 .664 .629 .673 .600 .642 .637 .666
75 .677 .712 .629 .694 .679 .702 .633 .679 .661 .673 .643 .695 .593 .635 .645 .679
100 .651 .691 .606 .675 .634 .680 .605 .669 .642 .667 .596 .676 .599 .637 .619 .664
ChatGPT .746 .724 .636 .626 .683 .675 .695 .666 .655 .645 .680 .677 .625 .610 .674 .662
Table3: Averagecorrelationresultsacross3runswithdifferentseedsformultilingualmodelswhenvaryingthe
amountoftranslateddata.
sion of more translations decreases performance 5.3 Effectoflow-qualitytranslationduring
significantly. Instead, a lower amount of transla- prediction
tions (5-10%) yields optimal performance. This
Onemightaskifalow-qualitytranslationcanin-
showsthatthissmallfinetuningstepisessentially
ducethesubmetricstooutputadifferentscore. In-
adapting a model that was already finetuned for
tuitively,wehypothesiseeachmodelwillattribute
thedownstreamtasktothetarget-languagedomain.
differentscoresinthefaceoflowqualitytransla-
ForSensibleness,weseethattheinclusionofmore
tions. Morespecifically,giventheresultspresented
translationsyieldsthebestresults. Assuch,wecan
inprevioussections,weexpectthetestprediction
concludethatlow-qualityMTdoesnotadversely
errortobe:
affectperformance. Wehypothesisethisisdueto
MTbeingabletocorrectlytranslatekeywordsthat
• Negatively correlated with the MT QE
indicatecontextawareness. Sinceweareonlycon-
scoresforVSP.Weknowthismodelishighly
cernedaboutrelevance, theoverallsentencemay
sensitivetolowqualitytranslations,sinceMT
stillcontainMTerrorsandbescoredhighly.
errorsfrequentlyaffectthefluencyofthere-
sponse(asidentifiedinprevioussections);
• WeaklycorrelatedfortheNSPmodel. The
ML Thecorrelationresultsforthemultilingual model showed robustness when including
modelsarepresentedinTable3. ForUnderstand- more translations during training, with per-
ability, we note that, on average, and similar to formancedecreasingonlywhenweincluded
LANG,thebestperformanceisattainedwiththe alltranslations(ML-100)duringtraining.
minimumamountoftranslateddata(ML-5),with
theperformancedecreasingwhenmoretranslations Inordertoevaluatetheseassumptions,thecor-
areadded. ComparingtheseresultswithChatGPT, relation plots of the MT QE z-scores (obtained
we observe an improvement in performance, but independentlyforeachlanguage)againstthesub-
ourencodermodelsarestillgenerallyweakerwhen metric absolute error using the best ML models
using Spearman as a metric. For Sensibleness, (ML-5 for VSP and ML-75 for NSP) for the test
decreasingtheamountofdatareducestheperfor- setarepresentedinFigure4.
manceofthemodel. However,wenoteadecrease For the Understandability subquality, we note
inperformancewhenincludingthefullamountof thatthereisaslightnegativecorrelationbetween
translateddata(ML-100). Thismaybeduetothe the absolute error and the MT QE score. This is
inclusionoftheworsttranslations–typicallyhallu- also confirmed by a calculated Pearson Correla-
cinations–whichiscompoundedbytrainingonall tion value of -0.245. For the Sensibleness sub-
languages. Unlike in Understandability, here we quality, the relationship between these two mea-
seethatChatGPTstilloutperformsthebestencoder sures is less obvious. For instance, we note that,
modelintermsofPearsoncorrelation. unlikeforUnderstandability,maximumdeviations
QE Score vs Understandability Absolute Error QE Score vs Sensibleness Absolute Error
100 100
10 1
10 1
Language 10 2 Language
10 2 pt pt
de 10 3 de
fr fr
zh zh
10 3 es 10 4 es
ja ja
1.5 1.0 0.5 0.0 0.5 1.5 1.0 0.5 0.0 0.5
MT QE MT QE
(a)Understandabilityscatterplot. (b)Sensiblenessscatterplot.
Figure4: ScatterplotcomparingthetestsetMBART50per-languageQEz-scores(x-axis)versusthepersample
AbsolutePredictionError(y-axisinlogscale)forUnderstandabilityandSensiblenesssubqualities.
arespreadevenlyacrosstheQEscale,whichpoints 6 Conclusions
tothemodelerroneouslypredictingSensibleness
irrespectiveofthetranslationquality. Conversely,
we also note a higher density of accurate predic-
tionswithlowerQEscores. Theseresults,paired
Thispaperexploredtheuseofcross-lingualknowl-
with the calculated Pearson Correlation value of
edgetransferforthenoveltaskofautomaticmul-
-0.129,confirmourhypothesisthattheNSPmodel
tilingual dialogue evaluation. We evaluated dif-
ismoreagnosticofMTqualitythanVSP.
ferentstrategiesforthistask,includingzero-shot
inference,MAD-XandMachineTranslationaug-
CTX:Tambémmeapercebidestaquestão.Ea mentation. Empiricallyweshowedthatthenaive
automatizaçãodosprocessosdoescritórioéessencial.
approach of leveraging MT for augmentation is
RES:Sim,fazertudomanualmentedemorademasiado.
EN-VSP:.394 EN-NSP:.824 insufficienttooutperformthebaselineofEnglish
ML-VSP:1.00 ML-NSP:1.00 finetuningwithamultilingualencoder-basedLM,
Unders.:1.00 Sensibl:0.00
let alone a strong LLM. Instead, by filtering out
CTX:Ja,ichleitedieJungsamKai.
lowqualitytranslations,wewereabletoreducethe
RES:Wow,dasklingtnacheinemfantastischenJob,de
dudabekommenhast. gap of performance on ChatGPT, outperforming
EN-VSP:.963 EN-NSP:.315
it on select correlation metrics. Experimental re-
ML-VSP:.941 ML-NSP:.981
Unders.:1.00 Sensibl:1.00 sultsshowedthatweobtainthebestperformance
whentrainingencodermodelswiththefollowing
Table4: Examplesofsubqualitypredictionsfromthe
proportionsofMT-QE:5%forUnderstandability
testset.
and75%forSensibleness.
Onecouldarguethenotionofqualityisintrin-
5.4 Exampletestpredictions sically related to cultural norms. For instance,
Japanesespeakersmaypreferapoliteconversation,
WepresentrepresentativeexamplesofourbestML whereasGermanspeakersmightpreferamoredi-
models’ prediction (ML 5/75) in Table 4. In the rect interaction. A future research direction is to
firstexample, thebaseline English modelfails to evaluate generative model responses in different
appropriatelyidentifytheunderstandabilityofthe languagesusingannotatorsexposedtotheculture
response. Inthesecondexample, weseethatthe associated with a given language. In addition to
multilingualmodelisabletocorrectlyidentifythat ensuringtheevaluationoftheresponsemeetsthe
theresponsetakesintoaccountthejobpresentedin criteriaof"quality"indifferentcultures,itwould
thecontext(manager)bycomplimentingit("fan- also allow for a qualitative analysis of the differ-
tasticjob"),whichtheENmodelfailedtoidentify. encesinthenotionofqualitybetweenlanguages.
rorrE
etulosbA
rorrE
etulosbA
Limitations References
DanielAdiwardana,Minh-ThangLuong,DavidRSo,
Perhaps the main limitation of this work is the
JamieHall,NoahFiedel,RomalThoppilan,ZiYang,
restricted amount of languages studied. Ideally, ApoorvKulshreshtha,GauravNemade,YifengLu,
wewouldhaveusedamorecomprehensiblesetof etal.2020. Towardsahuman-likeopen-domainchat-
languages,includinglow-resourceones,toevaluate bot. arXivpreprintarXiv:2001.09977.
theconsistencyoftheconclusionsdrawnfromthe
Dimitra Anastasiou, Anders Ruge, Radu Ion, Svet-
experiments. lana Sega˘rceanu, George Suciu, Olivier Pedretti,
PatrickGratz,andHooriehAfkari.2022. Amachine
Anotherlimitationisthefocusonasingleopen-
translation-powered chatbot for public administra-
domaindialoguedataset. Dialogueevaluationmet-
tion. InProceedingsofthe23rdAnnualConference
ricsareknowntocorrelatepoorlywhenevaluated oftheEuropeanAssociationforMachineTranslation,
on unseen datasets (Yeh et al., 2021). As such, pages329–330,Ghent,Belgium.EuropeanAssocia-
itisnotcertainthattheobservationspresentedin tionforMachineTranslation.
this work would hold for other datasets, or even
SatanjeevBanerjeeandAlonLavie.2005. METEOR:
differentannotations(Mehrietal.,2022). An automatic metric for MT evaluation with im-
Finally,thepretrainedencoder,MTandQEmod- provedcorrelationwithhumanjudgments. InPro-
ceedingsoftheACLWorkshoponIntrinsicandEx-
els used in this work are not fully representative
trinsic Evaluation Measures for Machine Transla-
ofallavailablemodels. Weacknowledgethatthe tionand/orSummarization,pages65–72,AnnArbor,
optimalamountoffilteringislikelytobedifferent, Michigan. Association for Computational Linguis-
dependingonthecombinationofmodelsused. tics.
MihaelaBornea,LinPan,SaraRosenthal,RaduFlorian,
EthicsStatement andAvirupSil.2021. Multilingualtransferlearning
for qa using translation as data augmentation. In
Thisworkleveragesdialoguesandannotationsde- Proceedings of the AAAI Conference on Artificial
Intelligence,volume35,pages12583–12591.
velopedexclusivelybyEnglish-speakers. Thisin-
troducesanEnglish-centricbiaswithrespecttothe AlexisConneau,KartikayKhandelwal,NamanGoyal,
notion of quality (and subqualities) in dialogues. Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzmán, Edouard Grave, Myle Ott, Luke Zettle-
Althoughnotevaluatedindepthinthiswork,there
moyer,andVeselinStoyanov.2020. Unsupervised
couldbeachancethatthemodelserroneouslyyield
cross-lingualrepresentationlearningatscale. InPro-
lower scores to responses not conforming to En- ceedings of the 58th Annual Meeting of the Asso-
glishnotionsofqualityresponses. ciationforComputationalLinguistics,pages8440–
8451, Online. Association for Computational Lin-
Theoriginaldialoguedatasetandgeneratedre-
guistics.
sponses were checked for personally identifiable
information or offensive content by the original WeiHu,ZhiyuanLi,andDingliYu.2020. Simpleand
effectiveregularizationmethodsfortrainingonnois-
authors. Although highly unlikely, we acknowl-
ily labeled data with generalization guarantee. In
edgethetranslationsmaycontainoffensivecontent
8thInternationalConferenceonLearningRepresen-
resultingfromdecoding. tations, ICLR 2020, Addis Ababa, Ethiopia, April
Thepost-editingconductedinthisworkuseda 26-30,2020.OpenReview.net.
crowdsourcingplatformthatawardedusersafair
Diederik P. Kingma and Jimmy Ba. 2015. Adam: A
wageaccordingtotheirlocation. method for stochastic optimization. In 3rd Inter-
national Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Acknowledgements
ConferenceTrackProceedings.
This research was supported by the Portuguese Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang
Recovery and Resilience Plan through project Cao,andShuziNiu.2017. DailyDialog: Amanually
labelledmulti-turndialoguedataset. InProceedings
C645008882-00000055(Responsible.AI),andby
oftheEighthInternationalJointConferenceonNat-
national funds through Fundação para a Ciên-
uralLanguageProcessing(Volume1: LongPapers),
cia e a Tecnologia (FCT) with references pages986–995,Taipei,Taiwan.AsianFederationof
PRT/BD/152198/2021andUIDB/50021/2020,and NaturalLanguageProcessing.
bytheP2020programMAIA(LISBOA-01-0247-
Chia-WeiLiu,RyanLowe,IulianSerban,MikeNose-
FEDER-045909).
worthy, Laurent Charlin, and Joelle Pineau. 2016.
How NOT to evaluate your dialogue system: An
empiricalstudyofunsupervisedevaluationmetrics Linguistics,pages4164–4178,Barcelona,Spain(On-
fordialogueresponsegeneration. InProceedingsof line).InternationalCommitteeonComputationalLin-
the2016ConferenceonEmpiricalMethodsinNatu- guistics.
ralLanguageProcessing,pages2122–2132,Austin,
Texas.AssociationforComputationalLinguistics. Telmo Pires, Eva Schlinger, and Dan Garrette. 2019.
HowmultilingualismultilingualBERT? InProceed-
YinhanLiu,JiataoGu,NamanGoyal,XianLi,Sergey ingsofthe57thAnnualMeetingoftheAssociationfor
Edunov, Marjan Ghazvininejad, Mike Lewis, and Computational Linguistics, pages 4996–5001, Flo-
LukeZettlemoyer.2020. Multilingualdenoisingpre- rence,Italy.AssociationforComputationalLinguis-
training for neural machine translation. Transac- tics.
tionsoftheAssociationforComputationalLinguis-
tics,8:726–742. RicardoRei,CraigStewart,AnaCFarinha,andAlon
Lavie.2020. Unbabel’sparticipationintheWMT20
ShikibMehri,JinhoChoi,LuisFernandoD’Haro,Jan metricssharedtask. InProceedingsoftheFifthCon-
Deriu, Maxine Eskenazi, Milica Gasic, Kallirroi ferenceonMachineTranslation,pages911–920,On-
Georgila, Dilek Hakkani-Tur, Zekang Li, Verena line.AssociationforComputationalLinguistics.
Rieser,SamiraShaikh,DavidTraum,Yi-TingYeh,
Sebastian Schuster, Sonal Gupta, Rushin Shah, and
ZhouYu,YizheZhang,andChenZhang.2022. Re-
MikeLewis.2019. Cross-lingualtransferlearning
portfromthensffuturedirectionsworkshoponauto-
formultilingualtaskorienteddialog. InProceedings
maticevaluationofdialog: Researchdirectionsand
ofthe2019ConferenceoftheNorthAmericanChap-
challenges.
teroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies,Volume1(Longand
Shikib Mehri and Maxine Eskenazi. 2020. USR: An
ShortPapers),pages3795–3805,Minneapolis,Min-
unsupervised and reference free evaluation metric
nesota.AssociationforComputationalLinguistics.
for dialog generation. In Proceedings of the 58th
AnnualMeetingoftheAssociationforComputational
Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju,
Linguistics,pages681–707,Online.Associationfor
Eric Michael Smith, Stephen Roller, Megan Ung,
ComputationalLinguistics.
Moya Chen, Kushal Arora, Joshua Lane, Morteza
Behrooz,W.K.F.Ngan,SpencerPoff,NamanGoyal,
JohnMendonca,AlonLavie,andIsabelTrancoso.2022.
Arthur D. Szlam, Y-Lan Boureau, Melanie Kam-
QualityAdapt: anautomaticdialoguequalityestima-
badur, and Jason Weston. 2022. Blenderbot 3: a
tionframework. InProceedingsofthe23rdAnnual
deployedconversationalagentthatcontinuallylearns
MeetingoftheSpecialInterestGrouponDiscourse
toresponsiblyengage. ArXiv,abs/2208.03188.
andDialogue,pages83–90,Edinburgh,UK.Associ-
ationforComputationalLinguistics.
KoustuvSinha,PrasannaParthasarathi,JasmineWang,
RyanLowe,WilliamL.Hamilton,andJoellePineau.
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car-
2020. Learning an unreferenced metric for online
rollL.Wainwright,PamelaMishkin,ChongZhang,
dialogueevaluation. InProceedingsofthe58thAn-
SandhiniAgarwal,KatarinaSlama,AlexRay,John
nualMeetingoftheAssociationforComputational
Schulman,JacobHilton,FraserKelton,LukeMiller,
Linguistics,pages2430–2441,Online.Association
Maddie Simens, Amanda Askell, Peter Welinder,
forComputationalLinguistics.
Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
Traininglanguagemodelstofollowinstructionswith
LuciaSpecia,CarolinaScarton,andGustavoHenrique
humanfeedback.
Paetzold.2018. Qualityestimationformachinetrans-
lation. SynthesisLecturesonHumanLanguageTech-
KishorePapineni,SalimRoukos,ToddWard,andWei-
nologies,11(1):1–162.
JingZhu.2002. Bleu: Amethodforautomaticevalu-
ationofmachinetranslation. InProceedingsofthe SwabhaSwayamdipta,RoySchwartz,NicholasLourie,
40th Annual Meeting on Association for Computa- YizhongWang,HannanehHajishirzi,NoahA.Smith,
tional Linguistics, ACL ’02, page 311–318, USA. andYejinChoi.2020. Datasetcartography:Mapping
AssociationforComputationalLinguistics. anddiagnosingdatasetswithtrainingdynamics. In
Proceedings of the 2020 Conference on Empirical
Jonas Pfeiffer, Ivan Vulic´, Iryna Gurevych, and Se- MethodsinNaturalLanguageProcessing(EMNLP),
bastian Ruder. 2020. MAD-X: An Adapter-Based pages9275–9293,Online.AssociationforComputa-
FrameworkforMulti-TaskCross-LingualTransfer. tionalLinguistics.
InProceedingsofthe2020ConferenceonEmpirical
MethodsinNaturalLanguageProcessing(EMNLP), RomalThoppilan,DanielDeFreitas,JamieHall,Noam
pages7654–7673,Online.AssociationforComputa- Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,
tionalLinguistics. Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.
2022. Lamda: Languagemodelsfordialogapplica-
VitouPhy,YangZhao,andAkikoAizawa.2020. Decon- tions. arXivpreprintarXiv:2201.08239.
structtoreconstructaconfigurableevaluationmetric
foropen-domaindialoguesystems. InProceedingsof LintingXue,NoahConstant,AdamRoberts,MihirKale,
the28thInternationalConferenceonComputational RamiAl-Rfou,AdityaSiddhant,AdityaBarua,and
ColinRaffel.2021. mT5: Amassivelymultilingual andtrainedtheremainingusingtheAdapterHub’s
pre-trainedtext-to-texttransformer. InProceedings MLMrecipe5 onWikipediadata6. Thefullyfine-
ofthe2021ConferenceoftheNorthAmericanChap-
tunedmodelsusedalearningrateof3e-6andwere
teroftheAssociationforComputationalLinguistics:
trainedfor3epochsusingabatchsizeof16. Eval-
HumanLanguageTechnologies,pages483–498,On-
line.AssociationforComputationalLinguistics. uation was conducted every 1,000 steps for the
smallertrainingsetsand10,000stepsforthelarger
Yi-TingYeh,MaxineEskenazi,andShikibMehri.2021.
ones(75%and100%). Thebestperformingmodel
A comprehensive assessment of dialog evaluation
metrics. InTheFirstWorkshoponEvaluationsand ontheevaluationsetwasselectedfortesting.
AssessmentsofNeuralConversationSystems,pages For the dialogue data preprocessing we
15–33,Online.AssociationforComputationalLin- used spaCy 7 and the corresponding core lan-
guistics.
guage models. For the translations we used
Chen Zhang, João Sedoc, L. F. D’Haro, Rafael E. facebook/mbart-large-50-one-to-many-mmt
Banchs, and Alexander I. Rudnicky. 2021. Auto- from HuggingFace. Batch size was set to 16 and
matic evaluation and moderation of open-domain
decodingwasconductedusingbeamsearch,with
dialoguesystems. ArXiv,abs/2111.02110.
thenumberofbeamssetto4.
ChiyuanZhang,SamyBengio,MoritzHardt,Benjamin WeusedasingleQuadroRTX600024GBGPU
Recht,andOriolVinyals.2017. Understandingdeep forallexperiments.
learning requires rethinking generalization. In 5th
International Conference on Learning Representa-
B AdditionalResults
tions,ICLR2017,Toulon,France,April24-26,2017,
ConferenceTrackProceedings.OpenReview.net.
Table5presentsthemonolingualmodelresultsfor
the experiments of Section 5. Due to time and
PengfeiZhang, XiaohuiHu, KaidongYu, JianWang,
Song Han, Cao Liu, and Chunyang Yuan. 2022a. computationalconstraints,weonlyconductthese
MME-CRS:Multi-MetricEvaluationBasedonCor- experimentsusingasingleseed.
relationRe-ScalingforEvaluatingOpen-DomainDi-
alogue. arXivpreprintarXiv:2206.09403.
QingyuZhang,XiaoyuShen,ErnieChang,JidongGe,
andPengkeChen.2022b. Mdia: Abenchmarkfor
multilingualdialoguegenerationin46languages.
TianyuZhao,DiveshLala,andTatsuyaKawahara.2020.
Designingpreciseandrobustdialogueresponseeval-
uators. InProceedingsofthe58thAnnualMeetingof
theAssociationforComputationalLinguistics,pages
26–33,Online.AssociationforComputationalLin-
guistics.
A TrainingsetupandHyperparamters
WeusedtheXLM-RLargeencodermodeldown-
loadedfromHuggingFace4 forallexperiments. A
tokenrepresentingthespeakerwasaddedforeach
turn,andahistorylengthof3turnswasused. We
applied a regression head consisting of a 2-layer
MLPwithahiddensizeof1024andahyperbolic
tangent function as activation for prediction. All
parametersweretrained/finetunedusingAdamop-
timizer(KingmaandBa,2015).
Thetaskadaptersweretrainedusingtherecipe
fromMendoncaetal.(2022),usingalearningrate
of 1e-4 and training for 10 epochs, with a batch
sizeof32. Weusedtheexistinglanguageadapters
fromAdapterHubwheneverpossible(EN,ZH,JA) 5github.com/adapter-hub
6dumps.wikimedia.org
4huggingface.co/xlm-roberta-large 7spacy.io
EN PT DE FR ZH ES JA AVG
Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp. Pr. Sp.
Understandability
0 .347 .192 .381 .176 .353 .184 .349 .106 .406 .251 .372 .210 .268 .223 .354 .212
5 .534 .259 .469 .223 .347 .095 .318 .263 .459 .223 .236 .208 .387 .231
10 .563 .236 .489 .227 .199 .102 .300 .233 .300 .191 .303 .206 .357 .218
20 .499 .233 .356 .211 .153 .082 .323 .223 .257 .163 .251 .191 .312 .201
50 .433 .214 .418 .185 .117 .017 .250 .198 .233 .140 .225 .163 .289 .175
75 .186 .189 .306 .158 .089 .026 .319 .198 .243 .156 .226 .185 .245 .169
100 .240 .165 .347 .144 .082 .043 .248 .206 .191 .109 .216 .146 .239 .155
Sensibleness
0 .621 .654 .618 .627 .667 .668 .621 .644 .605 .647 .628 .628 .577 .592 .620 .635
5 .615 .636 .687 .657 .632 .628 .618 .629 .599 .631 .538 .553 .616 .626
10 .647 .646 .672 .655 .562 .596 .607 .626 .635 .637 .587 .606 .619 .630
20 .639 .644 .680 .679 .627 .640 .620 .633 .615 .634 .582 .595 .626 .638
50 .651 .680 .654 .671 .601 .631 .637 .665 .613 .639 .603 .609 .626 .647
75 .634 .670 .640 .681 .643 .664 .629 .673 .615 .639 .608 .635 .627 .656
100 .671 .693 .681 .698 .631 .666 .650 .688 .589 .659 .617 .633 .637 .666
Table5: Averagecorrelationresultsforthemonolingualmodelswhenvaryingtheamountoftranslateddata.
