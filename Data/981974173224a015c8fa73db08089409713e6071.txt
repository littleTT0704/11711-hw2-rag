Learning from Post-Editing:
Online Model Adaptation for Statistical Machine Translation
MichaelDenkowski ChrisDyer AlonLavie
LanguageTechnologiesInstitute
CarnegieMellonUniversity
Pittsburgh,PA15213 USA
{mdenkows,cdyer,alavie}@cs.cmu.edu
Abstract task is challenging in two regards. First, from a
technicalperspective, post-editedoutputsmustbe
Using machine translation output as a
processedrapidly: aproductivepost-editorcannot
starting point for human translation has
wait for a standard batch MT training pipeline to
become an increasingly common applica-
be rerun after each sentence is corrected! Sec-
tionofMT.Weproposeandevaluatethree
ond, from a methodological perspective, it is ex-
computationally efficient online methods
pensive to run many human subject experiments,
for updating statistical MT systems in a
in particular when the human subjects must have
scenario where post-edited MT output is
translation expertise. We therefore use a sim-
constantly being returned to the system:
ulated post-editing paradigm in which either
(1) adding new rules to the translation
non-post-editedreferencetranslationsormanually
model from the post-edited content, (2)
post-editedtranslationsfromasimilarMTsystem
updating a Bayesian language model of
are used in lieu of human post-editors (§2). This
the target language that is used by the
paradigmallowsustoefficientlydevelopandeval-
MT system, and (3) updating the MT
uatesystemsthatcangoontofunctioninreal-time
system’s discriminative parameters with
post-editingscenarioswithoutmodification.
a MIRA step. Individually, these tech-
We present and evaluate three online methods
niquescansubstantiallyimproveMTqual-
for improving translation models using feedback
ity, even over strong baselines. Moreover,
from editors: adding new translations rules to
weseesuper-additiveimprovementswhen
thetranslationgrammar(§3),updatingaBayesian
allthreetechniquesareusedintandem.
language model with observations of the post-
edited output (§4), and using an online discrimi-
1 Introduction
native parameter update to minimize model error
Using machine translation outputs as a starting (§5). These techniques are computationally effi-
point for human translators is becoming increas- cient and make minimal use of approximation or
inglycommonandisnowarguablyoneofthemost heuristics,handlinginitialandincrementaldatain
commerciallyimportantapplicationsofMT.Con- a uniform way. We evaluate these techniques in a
siderable evidence has accumulated showing that variety of language and data scenarios that mimic
human translators are more productive and accu- thedemandsofreal-worldtranslationtasks. Com-
ratewhenpost-editingMToutputthanwhentrans- paredtoacompetitivebaseline,weshowsubstan-
lating from scratch (Guerberof, 2009; Carl et al., tial improvement from updating the translation
2011; Koehn, 2012; Zhechev, 2012, inter alia). grammar or language model independently and
An important (if unsurprising) insight from prior super-additive gains from combining these tech-
research in this area is that translators become niqueswithaMIRAupdate(§6). Wethendiscuss
more productive as MT quality improves (Tat- how our techniques relate to prior work (§7) and
sumi, 2009). While general improvements to MT conclude(§8).
continue to lead to further productivity gains, we
explore how MT quality can be improved specifi- 2 SimulatedPost-EditingParadigm
cally in an online post-editing scenario in which
sentence-level MT outputs are constantly being In post-editing scenarios, humans continuously
presented to human experts, edited, and then re- edit machine translation outputs into production-
turnedtothesystemforimmediatelearning. This quality translations, providing an additional, con-
395
Proceedingsofthe14thConferenceoftheEuropeanChapteroftheAssociationforComputationalLinguistics,pages395–404,
Gothenburg,Sweden,April26-302014.(cid:13)c2014AssociationforComputationalLinguistics
stant stream of data absent in batch translation.
Incrementaltrainingdata
This data consists of highly domain-relevant ref-
erence translations that are minimally different Holacontestadora... Hellovoicemail,...
from MT outputs, making them ideal for learn- Hellamadoaservicio... I’vecalledfortech...
ing. However, true post-editing data is infeasi- Ignore´laadvertencia... Iignoredmyboss’...
ble to collect during system development and in- Ahoraanochece,... Nowit’sevening,and...
ternal testing as standard MT pipelines require Todav´ıasigoenespera... I’mstillonhold...
tens of thousands of sentences to be translated Nocreoquemehayas... Idon’tthinkyou...
with low latency. To address this problem, Hardt Yahepresionadocada... Ipunchedeverytouch...
and Elming (2010) formulate the task of sim-
Source Target(Reference)
ulated post-editing, wherein pre-generated refer-
ence translations are used as a stand-in for actual
post-editing. This approximation is equivalent to Figure 1: Context when translating an input sen-
the case where humans edit each translation hy- tence (bold) with simulated post-editing. Previ-
pothesistobeidenticaltothereferenceratherthan ous sentences and references (shaded) are added
simply correcting the MT output to be grammat- to the training data. After the current sentence is
ical and meaning-equivalent to the source. Our translated,itisalignedtothereference(italic)and
workusesthisapproximationfortuningandeval- addedtothecontextforthenextsentence.
uation. Wealsointroduceamoreaccurateapprox-
imation wherein MT output from the target sys- doesnotallowaddingnewdatawithoutrepeating
tem(orasimilarsystem)ispost-editedinadvance, model estimation in its entirety, which may take
creating “offline” post-edited data that is similar hoursordays. Inthissection,wedescribeasimple
to expected system outputs and should thus min- techniqueforincorporatingnewbilingualtraining
imize unnecessary edits. An experiment in §6.4 data as soon as it is available. Our approach is
comparesthetwoapproximations. anextensionoftheon-demandgrammarextractor
In our simulated post-editing tasks, decoding described by Lopez (2008a). We extend the work
(for both the test corpus and each pass over the initially designed for on-the-fly grammar extrac-
development corpus during optimization) begins tion from static data (to mitigate the expense of
with baseline models trained on standard bilin- storinglargetranslationgrammars),tospecifically
gual and monolingual data. After each sentence handleincrementaldatafrompost-editing.
is translated, the following take place in order:
First, MIRA uses the new source–reference pair 3.1 SuffixArrayGrammarExtraction
toupdateweightsforthecurrentmodels. Second, Lopez (2008a) introduces an alternative to tradi-
the source is aligned to the reference and used to tional model estimation for hierarchical phrase-
update the translation grammar. Third, the refer- based statistical machine translation (Chiang,
enceisaddedtotheBayesianlanguagemodel. As 2007). Rather than estimating a single grammar
sentencesaretranslated, themodelsgainvaluable fromalltrainingdata,thealignedbitextisindexed
context information, allowing them to zero in on using a source-side suffix array (Manber and My-
the target document and translator. Context is re- ers,1993). Whenaninputsentenceistobetrans-
setatthestartofeachdevelopmentortestcorpus.1 lated, a grammar extraction program samples in-
This setup, which allows a uniform approach to stances of aligned phrase pairs from the suffix ar-
tuninganddecoding,isvisualizedinFigure1. ray that match the source side of the sentence.
Using statistics from these samples rather than
3 TranslationGrammarAdaptation the entire bitext, a sentence-specific grammar is
rapidlygenerated. Inadditiontospeedgainsfrom
Translation models (either phrase tables or syn-
sampling,indexingthesourcesideofthebitextfa-
chronous grammars) are typically generated of-
cilitatesamorepowerfulfeatureset. Rulesinon-
fline from large bilingual text. This is reasonable
demandgrammarsaregeneratedusingasampleS
in scenarios where available training data is fixed
foreachsourcephrasef intheinputsentence. The
overlongperiodsoftime. However,thisapproach
sample,containingpairshf,ei,isusedtocalculate
thefollowingstatistics:
1Initial experiments show this to outperform resetting
modelsonmorefine-graineddocumentboundaries,although
furtherinvestigationiswarranted.
396
Feature Baseline Adaptive lookup table and phrase occurrences are counted
on the source side. When subsequent grammars
coherent C (f,e) C (f,e)+C (f,e)
S S L are extracted, the suffix array sample S for each
p(e|f) |S| |S|+|L|
f isaccompaniedbyanexhaustivelookupLfrom
samplesize |S| |S|+|L| thelookuptable. Matchingstatisticsarecalculated
fromL:
co-occur-
rencehf,ei
C S(f,e) C S(f,e)+C L(f,e) • C L(f,e): count of instances in L where f
alignstoe.
C (f) C (f)+C (f) =
singletonf S S L • C L(f): countofinstancesinLwheref aligns
= 1 1
toanytargetphrase.
singleton C (f,e) C (f,e)+C (f,e) • |L|: total number of instances of f in post-
S S L
hf,ei = 1 = 1 editingdata(nosizelimit).
WeusecombinedstatisticsfromS andLtocalcu-
post-edit sup-
porthf,ei
0 C L(f,e) > 0 latescoresforthe“Adaptive”featuresetdefinedin
Table 1. In addition to updating existing features,
we introduce a new indicator feature that identi-
Table1: Phrasefeaturedefinitionsforbaselineand
fies rules supported by post-editor feedback. Fur-
adaptivetranslationmodels.
ther, our approach allows us to extract rules that
encodetranslations(phrasemappingsandreorder-
ings)onlyobservedintheincrementalpost-editing
• C (f,e): count of instances in S where f
S
data. This process, which can be seen as influ-
alignstoe(phraseco-occurrencecount).
encing the distribution from which grammars are
• C (f): countofinstancesinSwheref aligns
S
sampled over time, produces comparable results
toanytargetphrase.
to the infeasible process of rebuilding the transla-
• |S|: total number of instances in S, equal to
tion model after every sentence is translated with
number of occurrences of f in training data,
theaddedbenefitofallowinganoptimizertolearn
cappedbythesamplesizelimit.
a weight for the post-edited data via the post-edit
These statistics are used to instantiate translation
support feature. The simple aggregation of statis-
rulesX→hf,eiandcalculatescoresforthephrase
tics allows our model to handle initial and incre-
featuresetshowninthe“Baseline”columnofTa-
mentaldatainaformallyconsistentway. Further,
ble 1. Notably, the coherent phrase translation
anyadditionalfeaturesthatcanbecalculatedona
probability that conditions on f occurring in the
suffix array sample can be matched by an incre-
data(|S|)ratherthanf beingextractedaspartofa
mentaldatalookup,makingourtranslationmodel
phrasepair(C (f))isshownbyLopez(2008b)to
S
a viable platform for further exploration in online
yield significant improvement over the traditional
learningforMT.
translationprobability.
4 LanguageModelAdaptation
3.2 OnlineGrammarExtraction
When a human translator post-edits MT output, a Adapting language models in an online manner
new bilingual sentence pair is created. However, based on the content they are generating has long
in typical settings, it can be weeks or months be- beenseenasapromisingtechniqueforimproving
fore these training instances are incorporated into automaticspeechrecognitionandmachinetransla-
bilingual data and models retrained. Our exten- tion (Kuhn and de Mori, 1990; Zhao et al., 2004;
sion to on-demand grammar extraction incorpo- Sanchis-Trilles,2012,interalia). Thepost-editing
rates these new training instances into the model scenarioweareconsideringsimplifiesthisprocess
immediately. In addition to a static suffix array somewhat since rather than only having a poste-
that indexes initial data, our system maintains a rior distribution over machine-generated outputs
dynamic lookup table. Each new sentence pair is (any of which may be ungrammatical), the out-
word-aligned with the model estimated from the puts, once edited by human translators, may be
initial data (a process often called forced align- presumedtobegrammatical.
ment). This makes a generally insignificant ap- We thus take a novel approach to language
proximationwithrespecttotheoriginalalignment model adaptation, building on recent work show-
model. Extractable phrase pairs are stored in the ing that state-of-the-art language models can be
397
inferred as the posterior predictive distribution Spanish–English WMT10 WMT11TED1 TED2
of a Bayesian language model with hierarchi- HPYPLM 25.5 24.8 29.4 26.6
cal Pitman-Yor process priors, conditioned on the +data 25.8 25.2 29.5 27.0
trainingcorpus(Teh,2006). TheBayesianformu- English–Spanish WMT10 WMT11TED1 TED2
lation provides a natural way to incorporate pro- HPYPLM 25.1 26.8 26.0 24.3
gressively more data: by updating the posterior +data 25.4 27.2 26.2 25.0
distribution given subsequent observations. Fur-
Arabic–English MT08 MT09 TED1 TED2
thermore, the nonparametric nature of the model
HPYPLM 19.3 24.7 9.5 10.0
means that the model is well suited to poten-
+data 19.6 24.9 9.8 10.5
tially unbounded growth of vocabulary. Unfortu-
nately, in general, Bayesian techniques are com- Table 2: BLEU scores for systems with trigram
putationally difficult to work with. However, hi- HPYPLM (no large language model), with and
erarchical Pitman-Yor process language models withoutincrementalupdatesfromsimulatedpost-
(HPYPLMs) are convenient in this regard since editingdata. Scoresareaveragesover3optimizer
(1) inference can be carried out efficiently in a runs. Bold scores indicate statistically significant
convenientcollapsedrepresentation(the“Chinese improvement. Tuningsetscoresareitalicized.
restaurantfranchise”)and(2)theposteriorpredic-
tive distribution from a single sample provides a
highqualitylanguagemodel.
learn a single corpus-level weight for each fea-
We thus use the following procedure. Using ture. This forces an averaging effect that can lead
the target side of the bitext as observations, we to decoding individual sentences with suboptimal
run the Gibbs sampling procedure described by weights. We address the first issue by using ref-
Teh (2006) for 100 iterations in a 3-gram HPY- erencetranslationstosimulatepost-editing(Hardt
PLM.Theinferred“seatingconfiguration”defines and Elming, 2010) at tuning time and the second
aposteriorpredictivedistributionoverwordsin2- by using a version of the margin-infused relaxed
gram contexts (as with any 3-gram LM) as well algorithm(Crammeretal.,2006;Eidelman,2012)
asaposteriordistributionoverhowthemodelwill to make online parameter updates during decod-
generatesubsequentobservations. Weusethefor- ing. The result is a consistent approach to tuning
mer as a language model component of a transla- anddecodingthatbringsoutthepotentialofadap-
tionmodel. And,aspost-editedsentencesbecome tivemodels.
available, we add their n-grams to the model us-
ing the later. We do not run any Gibbs sampling.
5.1 ParameterOptimization
Just updating the language model in this way, we
obtaintheresultsshowninTable2fortheexperi- In order to make our decoding process fully con-
mentalconditionsdescribedin§6. sistent with tuning, we introduce an online dis-
criminativeparameterupdatethatallowsouradap-
5 LearningFeatureWeights tive translation and language models be weighted
appropriately as more data is available. This re-
MT system parameter optimization (learning fea- quires an optimization algorithm that can func-
tureweightsforthedecoder)isalsotypicallycon- tion as an online learner during decoding as well
ducted as a batch process. Discriminative learn- as a batch optimizer during tuning. Popular opti-
ing techniques such as minimum error rate train- mizers such as MERT (Och, 2003) and pairwise
ing (Och, 2003) are used to find feature weights rank optimization (Hopkins and May, 2011) can-
that maximize automatic metric score on a small not be used due to their reliance on corpus-level
development corpus. The resulting weight vector optimization. We select the cutting-plane variant
is then used to decode given input sentences. Us- of the margin-infused relaxed algorithm (Chiang,
ing this approach with post-editing tasks presents 2012;Crammeretal.,2006)withadditionalexten-
two major issues. First, reference translation are sions described by Eidelman (2012). MIRA is an
only considered after all sentences are translated, online large-margin learner that makes a param-
amismatchwithpost-editingwherereferencesare eter update after each model prediction with the
available incrementally. Second, despite the fact objective of choosing the correct output over the
that adaptive feature sets become more powerful incorrectoutputbyamarginatleastaslargeasthe
as post-editing data increases, an optimizer must cost of predicting the incorrect output. Applied
398
toMTsystemoptimizationonadevelopmentcor- Spanish–English WMT10 WMT11TED1 TED2
pus, MIRA proceeds as follows. The MT system BaseMERT 29.1 27.9 32.8 29.6
generatesalistofthek besttranslationsforasin- BaseMIRA 29.2 28.0 32.7 29.7
gle input sentence. From the list, a “hope” hy- G 29.8 28.3 34.2 30.7
pothesisisselectedasatranslationwithbothhigh L 29.2 28.1 33.0 29.8
model score and high automatic metric score. A M 29.2 28.1 33.1 29.8
“fear” hypothesis is selected as a translation with G+L+M 30.0 28.8 35.2 31.3
highmodelscorebutlowmetricscore. Parameters English–Spanish WMT10 WMT11TED1 TED2
areupdatedawayfromthefearhypothesis,toward BaseMERT 27.8 29.4 26.5 25.7
thehopehypothesis,andthesystemprocessesthe BaseMIRA 27.7 29.6 26.8 26.7
next input sentence. This process continues for a
G 28.1 29.8 27.9 27.5
setnumberofpassesoverthedevelopmentcorpus.
L 27.9 29.7 26.8 26.5
All adaptive systems used in our work are opti-
M 27.9 29.7 27.2 26.6
mizedwiththisvariantofMIRAusingtheparam-
G+L+M 28.4 30.4 28.6 27.9
eter settings described by Eidelman (2012). For
Arabic–English MT08 MT09 TED1 TED2
each pass over the data, translation and language
BaseMERT 21.5 25.0 10.4 10.5
modelshaveincrementalaccesstoreferencetrans-
BaseMIRA 21.2 25.9 10.6 10.9
lations (simulated post-editing data) as input sen-
G 21.8 26.2 11.0 11.7
tences are translated. Translation and language
L 20.6 25.7 10.6 10.9
modelsresettousingbackgrounddataonlyatthe
M 21.3 25.7 10.8 11.0
beginningofeachMIRAiteration.2
G+L+M 21.8 26.5 11.4 11.8
5.2 OnlineParameterUpdates
Table 3: BLEU scores for baseline and adap-
Our optimization strategy allows us to treat de- tive systems. Scores are averages over three opti-
coding as if it were simply the next iteration of mizerruns. Highestscoresareboldandtuningset
MIRA(oralternativelythatMIRAmakesasingle scores are italicized. All fully adaptive systems
pass over an input corpus that consists of the de- (G+L+M) show statistically significant improve-
velopmentdataconcatenatedntimesfollowedby mentoverbothMERTandMIRAbaselines.
unseen input data). After each sentence is trans-
lated, a reference translation (resulting from ac-
tualhumanpost-editinginproductionorsimulated ulated post-editing experiments that cover high-
post-editing for our experiments) is provided to traffic languages and challenging domains. We
the models and MIRA makes a parameter update. showincrementalimprovementfromouradaptive
Intheonlydeparturefromouroptimizationsetup, models and significantly larger gains when pair-
wedecreasethemaximumstepsizeforMIRA(de- ing our models with an online parameter update.
scribed in §6.2), effectively increasing regulariza- We finally validate our adaptive system on actual
tion strength. This allows us to prefer small ad- post-editeddata.
justments to already optimized decoding parame-
6.1 Data
ters over the large changes needed during tuning.
It is also important to note that by using MIRA We conduct a series of simulated post-editing
for updating weights during both tuning and de- experiments in three full scale language sce-
coding, we avoid scaling issues between multiple narios: Spanish–English, English–Spanish, and
optimizers (such as when tuning with MERT and Arabic–English. Spanish–English and English–
updatingwithapassive-aggressivealgorithm). Spanish systems are trained on the 2012 NAACL
WMT (Callison-Burch et al., 2012) constrained
6 Experiments resources (2 million bilingual sentences, 300 mil-
lionwordsofmonolingualSpanish,and1.1billion
We evaluate our online extensions to standard
words of monolingual English). Arabic–English
machine translation systems in a series of sim-
systems are trained on the 2012 NIST OpenMT
2Resettingtranslationandlanguagemodelspreventscon- (Przybocki, 2012)constrainedbilingualresources
tamination. If models retained state from previous passes plus a selection from the English Gigaword cor-
overthedevelopmentset,theywouldincludedataforinput
pus (Parker et al., 2011) (5 million bilingual sen-
sentencesbeforetheyweretranslated,ratherthanafterasin
post-editing. tencesand650millionwordsofmonolingualEn-
399
glish). We tune and evaluate on standard news News TEDTalks
sets: WMT10 and WMT11 for Spanish–English New Supp New Supp
and English–Spanish, and MT08 and MT09 for Spanish–English 15% 19% 14% 18%
Arabic–English. Tosimulatereal-worldpostedit- English–Spanish 12% 16% 9% 13%
ingwhereonetranslatorworksonadocumentata Arabic–English 9% 12% 23% 28%
time, we use only one of the four available refer-
encetranslationsetsforMT08andMT09. Table 5: Percentages of new rules (only seen
We also evaluate on a blind domain adapta- in incremental data) and post-edit supported rules
tion scenario that mimics the demands placed (Rules from all data for which the “post-edit sup-
on MT systems in real-world translation tasks. porthf,ei”featurefires)ingrammarsbydomain.
TheWebInventoryofTranscribedandTranslated
Talks (WIT3) corpus (Cettolo et al., 2012) makes
followingsystemsinTable3:
transcriptions of TED talks3 available in several
• G:BaselineMIRAsystemwithonlinegram-
languages, including English, Spanish, and Ara-
mar extraction, including incrementally up-
bic. For each language pair, we select two sets of
dating existing phrase features plus an addi-
10 talk transcripts each (2000-3000 sentences) as
tionalindicatorfeatureforpost-editsupport.
blindevaluationsets. Thesesetsconsistofspoken
• L: Baseline MIRA with a trigram hierarchi-
language covering a broad range of topics. Sys-
cal Pitman-Yor process language model that
tems have no access to any training or develop-
is incrementally updated, including a sepa-
mentdatainthisdomainpriortotranslation.
rateout-of-vocabularyfeature.
6.2 TranslationSystems • M: Baseline MIRA with online feature
weightupdatesfromcutting-planeMIRA.
For each language scenario, we first construct a
Finally, we report results for a fully adaptive
competitive baseline system. Bilingual data is
system that includes online grammar, language
word aligned using the model described by Dyer
model, and feature weight updates. This system
et al. (2013) and suffix array-backed transla-
isreportedas“G+L+M”.Toaccountforoptimizer
tion grammars are extracted using the method
instability, all systems are tuned (consisting of
described by Lopez (2008a). We add the stan-
running either MERT or MIRA) and evaluated 3
dard lexical and derivation features4 from Lopez
times. We report average scores over optimizer
(2008b) and Dyer et al. (2010). An unpruned,
runs and conduct statistical significance tests us-
modified Kneser-Ney-smoothed 4-gram language
ingthemethodsdescribedbyClarketal. (2011).
model is estimated using the KenLM toolkit
(Heafield et al., 2013). Feature weights are op-
6.3 Results
timized using the lattice-based variant of MERT
(Macherey et al., 2008; Och, 2003) on either Our simulated translation post-editing experi-
WMT10 or MT08. Evaluation sets are translated ments are summarized in Table 3. Simply mov-
using the cdec decoder (Dyer et al., 2010) and ing from MERT to cutting-plane MIRA for pa-
evaluated with the BLEU metric (Papineni et al., rameter optimization yields improvement in most
2002). These results are listed as “Base MERT” cases, corroborating existing work (Eidelman,
in Table 3. To establish a baseline for our adap- 2012). Using incremental post-editing data to up-
tive systems, we tune the same baseline system date translation grammars (G) yields further im-
usingcutting-planeMIRAwith500-bestlists, the provementinallcasesevaluated. Gainsaresignif-
pseudo-documentapproximationdescribedbyEi- icantlylargerforTEDtalkswheretranslatorfeed-
delman (2012), and a maximum update size of backcanbridgethegapbetweendomains. Table5
0.01. We begin with uniform weights and make showstheaggregatepercentagesofrulesinonline
20 passes over the development corpus. Results grammars that are entirely new (extracted from
forthissystemarelistedas“BaseMIRA”. post-editinginstancesonly)orpost-editsupported
(superset of new rules). While percentages vary
To evaluate the impact of each online model
by data set, the overall trend is a combination of
adaptation technique, we report the resultsfor the
learning new vocabulary and reordering and dis-
3http://www.ted.com/talks ambiguatingexistingtranslationchoices.
4Derivation features consist of word count, discretized
The introduction of a trigram Bayesian lan-
rule-level non-terminal count (0, 1, or 2), glue rule count,
andout-of-vocabularypass-throughcount. guage model (L) yields mixed results: in some
400
BaseMERT andchangingthedefinitionofwhattheZonaCerois.
G+L+M andthechangingdefinitionofwhattheGroundZerois.
Reference andthechangingdefinitionofwhatGroundZerois.
BaseMERT wasthatwhenwesidebysidecomparisonswithcoal,timber
G+L+M wasthatwhenwedidside-by-sidecomparisonswithwoodcharcoal,
Reference waswhenwedidside-by-sidecomparisonswithwoodcharcoal,
BaseMERT Therewasaway–therewasone–
G+L+M Therewasaway–therehadtobeaway–
Reference Therewasaway–therehadtobeaway–
Table 4: Translation examples from baseline and fully adaptive systems of Spanish TED talks into En-
glish. Examplesillustrate(fromtoptobottom)learningtranslationsfornewvocabularyitems,selecting
correcttranslationcandidatesforthedomain,andlearningdomain-appropriatephrasing.
cases it leads to slight improvement and in oth- ture can discriminate between true OOV items
ers, degradation. It appears that a static but large and vocabulary items in the post-editing data not
4-gram language model often outperforms an in- present in the monolingual data. By contrast, the
crementally updated but smaller trigram model. onlyOOVsinthebaselinesystemareuntranslated
Further, learning a single weight for the Bayesian items,asthetargetsideofthebitextisincludedin
model can lead to a harmful mismatch. As a tun- the language model training data. This interplay
ing pass over the development corpus proceeds, between the adaptive components in our transla-
themodelincorporatesadditionaldataandMIRA tion system leads to significant gains over MERT
learns a weight corresponding to its predictive and MIRA baselines. Table 4 contains examples
ability at the end of the corpus. During decod- from our system’s output that exemplify key im-
ing,allsentencesaretranslatedwiththislanguage provements in translation quality. With respect to
model weight, even before the model can ade- performance, our fully adaptive system translates
quately adapt itself to the target domain. This an average of 1.5 sentences per second per CPU
problemisalleviatedinourfullyadaptivesystem. core. The additional cost incurred updating trans-
Usingcutting-planeMIRAtoincrementallyup- lationgrammarsandlanguagemodelsislessthan
date weights during decoding (M) also leads to onesecondpersentence(thoughthebaselinecost
mixed results, frequently resulting in both small of on-demand grammar extraction can be up to a
increases and decreases in score. This could be few seconds). In total, the system is well within
due to the noise incurred when making small ad- the acceptable speed range needed to function in
justments to static features after each sentence: real-timehumantranslationscenarios.
depending on the similarity between the previous
6.4 EvaluationUsingPost-EditedReferences
and current sentence and the limit of the step size
(regularization strength), a parameter update may The2012ACLWorkshoponMachineTranslation
slightlyimproveordegradetranslation. (Callison-Burchetal.,2012)makesavailableaset
Finally, we see significantly larger gains for of1832English–Spanishparallelnewssourcesen-
our fully adaptive system (G+L+M) that com- tences,independentreferences,initialMToutputs,
binesadaptivetranslationgrammarsandlanguage and post-edited MT outputs. The employed MT
models with online parameter updates. In many systemistrainedonlargelythesameresourcesas
cases, the difference between the baseline sys- ourownEnglish–Spanishsystem,grantingtheop-
tems and our adaptive system is greater than the portunity for a much closer approximation to an
sum of the differences from our individual tech- actualpost-editingtask;oursystemconfigurations
niques, demonstrating the effectiveness of com- score between 54 and 56 BLEU against the sam-
bining online learning methods. Our final sys- ple MT, indicating that humans post-edited trans-
tem has two key advantages over any individual lations similar but not identical to our own. We
extension. First, incremental updates from MIRA split the data into development and test sets, each
can rescale weights for features that change over 916 sentences, and run 3 iterations of optimizing
time, keeping the model consistent. Second, the on the development set and evaluating on the test
Bayesianlanguagemodel’sout-of-vocabularyfea- setwithboththeMERTbaselineandourG+L+M
401
system on both types of references. Using inde- et al. (2012) introduce a support vector machine-
pendent references for tuning and evaluation (as based algorithm capable of learning from binary-
before), our system yields an improvement of 0.6 labeledexamples. Thislearningalgorithmisused
BLEU(23.3to23.9). Withpost-editedreferences, toincrementallyadjustfeatureweightsgivenuser
our system yields an improvement of 1.3 BLEU feedback on whether a translation is “good” or
(43.0 to 44.3). This provides strong evidence that “bad”. Aswithourwork,thisstrategycanbeused
our adaptive systems would provide better trans- duringbothoptimizationanddecoding.
lations (both in terms of absolute quality and im- Finally, Simard and Foster (2013) apply a
provementoverastandardbaseline)forreal-world pipeline solution to the post-editing task wherein
post-editingscenarios. a second stage automatic post-editor (APE) sys-
temlearnstoreplicatethecorrectionsmadetoini-
7 RelatedWork tial MT output by human translators. As incre-
mentaldataaccumulates,theAPE(itselfastatisti-
Prior work has led to the extension of standard
calphrase-basedsystem)attemptsto“correct”the
phrase-based translation systems to make use of
MToutputbeforeitisshowntohumans.
incrementally available data.5 Approaches gen-
erally fall into categories of adding new data to 8 Conclusion
translation models and of using incremental data
to adjust model parameters (feature weights). In Casting machine translation for post-editing as
thefirstcase,Nepveuetal.(2004)usecache-based an online learning task, we have presented three
translation and language models to incorporate methodsforincrementalmodeladaptation: adding
data from the current document into a computer- data to the indexed bitext from which gram-
aided translation scenario. Ortiz-Mart´ınez et al. mars are extracted, updating a Bayesian language
(2010) augment a standard translation model by model with incremental data, and using an on-
storing sufficient statistics in addition to feature line discriminative parameter update during de-
scores for phrase pairs, allowing feature values to coding. These methods, which allow the sys-
be incrementally updated as new sentence pairs tem to handle all data in a uniform way, are ap-
areavailableforphraseextraction. HardtandElm- plied to a strong baseline system optimized using
ing (2010) demonstrate the benefit of maintain- MIRAinconjunctionwithsimulatedpost-editing.
ing a distinction between background and post- In addition to showing gains for individual meth-
editing data in an adaptive model with simulated odsundervariouscircumstances,wereportsuper-
post-editing. Though not targeted at post-editing additive improvement from combining our tech-
applications, the most similar work to our online niques to produce a fully adaptive system. Im-
grammar adaptation is the stream-based transla- provementsgeneralizeoverlanguageanddatasce-
tion model described by Levenberg et al. (2010). narios, with the greatest gains realized in blind
The authors introduce a dynamic suffix array that out-of-domain tasks where the system must rely
can incorporate new training text as it becomes heavily on post-editor feedback to improve qual-
available. Sanchis-Trilles(2012)proposesastrat- ity. Gainsarealsomoresignificantwhenusingof-
egyforonlinelanguagemodeladaptationwherein fline post-edited references, showing promise for
several smaller domain-specific models are built applyingourtechniquestoreal-worldpost-editing
and their scores interpolated for each sentence tasks. All software used for our online model
translatedbasedonthetargetdomain. adaptationexperimentsisfreelyavailableunderan
opensourcelicenseaspartofthecdectoolkit.6
Focusing on incrementally updating model pa-
rameters with post-editing data, Mart´ınez-Go´mez
Acknowledgements
et al. (2012) and Lo´pez-Salcedo et al. (2012)
show improvement under some conditions when ThisworkissupportedinpartbytheNationalSci-
using techniques including passive-aggressive al- ence Foundation under grant IIS-0915327, by the
gorithms, perceptron, and discriminativeridge re- Qatar National Research Fund (a member of the
gression to adapt feature weights for systems ini- Qatar Foundation) under grant NPRP 09-1140-1-
tiallytunedusingMERT.Thisworkalsousesref- 177, and by the NSF-sponsored XSEDE program
erencetranslationstosimulatepost-editing. Saluja undergrantTG-CCR110017.
5Prior to phrase-based systems, NISHIDA et al. (1988) 6http://www.cs.cmu.edu/˜mdenkows/
usepost-editingdatatocorrecterrorsintransfer-basedMT. cdec-realtime.html
402
References machine translation. In Proceedings of the Seventh
WorkshoponStatisticalMachineTranslation,pages
[Callison-Burchetal.2012] Chris Callison-Burch,
480–489, Montre´al, Canada, June. Association for
Philipp Koehn, Christof Monz, Matt Post, Radu
ComputationalLinguistics.
Soricut, and Lucia Specia. 2012. Findings of the
2012 workshop on statistical machine translation. [Guerberof2009] Ana Guerberof. 2009. Productivity
In Proceedings of the Seventh Workshop on Statis- andqualityinmtpost-editing. InProceedingsofMT
tical Machine Translation, pages 10–51, Montre´al, SummitXII-Workshop: BeyondTranslationMemo-
Canada, June. Association for Computational ries: NewToolsforTranslatorsMT.
Linguistics.
[HardtandElming2010] Daniel Hardt and Jakob Elm-
[Carletal.2011] Michael Carl, Barbara Dragsted, ing. 2010. Incremental re-training for post-editing
Jakob Elming, Daniel Hardt, and Arnt Lykke smt. InProceedingsoftheNinthConferenceofthe
Jakobsen. 2011. The process of post-editing: A Association for Machine Translation in the Ameri-
pilot study. Copenhagen Studies in Language, cas.
41:131–142.
[Heafieldetal.2013] Kenneth Heafield, Ivan
[Cettoloetal.2012] Mauro Cettolo, Christian Girardi, Pouzyrevsky, Jonathan H. Clark, and Philipp
andMarcelloFederico. 2012. Wit3: Webinventory Koehn. 2013. Scalable modified Kneser-Ney
of transcribed and translated talks. In Proceedings language model estimation. In Proceedings of
oftheSixteenthAnnualConferenceoftheEuropean the 51st Annual Meeting of the Association for
AssociationforMachineTranslation. ComputationalLinguistics,Sofia,Bulgaria,August.
[Chiang2007] David Chiang. 2007. Hierarchical [HopkinsandMay2011] Mark Hopkins and Jonathan
phrase-based translation. Computational Linguis- May. 2011. Tuning as ranking. In Proceedings of
tics,33. the2011ConferenceonEmpiricalMethodsinNat-
uralLanguageProcessing,pages1352–1362,Edin-
[Chiang2012] DavidChiang. 2012. Hopeandfearfor
burgh,Scotland,UK.,July.AssociationforCompu-
discriminativetrainingofstatisticaltranslationmod-
tationalLinguistics.
els. Journal of Machine Learning Research, pages
1159–1187,April. [Koehn2012] Philipp Koehn. 2012. Computer-aided
translation. MachineTranslationMarathon.
[Clarketal.2011] JonathanH.Clark,ChrisDyer,Alon
Lavie, and Noah A. Smith. 2011. Better hypothe- [KuhnanddeMori1990] Roland Kuhn and Renato
sis testing for statistical machine translation: Con- de Mori. 1990. A cache-based natural language
trolling for optimizer instability. In Proceedings of model for speech recognition. IEEE Transac-
the49thAnnualMeetingoftheAssociationforCom- tionsonPatternAnalysisandMachineIntelligence,
putationalLinguistics: HumanLanguageTechnolo- 12(6).
gies,pages176–181,Portland,Oregon,USA,June.
AssociationforComputationalLinguistics. [Levenbergetal.2010] Abby Levenberg, Chris
Callison-Burch, and Miles Osborne. 2010.
[Crammeretal.2006] Koby Crammer, Ofer Dekel, Stream-based translation models for statistical
Joseph Keshet, Shai Shalev-Shwartz, and Yoram machine translation. In Human Language Tech-
Singer. 2006. Online passive-aggressive algo- nologies: The2010AnnualConferenceoftheNorth
rithms. Journal of Machine Learning Research, American Chapter of the Association for Compu-
pages551–558,March. tational Linguistics, pages 394–402, Los Angeles,
California, June. Association for Computational
[Dyeretal.2010] Chris Dyer, Adam Lopez, Juri Gan- Linguistics.
itkevitch, Jonathan Weese, Ferhan Ture, Phil Blun-
som, Hendra Setiawan, Vladimir Eidelman, and [Lopez2008a] Adam Lopez. 2008a. Machine transla-
Philip Resnik. 2010. cdec: A decoder, alignment, tion by pattern matching. In Dissertation, Univer-
andlearningframeworkforfinite-stateandcontext- sityofMaryland,March.
freetranslationmodels. InProceedingsoftheACL
2010SystemDemonstrations,pages7–12,Uppsala, [Lopez2008b] AdamLopez. 2008b. Tera-scaletransla-
Sweden, July. Association for Computational Lin- tion models via pattern matching. In Proceedings
guistics. of the 22nd International Conference on Compu-
tational Linguistics (Coling 2008), pages 505–512,
[Dyeretal.2013] Chris Dyer, Victor Chahuneau, and Manchester, UK, August. Coling 2008 Organizing
NoahA.Smith. 2013. Asimple,fast,andeffective Committee.
reparameterization of IBM model 2. In The 2013
Conference of the North American Chapter of the [Lo´pez-Salcedoetal.2012] Francisco-Javier Lo´pez-
AssociationforComputationalLinguistics: Human Salcedo, Germa´n Sanchis-Trilles, and Francisco
LanguageTechnologies. Casacuberta. 2012. Online learning of log-linear
weights in interactive machine translation. Ad-
[Eidelman2012] Vladimir Eidelman. 2012. Optimiza- vances in Speech and Language Technologies for
tion strategies for online large-margin learning in IberianLanguages,pages277–286.
403
[Machereyetal.2008] WolfgangMacherey,FranzOch, [Salujaetal.2012] AvneeshSaluja,IanLane,andYing
IgnacioThayer,andJakobUszkoreit. 2008. Lattice- Zhang. 2012. Machinetranslationwithbinaryfeed-
basedminimumerrorratetrainingforstatisticalma- back: a large-margin approach. In Proceedings of
chine translation. In Proceedings of the 2008 Con- theTenthBiennialConferenceoftheAssociationfor
ferenceonEmpiricalMethodsinNaturalLanguage MachineTranslationintheAmericas.
Processing, pages725–734, Honolulu,Hawaii, Oc-
tober.AssociationforComputationalLinguistics. [Sanchis-Trilles2012] Germa´n Sanchis-Trilles. 2012.
Buildingtask-orientedmachinetranslationsystems.
[ManberandMyers1993] Udi Manber and Gene My- InPh.D.Thesis,UniversitatPolitcnicadeValncia.
ers. 1993. Suffix arrays: A new method for on-
line string searches. SIAM Journal of Computing, [SimardandFoster2013] Michel Simard and George
22:935–948. Foster. 2013. PEPr: Post-edit propagation using
phrase-basedstatisticalmachinetranslation. InPro-
[Mart´ınez-Go´mezetal.2012] Pascual Mart´ınez- ceedings of the XIV Machine Translation Summit,
Go´mez, Germa´n Sanchis-Trilles, and Francisco pages191–198,,September.
Casacuberta. 2012. Online adaptation strategies
for statistical machine translation in post-editing [Tatsumi2009] Midori Tatsumi. 2009. Correlation
scenarios. PatternRecognition,45:3193–3203. between automatic evaluation metric scores, post-
editing speed, and some other factors. In Proceed-
[Nepveuetal.2004] Laurent Nepveu, Guy Lapalme, ingsoftheTwelfthMachineTranslationSummit.
PhilippeLanglais,andGeorgeFoster. 2004. Adap-
tive language and translation models for interactive [Teh2006] Yee Whye Teh. 2006. A hierarchical
machinetranslation. InDekangLinandDekaiWu, BayesianlanguagemodelbasedonPitman-Yorpro-
editors, Proceedings of EMNLP 2004, pages 190– cesses. InProc.ofACL.
197, Barcelona, Spain, July. Association for Com-
putationalLinguistics. [Zhaoetal.2004] Bing Zhao, Matthias Eck, and
Stephan Vogel. 2004. Language model adaptation
[NISHIDAetal.1988] Fujio NISHIDA, Shinobu for statistical machine translation with structured
TAKAMATSU, Tadaaki TANI, and Tsunehisa querymodels. InProc.ofCOLING.
DOI. 1988. Feedback of correcting information
in postediting to a machine translation system. In [Zhechev2012] Ventsislav Zhechev. 2012. Machine
Proc.ofCOLING. Translation Infrastructure and Post-editing Perfor-
mance at Autodesk. In AMTA 2012 Workshop
[Och2003] FranzJosefOch. 2003. Minimumerrorrate on Post-Editing Technology and Practice (WPTP
training in statistical machine translation. In Pro- 2012),pages87–96,SanDiego,USA,October.As-
ceedingsofthe41stAnnualMeetingoftheAssocia- sociation for Machine Translation in the Americas
tionforComputationalLinguistics,pages160–167, (AMTA).
Sapporo,Japan,July.AssociationforComputational
Linguistics.
[Ortiz-Mart´ınezetal.2010] Daniel Ortiz-Mart´ınez, Is-
mael Garc´ıa-Varea, and Francisco Casacuberta.
2010. Onlinelearningforinteractivestatisticalma-
chine translation. In Human Language Technolo-
gies: The 2010 Annual Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 546–554, Los Ange-
les,California,June.AssociationforComputational
Linguistics.
[Papinenietal.2002] Kishore Papineni, Salim Roukos,
Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a
method for automatic evaluation of machine trans-
lation. In Proceedings of 40th Annual Meeting
of the Association for Computational Linguistics,
pages 311–318, Philadelphia, Pennsylvania, USA,
July.AssociationforComputationalLinguistics.
[Parkeretal.2011] Robert Parker, David Graff, Junbo
Kong, Ke Chen, and Kazuaki Maeda. 2011. En-
glishGigawordFifthEdition,June. LinguisticData
Consortium,LDC2011T07.
[Przybocki2012] Mark Przybocki. 2012. Nist open
machine translation 2012 evaluation (openmt12).
http://www.nist.gov/itl/iad/mig/openmt12.cfm.
404
