Efficiency Pentathlon:
A Standardized Arena for Efficiency Evaluation
HaoPeng♠ QingqingCao♢ JesseDodge♠ MatthewE.Peters♠ JaredFernandez♡
TomSherborne♣∗ KyleLo♠† SamSkjonsberg♠† EmmaStrubell♡♠†
DarrellPlessas♠† IzBeltagy♠† EvanPeteWalsh♠†
NoahA.Smith♢♠ HannanehHajishirzi♢♠
♠AllenInstituteforArtificialIntelligence
♢PaulG.AllenSchoolofComputerScience&Engineering,UniversityofWashington
♡LanguageTechnologiesInstitute,CarnegieMellonUniversity
♣InstituteforLanguage,CognitionandComputation,UniversityofEdinburgh
{haop,jessed,matthewp,kylel,sams,darrellp,beltagy,petew}@allenai.org
{qicao,nasmith,hannaneh}@cs.washington.edu
{jaredfern,strubell}@cmu.edu,tom.sherborne@ed.ac.uk
Abstract
Risingcomputationaldemandsofmodernnaturallanguageprocessing(NLP)sys-
tems have increased the barrier to entry for cutting-edge research while posing
seriousenvironmentalconcerns. Yet,progressonmodelefficiencyhasbeenim-
pededbypracticalchallengesinmodelevaluationandcomparison. Forexample,
hardwareischallengingtocontrolduetodisparatelevelsofaccessibilityacross
differentinstitutions. Moreover,improvementsinmetricssuchasFLOPsoften
failtotranslatetoprogressinreal-worldapplications. Inresponse,weintroduce
efficiencyPentathlon,abenchmarkforholisticandrealisticevaluationofmodel
efficiency. Pentathlonfocusesoninference,whichaccountsforamajorityofthe
computeinamodel’slifecycle. Itoffersastrictly-controlledhardwareplatform,
andisdesignedtomirrorreal-worldapplicationsscenarios. Itincorporatesasuite
ofmetricsthattargetdifferentaspectsofefficiency,includinglatency,throughput,
memory overhead, number of parameters, and energy consumption, hence the
name Pentathlon. It also comes with a software library that can be seamlessly
integratedintoanycodebaseandenableevaluation. Asastandardizedandcentral-
izedevaluationplatform,Pentathloncandrasticallyreducetheworkloadtomake
fairandreproducibleefficiencycomparisons. Whileinitiallyfocusedonnatural
languageprocessing(NLP)models,Pentathlonisdesignedtoallowflexibleexten-
siontootherfields. WeenvisionPentathlonwillstimulatealgorithmicinnovations
inbuildingefficientmodels,andfosteranincreasedawarenessofthesocialand
environmentalimplicationsinthedevelopmentoffuture-generationNLPmodels.
1 Introduction
Theremarkablerecentprogressinartificialintelligenceowesmuchtoadvancesinlarge-scaledeep
learning models (Brown et al., 2020; Chowdhery et al., 2022; Thoppilan et al., 2022, inter alia).
However,theirrapidly-increasingcomputationaldemandshaveintroducedsubstantialchallenges.The
barriertoentrytocutting-edgeresearchisraised,particularlyimpactingresearchersandpractitioners
with fewer resources and exacerbating disparities in the AI research landscape. Moreover, the
escalatingenergyconsumptionassociatedwiththesecomputation-intensivemodelsleadstoserious
∗ ThisworkwasdoneduringTomSherborne’sinternshipatAI2.†denotesequalcontribution.
Preprint.Underreview.
3202
luJ
91
]LC.sc[
1v10790.7032:viXra
environmentalconcerns(Lacosteetal.,2019;Schwartzetal.,2020;Hendersonetal.,2020;Strubell
etal.,2020,interalia).
Therefore,buildingmoreefficientmodelsforAIsystemshasbecomeapressingchallenge,drawing
widespreadattentionfromthecommunity(Reddietal.,2020;Tayetal.,2020;Trevisoetal.,2022;
Liu et al., 2022; Yao et al., 2022; Fu et al., 2023, inter alia). However, a lack of standardized
evaluationprotocolsmakesitchallengingtomeasuretheprogressinefficiencyimprovementsand
obstructstheeffortsindevelopingmoreefficientmodels. Inmanycases,modelsareevaluatedin
scenariosthathardlyreflectthedeploymentofmachinelearningmodelsinpractice(Hendersonetal.,
2020). Moreover, some widely-adopted efficiencymetricssuchas FLOPsoftenpoorlycorrelate
with models’ real-world efficiency performance (Dehghani et al., 2022; Fernandez et al., 2023).
The issue is exacerbated by several practical
challenges. Forinstance,hardwareisacritical
Previous models
confounding factor in efficiency comparisons,
but is very challenging to control in practice, Efficiency Pentathlon
due to disparate levels of hardware accessibil- A strictly-controlled
… hardware platform
ityacrossinstitutions. Consequently,thisleads
todisconnectionsbetweenefficiencyimprove- A diverse
set of metrics
mentsinresearchandtangibleprogressinprac-
tice. Thereisapressingneedforastandardized Realistic scenarios Comprehensive
New model efficiency evaluation
efficiencyevaluationframework.
Figure1: BysubmittingtoPentathlon,practition-
To address these challenges, we present Pen-
erscancomparetheirmodelsagainstallprevious
tathlon. It is designed to establish a standard-
submissionsonidenticalhardware,eliminatingthe
izedplatformforevaluatingtheinferenceeffi-
needtore-implementpreviousworksandsubstan-
ciency of AI models. As shown by Patterson
tially reducing the workloads for fair efficiency
et al. (2022) and Wu et al. (2022a), inference
comparisons. Models are evaluated in four real-
accountsforover60%ofenergyconsumption
istic scenarios designed to mirror real-world ap-
inreal-worldmachinelearningworkloads. Pen-
plications. Ourplatformevaluatesthesubmission
tathlonaimstoprovidecomprehensiveandreal-
across five crucial efficiency metrics, including
isticevaluationofefficiency,andofferthecom-
throughput,latency,memoryoverhead,thenum-
munityaplatformtomakefaircomparisonsin
berofparameters,andenergyconsumption,hence
astrictlycontrolledenvironment. Toachievethis,wemakeseveralkeydesignchoices:
thenamePentathlon.
• Controlledhardwareenvironment(§2.1): hostedbyadedicatedserver,Pentathlonprovidesa
centralizedplatformwithastrictlycontrolledhardwareenvironment. Thisremovesthenecessity
for practitioners to reproduce previous works on their own hardware for fair comparisons and
allowseasycomparisonswithmodelspreviouslyevaluatedonPentathlonusingidenticalhard-
ware. Moreover,itallowsustousepowermonitoringdevicestoaccuratelymeasuretheenergy
consumptionduringmodels’inference,whichwaspreviouslyimpossible.
• Realisticscenarios(§2.2): Itevaluatesmodelsundervariousscenariosspecificallydesignedto
mirrorreal-worlddeploymentcontexts,allowingdifferentapproachestobatchinginputinstances,
aimingtobridgethegapbetweenresearchcontextandpracticalapplications.
• Comprehensivemetrics(§2.3): Pentathlonevaluatesmodelswithfivecrucialmetrics,including
throughput,latency,memoryoverhead,thenumberofparameters,andenergyconsumption,hence
thenamePentathlon. Thisprovidesamoreholisticunderstandingofamodel’sefficiency.
• Flexibility(§2.4)Pentathlonisflexiblebydesignandcanbeseamlesslyintegratedintoanycode-
base. Althoughwefocusonnaturallanguageprocessing(NLP)modelsinthispaper,Pentathlon
canbeeasilyextendedtootherfields.
Pentathlonisreadytoacceptsubmissions,helpingtoreducetheworkloadofconductingfairefficiency
comparisons: https://github.com/allenai/efficiency-pentathlon. As we demonstrate
intheexperiments(§3),Pentathloncanprovidefreshinsightsintoexistingmodels. Throughourcom-
parisonsofseveralestablishedmachinetranslationmodels,thecomprehensiveevaluationofferedby
Pentathlonhighlightstheparticulareffectivenessofquantizationinlargemodels. Furthermore,Pen-
tathlon’senergyevaluationcomponentrevealsnewperspectivesonthemodels’energyconsumption
duringinference.
Weenvisionthatbyofferingstandardizedefficiencyevaluation,Pentathlonwillstimulatethedevel-
opmentofmoreefficientmodelsandfosteradeeperawarenessofthecomputationalcostsofAI
research,andaccelerateprogressonreducingthem.
2
2 EfficiencyPentathlon
Thissectiondiscussesthecurrentchallengesinefficiencyevaluationandoutlinesthedesignchoices
weadoptedinPentathlontoeffectivelyaddressthem.
2.1 ControllingtheHardwareforFairEfficiencyComparisons
Thehardwarestandsasacriticalconfoundingfactorwhencomparingefficiency,andcansignificantly
influencetheconclusionsofsuchcomparisons. Asdemonstratedbyseveralrecentstudies,thetrends
inefficiencycomparisonscanvarysubstantiallywhendifferentacceleratorsareused(Pengetal.,
2021;Kasaietal.,2021a;Wuetal.,2022b;Wangetal.,2020,interalia). Compoundingthisissueis
thepracticaldifficultyincontrollingforhardware,primarilybecauseaccesstohardwareplatforms
oftenvariesamonginstitutions. Thisisamajorobstacleforfairefficiencycomparisons. Evenwith
publiclyavailableimplementations,practitionersoftenneedtoadaptthesetotheirownhardware
environmentstoensurefaircomparisons.
Our approach. Pentathlon aims to stimulate algorithmic innovations that can generalize across
different hardware. Therefore we control for hardware while conducting efficiency comparisons
andofferavariedselectionofhardwaretosimulatedifferentusecases. Pentathlonishostedwitha
dedicatedin-houseserver. Participantscansubmittheirmodels’codeandcheckpointstoourserver
through an easy-to-use tool that we provide (§2.4). This ensures that all models evaluated using
Pentathlonuseanidenticalhardwareenvironment,guaranteeingfaircomparisons. Byrequiringcode
submissionPentathlonhelpsimprovetransparency. Thespecificimplementationchoicesforeach
submission,suchasdataIOandpadding,willbethoroughlydocumented. Thisisappealingbecause
ithelpsdisentangletheefficiencygainsduetoalgorithmicinnovationsfromthoseachievedbybetter
implementationsthatcanequallybenefitallmodels. Further,adedicatedin-houseserverallowsusto
measureenergyconsumption,whichwouldotherwisebeverychallengingtoincorporate(§2.3).
ThehostingmachineofPentathlonhastwoNVIDIARTX8000GPUs,twoIntelXeonIceLakeGold
634828-CoreCPUs,and1TBDDR4memory. ItsupportsevaluationusingGPUsandCPUs,and
CPUsonly. WeplantoextendPentathlontoofferabroaderselectionofhardwareinthenearfuture.2
Toaccuratelymeasureeachsubmission’sefficiencywithoutinterference,wehaveimplementeda
schedulerontheserver. Thisensuresthatonlyoneinferenceworkloadisrunningatanygiventime.
InPentathlon,theefficiencymeasurementbeginswhenthemodelhasbeenloadedandisreadyfor
predictions,excludingtheoverheadassociatedwithbothmodelanddataloading.
2.2 RealisticEvaluationScenariosDesignedtoEmulateReal-worldApplications
Scenarios Acc. TP. Latency Mem. Energy&CO BSZ Online
2
Fixedbatching ✓ ✓ ✓ ✓ ✓ Userspecified ✓
Poissonbatching ✗ ✓ ✓ ✓ ✓ Random ✓
Singlestream ✗ ✗ ✓ ✓ ✓ 1 ✓
Offline ✗ ✓ ✗ ✓ ✓ Userspecified ✗
Table1: Fourevaluationscenariosandthemetricstheyfocuson. Acc.: accuracy,TP.: throughput,
Mem.: memory. Inthethreeonlinescenarios,Pentathloninterfaceswiththesubmittedmodelvia
standardinput/output(stdio),providinginputsandcapturingoutputsinreal-time. Rearrangementof
instanceorderisprohibitedinthesescenarios. Intheofflinescenario,themodelisgivenimmediate
accesstoallevaluationinstancesviaafile,enablingtechniquessuchassortingbylengths.
NLP systems are deployed across a broad range of practical applications, each with its unique
requirementsforefficiency. Consider,forinstance,anonlinesearchengine. Thearrivalsofusers’
queriesareunpredictable,andsoisthemodel’sinferencebatchsize. AnAIassistantoperatingona
smartphonetypicallyprocessesonerequestatatime,whileanofflinetranslationsystemtranslatingan
entirebookmustuselargebatchsizestoprioritizemaximizingthroughput. Thesepracticalscenarios
arerarelyreflectedbyconventionalefficiencyevaluationsintheresearchcontext,wheremodelsare
2We plan to use the NVIDIA Jetson TX2 Module (https://developer.nvidia.com/embedded/
jetson-tx2) to simulate limited-resource settings such as on an automobile, and extend Pentathlon to a
smartphonetoevaluatemachinelearningmodelsdesignedtorunonmobiledevices.
3
typicallyassessedwithafixedbatchsize. Suchdisparityunderscoresthepressingneedforevaluation
protocolsthatbetterreflectreal-worlddeployments.
Ourapproach. InspiredbyReddietal.(2020), weincludefourdistinctevaluationscenariosto
provideacomprehensiveevaluationofNLPmodelsinavarietyofrealisticsettings:
• Fixedbatching. Theevaluationdataisfirstrandomlyshuffledbeforebeinggroupedintobatches
ofauser-specifiedbatch-size. Thissettingisintendedtomimictypicalresearchexperimental
settings. Wedefertotheuserschoosingoptimalbatchsizesfortheirmodels.
• Poisson batching is similar to the fixed batching scenario, but the size of each batch is ran-
domly drawn from a Poisson distribution with a mean of batch-size: batch-size ∼
Pois
Pois(batch-size). Thissetupaimstosimulateanonlineservicewherethevolumeofrequestsis
unpredictablebuttheaveragecanbeestimated.
• Singlestreamrandomlyshufflestheevaluationinstancesandusesabatchsizeofone,reflecting
theapplicationsprocessingonerequestatatime.
• Offline: Inthisscenario,themodelhasimmediateaccesstotheentireevaluationdataset,enabling
techniquessuchassortingtheinputsbylengthoradaptivebatchingtoenhancethroughputand
memoryefficiency. Thisscenarioreflectslarge-scale,offlinetasks.
Thesevariedevaluationscenariosaredesignedtohighlightthestrengthsandweaknessesofdifferent
modelsindiversedeploymentcontexts.
2.3 ADiverseSetofMetricsforComprehensiveEfficiencyEvaluation
AIsystems’efficiencyinpracticalcontextsismultifacetedandcanhardlybeadequatelyrepresented
by any single metric. Different use cases prioritize different efficiency aspects. For example, a
modeldeployedonmobiledevicesprioritizesenergyefficiency,anofflinemodelrequiresoptimal
throughput,whileanonlineservicemodeldemandslowlatency. However,thewidely-usedmetrics
oftenfailtoshowstrongcorrelationswiththesediversepracticalaspectsofefficiency. Take, for
instance,thenumberoffloatingpointnumberoperations(FLOPs)amodeltakesforperforminga
workload. Ithasbecomeastandardefficiencymetricpartlyduetoitshardwareandimplementation-
agnostic nature, highlighting the algorithmic advancements in model efficiency (Schwartz et al.,
2020). Yetrecentresearchhascastdoubtonitsrelevance,showingthatitisapoorindicatorofmany
practicalmetricsincludingthroughput,latency,andenergyconsumption(Hendersonetal.,2020).
Evenformodelssharingsimilararchitecturesandnumbersofparameters,theirenergyefficiencycan
divergesignificantlyunderidenticalworkloads,partlyduetospecificdeeplearningoperationsthey
areimplementedwith(Caoetal.,2021).
This highlights the limitations of conventional evaluation protocols, which risk oversimplifying
efficiencycomparisonsbyattemptingtoencapsulateperformanceinasinglemeasure. Instead,we
proposeamorecomprehensiveapproachthatconsidersadiversesuiteofmetrics. Itmoreaccurately
reflectsthemultifacetednatureofefficiencyinAImodels.
Ourapproach. Ourbenchmark’ssuiteofevaluationmetricsincludesthefollowing:
• Throughputmeasuresthevolumeofdataasystemcanprocessinaunitoftime. Wemeasure
throughputwithinstances/s;fortasksthatrequiregeneratingtext,wealsoconsiderwords/s.
• Latency,inmilliseconds. Itquantifiesthedelaybetweenthesystemreceivingauserrequestand
providingaresponse. Complementingthroughput,it’sespeciallycriticalinreal-timeapplications,
suchassmartphone-basedAIassistants.
• Memoryoverhead,inGiB,providesinsightintoasystem’sapplicabilityinlow-resourcesettings,
where available memory can be a bottleneck. In resource-abundant settings, lower memory
overheadallowslargerbatchsizesduringinference,improvingmetricssuchasthroughput. Our
benchmarkmeasuresmaximumCPUandGPU(ifapplicable)memoryconsumption.
• Energyconsumptionandcarbonfootprint. Theenergyoverheadofasystem,measuredinW·h,
indicatesitssuitabilityforbattery-powereddevices. Combinedwithcarbonintensitydata,itcan
also assess a model’s carbon footprint in terms of the amount of CO emissions, providing an
2
environmentalimpactcomparisonformodelsdeployedinpractice. Weprovidemoredetailsabout
measuringenergyconsumptionin§2.3.1.
• Model size, measured in the number of parameters, serves as an indicator of models’ storage
overhead,andoftencorrelateswithitsmemoryoverhead.
4
Ourapproachprovidesaholisticviewofmodelefficiency,witheachfocusingonspecificapplication
contexts,allowingpractitionerstoselectefficientmethodscateredtotheirapplications.
2.3.1 ChallengesinMeasuringEnergyandourSolution
Whilemostofthemetricsabovecanbemeasuredwithexistingtools,accuratelymeasuringenergy
presents unique challenges, primarily due to the lack of established software for this purpose.
AlthoughCUDAofferstoolkitstomeasureGPUpower,thepowerusageofCPUs,DRAM,anddisks
isonlyaccessibleonspecifictypeshardwareandrequiresrootaccess(Khanetal.,2018).
ManyexistingmethodsestimateenergyconsumptionfortrainingusingGPUenergyalone(Luccioni
etal.,2022;Liangetal.,2022a). However,aswewilldemonstrateintheexperiments,thisapproach
is not suitable for our purposes for two primary reasons. First, it excludes energy comparisons
ofmodelsrunningonCPUs,whichourstudyaimstoexplore. Second,inferencetasksbynature
entailmorefrequentdataIOinteractions,imposingmoresignificantworkloadsonCPUs,DRAM,
disks, etc., comparedtotraining. Inourexperiments, theyaccountformorethan60%ofenergy
consumption—-asignificantincreasecomparedtopreviousestimatesfortraining(Dodgeetal.,2022).
Therefore,itisessentialtomeasurenotonlyGPUenergybutthetotalenergyconsumedbytheentire
machineaccurately.
Tothisend,weuseanenergy-monitoringdevicetomeasurethepowerconsumption.3 Thisdata,in
conjunctionwiththemodel’sruntime,canbeusedtocalculatethemodel’senergyconsumption.
Physically connected to the host machine’s power cables, this device’s sensors provide accurate
real-timepowerusagedata. Accordingtothemanufacturer,theerrorrateis±1.2%.
Thepowerconsumptioniscalculatedbysubtractingthehostmachine’sidlingpowerfromthemeter
readingduringaninferencerun. Tocalculatethecarbonemissions,weusethecarbonintensitydata
providedbySchmidtetal.(2022)basedonthegeographicallocationandtimeoftheday.
2.4 EnsuringFlexibilityinPentathlon
Requiringcodeandcheckpointsubmissionimposesadditionalimplementationeffortfrompartic-
ipants,atradeoffwebelieveisworthwhileforachievingfaircomparisonsonastrictly-controlled
hardwareplatform. Recognizingfrompastbenchmarkeffortsthatthismightdiscouragepractitioners
fromparticipating,wehavemadeaconcertedefforttoensurethatPentathloncanbeeasilyintegrated
intoexistingcodebasesandtostreamlinethesubmissionprocess.4
Accommodating diverse software frameworks. We aim to encourage wide participation and
ensure our platform is accessible to practitioners accustomed to various software infrastructures.
Therefore,Pentathlonmakesnoassumptionaboutthesubmission’sdeeplearningframework(ifa
deeplearningmodelisusedatall)ortheprogramminglanguageit’simplementedin. Werequire
thateverysubmission: (1)IncludeaGitHubrepositorycontainingthecodeandlistingdependencies
(thisrepositorydoesnotneedtobepublic);(2)Interfacethemodeltoreadinputsfromstdinand
write outputs to stdout;5 (3) Implement the necessary tools to download the model checkpoint
forevaluation. Weprovidedetailedinstructionsandexamplestoguidepractitionersthroughthis
process. Basedonourinternaltesting,learningtointegratePentathlonintoanexistingcodebase
andsubmittingittoourserverforevaluationtakesaparticipantlessthanonehour;andanonward
submissiontakesasinglecommandline. Furthermore,Pentathloncanserveasastandalonetoolfor
preparingthesubmissionandprovidingbasicefficiencymetrics.
Inprovidingabstractionsaroundtheevaluationinterface, welimitassumptionsmadearoundthe
underlyingsystemimplementationandallowfortheinstallationofuserdependenciesasneeded. This
enablessupportforadiversityofbackendframeworksandruntimesastheuserisnotconstrained
toasingledeeplearningframeworkordataformat. Forexample,Pentathlonallowsuserstouse
bothresearchframeworks(e.g.,eagerexecutionPyTorchandTensorFlow2.0)aswellasspecialized
3WeuseanemonTxV4forpowerconsumptionmeasurement:https://shop.openenergymonitor.com/
single-phase-6-channel-energy-monitoring-emontx-v4/.
4ThisisalessonthatsomeoftheauthorslearnedfromtheNAACL2022reproducibilitytrack: https:
//2022.naacl.org/blog/reproducibility-track/
5WeprovideaPythontoolforthisstdiointeraction.Userscanimplementtheirowninterfacesiftheydecide
touseotherprogramminglanguages.
5
inferenceruntimes(e.g.,ONNXRuntime,TVM,andTensorRT).Theadditionalflexibilityprovided
by this format allows Pentathlon to remain accessible to researchers familiar with a particular
framework,whilealsoenablingtheexplorationofdifferentmeansofincreasingoverallend-to-end
efficiencyofthemachinelearningsystemthatisavailableindeploymentsettings. Thisdesignallows
userstoevaluateefficiencygainsfromimprovingdifferentaspectsoftheoverallsystem,suchas
thoseobtainedfromoptimizingthemodelarchitecturesorfromutilizingfastersoftwareframeworks.
PentathlonbuildsuponestablishedsoftwaredevelopedandmaintainedbyAI2. Thesetoolshave
beenthoroughlytestedbyAI2researchersandengineers,enhancingPentathlon’srobustnessandease
ofuse. Forexample,empoweredbyCatwalk,PentathlonsupportsadiversesetofNLPtasks,and
allowsPentathlontoeasilyextendtomanyothertasksandresearchfields.6
3 Experiments
WeusePentathlontobenchmarkseveralestablishedmodelsformachinetranslationandtextclassifi-
cationwiththeRAFTdataset(Alexetal.,2021). Intheinterestofspace,wereferthereaderstothe
appendicesfortheRAFTexperiments.
MachineTranslation. Improvingtheefficiencyofmachinetranslation(MT)andtextgeneration
modelshasgainedsignificantmomentum. Agrowingnumberofrecentworkshopsandsharedtasks
havehelddedicatedefficiencytracks(Birchetal.,2018;Hayashietal.,2019;Heafieldetal.,2020;
Akhbardehetal.,2021;Kocmietal.,2022,interalia).Alignedwiththisgoal,weseektocontributeto
thisongoingeffort. Tothisend,ourinitialexperimentswithPentathlonfocusonmachinetranslation.
Dataset and setting. We present results for WMT14 DE-EN (Bojar et al., 2014), a well-
studied dataset that is selected as the testbed in the efficiency tracks of two recent WMT work-
shops(Akhbardehetal.,2021;Kocmietal.,2022). PentathlonalreadysupportsmanyotherMTand
textgenerationdatasets,andcanbeeasilyextendedtomore. WefocusonDE->ENtranslationhere;
additionalresultswithEN->DEareavailableintheAppendices.
Balancingtheinferencewallclocktimeandaccuratelymeasuringtheefficiency,weusedifferent
numbersofevaluatinginstancesacrossthefourscenarios. ForWMT14DE-EN:
• Fixedbatchingusesthefulltestsetof3,002instances. Italsomeasuresthetranslationquality
usingSacreBLEU(Post,2018).
• Poissonbatchingrandomlydraws4,000instances(withreplacement)fromthetestset.
• Inthesinglestreamscenario,1,000randomlyselectedtestinstancesareused.
• Differentlyfromothers,theofflinescenariorandomlyselects8,000instancesfromthetraining
data.7 Weensurethattheselectedinstanceshaveanaveragelengthmatchingthatofthetestset.
Controllingfortherandomseed,allmodelsareevaluatedonthesamesetofinstancesinthesame
order,andidenticalbatchsizesinthePoissonbatchingscenario. Preliminaryexperimentsindicate
thatthemodels’efficiencyperformanceremainsconsistentacrossmultipleruns. Assuch,weopt
outofconductingmultipleroundsofevaluation. AllmodelsareevaluatedononeRTX8000GPU,
andtheinferencebatchsizesforthefixedbatchingandofflinescenariosaretunedtotheallowable
maximumfortheavailableGPUhardware.
Models. Webenchmarkthefollowingpublicly-availablemodelscoveringawiderangeofsizes:
• MBART(Tangetal.,2021): a610M-parameter-sizedTransformermodelformultilingualtrans-
lation. Ithastwovariants,many-to-one(MBARTM2O)translatesotherlanguagesintoEnglish,
andmany-to-many(M2M)cantranslatebetweenmultiplelanguagepairs. WeusetheMBART50
variant,originallypre-trainedonmonolingualcorporain25languages,byfine-tuningonparallel
corporainacross50languagesfordirectuseasatranslationengine.
• M2M100(Fanetal.,2021): Transformer-basedmultilingualmodelsformany-to-manytranslation.
We report on two sizes with 418M and 1.2B parameters respectively. The M2M100 model is
6CatwalkprovidesaunifiedinterfacetoabroadrangeofexistingNLPtasksandmodels.Alistoftasksthat
arecurrentlysupportedbyPentathloncanbefoundathttps://github.com/allenai/catwalk.
7Inthisscenariothemodelsaregrantedimmediateaccesstoallinstancesandcansortthembylength.If
theinstancesweredrawnfromthetestset,thiswouldresultintheartifactthatgroupsduplicatesofthesame
instanceinthesamebatch,whichweaimtoavoid.
6
trainedusingparallelcorpora(e.g.,WMTcorporadescribedabove)andminedbitexttoenable
translationbetweenanytwoof100languages.
• OPUS(Tiedemann&Thottingal,2020): abilingualTransformermodelwith74Mparametersfor
DE->ENtranslation. ThemodelistrainedonOPUSbitextcorpora(Tiedemann,2012).
• WMT19-Meta(Ngetal.,2019): aDE->ENTransformermodelwith314Mparameters.
ThissystemwontheWMT19taskonGermantoEnglishnewstranslation(Barraultetal.,2019).
• WMT21-Meta (Tran et al., 2021): a M2O Transformer model with 4.7B parameters. Unlike
WMT19-Meta,thismodelismultilingualandtrainedondatafromalllanguagesfortheWMT
2021sharedtask.Trainingdataisamixtureofparallelcorpora,monolingualcorporaandmined
bitext. ThismultilingualsystemrankedhighinseveralWMT21newstranslationtasks(Akhbardeh
etal.,2021). WerefertoTranetal.(2021)forcompletedetails.
WeevaluateusingPyTorchwithbothfullprecision(FP32)andhalfprecision(FP16),tostudythe
effectofquantization. Inourpreliminaryexperiments,wefoundthatemployingmoreaggressive
quantization techniques such as 8-bit and 4-bit quantization using naive methods led to severely
compromisedtranslationquality,withtheBLEUscoredroppingtoaround1,effectivelyresultingin
afailedtranslation. Allmodels’implementationandcheckpointsareavailableonHuggingFace.
Results. Figure2summarizestheefficiencyperformanceofdifferentmodelsinontheWMT14
DE-ENdataset,alongwiththeirtranslationquality. Overall,modelstrainedforEnglishtranslation
demonstratedbettertrade-offsbetweentranslationqualityandefficiency.Notably,OPUSoutperforms
themuchlargerMBARTM2MandM2M100modelsinbothaccuracyandallaspectsofefficiency,
andisthemostefficientmodelamongall. AlthoughWMT21-Meta,thelargestmodelconsidered,
providesthehighestBLEUscore,ittakesasubstantialhitinefficiency.
Interestingly,despitebeingmorethanfourtimeslarger,WMT19-Metaachievesefficiencyperfor-
mancecomparabletoOPUSinlatency,memoryoverhead,andenergyconsumption,andsignificantly
outperformsitintermsofBLEU.However,itfallsshortofOPUSinthroughput. Thisobservation
confirmsthatrelyingonasingleefficiencymetricrisksoversimplifyingthecomplexperformance
landscapeofefficiencyinpracticalapplications.
WithONNX,themodelsachieveover20%improvementsinlatencyandthroughputinthesingle-
streamscenario,accompaniedbyasignificantreductioninmemoryandenergyoverhead. However,
lessefficiencyimprovementisobservedinotherscenarioswithlargerbatchsizes.
Larger models benefit more from FP16 quantization. By comparing Figures 2a and 2b, we
observe that FP16 quantization improves all models’ efficiency performance (except #Params.),
particularlymemoryoverhead. Largermodelsappeartobenefitmorefromquantization. Asshown
inFigures2cand2d, whileOPUSexperiencesminimalefficiencygainsfromquantizationapart
fromincreasedthroughput,WMT21-Meta’sefficiencydramaticallyimproveswithFP16quantization,
nearlydoublingthroughputandreducinglatency,memoryoverhead,andenergyconsumptionbyhalf
ormore. Theseresultshighlightthepromiseofadvancingquantizationtechniquesforlargermodels
inordertoimprovethetrade-offbetweenaccuracyandefficiency.
Insingle-GPUinference,theGPUaccountsforonlyaminorportionoftheenergyconsumption.
ThisisdemonstratedbyFigure3. ThisexperimentusesasingleRTX8000GPUwithamaximum
powerof260W.WenotethattheGPUrarelyoperatesatfullpower,implyingthatGPUhours,a
metriccommonlyusedtogaugetrainingcomputationaloverhead(Hendersonetal.,2020;Kasaietal.,
2021b),isunsuitableforestimatinginferenceGPUenergy. EvenduringthemostGPU-intensive
runsbytheWMT21-Metamodel,whereitdoesoperateatfullcapacity,theGPUonlyaccountsfor
onethirdofthetotalmachinepower. Thisobservationdivergesfrompreviousfindingsontraining,
whereGPUsareestimatedtoconstitutearound70%oftheenergyusage(Dodgeetal.,2022). We
attributethedifferencetotheincreasedmemoryanddiskIOdemandsduringinference,coupledwith
lowerGPUutilizationandincreasedidlingtimeduetosmallercomputekernelsduringinference
Thisdisparitysuggeststhatefficiencyconclusionsdrawnfromtrainingneedcarefulexamination
whenappliedtoinference. Interestingly,weobserveacorrelationbetweenhigherGPUpowerand
higherpowerutilizationbyothercomponents. Weconjecturethatthisisatleastpartiallyduetothe
increasedfanactivityneededforcooling.
7
T (h wro ou rdg sh /p su )t #Params M M M MB B 2 2M MA AR R 1 1T T 0
0
0 0M M 4 12 2 1 .O M 28 BM T (h wro ou rdg sh /p su )t #Params M M M MB B 2 2M MA AR R 1 1T T 0
0
0 0M M 4 12 2 1 .O M 28 BM
1600 10M O WP MU TS 19-Meta 1600 10M O WP MU TS 19-Meta
WMT21-Meta WMT21-Meta
1200 100M 1200 100M
800 1B 800 1B
400 10B 400 10B
Latency 100 400 700 1000 30 35 40 45BLEU Latency 100 400 700 1000 30 35 40 45BLEU
(ms) (ms)
24 150 24 150
16 100 16 100
8 50 8 50
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(a)FP32. (b)FP16
Throughput #Params FP32 Throughput #Params FP32
(words/s) FP16 (words/s) FP16
1600 10M 1600 10M
1200 100M 1200 100M
800 1B 800 1B
400 10B 400 10B
Latency 100 400 700 1000 30 35 40 45BLEU Latency 100 400 700 1000 30 35 40 45BLEU
(ms) (ms)
24 150 24 150
16 100 16 100
8 50 8 50
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(c)OPUS,FP32vs.FP16. (d)WMT21-Meta,FP32vs.FP16.
Figure2: PerformanceofvariousmodelsontheWMT14DE-EN,representedintermsofBLEU
scores and a range of efficiency metrics. To more accurately reflect real-world applications, the
figuresincludethroughputmetricsfromtheofflinescenario,latencyandGPUmemorymetricsfrom
thesinglestreamscenario,andenergymetricsfromthefixedbatchingscenario. Forallmetrics,outer
ringsindicatebetterperformance. #Paramsispresentedonalogarithmicscale.
68 00 00 3 10. 91 9% 1 97. 96% 2 29. 06 2% 1 97. 88% 2 17.
8P
9
5o %w
1
96e
.
2r
4
o %f the
3
2R
0.
1e 7s 6%t
1 19. 12 0%
G 1P
6
9.U
03
P
%
1o 85.w 14e %r
2 18. 72 8% 1 86. 70% 233 6.
00%
3 21 2.9 6% 68 00 00 3 10. 91 9% 1 97. 96% 2 29. 06 2% 1 97. 88% 2 17.
8P
9
5o %w
1
96e
.
2r
4
o %f the
3
2R
0.
1e 7s 6%t
1 19. 12 0%
G 1P
6
9.U
03
P
%
1o 85.w 14e %r
2 18. 72 8% 1 86. 70% 233 6.
00%
3 21 2.9 6%
400 400
200 463464 480455 477469 488464 463448 455459 533482 200 463464 480455 477469 488464 463448 455459 533482
0 0
FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16 FP32 FP16
MBART M2OMBART M2M M2M100 M2M100 OPUS WMT19-MetaWMT21-Meta MBART M2OMBART M2M M2M100 M2M100 OPUS WMT19-MetaWMT21-Meta
610M 610M 418M 1.2B 74M 314M 4.7B 610M 610M 418M 1.2B 74M 314M 4.7B
(a)Singlestream. (b)Offline.
Figure3: PowerconsumptioninWattsacrossdifferentmodelinferencerunsinthesinglestream(3a)
andoffline(3b)scenarios. PurplebarsindicatethepowerconsumedbytheGPU,whilethelightblue
barsrepresentthepowerconsumptionofallothersystemcomponents,excludingtheGPU.Thewhite
numbersdenotetheabsolutepowerconsumptionvaluesinWatts,whilethepercentagenumbersatop
thebarsprovidetheproportionofpowerconsumptionthatisaccountedforbytheGPU.
8
)W(
rewoP
egarevA
)W(
rewoP
egarevA
4 RelatedWork
ThereisgrowinginterestinputtingefficiencyinNLPbenchmarks. Dynabench(Kielaetal.,2021)
andDynaboard(Maetal.,2021)concentrateondynamicdatasetcreationandmodelassessment,
incorporatingefficiencymetricssuchasthroughputandmemory,alongsidefairnessandrobustness
HELM (Liang et al., 2022b) evaluates language models with seven metrics including efficiency.
Though training efficiency in HELM covers energy, carbon, and wallclock time, the inference
efficiencyinthisbenchmarkonlymeasuresinferenceruntime,andtheenergyandcarbonfootprint
areonlyroughlyestimated. HULK(Zhouetal.,2021)evaluatesenergyefficiencyasaproxyof
time and cost, while Pentathlon evaluates multiple different efficiency metrics in a realistic way.
Long-RangeArena(Tayetal.,2021)buildsasetofsynthesizedtaskstoevaluatethelong-range
capabilitiesofNLPmodelsintermsofgeneralizationandcomputationalefficiencyincludingspeed
andmemoryfootprint. Anotherlineofworkhasstudiedapplication-ortask-specificefficiencysuch
astrade-offsbetweenaccuracyandenergyconsumptionforlongcontextNLPmodels(Angetal.,
2022),inferenceenergycompetitionformodelsonSuperGLUE(Wang&Wolf,2020)orstorage
efficiencyforopendomainquestionanswering(Minetal.,2021).MostrelatedtoPentathlon,MLPerf
targetsinferenceefficiencyacrossvariousreal-worldscenarios(Reddietal.,2020;Banburyetal.;
Mattsonetal.,2020). WhileMLPerfaimstostimulatebuildingmoreefficienthardwareplatforms,
Pentathlonincentivizesalgorithmicinnovations,controllingthehardware. Hostedonanin-house
machine,Pentathloncanaccuratelymeasureinferenceenergyconsumption,whichwasimpossible
forpreviousbenchmarkefforts.
5 Conclusions
We present Pentathlon, a benchmark for holistic and realistic evaluation of inference efficiency.
Pentathlontargetsmultipleaspectsofefficiencyincludinglatency,throughput,memoryoverhead,
numberofparameters,andenergyconsumption,onastrictly-controlledhardwareplatform. Inte-
gratingevaluationwithPentathlonisseamlessandcandrasticallyreducetheworkloadtomakefair
andreproducibleefficiencycomparisons. Pentathlonoffersbothtestinginreal-worldapplication
scenariosandastandardizedplatformforcomparisonbetweenanytwosubmissions. Weestablish
thistoolforNLPmodelsbutofferflexibleextensionstoadditionaltasksandscenarios. Weenvision
Pentathlontoprovideanewlensontestingalgorithmicinnovationsbyloweringthebarriertoentry
forevaluatingefficiencyandcharacterizingenvironmentalimpactoffuturemodels.
References
FarhadAkhbardeh,ArkadyArkhangorodsky,MagdalenaBiesialska,OndˇrejBojar,RajenChatterjee,
VishravChaudhary,MartaR.Costa-jussa,CristinaEspaña-Bonet,AngelaFan,ChristianFeder-
mann, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Leonie Harter,
KennethHeafield,ChristopherHoman,MatthiasHuck,KwabenaAmponsah-Kaakyire,JungoKa-
sai,DanielKhashabi,KevinKnight,TomKocmi,PhilippKoehn,NicholasLourie,ChristofMonz,
MakotoMorishita,MasaakiNagata,AjayNagesh,ToshiakiNakazawa,MatteoNegri,SantanuPal,
AllahseraAugusteTapo,MarcoTurchi,ValentinVydrin,andMarcosZampieri. Findingsofthe
2021conferenceonmachinetranslation(WMT21). InProceedingsoftheSixthConferenceonMa-
chineTranslation,pp.1–88,Online,November2021.AssociationforComputationalLinguistics.
URLhttps://aclanthology.org/2021.wmt-1.1.
NeelAlex,EliLifland,LewisTunstall,AbhishekThakur,PegahMaham,C.JessRiedel,Emmie
Hine,CarolynAshurst,PaulSedille,AlexisCarlier,MichaelNoetel,andAndreasStuhlmüller.
RAFT:Areal-worldfew-shottextclassificationbenchmark. InThirty-fifthConferenceonNeural
InformationProcessingSystemsDatasetsandBenchmarksTrack(Round2),2021. URLhttps:
//openreview.net/forum?id=bgWHz41FMB7.
PhyllisAng,BhuwanDhingra,andLisaWuWills.Characterizingtheefficiencyvs.accuracytrade-off
forlong-contextNLPmodels. InProceedingsofNLPPower! TheFirstWorkshoponEfficient
BenchmarkinginNLP,pp.113–121,Dublin,Ireland,May2022.AssociationforComputational
Linguistics. doi: 10.18653/v1/2022.nlppower-1.12. URLhttps://aclanthology.org/2022.
nlppower-1.12.
9
Colby Banbury, Vijay Janapa Reddi, Peter Torelli, Jeremy Holleman, Nat Jeffries, Csaba Kiraly,
PietroMontino,DavidKanter,SebastianAhmed,DaniloPau,etal. Mlperftinybenchmark.
LoïcBarrault,OndˇrejBojar,MartaR.Costa-jussà,ChristianFedermann,MarkFishel,YvetteGraham,
BarryHaddow,MatthiasHuck,PhilippKoehn,ShervinMalmasi,ChristofMonz,MathiasMüller,
Santanu Pal, Matt Post, and Marcos Zampieri. Findings of the 2019 conference on machine
translation(WMT19). InProceedingsoftheFourthConferenceonMachineTranslation(Volume2:
SharedTaskPapers,Day1),pp.1–61,Florence,Italy,August2019.AssociationforComputational
Linguistics. doi: 10.18653/v1/W19-5301. URLhttps://aclanthology.org/W19-5301.
AlexandraBirch,AndrewFinch,Minh-ThangLuong,GrahamNeubig,andYusukeOda. Findings
of the second workshop on neural machine translation and generation. In Proceedings of the
2ndWorkshoponNeuralMachineTranslationandGeneration,pp.1–10,Melbourne,Australia,
July 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-2701. URL
https://aclanthology.org/W18-2701.
OndˇrejBojar,ChristianBuck,ChristianFedermann,BarryHaddow,PhilippKoehn,ChristofMonz,
MattPost,andLuciaSpecia(eds.). ProceedingsoftheNinthWorkshoponStatisticalMachine
Translation,Baltimore,Maryland,USA,June2014.AssociationforComputationalLinguistics.
doi: 10.3115/v1/W14-33. URLhttps://aclanthology.org/W14-3300.
TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,
ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal. Languagemodelsare
few-shotlearners. Advancesinneuralinformationprocessingsystems,33:1877–1901,2020.
QingqingCao,YashKumarLal,HarshTrivedi,ArunaBalasubramanian,andNiranjanBalasubrama-
nian. IrEne: Interpretableenergypredictionfortransformers. InProc.ofACL,2021.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:
Scalinglanguagemodelingwithpathways. arXivpreprintarXiv:2204.02311,2022.
Mostafa Dehghani, Yi Tay, Anurag Arnab, Lucas Beyer, and Ashish Vaswani. The efficiency
misnomer. In International Conference on Learning Representations, 2022. URL https://
openreview.net/forum?id=iulEMLYh1uR.
JesseDodge,TaylorPrewitt,RemiTachetdesCombes,ErikaOdmark,RoySchwartz,EmmaStrubell,
AlexandraSashaLuccioni,NoahA.Smith,NicoleDeCario,andWillBuchanan. Measuringthe
carbonintensityofaiincloudinstances. In2022ACMConferenceonFairness,Accountability,
and Transparency, FAccT ’22, pp. 1877–1894, New York, NY, USA, 2022. Association for
ComputingMachinery. ISBN9781450393522. doi: 10.1145/3531146.3533234. URLhttps:
//doi.org/10.1145/3531146.3533234.
Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal,
MandeepBaines,OnurCelebi,GuillaumeWenzek,VishravChaudhary,NamanGoyal,TomBirch,
VitaliyLiptchinsky,SergeyEdunov,EdouardGrave,MichaelAuli,andArmandJoulin. Beyond
english-centricmultilingualmachinetranslation. J.Mach.Learn.Res.,22(1),jan2021. ISSN
1532-4435.
JaredFernandez, JacobKahn, ClaraNa, YonatanBisk, andEmmaStrubell. Theframeworktax:
Disparitiesbetweeninferenceefficiencyinresearchanddeployment,2023.
YoavFreundandRobertE.Schapire. Adesicion-theoreticgeneralizationofon-linelearningandan
applicationtoboosting. InPaulVitányi(ed.),ComputationalLearningTheory,pp.23–37,Berlin,
Heidelberg,1995.SpringerBerlinHeidelberg. ISBN978-3-540-49195-8.
YaoFu,HaoPeng,LituOu,AshishSabharwal,andTusharKhot. Specializingsmallerlanguage
modelstowardsmulti-stepreasoning,2023.
HiroakiHayashi,YusukeOda,AlexandraBirch,IoannisKonstas,AndrewFinch,Minh-ThangLuong,
Graham Neubig, and Katsuhito Sudoh. Findings of the third workshop on neural generation
andtranslation. InProceedingsofthe3rdWorkshoponNeuralGenerationandTranslation,pp.
1–14,HongKong,November2019.AssociationforComputationalLinguistics. doi: 10.18653/v1/
D19-5601. URLhttps://aclanthology.org/D19-5601.
10
KennethHeafield,HiroakiHayashi,YusukeOda,IoannisKonstas,AndrewFinch,GrahamNeubig,
XianLi,andAlexandraBirch.Findingsofthefourthworkshoponneuralgenerationandtranslation.
InProceedingsoftheFourthWorkshoponNeuralGenerationandTranslation,pp.1–9,Online,
July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ngt-1.1. URL
https://aclanthology.org/2020.ngt-1.1.
Peter Henderson, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan Jurafsky, and Joelle Pineau.
Towardsthesystematicreportingoftheenergyandcarbonfootprintsofmachinelearning. Journal
ofMachineLearningResearch,21(1),2020.
JungoKasai,HaoPeng,YizheZhang,DaniYogatama,GabrielIlharco,NikolaosPappas,YiMao,
WeizhuChen,andNoahA.Smith. FinetuningpretrainedtransformersintoRNNs. InProceedings
ofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pp.10630–10643,
OnlineandPuntaCana,DominicanRepublic,November2021a.AssociationforComputational
Linguistics. doi:10.18653/v1/2021.emnlp-main.830. URLhttps://aclanthology.org/2021.
emnlp-main.830.
Jungo Kasai, Hao Peng, Yizhe Zhang, Dani Yogatama, Gabriel Ilharco, Nikolaos Pappas,
Yi Mao, Weizhu Chen, and Noah A. Smith. Finetuning pretrained transformers into RNNs.
arXiv:2103.13076,2021b.
KashifNizamKhan, MikaelHirki, TapioNiemi, JukkaK.Nurminen, andZhonghongOu. Rapl
in action: Experiences in using rapl for power measurements. ACM Trans. Model. Perform.
Eval. Comput. Syst., 3(2), mar 2018. ISSN 2376-3639. doi: 10.1145/3177754. URL https:
//doi.org/10.1145/3177754.
DouweKiela,MaxBartolo,YixinNie,DivyanshKaushik,AtticusGeiger,ZhengxuanWu,Bertie
Vidgen,GrushaPrasad,AmanpreetSingh,PratikRingshia,ZhiyiMa,TristanThrush,Sebastian
Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, and
Adina Williams. Dynabench: Rethinking benchmarking in NLP. In Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational Linguistics:
HumanLanguageTechnologies,pp.4110–4124,Online,June2021.AssociationforComputational
Linguistics. doi: 10.18653/v1/2021.naacl-main.324. URLhttps://aclanthology.org/2021.
naacl-main.324.
TomKocmi,RachelBawden,OndˇrejBojar,AntonDvorkovich,ChristianFedermann,MarkFishel,
Thamme Gowda, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Rebecca Knowles,
PhilippKoehn,ChristofMonz,MakotoMorishita,MasaakiNagata,ToshiakiNakazawa,Michal
Novák,MartinPopel,andMajaPopovic´. Findingsofthe2022conferenceonmachinetranslation
(WMT22). InProceedingsoftheSeventhConferenceonMachineTranslation(WMT),pp.1–45,
Abu Dhabi, United Arab Emirates (Hybrid), December 2022. Association for Computational
Linguistics. URLhttps://aclanthology.org/2022.wmt-1.1.
AlexandreLacoste,AlexandraSashaLuccioni,VictorSchmidt,andThomasDandres. Quantifying
thecarbonemissionsofmachinelearning. ArXiv,abs/1910.09700,2019.
MikeLewis,YinhanLiu,NamanGoyal,MarjanGhazvininejad,AbdelrahmanMohamed,OmerLevy,
VeselinStoyanov,andLukeZettlemoyer. BART:Denoisingsequence-to-sequencepre-training
for natural language generation, translation, and comprehension. In Proceedings of the 58th
AnnualMeetingoftheAssociationforComputationalLinguistics,pp.7871–7880,Online,July
2020.AssociationforComputationalLinguistics. doi: 10.18653/v1/2020.acl-main.703. URL
https://aclanthology.org/2020.acl-main.703.
PercyLiang,RishiBommasani,TonyLee,DimitrisTsipras,DilaraSoylu,MichihiroYasunaga,Yian
Zhang,DeepakNarayanan,YuhuaiWu,AnanyaKumar,BenjaminNewman,BinhangYuan,Bobby
Yan,CeZhang,ChristianCosgrove,ChristopherD.Manning,ChristopherRé,DianaAcosta-Navas,
DrewA.Hudson,EricZelikman,EsinDurmus,FaisalLadhak,FriedaRong,HongyuRen,Huaxiu
Yao,JueWang,KeshavSanthanam,LaurelOrr,LuciaZheng,MertYuksekgonul,MiracSuzgun,
NathanKim,NeelGuha,NiladriChatterji,OmarKhattab,PeterHenderson,QianHuang,Ryan
Chi,SangMichaelXie,ShibaniSanturkar,SuryaGanguli,TatsunoriHashimoto,ThomasIcard,
TianyiZhang,VishravChaudhary,WilliamWang,XuechenLi,YifanMai,YuhuiZhang,andYuta
Koreeda. Holisticevaluationoflanguagemodels,2022a.
11
PercyLiang,RishiBommasani,TonyLee,DimitrisTsipras,DilaraSoylu,MichihiroYasunaga,Yian
Zhang,DeepakNarayanan,YuhuaiWu,AnanyaKumar,BenjaminNewman,BinhangYuan,Bobby
Yan,CeZhang,ChristianCosgrove,ChristopherD.Manning,ChristopherRé,DianaAcosta-Navas,
DrewA.Hudson,EricZelikman,EsinDurmus,FaisalLadhak,FriedaRong,HongyuRen,Huaxiu
Yao,JueWang,KeshavSanthanam,LaurelOrr,LuciaZheng,MertYuksekgonul,MiracSuzgun,
NathanKim,NeelGuha,NiladriChatterji,OmarKhattab,PeterHenderson,QianHuang,Ryan
Chi,SangMichaelXie,ShibaniSanturkar,SuryaGanguli,TatsunoriHashimoto,ThomasIcard,
TianyiZhang,VishravChaudhary,WilliamWang,XuechenLi,YifanMai,YuhuiZhang,andYuta
Koreeda. Holisticevaluationoflanguagemodels,2022b.
XiangyangLiu,TianxiangSun,JunliangHe,JiawenWu,LinglingWu,XinyuZhang,HaoJiang,
Zhao Cao, Xuanjing Huang, and Xipeng Qiu. Towards efficient NLP: A standard evaluation
andastrongbaseline. InProceedingsofthe2022ConferenceoftheNorthAmericanChapterof
theAssociationforComputationalLinguistics: HumanLanguageTechnologies,pp.3288–3303,
Seattle,UnitedStates,July2022.AssociationforComputationalLinguistics. doi: 10.18653/v1/
2022.naacl-main.240. URLhttps://aclanthology.org/2022.naacl-main.240.
AlexandraSashaLuccioni,SylvainViguier,andAnne-LaureLigozat. Estimatingthecarbonfootprint
ofbloom,a176bparameterlanguagemodel,2022.
ZhiyiMa,KawinEthayarajh,TristanThrush,SomyaJain,LedellYuWu,RobinJia,Christopher
Potts,AdinaWilliams,andDouweKiela. Dynaboard: AnEvaluation-As-A-ServicePlatformfor
HolisticNext-GenerationBenchmarking. November2021. URLhttps://openreview.net/
forum?id=TCarYAus7JL.
PeterMattson,VijayJanapaReddi,ChristineCheng,CodyColeman,GregDiamos,DavidKanter,
PauliusMicikevicius,DavidPatterson,GuentherSchmuelling,HanlinTang,etal. Mlperf: An
industrystandardbenchmarksuiteformachinelearningperformance. IEEEMicro,40(2):8–16,
2020.
SewonMin,JordanBoyd-Graber,ChrisAlberti,DanqiChen,EunsolChoi,MichaelCollins,Kelvin
Guu,HannanehHajishirzi,KentonLee,JennimariaPalomaki,ColinRaffel,AdamRoberts,Tom
Kwiatkowski, PatrickLewis, YuxiangWu, HeinrichKüttler, LinqingLiu, PasqualeMinervini,
PontusStenetorp,SebastianRiedel,SoheeYang,MinjoonSeo,GautierIzacard,FabioPetroni,
Lucas Hosseini, Nicola De Cao, Edouard Grave, Ikuya Yamada, Sonse Shimaoka, Masatoshi
Suzuki, Shumpei Miyawaki, Shun Sato, Ryo Takahashi, Jun Suzuki, Martin Fajcik, Martin
Docekal, Karel Ondrej, Pavel Smrz, Hao Cheng, Yelong Shen, Xiaodong Liu, Pengcheng He,
Weizhu Chen, Jianfeng Gao, Barlas Oguz, Xilun Chen, Vladimir Karpukhin, Stan Peshterliev,
DmytroOkhonko,MichaelSchlichtkrull,SonalGupta,YasharMehdad,andWen-tauYih. Neurips
2020efficientqacompetition: Systems,analysesandlessonslearned. InHugoJairEscalanteand
KatjaHofmann(eds.),ProceedingsoftheNeurIPS2020CompetitionandDemonstrationTrack,
volume133ofProceedingsofMachineLearningResearch,pp.86–111.PMLR,06–12Dec2021.
URLhttps://proceedings.mlr.press/v133/min21a.html.
NathanNg,KyraYee,AlexeiBaevski,MyleOtt,MichaelAuli,andSergeyEdunov. Facebookfair’s
wmt19newstranslationtasksubmission. InProc.ofWMT,2019.
DavidPatterson,JosephGonzalez,UrsHölzle,QuocLe,ChenLiang,Lluis-MiquelMunguia,Daniel
Rothchild,DavidR.So,MaudTexier,andJeffDean. Thecarbonfootprintofmachinelearning
trainingwillplateau,thenshrink. Computer,55(7):18–28,2022. doi: 10.1109/MC.2022.3148714.
Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah Smith, and Lingpeng Kong.
Randomfeatureattention. InProc.ofICLR,2021.
MattPost.AcallforclarityinreportingBLEUscores.InProceedingsoftheThirdConferenceonMa-
chineTranslation: ResearchPapers,pp.186–191,Belgium,Brussels,October2018.Association
forComputationalLinguistics. URLhttps://www.aclweb.org/anthology/W18-6319.
AlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,andIlyaSutskever. Language
modelsareunsupervisedmultitasklearners,2018.
12
VijayJanapaReddi,ChristineCheng,DavidKanter,PeterMattson,GuentherSchmuelling,Carole-
JeanWu,BrianAnderson,MaximilienBreughe,MarkCharlebois,WilliamChou,RameshChukka,
CodyColeman,SamDavis,PanDeng,GregDiamos,JaredDuke,DaveFick,J.ScottGardner,
ItayHubara,SachinIdgunji,ThomasB.Jablin,JeffJiao,TomSt.John,PankajKanwar,David
Lee,JefferyLiao,AntonLokhmotov,FranciscoMassa,PengMeng,PauliusMicikevicius,Colin
Osborne,GennadyPekhimenko,ArunTejusveRaghunathRajan,DilipSequeira,AshishSirasao,
FeiSun,HanlinTang,MichaelThomson,FrankWei,EphremWu,LingjieXu,KoichiYamada,
Bing Yu, George Yuan, Aaron Zhong, Peizhao Zhang, and Yuchen Zhou. Mlperf inference
benchmark. 2020ACM/IEEE47thAnnualInternationalSymposiumonComputerArchitecture
(ISCA),May2020. doi: 10.1109/isca45697.2020.00045. URLhttp://dx.doi.org/10.1109/
ISCA45697.2020.00045.
Victor Schmidt, Goyal-Kamal, Benoit Courty, Boris Feld, SabAmine, kngoyal, Franklin Zhao,
Aditya Joshi, Sasha Luccioni, Mathilde Léval, Alexis Bogroff, Hugues de Lavoreille, Niko
Laskaris,LiamConnell,ZiyaoWang,ArminCatovic,DouglasBlank,MichałSte˛chły,alencon,
AmineSaboni,JPW,MinervaBooks,HervéM.,ConnorMcCarthy,ErikJohannesHusom,Jake
Tae, Sébastien Tourbier, and kraktus. mlco2/codecarbon: v2.1.1, May 2022. URL https:
//doi.org/10.5281/zenodo.6537300.
RoySchwartz,JesseDodge,NoahA.Smith,andOrenEtzioni. Greenai. Communicationsofthe
ACM,63(12):54–63,2020.
Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy considerations for
moderndeeplearningresearch. InAAAIConferenceonArtificialIntelligence,2020.
YuqingTang,ChauTran,XianLi,Peng-JenChen,NamanGoyal,VishravChaudhary,JiataoGu,
and Angela Fan. Multilingual translation from denoising pre-training. In Findings of the As-
sociation for Computational Linguistics: ACL-IJCNLP 2021, pp. 3450–3466, Online, August
2021.AssociationforComputationalLinguistics. doi: 10.18653/v1/2021.findings-acl.304. URL
https://aclanthology.org/2021.findings-acl.304.
YiTay,MostafaDehghani,DaraBahri,andDonaldMetzler. Efficienttransformers: Asurvey. arXiv:
2009.06732,2020.
Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao,
LiuYang,SebastianRuder,andDonaldMetzler. Longrangearena: Abenchmarkforefficient
transformers. InProc.ofICLR,2021.
RomalThoppilan,DanielDeFreitas,JamieHall,NoamShazeer,ApoorvKulshreshtha,Heng-Tze
Cheng,AliciaJin,TaylorBos,LeslieBaker,YuDu,YaGuangLi,HongraeLee,HuaixiuSteven
Zheng,AminGhafouri,MarceloMenegali,YanpingHuang,MaximKrikun,DmitryLepikhin,
JamesQin,DehaoChen,YuanzhongXu,ZhifengChen,AdamRoberts,MaartenBosma,Yanqi
Zhou,Chung-ChingChang,IgorKrivokon,WillRusch,MarcPickett,KathleenS.Meier-Hellstern,
MeredithRingelMorris,TulseeDoshi,RenelitoDelosSantos,TojuDuke,JohnnySoraker,Ben
Zevenbergen,VinodkumarPrabhakaran,MarkDiaz,BenHutchinson,KristenOlson,Alejandra
Molina,ErinHoffman-John,JoshLee,LoraAroyo,RaviRajakumar,AlenaButryna,Matthew
Lamm,ViktoriyaKuzmina,JoeFenton,AaronCohen,RachelBernstein,RayKurzweil,Blaise
Aguera-Arcas,ClaireCui,MarianCroak,EdH.Chi,andQuocLe. Lamda: Languagemodels
fordialogapplications. CoRR,abs/2201.08239,2022. URLhttps://arxiv.org/abs/2201.
08239.
Jörg Tiedemann. Parallel data, tools and interfaces in OPUS. In Proceedings of the Eighth In-
ternational Conference on Language Resources and Evaluation (LREC’12), pp. 2214–2218,
Istanbul,Turkey,May2012.EuropeanLanguageResourcesAssociation(ELRA). URLhttp:
//www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf.
JörgTiedemannandSanthoshThottingal. OPUS-MT—Buildingopentranslationservicesforthe
World. InProceedingsofthe22ndAnnualConferenecoftheEuropeanAssociationforMachine
Translation(EAMT),Lisbon,Portugal,2020.
ChauTran,ShrutiBhosale,JamesCross,PhilippKoehn,SergeyEdunov,andAngelaFan. Facebook
ai’swmt21newstranslationtasksubmission. InProc.ofWMT,2021.
13
MarcosTreviso,Ji-UngLee,TianchuJi,BettyvanAken,QingqingCao,ManuelR.Ciosici,Michael
Hassid, Kenneth Heafield, Sara Hooker, Colin Raffel, Pedro H. Martins, André F. T. Martins,
JessicaZosaForde,PeterMilder,EdwinSimpson,NoamSlonim,JesseDodge,EmmaStrubell,
Niranjan Balasubramanian, Leon Derczynski, Iryna Gurevych, and Roy Schwartz. Efficient
methodsfornaturallanguageprocessing: Asurvey,2022.
AlexWangandThomasWolf. OverviewoftheSustaiNLP2020sharedtask. InProceedingsof
SustaiNLP:WorkshoponSimpleandEfficientNaturalLanguageProcessing,pp.174–178,Online,
November2020.AssociationforComputationalLinguistics.doi:10.18653/v1/2020.sustainlp-1.24.
URLhttps://aclanthology.org/2020.sustainlp-1.24.
YuWang,Gu-YeonWei,andDavidBrooks. Asystematicmethodologyforanalysisofdeeplearning
hardwareandsoftwareplatforms. ProceedingsofMachineLearningandSystems,2:30–43,2020.
Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus
for sentence understanding through inference. In Proceedings of the 2018 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, Volume 1 (Long Papers), pp. 1112–1122, New Orleans, Louisiana, June
2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1101. URL https:
//aclanthology.org/N18-1101.
Carole-JeanWu,RamyaRaghavendra,UditGupta,BilgeAcun,NewshaArdalani,KiwanMaeng,
GloriaChang,FionaAgaBehram,JamesHuang,CharlesBai,MichaelGschwind,AnuragGupta,
MyleOtt,AnastasiaMelnikov,SalvatoreCandido,DavidBrooks,GeetaChauhan,BenjaminLee,
Hsien-HsinS.Lee,BugraAkyildiz,MaximilianBalandat,JoeSpisak,RaviJain,MikeRabbat,
andKimHazelwood. Sustainableai: Environmentalimplications,challengesandopportunities. In
MLSys,2022a.
Zhaofeng Wu, Hao Peng, Nikolaos Pappas, and Noah A. Smith. Modeling context with linear
attentionforscalabledocument-leveltranslation. InFindingsoftheAssociationforComputa-
tionalLinguistics: EMNLP2022,pp.6931–6939,AbuDhabi,UnitedArabEmirates,December
2022b.AssociationforComputationalLinguistics. URLhttps://aclanthology.org/2022.
findings-emnlp.515.
ZheweiYao,RezaYazdaniAminabadi,MinjiaZhang,XiaoxiaWu,ConglongLi,andYuxiongHe.
Zeroquant: Efficientandaffordablepost-trainingquantizationforlarge-scaletransformers. ArXiv,
abs/2206.01861,2022.
YanliZhao,RohanVarma,Chien-ChinHuang,ShenLi,MinXu,andAlbanDesmaison. Introducing
pytorch fully sharded data parallel (FSDP) api, 2021. URL https://pytorch.org/blog/
introducing-pytorch-fully-sharded-data-parallel-api/.
XiyouZhou,ZhiyuChen,XiaoyongJin,andWilliamYangWang. HULK:Anenergyefficiency
benchmark platform for responsible natural language processing. In Proceedings of the 16th
ConferenceoftheEuropeanChapteroftheAssociationforComputationalLinguistics: System
Demonstrations,pp.329–336,Online,April2021.AssociationforComputationalLinguistics. doi:
10.18653/v1/2021.eacl-demos.39. URLhttps://aclanthology.org/2021.eacl-demos.39.
14
Checklist
1. Forallauthors...
(a) Dothemainclaimsmadeintheabstractandintroductionaccuratelyreflectthepaper’s
contributionsandscope? [Yes]
(b) Didyoudescribethelimitationsofyourwork? [Yes] AsmentionedinSection 2.1,
our current server for Pentathlon houses two Nvidia RTX 8000 GPUs. We plan to
supportotherhardwareplatformssuchastheedgeNvidiaJetsonTX2inthenearfuture.
OurcurrentGPUsarebasedonthepreviousgenerationofTuringmicroarchitecture,
whichmightnotfullyutilizethestate-of-the-artGPUtechnologyandCUDAsoftware
improvements.Toaddressthis,wehaveplanstoupgradeourserverwithmoreadvanced
GPUsinthenearfuture.
Ourrequirementsforsubmissionofcodeandcheckpointsnaturallyprohibittheevalua-
tionoflargelanguagemodelsthatarenotpubliclyavailable,oranylargemodelthat
ourhardwareisnotcapableofrunning. Inadditiontotheplantoupgradeourhardware,
theinsightslearnedfromPentathloncouldhelpbetterquantifyhardware’simpacton
efficiencyandpossiblyextrapolatethefindingstothemodelswearecurrentlyunable
toevaluate.
Finally,whilePentathlonfocusesonevaluatinginferenceefficiency,weacknowledge
thechallengesandcomplexityofproperlyevaluatingtrainingefficiency. Ourhopeis
thattheinsightsandmethodologiesdevelopedthroughPentathloncanalsocontribute
toimprovedtoolsandstrategiesforevaluatingandcomparingthetrainingefficiencyof
largemodelsinthefuture.
(c) Didyoudiscussanypotentialnegativesocietalimpactsofyourwork? [Yes]Thegoal
ofthisworkistomitigatethenegativesocietalimpactsofMLduetotheincreasing
computationaldemandsofMLmodels,byprovidingabetterplatformforbenchmarking
modelefficiency. Wedonotanticipateanydirectnegativesocietalimpacts. Theremay
bepotentialindirectimpactsifourplatformfacilitatesdrasticimprovementsinML
modelefficiency,leadingtoe.g. (a)increasedoverallemissionsduetoincreasedease
ofuse/access(i.e. Jevonsparadox)or(b)increasedaccesstoMLmodelsbybadactors,
whowouldhaveotherwisebeenlimitedbycomputationalresources. Inthecaseof(b),
wehopethatanyincreasedaccessfacilitatedbyourworkisequallyapplicabletogood
actors,balancingtheeffect.
(d) Haveyoureadtheethicsreviewguidelinesandensuredthatyourpaperconformsto
them? [Yes]
2. Ifyouareincludingtheoreticalresults...
(a) Didyoustatethefullsetofassumptionsofalltheoreticalresults? [N/A]
(b) Didyouincludecompleteproofsofalltheoreticalresults? [N/A]
3. Ifyouranexperiments(e.g. forbenchmarks)...
(a) Didyouincludethecode,data,andinstructionsneededtoreproducethemainexperi-
mentalresults(eitherinthesupplementalmaterialorasaURL)?[Yes]TheURLto
codeisprovidedinSection1.
(b) Didyouspecifyallthetrainingdetails(e.g.,datasplits,hyperparameters,howthey
werechosen)? [Yes]WeusethestandarddatasplitsforevaluationwiththeWMT14
DE-ENdataset. Wedonotperformmodeltraininginthiswork.
(c) Didyoureporterrorbars(e.g.,withrespecttotherandomseedafterrunningexperi-
mentsmultipletimes)? [No]Wedonotperformtraining,sotherearenoaveragesover
randomseeds. AsdiscussedinSection3,wefoundinpreliminaryexperimentsthat
therewaslittlevariationinefficiencymeasuresacrossruns,soweruneachevaluation
settingonlyonce.
(d) Didyouincludethetotalamountofcomputeandthetypeofresourcesused(e.g.,type
of GPUs, internal cluster, or cloud provider)? [Yes] Reported or computable from
resultsreportedinSection3.
4. Ifyouareusingexistingassets(e.g.,code,data,models)orcurating/releasingnewassets...
(a) Ifyourworkusesexistingassets,didyoucitethecreators? [Yes]SeeSection3.
15
(b) Didyoumentionthelicenseoftheassets? [No]ThelicenseoftheWMT14DE-EN
datasetisnotlistedonthedatasetwebsite. However,dataissourcedfromtheEuroParl
corpuswithnolistedcopyrightrestrictions.8
(c) DidyouincludeanynewassetseitherinthesupplementalmaterialorasaURL?[No]
(d) Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou’re
using/curating? [No] We use WMT14 DE-EN, a popular long-standing corpus of
paralleltranslationdata. Thecuratorsofthisdatasetdonotreportthisinformation.
(e) Didyoudiscusswhetherthedatayouareusing/curatingcontainspersonallyidentifiable
information or offensive content? [No] We use WMT14 DE-EN, a popular long-
standingcorpusofparalleltranslationdata. Thecuratorsofthisdatasetdonotreport
thisinformation.
5. Ifyouusedcrowdsourcingorconductedresearchwithhumansubjects...
(a) Didyouincludethefulltextofinstructionsgiventoparticipantsandscreenshots,if
applicable? [N/A]
(b) Did you describe any potential participant risks, with links to Institutional Review
Board(IRB)approvals,ifapplicable? [N/A]
(c) Didyouincludetheestimatedhourlywagepaidtoparticipantsandthetotalamount
spentonparticipantcompensation? [N/A]
8FormoreinformationseetheWMT-14Taskhttps://www.statmt.org/wmt14/translation-task.
htmlandtheEuroParlCorpushttps://www.statmt.org/europarl/
16
Appendices
A TextClassificationwithRAFT
RAFTisacollectionof11datasetsthatfocusonfew-shottextclassificationinreal-worldsettings.
HerewefocusontheADECorpusV2(ADE)portion,aimingtoclassifysentencesderivedfrom
medicalreportsasrelatedorunrelatedtoadversedrugeffects. Severalbaselinemodels,providedby
theauthors,wereevaluatedforefficiency,including:
• AdaBoost(Freund&Schapire,1995): astrongnon-neuralclassifierbasedondecisiontrees.
• BARTZeroShotMNLI:BART(Lewisetal.,2020)finetunedontheMNLIdataset(Williams
etal.,2018). Itisusedasazero-shotclassifier.
• GPT-2(Radfordetal.,2018): usedasafew-shotclassifierwith25in-contexttrainingdemonstra-
tionsandtask-specificinstructions.
TheimplementationforallmodelsisattributedtoAlexetal.(2021).9 Atthetimeofwriting,RAFT
hasnotreleasedthegoldlabelsofthetestsplit,andthereforewereporttheF1performancebyAlex
etal.(2021).
AdaBoost
Results. Figure 4 provides a comparison of the above
Throughput ( 1in 0s Kt./s) # 1Params G B MAP aRT j.2 T
modelswithamajority-classbaseline(Maj.). AdaBoost,a 1K 1K
non-neuralmodel,emergesasastrongcompetitorinterms 100 1M
oftheaccuracy-efficiencytrade-off. Interestingly,GPT-2,
10 1B
despite having fewer parameters, lags behind BART in
termsofthroughput,latency,andenergyconsumption.We Latency (ms)0 20 40 60 20 40 60 80F1
believethatthiscouldbeduetothein-contextfew-shot 3 30
examples, which lead to significantly longer inputs for 2 20
GPT-2comparedtoBART.Nonetheless,GPT-2manages
1 10
toachievethehighestF1scoreinthisexperiment.
0 0
GPU Memory (GiB) Energy (W.h)
B Additional
Figure4: Models’efficiencyandaccu-
ExperimentswithMachineTranslation racyperformanceonRAFTtestdata. F1
numbersareduetoAlexetal.(2021).
All models’ implementation and checkpoints are available on Hugging Face, with the following
identifiers:
• MBART50: facebook/mbart-large-50-many-to-{many, one}-mmt;
• M2M100: facebook/m2m100_{418M, 1.2B};
• OPUS:Helsinki-NLP/opus-mt-de-en;
• WMT19-Meta: facebook/wmt19-de-en;
• WMT21-Meta: facebook/wmt21-dense-24-wide-en-x.
AdditionalFP32vs.FP16comparisons.Figure5providesanadditionalsetofcomparisonsbetween
FP32andFP16acrossvariousmodelsonWMT14DE-EN,complementingtheresultspresentedin
Section3. Thegeneraltrendsmirrorthoseobservedearlier,withlargermodelsbenefitingmorein
termsofefficiencyfromquantizationcomparedtosmallerones.
ONNX improves throughput, latency, and energy overhead, at the cost of increased GPU
memoryoverhead. Pentathlonmakeslittleassumptionsonthemodels’implementationandbackend
runtime, andallowsuserstousebotheager-executionresearchframeworkslikePyTorchaswell
as specialized inference runtimes like Open Neural Network Exchange (ONNX). Here we study
ONNX’simpactonthemodel’sefficiency.
ONNXisacross-platformstaticruntimethatusespre-compiledcomputationalgraphs. Itallows
foraggressive,globalahead-of-timecompileroptimizations,andcanbringsubstantiallatencyand
throughput improvements in inference settings with small batch size. The readers are referred
9https://github.com/oughtinc/raft-baselines
17
to https://onnx.ai/ for more details. As of now, ONNX supports conversion from models
implementedwithPyTorch,Tensorflow,andJAX,enablingustomakedirectcomparisonsbetween
PyTorchimplementationandONNXinourmachinetranslationexperimentswithWMT14DE-EN.
As shown in Figure 7, when comparing five different models in a single-stream scenario using
PyTorchandONNXruntime,ONNXdeliverssubstantialimprovementsinthroughput,latency,and
energyoverhead,especiallyforlargermodels. However,thiscomeswithanincreaseinGPUmemory
consumption,whichislikelyduetothestorageofpre-compiledcomputationalgraphsontheGPU.
WMT19MetaandWMT21,whichutilizetheFullyShardedDataParalleltechnique(FSDP;Zhao
etal.,2021),areexcludedfromthisexperimentduetocompatibilitychallengeswithONNXand
FSDP.
Our preliminary experiments find that ONNX brings marginal efficiency improvements in other
scenariosthatuselargerbatchsizes, whichisconsistentwiththeobservationbyFernandezetal.
(2023).
ResultsonWMT14EN->DE.
Figure6providesasummaryoftheefficiencyperformanceofvariousmodelsontheWMT14English-
to-German(EN->DE)translationtask. TheresultsareshownforbothFP32andFP16models. The
observedtrendsalignwiththosediscussedinSection3.
18
Throughput #Params FP32 Throughput #Params FP32
(words/s) FP16 (words/s) FP16
1600 10M 1600 10M
1200 100M 1200 100M
800 1B 800 1B
400 10B 400 10B
Latency 100 400 700 1000 30 35 40 45BLEU Latency 100 400 700 1000 30 35 40 45BLEU
(ms) (ms)
24 150 24 150
16 100 16 100
8 50 8 50
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(a)MBARTM2O. (b)MBARTM2M.
Throughput #Params FP32 Throughput #Params FP32
(words/s) FP16 (words/s) FP16
1600 10M 1600 10M
1200 100M 1200 100M
800 1B 800 1B
400 10B 400 10B
Latency 100 400 700 1000 30 35 40 45BLEU Latency 100 400 700 1000 30 35 40 45BLEU
(ms) (ms)
24 150 24 150
16 100 16 100
8 50 8 50
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(c)M2M100418M. (d)M2M1001.2B.
Throughput #Params FP32
(words/s) FP16
1600 10M
1200 100M
800 1B
400 10B
Latency 100 400 700 1000 30 35 40 45BLEU
(ms)
24 150
16 100
8 50
0 0
GPU Memory Energy
(GiB) (W.h)
(e)WMT19Meta.
Figure5: AdditionalresultsofvariousmodelsontheWMT14DE-ENusingFP32(red)andFP16
(blue). SimilarlytoFigure2,thethroughputmetricsarefromtheofflinescenario,latencyandGPU
memorymetricsfromthesinglestreamscenario,andenergymetricsfromthefixedbatchingscenario.
19
T (h wro ou rdg sh /p su )t #Params M M M MB B 2 2M MA AR R 1 1T T 0
0
0 0M M 4 12 2 1 .O M 28 BM T (h wro ou rdg sh /p su )t #Params M M M MB B 2 2M MA AR R 1 1T T 0
0
0 0M M 4 12 2 1 .O M 28 BM
1600 10M O WP MU TS 19-Meta 1600 10M O WP MU TS 19-Meta
WMT21-Meta WMT21-Meta
1200 100M 1200 100M
800 1B 800 1B
400 10B 400 10B
Latency 100 400 700 1000 30 35 40 45BLEU Latency 100 400 700 1000 30 35 40 45BLEU
(ms) (ms)
24 150 24 150
16 100 16 100
8 50 8 50
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(a)FP32. (b)FP16
Figure6: PerformanceofvariousmodelsontheWMT14EN-DE.FollowingFigure2,thefigures
includethroughputmetricsfromtheofflinescenario,latencyandGPUmemorymetricsfromthe
singlestreamscenario,andenergymetricsfromthefixedbatchingscenario. Forallmetrics,outer
ringsindicatebetterperformance. #Paramsispresentedonalogarithmicscale.
20
Throughput #Params PyTorch Throughput #Params PyTorch
(words/s) ONNX (words/s) ONNX
280 10M 280 10M
210 100M 210 100M
140 1B 140 1B
70 10B 70 10B
Latency 0 150 300 450 25 30 35 40BLEU Latency 0 150 300 450 25 30 35 40BLEU
(ms) (ms)
12 45 12 45
8 30 8 30
4 15 4 15
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(a)MBARTM2O. (b)MBARTM2M.
Throughput #Params PyTorch Throughput #Params PyTorch
(words/s) ONNX (words/s) ONNX
280 10M 280 10M
210 100M 210 100M
140 1B 140 1B
70 10B 70 10B
Latency 0 150 300 450 25 30 35 40BLEU Latency 0 150 300 450 25 30 35 40BLEU
(ms) (ms)
12 45 12 45
8 30 8 30
4 15 4 15
0 0 0 0
GPU Memory Energy GPU Memory Energy
(GiB) (W.h) (GiB) (W.h)
(c)M2M100418M. (d)M2M1001.2B.
Throughput #Params PyTorch
(words/s) ONNX
280 10M
210 100M
140 1B
70 10B
Latency 0 150 300 450 25 30 35 40BLEU
(ms)
12 45
8 30
4 15
0 0
GPU Memory Energy
(GiB) (W.h)
(e)OPUS.
Figure7: Accuracyandefficiencyperformancecomparisonsoffivedifferentmodelswhileusing
PyTorch(red)andONNX(blue)runtime. WMT19MetaandWMT21MetarelyontheFullySharded
DataParallel(FSDP;Zhaoetal.,2021)intheirimplementation,whichcomplicatestheirconversions
toONNX,andarethereforenotincludedinthisfigure. Allefficiencymetricsaremeasuredinthe
single-streamscenario;inpreliminaryexperiments,weobservethattheefficiencygainsfromONNX
aremarginalinotherscenarios,asexpected.
21
