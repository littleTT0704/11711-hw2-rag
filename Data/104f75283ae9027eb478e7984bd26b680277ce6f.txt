Robust Navigation with Language Pretraining and Stochastic Sampling
XiujunLi♠♦ ChunyuanLi♦ QiaolinXia♣ YonatanBisk♠♦♥
AsliCelikyilmaz♦ JianfengGao♦ NoahA.Smith♠♥ YejinChoi♠♥
♠PaulG.AllenSchoolofComputerScience&Engineering,UniversityofWashington
♣PekingUniversity ♦MicrosoftResearchAI ♥AllenInstituteforArtificialIntelligence
xiujun,ybisk,nasmith,yejin @cs.washington.edu
{ }
xql@pku.edu.cn xiul,chunyl,jfgao @microsoft.com
{ }
Abstract Training Evaluation
Challenge1 SeenEnv. UnseenEnv.
Core to the vision-and-language navigation
(VLN)challengeisbuildingrobustinstruction
Generalization
representations and action decoding schemes,
which can generalize well to previously un-
Challenge2 Teacher.Forcing Student.Forcing
seeninstructionsandenvironments.Inthispa-
per, wereporttwosimplebuthighlyeffective
ExposureBias
methods to address these challenges and lead
to a new state-of-the-art performance. First, Figure1: TwochallengesinVLN.
weadaptlarge-scalepretrainedlanguagemod-
elstolearntextrepresentationsthatgeneralize enhanced with attention (Anderson et al., 2018;
better to previously unseen instructions. Sec-
Wang et al., 2019; Fried et al., 2018; Ma et al.,
ond,weproposeastochasticsamplingscheme
2019a). Twoimportantcomponentsaresharedby
toreducetheconsiderablegapbetweentheex-
all VLN agents: (i) an Instruction Encoder that
pert actions in training and sampled actions
employs a language model (LM) for instruction
in test, so that the agent can learn to correct
itsownmistakesduringlongsequentialaction understanding; and (ii) an Action Decoder, where
decoding. Combiningthetwotechniques, we an appropriate sequence-level training scheme is
achieveanewstateoftheartontheRoom-to- required for sequential decision-making. Each
Roombenchmarkwith6%absolutegainover componentfacesitsownchallenges(seeFigure1).
the previous best result (47% 53%) on the
The first challenge is generalizing grounded
→
SuccessRateweightedbyPathLengthmetric.
natural language instruction understanding from
seen to unseen environments. Specifically, in the
1 Introduction
R2R task, only 69% of bigrams are shared be-
The vision-and-language navigation (VLN) task, tween training and evaluation.1 Existing work
learning to navigate in visual environments based leveragespretrainedGloVeembeddings(Penning-
on natural language instructions, has attracted ton et al., 2014) to help generalize. In computer
interest throughout the artificial intelligence re- vision, it has been shown that large-scale models
searchcommunity(Hemachandraetal.,2015;An- pretrained on ImageNet can transfer the knowl-
dersonetal.,2018;Chenetal.,2019;Savvaetal., edge to downstream applications (Yosinski et al.,
2019). Itfostersresearchonmultimodalrepresen- 2014), thus improving generalization. Compara-
tationsandreinforcementlearning,andservesasa ble language-based transfer learning has not been
test bed for many real-world applications such as shownforinstructionunderstandinginVLN.
in-homerobots. Thesecondchallengeisexposurebias(Ranzato
IntherecentRoom-to-Room(R2R)VLNchal- et al., 2016) for the action decoder, due to the
lenge (Anderson et al., 2018), most state-of-the- discrepancy between training and inference. This
art methods are developed based on an encoder- problem is common to many tasks where decod-
decoder framework (Cho et al., 2014; Sutskever ing is needed, including text generation, abstrac-
et al., 2014), where a natural language instruc- tivesummarization,andmachinetranslation(Ben-
tion is represented as a sequence of words, and
1Table1showsn-gramoverlapstatisticsbetweentraining
a navigation trajectory as a sequence of actions, seenandvalidationseen/unseenenvironments.
Pre5trainedLanguageModels
n-gram(s) ValidationSeen ValidationUnseen
Language x c z
1 87.2% 80.7% Instructions i i,t t <<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""RRRR3333kkkkVVVVmmmmaaaauuuuppppHHHHwwwwFFFFqqqqDDDDyyyyHHHHVVVV////vvvvQQQQYYYYXXXXaaaaWWWWxxxxTTTTLLLLEEEE===="""">>>>AAAAAAAAAAAABBBB8888HHHHiiiiccccbbbbVVVVAAAA9999SSSSwwwwNNNNBBBBEEEEJJJJ2222LLLLXXXXzzzzFFFF++++RRRRSSSS1111ttttFFFFooooNNNNggggFFFFeeee5555EEEE0000DDDDJJJJooooYYYYxxxxnnnnBBBBJJJJEEEEooooSSSSwwwwtttt5555mmmmLLLL1111mmmmyyyyuuuu3333ffffsssszzzzoooonnnnhhhhyyyyKKKK++++wwwwssssVVVVDDDDEEEE1111pppp9999jjjj555577779999xxxxkkkk1111yyyyhhhhiiiiQQQQ8888GGGGHHHHuuuu////NNNNMMMMDDDDMMMMvvvvTTTTKKKKSSSSwwww6666PPPPvvvvffffXXXXmmmmFFFFllllddddWWWW11119999oooo7777hhhhZZZZ2222ttttrrrreeee2222dddd0000rrrr7777xxxx88880000bbbbZZZZwwwwaaaaxxxxhhhhssssssssllllrrrrGGGG5555DDDD6666nnnnllllUUUUmmmmjjjjeeeeQQQQIIIIGGGGSSSS3333yyyyeeeeGGGGUUUUxxxxVVVVKKKK3333ggggppppHHHH11111111OOOO////9999cccciiiiNNNNFFFFbbbbGGGG++++wwww3333HHHHCCCCuuuu4444ooooOOOOttttIIIIggggEEEEoooo++++iiiikkkkhhhh6666wwwwTTTTRRRRuuuuRRRRpppp0000hhhhOOOO9999ccccssssWWWWvvvv++++jjjjOOOOQQQQZZZZRRRRLLLLkkkkppppAAAAIIII55556666rrrr3333yyyyVVVV6666ccccffffssss1111RRRRxxxxjjjjUUUUxxxxSSSSaaaa9999uuuuBBBBnnnn2222AAAA3333oooowwwwYYYYFFFFkkkk3333xxxxSSSS6666qqqqSSSSWWWWJJJJ5555SSSSNNNN6666IIIICCCC3333HHHHddddVVVVUUUUccccddddvvvvNNNNZZZZggggddddPPPPyyyyIIIIllllTTTT++++iiiiSSSSKKKKjjjjSSSSuuuuNNNNZZZZKKKKbbbb++++nnnnssssiiiioooossssnnnnaaaassssQQQQtttteeeeppppKKKKAAAA7777ttttoooojjjjccccVVVV////////PPPPaaaaKKKKUUUUaaaaXXXX3333UUUUzzzzooooJJJJEEEEWWWWuuuu2222XXXXxxxxRRRRllllEEEEqqqqCCCCMMMMZZZZllll++++TTTT////rrrrCCCCccccIIIIZZZZyyyy7777AAAAhhhhllllRRRRrrrrhhhhbbbbCCCCRRRRttttSSSSQQQQxxxxmmmm6666jjjjEEEEoooouuuuhhhhGGGGDDDDxxxx5555WWWWXXXXSSSSPPPPKKKKssssGGGGffffjjjjWWWW4444PPPPaaaa////UUUUrrrrvvvvIIII4444iiiinnnnAAAAEEEExxxx3333AAAAKKKKAAAAVVVVxxxxAAAADDDDWWWW6666ggggDDDDgggg1111ggggooooOOOOAAAAZZZZXXXXuuuuHHHHNNNNMMMM99996666LLLL9999++++55559999zzzzFFFFssssLLLLXXXXjjjj5555zzzzCCCCHHHH////ggggffffffff4444AAAArrrreeeeKKKKQQQQUUUUAAAA========<<<<////llllaaaatttteeeexxxxiiiitttt>>>> <<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""GGGG2222VVVVWWWWRRRR8888ggggiiiiqqqqPPPP77777777iiiiYYYY8888hhhhyyyyFFFFXXXXppppkkkkXXXXQQQQccccttttnnnngggg===="""">>>>AAAAAAAAAAAABBBB9999HHHHiiiiccccbbbbVVVVDDDDLLLLSSSSggggNNNNBBBBEEEEOOOOyyyyNNNNrrrrxxxxhhhhffffUUUUYYYY9999eeeeBBBBooooPPPPggggQQQQccccKKKKuuuuCCCCHHHHooooMMMMeeeevvvvEEEEYYYYwwwwTTTTwwwwggggWWWWccccLLLLssssZZZZDDDDYYYYZZZZMMMMjjjjuuuu7777zzzzvvvvQQQQGGGGwwwwrrrrLLLLffff4444ccccWWWWDDDDIIIIllll77779999GGGGGGGG////++++jjjjZZZZPPPPHHHHQQQQRRRRMMMMLLLLGGGGooooqqqqqqqqbbbbrrrrqqqq7777ggggkkkkQQQQKKKKgggg6666777777777777RRRRTTTTWWWW1111jjjjcccc2222tttt4444rrrrbbbbppppZZZZ3333ddddvvvvffff2222DDDD8888uuuuFFFFRRRR00008888SSSSppppZZZZrrrrzzzzBBBBYYYYhhhhnnnnrrrrddddkkkkAAAANNNNllll0000LLLLxxxxBBBBggggqqqqUUUUvvvvJJJJ1111ooooTTTTqqqqNNNNAAAA8888llllYYYYwwwwuuuuppppvvvv6666rrrrTTTTHHHHXXXXRRRRssssTTTTqqqqEEEESSSSccccJJJJ9999yyyyMMMM6666UUUUCCCCIIIIUUUUjjjjKKKKKKKKVVVV////KKKKwwwwbbbbhhhhIIIITTTTllllvvvvUUUUxxxxccccYYYYNNNN4444rrrrVVVV9999yyyyqqqqOOOOwwwwNNNNZZZZJJJJdddd6666CCCCVVVVGGGGCCCCBBBBeeeeqqqq////88881111eeee3333HHHHLLLLIIII22224444QQQQiiiiaaaappppMMMMRRRR3333PPPPTTTTddddDDDDPPPPqqqqEEEEbbbbBBBBJJJJMMMM9999LLLL3333ddddTTTTwwwwhhhhLLLLIIIIRRRRHHHHffffCCCCOOOOppppYYYYppppGGGG3333PPPPjjjjZZZZ7777OOOOiiiiccccnnnnFFFFmmmmllllTTTT8888JJJJYYYY22221111JJJJIIIIZZZZuuuurrrrvvvviiiiYYYYxxxxGGGGxxxxkkkkyyyyiiiiwwwwHHHHZZZZGGGGFFFFIIIIddddmmmm2222ZZZZuuuuKKKK////3333mmmmddddFFFFMMMMMMMMbbbbPPPPxxxxMMMMqqqqSSSSZZZZEEEErrrrNNNNllll8888UUUUppppppppJJJJggggTTTTKKKKYYYYJJJJkkkkLLLL7777QQQQnnnnKKKKGGGGccccWWWWEEEEKKKKZZZZFFFFvvvvZZZZWWWWwwwwooooZZZZUUUUUUUU4444YYYY2222pppp5555IIIINNNNwwwwVVVVtttt++++eeeeZZZZUUUU0000LLLL6666uuuueeeeWWWW////UUUUeeeerrrriiiiqqqq111122220000UUUUccccRRRRTTTTiiiiBBBBUUUUzzzzggggHHHHDDDD66666666hhhhBBBBvvvvddddQQQQhhhhwwwwYYYYwwwweeeeIIIIJJJJnnnneeeeIIIIUUUU3333ZZZZ++++yyyy8888OOOOOOOO////OOOOxxxx7777yyyy11114444CCCCxxxxmmmmjjjjuuuuEEEEPPPPnnnnMMMM8888ffffnnnnCCCCOOOORRRR++++wwww========<<<<////llllaaaatttteeeexxxxiiiitttt>>>> <<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""llllSSSS9999++++rrrrvvvv3333////YYYYddddddddssssZZZZ2222ccccvvvvTTTTXXXXEEEESSSSPPPPXXXXllllhhhhaaaaUUUUUUUU===="""">>>>AAAAAAAAAAAABBBB8888HHHHiiiiccccbbbbVVVVAAAA9999SSSSwwwwNNNNBBBBEEEEJJJJ2222LLLLXXXXzzzzFFFF++++RRRRSSSS1111ttttFFFFooooNNNNggggFFFFeeee5555EEEE0000DDDDJJJJooooYYYYxxxxnnnnBBBBJJJJEEEEooooSSSSwwwwtttt5555mmmmLLLL1111mmmmyyyyuuuu3333ffffsssszzzzggggnnnnxxxxyyyyKKKK++++wwwwssssVVVVDDDDEEEE1111pppp9999jjjj555577779999xxxxkkkk1111yyyyhhhhiiiiQQQQ8888GGGGHHHHuuuu////NNNNMMMMDDDDMMMMvvvvTTTTKKKKSSSSwwww6666PPPPvvvvffffXXXXmmmmFFFFllllddddWWWW11119999oooo7777hhhhZZZZ2222ttttrrrreeee2222dddd0000rrrr7777xxxx88880000bbbbZZZZwwwwaaaaxxxxhhhhssssssssllllrrrrGGGG5555DDDD6666nnnnllllUUUUmmmmjjjjeeeeQQQQIIIIGGGGSSSS3333yyyyeeeeGGGGUUUUxxxxVVVVKKKK3333ggggppppHHHH11111111OOOO////9999cccciiiiNNNNFFFFbbbbGGGG++++wwww3333HHHHCCCCuuuu4444ooooOOOOttttIIIIggggEEEEoooo++++iiiikkkkhhhh6666wwwwTTTTRRRRuuuuRRRRpppp0000ssssNNNNeeeeuuuueeeeJJJJXXXX////RRRRnnnnIIIIMMMMggggllllyyyyUUUUooooEEEEcccc9999VVVV77775555qqqq9999OOOOPPPPWWWWaaaaqqqq4444RRRRiiiiaaaapppptttteeee3333AAAATTTT7777CCCCbbbbUUUUYYYYOOOOCCCCSSSSTTTT4444ppppddddVVVVLLLLLLLLEEEE8888ppppGGGGddddMMMMDDDDbbbbjjjjmmmmqqqqqqqquuuuOOOO1111mmmmssss4444MMMMnnnn5555MMMMQQQQppppffffRRRRLLLLFFFFxxxxppppVVVVGGGGMMMMllllNNNN////TTTT2222RRRRUUUUWWWWTTTTttttWWWWooooeeeettttUUUUFFFFIIIIdddd22220000ZZZZuuuuKKKK////3333nnnnttttFFFFKKKKPPPPLLLLbbbbiiiiZZZZ0000kkkkiiiiLLLLXXXXbbbbLLLL4444ooooSSSSiiiiXXXXBBBBmmmmEEEEyyyy////JJJJ33331111hhhhOOOOEEEEMMMM5555ddddooooQQQQyyyyIIII9999yyyytttthhhhAAAA2222ppppooooQQQQxxxxddddRRRRiiiiUUUUXXXXQQQQrrrrDDDD44448888jjjjJJJJppppnnnnllllUUUUDDDDvvvvxxxxrrrrccccnnnnllllddddqqqqVVVV3333kkkkccccRRRRTTTTiiiiCCCCYYYYzzzziiiiFFFFAAAACCCC6666ggggBBBBjjjjddddQQQQhhhhwwwwYYYYwwwwUUUUPPPPAAAAMMMMrrrr////DDDDmmmmGGGGeeee////FFFFeeee////cccc++++5555qqqq0000FFFFLLLL555588885555hhhhDDDD////wwwwPPPPnnnn8888AAAAwwwwZZZZyyyyQQQQXXXXQQQQ========<<<<////llllaaaatttteeeexxxxiiiitttt>>>>
2 77.4% 68.9%
3 65.6% 57.3%
4 50.8% 44.4% TeacherAction
aT
StochasticActionSampling
<<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""YYYYNNNNuuuuNNNN9999YYYYRRRRPPPP1111nnnnVVVVPPPP2222ffffYYYYvvvvNNNNffffiiiiNNNNQQQQkkkkhhhhUUUUttttLLLL4444===="""">>>>AAAAAAAAAAAABBBB////HHHHiiiiccccbbbbVVVVDDDDLLLLSSSSssssNNNNAAAAFFFFJJJJ33334444rrrrPPPPUUUUVVVV7777ddddLLLLNNNNYYYYBBBBFFFFccccllllUUUUQQQQEEEEXXXXRRRRbbbbdddduuuuKKKKzzzzQQQQFFFF7777SSSSxxxxTTTTKKKKaaaaTTTTdddduuuuhhhhkkkkEEEEmmmmZZZZuuuuhhhhBBBBDDDDiiiirrrr7777hhhhxxxxooooYYYYhhhhbbbbPPPP8888SSSSddddffff++++OOOOkkkkzzzzUUUUJJJJbbbbDDDDwwwwwwwwcccczzzzrrrrmmmmXXXXeeee++++bbbb4444sssseeeeAAAAaaaaHHHHOOOOffffbbbbWWWWllllvvvvffff2222NNNNzzzzaaaarrrruuuuxxxxUUUUdddd////ffff2222DDDDwwww7777ttttoooo++++OOOOuuuujjjjhhhhJJJJFFFFWWWWYYYYddddGGGGIIIIllllJJJJ9999nnnn2222ggggmmmmuuuuGGGGQQQQdddd4444CCCCBBBBYYYYPPPP1111aaaaMMMMhhhhLLLL5555ggggPPPPXXXX99992222WWWW////iiii9999RRRR6666YYYY0000jjjj2222QQQQbbbb0000pppphhhh5555IIIIZZZZllllIIIIHHHHnnnnBBBBKKKKwwwwEEEEggggjjjjuuuuzzzzbbbb0000gggg4444zzzzkkkkDDDD9999kkkkwwwwJJJJDDDDAAAAFFFFyyyyNNNNpppp5555PPPPrrrrLLLLrrrrTTTTssssOOOOZZZZAAAA66668888SSSSttttyyyyRRRR1111VVVVKKKKIIII1111ssssrrrr++++GGGG44444444ggggmmmmIIIIZZZZNNNNAAAABBBBddddFFFF66664444DDDDooooxxxxeeeeBBBBllllRRRRwwwwKKKKllllggggeeeeXXXXWWWWYYYYaaaaBBBBYYYYTTTTOOOOiiiiMMMMTTTTNNNNjjjjBBBBUUUUkkkkppppBBBBppppLLLL5555uuuuHHHHzzzz////GGGGZZZZUUUUccccYYYY4444iiiiJJJJRRRR5555EEEEvvvvBBBBcccc////bbbb2222RRRRkkkkVVVVDDDDrrrrNNNNPPPPTTTTNNNNZZZZBBBBFFFFRRRRLLLL3333uuuuFFFF++++JJJJ88883333SSSSCCCCCCCC44449999jjjjIIIIuuuu4444wwwwSSSSYYYYppppIIIIttttDDDDQQQQSSSSIIIIwwwwRRRRLLLLhhhhooooAAAAoooo++++5555YYYYhhhhRRRREEEEaaaaggggiiiihhhhiiiippppuuuussssmmmmEEEE6666JJJJIIIIhhhhRRRRMMMMXXXX1111VVVVTTTTggggrrrrvvvv88885555VVVVXXXXSSSSvvvvWWWWiiii4444TTTTssssOOOO9999vvvv6666wwww3333bbbb8888oooo6666KKKKuuuuggggEEEEnnnnaaaaJJJJzzzz5555KKKKIIIIrrrr1111EEEERRRR3333qqqqIIIIUUUU6666iiiiKKKKIIIIUUUUPPPPaaaaNNNNXXXX9999GGGGYYYY9999WWWWSSSS////WWWWuuuu////WWWWxxxxGGGGFFFF2222zzzzyyyypppp0000aaaa++++ggggPPPPrrrr8888wwwweeee8888++++5555VVVV2222<<<<////llllaaaatttteeeexxxxiiiitttt>>>>
T vaa lb il de at1 i: onN- sg er ea nm as ndin ust nr su ec eti no en no vv ire orl na mp es nta tsti .sticsbetween
StudentAction
a
<<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""5555NNNNKKKKqqqqRRRRooooYYYYCCCCuuuuZZZZBBBBddddMMMM4444ZZZZCCCCaaaa1111QQQQaaaayyyyppppRRRRLLLL++++rrrrIIII===="""">>>>AAAAAAAAAAAABBBB////HHHHiiiiccccbbbbVVVVDDDDLLLLSSSSssssNNNNAAAAFFFFJJJJ33334444rrrrPPPPUUUUVVVV7777ddddLLLLNNNNYYYYBBBBFFFFccccllllUUUUQQQQEEEEXXXXRRRRbbbbdddduuuuKKKKxxxxooooHHHH9999DDDDGGGGMMMMppppllllOOOO2222qqqqGGGGTTTTSSSSZZZZiiii5555EEEEUUUUKKKKIIIIvvvv++++LLLLGGGGhhhhSSSSJJJJuuuu////RRRRBBBB3333////oooo2222TTTTNNNNggggttttttttPPPPTTTTBBBBwwwwOOOOOOOOddddeeee7777ppppnnnnjjjjxxxx4444JJJJrrrrccccJJJJxxxxvvvvaaaa2222VVVV1111bbbbXXXX1111jjjjssss7777JJJJVVVV3333dddd7777ZZZZ3333dddduuuu3333DDDDwwww44447777OOOOkkkkooooUUUUZZZZWWWW0000aaaaiiiiUUUUjjjj1111ffffKKKKKKKKZZZZ4444JJJJKKKK1111ggggYYYYNNNNggggvvvvVVVVggggxxxxEEEEvvvvqqqqCCCCddddffff3333ppppddddeeeeFFFF3333HHHH5555nnnnSSSSPPPPJJJJLLLL3333kkkkMMMMbbbbMMMMCCCC8888llllYYYY8888ooooBBBBTTTTAAAAkkkkYYYYaaaa2222rrrrWWWWBBBBHHHH2222QQQQkkkkffff8888ggggGGGGIIIIYYYYEEEEJJJJQQQQHHHHaaaaXXXX55550000OOOO77777777jjjjSSSSccccGGGGffffAAAAyyyyccccUUUUttttSSSSRRRRyyyyVVVVaaaaQQQQ////ttttrrrrMMMMIIIIppppooooEEEEjjjjIIIIJJJJVVVVBBBBCCCCtttt++++66664444TTTTgggg5555ccccRRRRBBBBZZZZwwwwKKKKllllllllccccHHHHiiiiWWWWYYYYxxxxooooVVVVMMMMyyyyZZZZnnnn1111DDDDJJJJQQQQmmmmZZZZ9999rrrrJJJJZZZZ++++BBBByyyyffffGGGGGGGGWWWWEEEEgggg0000iiiiZZZZJJJJwwwwHHHHPPPP1111NNNN8888bbbbGGGGQQQQmmmm1111TTTTkkkkPPPPffffTTTTBBBBYYYYRRRR9999aaaaJJJJXXXXiiiiPPPP99995555////QQQQSSSSCCCCSSSSyyyy////jjjjMMMMkkkk6666AAAASSSSTTTToooo////FFFFCCCCQQQQCCCCQQQQ4444SSSSLLLLJJJJvvvvCCCCIIIIKKKK0000ZZZZBBBBppppIIIIYYYYQQQQqqqqrrrrjjjjJJJJiiiiuuuummmmEEEEKKKKEEEELLLLBBBB9999FFFFUUUU1111JJJJbbbbiiiiLLLLXXXX11114444mmmmnnnnbbbbOOOOGGGG6666zzzzTTTTcccc2222////NNNN666688886666qqqqssssoooo4444KKKKOOOO0000DDDDEEEE6666RRRRSSSS66666666QQQQEEEE11110000gggg1111qqqqoooojjjjSSSShhhhKKKK0000TTTTNNNN6666RRRRWWWW////WWWWkkkk////VVVViiiivvvvVVVVssssffff88889999EEEEVVVVqqqq9999yyyyppppooooTTTT++++wwwwPPPPnnnn8888AAAAuuuu3333WWWWVVVVddddQQQQ========<<<<////llllaaaatttteeeexxxxiiiitttt>>>>
S
g
<<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""LLLLVVVV4444YYYYccccFFFFOOOOccccoooojjjjaaaapppp3333BBBBTTTT6666BBBBSSSSXXXXOOOOaaaassssQQQQ8888eeeeRRRR8888===="""">>>>AAAAAAAAAAAABBBB77773333iiiiccccbbbbVVVVBBBBNNNNSSSS8888NNNNAAAAEEEEJJJJ3333UUUUrrrr1111qqqq////qqqqhhhh66669999LLLLBBBBaaaahhhhXXXXkkkkooooiiiigggghhhh6666LLLLXXXXjjjjxxxxWWWWssssBBBB////QQQQhhhhrrrrLLLLZZZZbbbbNNNNqqqqllllmmmm00003333ccccnnnnQQQQiiiillll9999EEEE999944448888aaaaCCCCIIIIVVVV////++++OOOONNNN////++++NNNN2222zzzzYYYYHHHHbbbbXXXX0000wwww8888HHHHhhhhvvvvhhhhppppllll5555QQQQSSSSqqqqFFFFQQQQddddffff9999ddddggggpppprrrr6666xxxxuuuubbbbWWWW8888XXXXtttt0000ssss7777uuuu3333vvvv5555BBBB++++ffffCCCCooooZZZZZZZZJJJJMMMMMMMM99995555kkkkiiiiUUUUxxxx0000JJJJ6666CCCCGGGGSSSS6666FFFF4444EEEEwwwwVVVVKKKK3333kkkkkkkk1111pppp3333EEEEggggeeeeTTTTssssYYYY3333cccc777788889999hhhhPPPPXXXXRRRRiiiiTTTTqqqqAAAAccccccccpppp99992222MMMM6666UUUUCCCCIIIISSSSjjjjKKKKKKKKVVVVOOOOooooNNNNqqqqjjjj4444UUUUJJJJnnnnvvvvffffLLLLFFFFbbbbffffmmmmzzzzkkkkFFFFWWWWiiiiZZZZeeeeTTTTCCCCuuuuRRRRoooo9999MMMMttttffffvvvvTTTTBBBBhhhhWWWWccccwwwwVVVVMMMMkkkkmmmmNNNN6666XXXXppppuuuuiiiivvvv6666EEEEaaaahhhhRRRRMMMM8888mmmmmmmmppppllllxxxxmmmmeeeeUUUUjjjjaaaaiiiiAAAA999966661111VVVVNNNNGGGGYYYYGGGG33338888yyyyvvvv3333ddddKKKKzzzzqqqqwwwwSSSSkkkkiiiijjjjRRRRtttthhhhSSSSSSSSuuuuffffpppp7777YYYYkkkkJJJJjjjjYYYY8888ZZZZxxxxYYYYDDDDttttjjjjiiiikkkkOOOOzzzz7777MMMM3333EEEE////7777xxxxuuuuhhhhttttGGGG1111PPPPxxxxEEEEqqqqzzzzZZZZAAAArrrrttttllllggggUUUUZZZZZZZZJJJJggggQQQQmmmmbbbbPPPPkkkk1111BBBBoooozzzzllllCCCCOOOOLLLLaaaaFFFFMMMMCCCC3333ssssrrrrYYYYUUUUOOOOqqqqKKKKUUUUMMMMbbbbUUUUccccmmmmGGGG4444CCCC2222////vvvvEEEEppppaaaaFFFFzzzzXXXXPPPPrrrrXXXXnnnn3333llll5555XXXX6666TTTTRRRR5555HHHHEEEEUUUU7777ggggFFFFKKKKrrrrggggwwwwRRRRXXXXUUUU4444QQQQ4444aaaa0000AAAAQQQQGGGGEEEEpppp7777hhhhFFFFdddd6666ccccRRRR++++ffffFFFFeeeeXXXXcccc++++FFFFqqqq0000FFFFJJJJ555588885555hhhhjjjj9999wwwwPPPPnnnn8888AAAAZZZZJJJJmmmmPPPPiiiiAAAA========<<<<////llllaaaatttteeeexxxxiiiitttt>>>>
( ·) Visuas
<<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""yyyyZZZZ00001111YYYYkkkkzzzzddddYYYYaaaabbbb6666KKKK7777wwwwkkkkaaaa8888OOOOrrrreeeeoooosssshhhhBBBB5555YYYY===="""">>>>AAAAAAAAAAAABBBB8888HHHHiiiiccccbbbbVVVVDDDDLLLLSSSSggggNNNNBBBBEEEEOOOOyyyyNNNNrrrrxxxxhhhhffffUUUUYYYY9999eeeeBBBBooooPPPPggggKKKKeeeeyyyyKKKKooooMMMMeeeeggggFFFF44448888RRRRzzzzEEEEOOOOSSSSEEEEGGGGYYYYnnnnssss8888mmmmQQQQmmmmddddllllllllppppllllccccIIIISSSS77777777CCCCiiiiwwwwddddFFFFvvvvPPPPoooo55553333vvvvwwwwbbbbJJJJ8888kkkkeeeeNNNNLLLLGGGGggggooooaaaajjjjqqqqpppprrrrssssrrrrTTTTKKKKSSSSwwww6666PPPPvvvvffffXXXXmmmmFFFFttttffffWWWWNNNNzzzzqqqq7777hhhhdddd2222ttttnnnndddd2222zzzz8888ooooHHHHxxxx44441111bbbbZZZZwwwwaaaaxxxxhhhhssssssssllllrrrrFFFFpppphhhh9999RRRRyyyyKKKKTTTTRRRRvvvvooooEEEEDDDDJJJJ22224444nnnnhhhhVVVVIIIIWWWWSSSStttt8888LLLLxxxx7777ccccxxxxvvvvPPPPXXXXFFFFjjjjRRRRaaaawwwwffffccccJJJJLLLLwwwwnnnnqqqqJJJJDDDDLLLLSSSSLLLLBBBBKKKKDDDDrrrrppppMMMMeeeeuuuuGGGGEEEEbbbbHHHHTTTTPPPPvvvvbbbbLLLLFFFFbbbb////qqqqzzzz0000FFFFWWWWSSSSZZZZCCCCTTTTCCCCuuuuSSSSoooo99998888ttttffff3333UUUUHHHHMMMMUUUUssssUUUU1111MMMMkkkkmmmmtttt7777QQQQRRRR++++ggggrrrr2222MMMMGGGGhhhhRRRRMMMM8888mmmmmmmmppppmmmm1111qqqqeeeeUUUUDDDDaaaammmmQQQQ99995555xxxxVVVVFFFFPPPPFFFFbbbbSSSS++++bbbbHHHHzzzzwwwwllllZZZZ00004444ZZZZkkkkCCCCgggg2222rrrrjjjjSSSSSSSSuuuuffffpppp7777IIIIqqqqPPPPKKKK2222ooookkkkKKKKXXXXaaaaeeeeiiiiOOOOLLLLLLLLLLLL3333kkkkzzzz8888zzzz++++uuuukkkkGGGGFFFF33333333MMMMqqqqGGGGTTTTFFFFLLLLllllmmmmiiii0000VVVVRRRRKKKKggggnnnnGGGGZZZZPPPPYYYY9999GGGGQQQQjjjjDDDDGGGGccccqqqqJJJJIIII5555QQQQZZZZ4444WWWW4444llllbbbbEEEEQQQQNNNNZZZZeeeeggggyyyyKKKKrrrrkkkkQQQQgggguuuuWWWWXXXXVVVV0000nnnnzzzzoooohhhhrrrr44441111eeeeDDDD++++ssssllllKKKK7777yyyyeeeeMMMMoooowwwwggggmmmmccccwwwwjjjjkkkkEEEEccccAAAAUUUU1111uuuuIIIIMMMM6666NNNNIIIICCCCBBBBggggmmmmdddd4444hhhhTTTTffffPPPPeeeeCCCC////eeeeuuuu////eeeexxxxaaaaCCCC11114444++++ccccwwwwxxxx////IIIIHHHH3333++++QQQQOOOO222266665555BBBBWWWW<<<<////llllaaaatttteeeexxxxiiiitttt>>>>
lFt
eature
Aca
<<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====""""OOOOhhhhyyyy8888PPPPyyyy////VVVVNNNNTTTTUUUU4444MMMMVVVVssssPPPPLLLLCCCCKKKKXXXX4444OOOO666688881111IIIIUUUU===="""">>>>AAAAAAAAAAAABBBB8888HHHHiiiiccccbbbbVVVVDDDDLLLLSSSSggggNNNNBBBBEEEEOOOOyyyyNNNNrrrrxxxxhhhhffffUUUUYYYY9999eeeeBBBBooooPPPPggggKKKKeeeeyyyyKKKKooooMMMMeeeeggggFFFF44448888RRRRzzzzEEEEOOOOSSSSEEEEGGGGYYYYnnnnssss8888mmmmQQQQmmmmddddllllllllppppllllccccIIIISSSS77777777CCCCiiiiwwwwddddFFFFvvvvPPPPoooo55553333vvvvwwwwbbbbJJJJ8888kkkkeeeeNNNNLLLLGGGGggggooooaaaajjjjqqqqpppprrrrssssrrrrTTTTKKKKSSSSwwww6666PPPPvvvvffffXXXXmmmmFFFFttttffffWWWWNNNNzzzzqqqq7777hhhhdddd2222ttttnnnndddd2222zzzz8888ooooHHHHxxxx44441111bbbbZZZZwwwwaaaaxxxxhhhhssssssssllllrrrrFFFFpppphhhh9999RRRRyyyyKKKKTTTTRRRRvvvvooooEEEEDDDDJJJJ22224444nnnnhhhhVVVVIIIIWWWWSSSStttt8888LLLLxxxx7777ccccxxxxvvvvPPPPXXXXFFFFjjjjRRRRaaaawwwwffffccccJJJJLLLLwwwwnnnnqqqqJJJJDDDDLLLLSSSSLLLLBBBBKKKKDDDDrrrrppppMMMMeeeeuuuuGGGGEEEEaaaaHHHHTTTTPPPPvvvvbbbbLLLLFFFFbbbb////qqqqzzzz0000FFFFWWWWSSSSZZZZCCCCTTTTCCCCuuuuSSSSoooo99998888ttttffff3333UUUUHHHHMMMMUUUUssssUUUU1111MMMMkkkkmmmmtttt7777QQQQRRRR++++ggggrrrr2222MMMMGGGGhhhhRRRRMMMM8888mmmmmmmmppppmmmm1111qqqqeeeeUUUUDDDDaaaammmmQQQQ99995555xxxxVVVVFFFFPPPPFFFFbbbbSSSS++++bbbbHHHHzzzzwwwwllllZZZZ00004444ZZZZkkkkCCCCgggg2222rrrrjjjjSSSSSSSSuuuuffffpppp7777IIIIqqqqPPPPKKKK2222ooookkkkKKKKXXXXaaaaeeeeiiiiOOOOLLLLLLLLLLLL3333kkkkzzzz8888zzzz++++uuuukkkkGGGGFFFF33333333MMMMqqqqGGGGTTTTFFFFLLLLllllmmmmiiii0000VVVVRRRRKKKKggggnnnnGGGGZZZZPPPPYYYY9999GGGGQQQQjjjjDDDDGGGGccccqqqqJJJJIIII5555QQQQZZZZ4444WWWW4444llllbbbbEEEEQQQQNNNNZZZZeeeeggggyyyyKKKKrrrrkkkkQQQQgggguuuuWWWWXXXXVVVV0000nnnnzzzzoooohhhhrrrr44441111eeeeDDDD++++ssssllllKKKK7777yyyyeeeeMMMMoooowwwwggggmmmmccccwwwwjjjjkkkkEEEEccccAAAAUUUU1111uuuuIIIIMMMM6666NNNNIIIICCCCBBBBggggmmmmdddd4444hhhhTTTTffffPPPPeeeeCCCC////eeeeuuuu////eeeexxxxaaaaCCCC11114444++++ccccwwwwxxxx////IIIIHHHH3333++++QQQQOOOObbbbbbbbZZZZBBBBEEEE<<<<////llllaaaatttteeeexxxxiiiitttt>>>>
tiot
n
Figure2: Illustrationofproposedmethods.
gioetal.,2015). Twowidelyusedtrainingstrate-
Each instruction x is a sequence of L words,
gies are student-forcing and teacher-forcing (de- i i
x = [x ,x ,...,x ]. Given , the goal is
scribed in detail in Section 2.2). It is well-known i i,1 i,2 i,Li X
to train an agent to navigate from a starting posi-
that the sequence length determines which train-
tion s to a target position, via completing a T-
ing strategy is more effective. In the VLN lit- 0
step trajectory τ = [s ,a ,s ,a , ,s ,a ],
erature, student-forcing has been widely used, as 0 0 1 1 ··· T T
where s and a are the visual state and naviga-
early work (Anderson et al., 2018) used long tra- t t
tion action, respectively, at step t. The training
jectories(upto20steps)withasimplediscreteac-
dataset = τ, consistsofexamplepairsof
tionspace. Mostrecentwork,however,hasrelied DE { X}
instruction set and a corresponding expert tra-
on a panoramic action space (Fried et al., 2018) X
jectory τ. Our goal is to learn a policy π (τ )
in which most trajectories are only up to seven θ |X
thatmaximizesthelog-likelihoodofthetargettra-
stepslong. Insuchcases,teacher-forcingisprefer-
jectoryτ giveninstructions :
able(Tanetal.,2019). Neitherstrategyisperfect: X
teacher-forcing has exposure bias, while student- T
(cid:88)
forcing’srandomactionscancauseanagenttode- logπ θ(τ ) = logπ θ(a t s t, ), (1)
|X | X
viatefarfromthecorrectpath,renderingtheorig- t=1
inalinstructioninvalid.2
where θ are trainable parameters. The policy
To tackle these challenges, we have devel-
is usually parameterized as an attention-based
oped two techniques to enable the agent to nav-
seq2seq model, with a language encoder z =
t
igate more efficiently. For the first challenge,
f (x), and an action decoder a = f (z ,s ).
we leverage the recent large-scale pretrained lan-
θE t θD t t
Successful navigation depends on (i) precisely
guage models, BERT (Devlin et al., 2019) and
groundingtheinstructions inτ invariousenvi-
GPT(Radfordetal.,2018),toimprovetheagent’s X
ronments,and(ii)correctlymakingthecurrentde-
robustnessinunseenenvironments. Weshowthat
cision a based on previous actions/observations
t
large-scale language-only pretraining improves
τ = [s ,a , ,s ]. To address these con-
<t 0 0 t−1
generalization in grounded environments. For ···
cerns,wepropose PRESS,illustratedinFigure2.
the second challenge, we propose a stochastic
sampling scheme to balance teacher-forcing and 2.1 InstructionUnderstandingwith
student-forcing during training, so that the agent PretrainedLanguageModels
can recover from its own mistakes at inference
At each step t, the agent decides where to navi-
time. Asaresultofcombiningbothtechniques,on
gate by updating a dynamic understanding of the
the R2R benchmark test set, our agent (PRESS)3
instructionsz ,accordingtoitscurrentvisualstate
t
achieves 53% on SPL, an absolute 6% gain over
s . Giveninstructionx,thelanguageencoderpro-
t
thecurrentstateoftheart.
ceeds in two steps, end-to-end, by considering a
functiondecompositionf = f f :
2 Method
θE θx→e
◦
θe→z
f : x e, where x = [x , ,x ] is
In the VLN task, instructions are represented as a •
θx→e
→
1
···
L
represented as its (contextualized) word em-
set = x M ofM instructionspertrajectory.
X { i }i=1 beddingforme = [e 1, ,e L],withe iasthe
···
2To compensate, beam search is often used to improve
representationforwordx i;
successrates. Recentwork,e.g.,usingsearchstrategies(Ke f : e z : Foreachembeddedinstruc-
etal.,2019)orprogressmonitors(Maetal.,2019b),hasfo- •
θe→z
→
t
tion e, we ground its representations as c
cusedonmitigatingthecostofcomputingtop-krollouts. i,t
3PRETRAINEDLMSANDSTOCHASTICSAMPLING for state s
t
via neural attention. To handle
gniniarT
language variability, one may aggregate fea- W andW aretrainableprojectionmatrices.
h s
tures of multiple instructions = c M
intoasinglejointfeaturez
t
=C Mt 1 (cid:80){ M i=i 1,t c} ii ,= t.1 4 h t = f θD([s t,a t−1],h t−1) (3)
where a is the action taken at previous step,
t−1
Previous methods in VLN learn e either from andθ aretheLSTMdecoderparameters.
D
pretrained word embeddings (Pennington et al.,
Two-stage learning. The parameters of our
2014) which do not take into account word con-
agent are θ = θ ,θ ,θ . In practice,
text, or from scratch. As a result, their repre- x→e e→z D
{ }
we find that the agent overfits quickly, when the
sentations do not capture contextual information
full model is naively fine-tuned, with θ ini-
within each instruction. More importantly, they x→e
tialized by pretrained LMs (e.g., BERT). In this
tend to overfit the training instructions associated
paper, we consider a two-stage learning scheme
with seen environments, limiting their utility in
to facilitate the use of pretrained LMs for VLN.
unseenenvironments. Toremedytheseissues,we
(i)Embedding-basedstage: Wefixθ ,anduse
propose to represent e with contextualized word x→e
BERTorGPTtoprovideinstructionembeddings.
embeddingsproducedusinglarge-scalepretrained
Only θ ,θ are updated (while tuning on
languagemodels,suchasBERTandGPT. e→z D
{ }
validation). (ii) Fine-tuning stage: We train all
InstructionEncoder. Theagent’smemoryvec- model parameters θ with a smaller learning rate,
tor h captures the perception and action his- sothatθ canadapttoourVLNtask.
t−1 x→e
tory and is used to attend to the instruction x.
2.2 StochasticActionSampling
A pretrained LM f encodes the instruction
θx→e
e = [e , ,e ]; e where the representation for Acorequestionishowtolearnusefulstaterepre-
1 L i
···
word x , is built with f GPT, BERT , sentations s in Eq. (1) during the trajectory roll-
i θx→e
∈ { }
t
and θ are fine-tuned parameters. The embed- out. In other words, which action should we use
x→e
dedwordse = [e , ,e ]arepassedthroughan to interact with the environment to elicit the next
1 L
···
LSTMf toproduceasequenceoftextualfea- state? As noted, most existing work uses one of
θe→z
tures [he, ,he]. At each time step t, the tex- twoschemes: (i)Teacher-forcing(TF),wherethe
1 L
···
tual context for the instruction x is computed as agent takes ground-truth actions aT only. Though
weightedsumoftextualfeaturesinthesequence: TF enables efficient training, it results in “ex-
posure bias” because agents must follow learned
(cid:88)L rather than gold trajectories at test time. In con-
c i,t = α lhe l (2) trast,(ii)Student-forcing(SF),whereanactionaS
l=1 is drawn from the current learned policy, allows
the agent to learn from its own actions (aligning
where α = Softmax(h(cid:62)he), α places more
l t l l training and evaluation), however, it is inefficient,
weight on the word representations that are most
as the agent explores randomly when confused or
relevanttotheagent’scurrentstatus.
intheearlystagesoftraining.
Decoder. Ateachstep,theagenttakesanaction In this work, we consider a stochastic scheme
a , and the environment returns new visual obser-
(SS)toalternatebetweenchoosingactionsfromaT
t
vations; the agent first performs one-hop visual
andaSforstatetransitions g(aT,aS),inspired
←
attention f( ) to all the visual image features s , by scheduled sampling (Bengio et al., 2015). As
t
·
basedonitspreviousmemoryvectorh . Then, illustratedinFigure2,ateachstep,theagent“flips
t−1
theagentupdatesitsvisualstates astheweighted acoin”withsomeprobability(cid:15)todecidewhether
t
sum of the panoramic features, s =
(cid:80)
γ s .
totaketheteacher’sactionaTorasampledoneaS:
t j t,j t,j
Theattentionweightγ forthej-thvisualfeature
t,j
a = δaT+(1 δ)aS, (4)
s represents its importance with respect to the
t,j −
previoushistorycontexth ,computedasγ =
t−1 t,j
where δ Bernoulli((cid:15)). This allows the agent to
Softmax((W hh t−1)(cid:62)W ss t,j)(Frie (cid:80)detal.,2018) leverage∼
theadvantagesofbothTFandSF,yield-
where Softmax(r j) = exp(r j)/ j(cid:48)exp(r j(cid:48)),
ing a faster and less biased learner. We fix (cid:15) as a
constant during learning, which is different from
4Thisrecoversz = c whenonlyasingleinstructionis
t t
available. thedecayingschedulein(Bengioetal.,2015).
ValidationSeen ValidationUnseen
3 Experiments
Setting Agent SR↑ SPL↑ SR↑ SPL↑
seq2seq 51 46 32 25
3.1 Dataset S
PRESS 47(-4) 43(-3) 43(+11) 38(+13)
seq2seq 49 44 33 26
We use the Room-to-Room dataset for the VLN M
PRESS 56(+7) 53(+9) 56(+23) 50(+24)
task, built upon the Matterport3D dataset (Chang
et al., 2017), which consists of 10,800 panoramic Table2: ComparisonofPRESSandseq2seq.
views and 7,189 trajectories. Each trajectory is
paired with three natural language instructions. 3.3 EvaluationMetrics
TheR2Rdatasetconsistsoffoursplits: trainseen,
Webenchmarkouragentonthefollowingmetrics:
validation seen, validation unseen, and test un-
TL Trajectory Length measures the average
seen. Thereisnooverlapbetweenseenandunseen
lengthofthenavigationtrajectory.
environments. At the beginning of each episode,
NE NavigationErroristhemeanoftheshortest
the agent starts at a specific location, and is given
path distance in meters between the agent’s
naturalinstructions,thegoaloftheagentistonav-
finallocationandthetargetlocation.
igatetothetargetlocationasquicklyaspossible.
SR SuccessRatewithwhichtheagent’sfinallo-
cationislessthan3metersfromthetarget.
3.2 BaselineSystems
SPL SuccessweightedbyPathLengthtrades-off
Wecompareourapproachwitheightrecentlypub-
SRagainstTL.
lishedsystems: SPL is the recommended primary metric, other
RANDOM: an agent that randomly selects a metricsareconsideredasauxiliarymeasures.
•
directionandmovesfivestepinthatdirection
3.4 Implementation
(Andersonetal.,2018).
SEQ2SEQ: sequence-to-sequencemodelpro- We use a LSTM/GPT/BERT for the language en-
•
posedbyAndersonetal. asabaselineforthe coder,andasecondsingle-layerLSTMfortheac-
R2R benchmark (Anderson et al., 2018) and tiondecoder(h=1024). WeuseAdamaxandbatch
analyzedin(Thomasonetal.,2019). sizes of 24/16 for pretraining/finetuning. The
RPA (Wang et al., 2018): is an agent which learningratesforMLEare1e−4,duringfinetuning
•
combines model-free and model-based rein- BERT the learning rate is 5e−5. Following (Fried
forcementlearning,usingalook-aheadmod- etal.,2018),weuseapanoramicactionspaceand
uleforplanning. theResNetimagefeaturesprovidedby(Anderson
SPEAKER-FOLLOWER (Fried et al., 2018): et al., 2018). The code is publicly available here:
•
anagenttrainedwithdataaugmentationfrom https://github.com/xjli/r2r_vln.
aspeakermodelwithpanoramicactions.
SMNA (Ma et al., 2019a): an agent trained 3.5 Results
•
with a visual-textual co-grounding module
Robust Generalization. First, we compare
andprogressmonitoronpanoramicactions.
PRESS to a baseline seq2seq model5 in two eval-
RCM+SIL(TRAIN) (Wang et al., 2019): an
• uation settings on the validation splits: (1) S: A
agenttrainedwithcross-modalgroundinglo-
single instruction is provided to the agent at a
callyandgloballyviareinforcementlearning.
time. Thus, three separate navigation trajectories
REGRETFUL (Ma et al., 2019b): an agent
• are generated corresponding to three alternative
with a trained progress monitor heuristic for
instructionsinthissetting. Wereporttheaveraged
searchthatenablesbacktracking.
performance over three separate runs. (2) M: All
FAST (Keetal.,2019): anagentwhichcom-
• threeinstructionsareprovidedtotheagentatonce.
binesglobalandlocalknowledgetocompare
The seq2seq baseline does not have an aggrega-
partial trajectories of different lengths, en-
tion strategy so we report its performance for the
ablingefficientbacktrackafteramistake.
single trajectory with maximum likelihood. For
ENVDROP (Tan et al., 2019): proposed an
• PRESS, we aggregate the instructions via context
environmentdropoutmethod,whichcangen-
eratemoreenvironmentsbasedonthelimited
5The baseline seq2seq agent is the FOLLOWER of
seenenvironments. SPEAKER-FOLLOWER(Friedetal.,2018).
ValidationSeen ValidationUnseen TestUnseen
Model TL↓ NE↓ SR↑ SPL↑ TL↓ NE↓ SR↑ SPL↑ TL↓ NE↓ SR↑ SPL↑
RANDOM 9.58 9.45 16 - 9.77 9.23 16 - 9.93 9.77 13 12
SEQ2SEQ 11.33 6.01 39 - 8.39 7.81 22 - 8.13 7.85 20 18
RPA - 5.56 43 - - 7.65 25 - 9.15 7.53 25 23
SPEAKER-FOLLOWER - 3.36 66 - - 6.62 35 - 14.82 6.62 35 28
SMNA - - - - - - - - 18.04 5.67 48 35
RCM+SIL(TRAIN) 10.65 3.53 67 - 11.46 6.09 43 - 11.97 6.12 43 38
REGRETFUL - 3.23 69 63 - 5.32 50 41 13.69 5.69 48 40
FAST - - - - 21.17 4.97 56 43 22.08 5.14 54 41
ENVDROP 11.00 3.99 62 59 10.70 5.22 52 48 11.66 5.23 51 47
PRESS 10.35 3.09 71 67 10.06 4.31 59 55 10.52 4.53 57 53
Human - - - - - - - - 11.85 1.61 86 76
Table3: Comparisonwiththestate-of-the-artmethods. Blueindicatesbestvalueoverall.
mean-poolingandgenerateasingletrajectory. No ValidationSeen ValidationUnseen
dataaugmentationisappliedtoeithermodel. LM TL NE SR SPL TL NE SR SPL
The results are summarized in Table 2. (i) TF 10.50 5.74 44 42 9.86 6.23 42 39
SF 11.87 3.97 59 53 13.23 6.17 40 31
PRESS drastically outperforms the seq2seq mod-
SS 10.99 3.46 64 59 10.73 4.89 53 48
els on unseen environments in both settings,
TF 10.03 4.05 60 58 9.43 3.36 49 46
and (ii) Interestingly, our method shows a much
SF 11.46 2.53 73 67 13.13 5.13 49 41
smaller gap between seen and unseen environ- SS 10.60 2.99 71 68 10.79 3.05 56 51
ments than seq2seq. It demonstrates the impor- TF 10.57 4.06 59 56 9.61 5.13 51 47
tance of pretrained LMs and stochastic sampling SF 12.39 2.71 73 64 13.12 5.06 51 42
SS 10.35 3.09 71 67 10.06 4.31 59 55
forstronggeneralizationinunseenenvironments.
Comparison with SoTA. In Table 3, we com- Table4:Ablationresultsofdifferentlanguagepretrain-
pare the performance of our agent against all the ingsandtrainingstrategies:TeacherForcing(TF),Stu-
dentForcing(SF)andStochasticSampling(SS).
publishedmethods,ourPRESSagentoutperforms
theexistingmodelsonnearlyallthemetrics.
(2) The second set in Figure 4 shows how the
AblationAnalysis. Keytothisworkisleverag-
agents trained with different training strategies
inglarge-scalepretrainedLMsandeffectivetrain-
performs in an unseen environment. The agents
ing strategies for action sequence decoding. Ta-
trained with teacher-forcing and student-forcing
ble 4 shows an ablation of these choices. (1)
BERT and GPT are better than LSTM on both
bothfail,while PRESS succeeds.
seen and unseen environments, and BERT gener-
4 Conclusion
alizes better than GPT on unseen environments.
(2) Teacher-forcing performs better than student- We present PRESS, a navigation agent based on
forcing on validation unseen environments, while twopreviouslyunderexploredtechniquesinVLN:
anoppositeconclusionisdrawnonvalidationseen pretrained language models and stochastic action
environments. SSperformsthebestonunseenen- sampling. OurPRESSdemonstratesrobustgener-
vironments. alization in the unseen environments, leading to a
newstate-of-the-artperformanceovermanyofthe
QualitativeExamples. Weprovidetwonaviga-
much more complex approaches previously pro-
tion examples of PRESS on the validation unseen
posed. As both the components of PRESS can
environmentswiththestep-by-stepviewsandtop-
be easily integrated, future models can consider
downviewsinAppendix.
buildinguponthemasastrongbaselinesystem.
(1) Figure 3 shows how the agent with LSTM
instruction encoder performs compared with our
Acknowledgments
PRESS agent. There are two rare words “man-
nequins” and “manikins” which are not in the We thank the anonymous reviewers for their in-
training dataset and confuse the LSTM agent, sightful comments, NSF IIS-1703166, DARPA’s
while, PRESS successfullymapsthesetwo“man- CwCprogramthroughAROW911NF-15-1-0543,
nequins”and“manikins”tothecorrectobjects. andtheAllenInstituteforArtificialIntelligence.
ydeerG
MTSL
TPG
TREB
References Xiong.2019a. Self-monitoringnavigationagentvia
auxiliaryprogressestimation. InInternationalCon-
Peter Anderson, Qi Wu, Damien Teney, Jake Bruce,
ferenceonLearningRepresentations.
MarkJohnson,NikoSu¨nderhauf,IanReid,Stephen
Gould, and Anton van den Hengel. 2018. Vision- Chih-YaoMa,ZuxuanWu,GhassanAlRegib,Caiming
and-language navigation: Interpreting visually- Xiong, and Zsolt Kira. 2019b. The regretful agent:
grounded navigation instructions in real environ- Heuristic-aidednavigationthroughprogressestima-
ments. InIEEEConferenceonComputerVisionand tion. In IEEE Conference on Computer Vision and
PatternRecognition. PatternRecognition.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Jeffrey Pennington, Richard Socher, and Christopher
Noam Shazeer. 2015. Scheduled sampling for se- Manning. 2014. GloVe: Global vectors for word
quence prediction with recurrent neural networks. representation. InConferenceonempiricalmethods
InNeuralInformationProcessingSystems. innaturallanguageprocessing.
Angel Chang, Angela Dai, Thomas Funkhouser, Ma- AlecRadford,KarthikNarasimhan,TimSalimans,and
ciejHalber,MatthiasNießner,ManolisSavva,Shu- Ilya Sutskever. 2018. Improving language under-
ranSong,AndyZeng,andYindaZhang.2017. Mat- standingbygenerativepre-training.
terport3D:LearningfromRGB-Ddatainindooren-
vironments. InInternationalConferenceon3DVi- Marc’Aurelio Ranzato, Sumit Chopra, Michael Auli,
sion. andWojciechZaremba.2016. Sequenceleveltrain-
ingwithrecurrentneuralnetworks. InInternational
Howard Chen, Alane Shur, Dipendra Misra, Noah ConferenceonLearningRepresentations.
Snavely,andYoavArtzi.2019. Touchdown:Natural
Manolis Savva, Abhishek Kadian, Oleksandr
language navigation and spatial reasoning in visual
Maksymets, Yili Zhao, Erik Wijmans, Bha-
street environments. In IEEE Conference on Com-
vana Jain, Julian Straub, Jia Liu, Vladlen Koltun,
puterVisionandPatternRecognition.
JitendraMalik,etal.2019. Habitat: Aplatformfor
Kyunghyun Cho, Bart Van Merrie¨nboer, Caglar Gul- embodied ai research. In International Conference
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger onComputerVision.
Schwenk, and Yoshua Bengio. 2014. Learning
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
phrase representations using rnn encoder-decoder
Sequence to sequence learning with neural net-
forstatisticalmachinetranslation. InConferenceon
works. InNeuralInformationProcessingSystems.
Empirical Methods in Natural Language Process-
ing.
HaoTan,LichengYu,andMohitBansal.2019. Learn-
ingtonavigateunseenenvironments: Backtransla-
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
tionwithenvironmentaldropout. IntheNorthAmer-
KristinaToutanova.2019. Bert:Pre-trainingofdeep
ican Chapter of the Association for Computational
bidirectional transformers for language understand-
Linguistics: HumanLanguageTechnologies.
ing. In the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
Jesse Thomason, Daniel Gordon, and Yonatan Bisk.
guageTechnologies.
2019. Shifting the Baseline: Single Modality Per-
formanceonVisualNavigation&QA. IntheNorth
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna
American Chapter of the Association for Computa-
Rohrbach,JacobAndreas,Louis-PhilippeMorency,
tionalLinguistics: HumanLanguageTechnologies.
Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein,
andTrevorDarrell.2018. Speaker-followermodels Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jian-
for vision-and-language navigation. In Neural In- feng Gao, Dinghan Shen, Yuan-Fang Wang,
formationProcessingSystems. William Yang Wang, and Lei Zhang. 2019. Re-
inforced cross-modal matching and self-supervised
Sachithra Hemachandra, Felix Duvallet, Thomas M
imitation learning for vision-language navigation.
Howard, Nicholas Roy, Anthony Stentz, and
In IEEE Conference on Computer Vision and Pat-
Matthew R Walter. 2015. Learning models for fol-
ternRecognition.
lowing natural language directions in unknown en-
vironments. In IEEE International Conference on Xin Wang, Wenhan Xiong, Hongmin Wang, and
RoboticsandAutomation. William Yang Wang. 2018. Look before you
leap: Bridging model-free and model-based rein-
Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtz-
forcement learning for planned-ahead vision-and-
man, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin
languagenavigation. InIEEEEuropeanConference
Choi, and Siddhartha Srinivasa. 2019. Tactical
onComputerVision.
rewind: Self-correction via backtracking in vision-
and-language navigation. In IEEE Conference on Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod
ComputerVisionandPatternRecognition. Lipson.2014. Howtransferablearefeaturesindeep
neuralnetworks? InNeuralInformationProcessing
Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan Al-
Systems.
Regib, Zsolt Kira, Richard Socher, and Caiming
