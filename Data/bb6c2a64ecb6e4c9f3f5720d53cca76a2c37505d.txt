Experience Grounds Language
YonatanBisk* AriHoltzman* JesseThomason*
JacobAndreas YoshuaBengio JoyceChai MirellaLapata
AngelikiLazaridou JonathanMay AleksandrNisnevich NicolasPinto JosephTurian
Abstract
Meaningisnotauniquepropertyoflanguage,buta
generalcharacteristicofhumanactivity...Wecannot
Languageunderstandingresearchisheldback saythateachmorphemeorwordhasasingleorcentral
meaning,oreventhatithasacontinuousorcoherent
by a failure to relate language to the physical
rangeofmeanings...therearetwoseparateusesand
worlditdescribesandtothesocialinteractions
meaningsoflanguage–theconcrete...andtheabstract.
it facilitates. Despite the incredible effective-
ZelligS.Harris(DistributionalStructure1954)
ness of language processing models to tackle
tasksafterbeingtrainedontextalone,success-
trainedsolelyontextcorpora,evenwhenthosecor-
fullinguisticcommunicationreliesonashared
experienceoftheworld. Itisthissharedexpe- poraaremeticulouslyannotatedorInternet-scale.
riencethatmakesutterancesmeaningful. Youcan’tlearnlanguagefromtheradio. Nearly
every NLP course will at some point make this
Naturallanguageprocessingisadiversefield,
claim. Thefutilityoflearninglanguagefromlin-
and progress throughout its development has
comefromnewrepresentationaltheories,mod- guistic signal alone is intuitive, and mirrors the
eling techniques, data collection paradigms, belief that humans lean deeply on non-linguistic
and tasks. We posit that the present success knowledge(Chomsky,1965,1980). However,as
of representation learning approaches trained
afieldweattemptthisfutility: tryingtolearnlan-
on large, text-only corpora requires the paral-
guage from the Internet, which stands in as the
lel tradition of research on the broader physi-
modernradiotodeliverlimitlesslanguage. Inthis
cal and social context of language to address
piece,wearguethattheneedforlanguagetoattach
thedeeperquestionsofcommunication.
to“extralinguisticevents"(Ervin-Tripp,1973)and
therequirementforsocialcontext(Baldwinetal.,
Improvementsinhardwareanddatacollection
1996)shouldguideourresearch.
have galvanized progress in NLP across many
benchmarktasks. Impressiveperformancehasbeen DrawinginspirationfrompreviousworkinNLP,
achieved in language modeling (Radford et al., CognitiveScience,andLinguistics,weproposethe
2019;Zellersetal.,2019b;Keskaretal.,2019)and notion of a World Scope (WS) as a lens through
span-selection question answering (Devlin et al., whichtoauditprogressinNLP.Wedescribefive
2019;Yangetal.,2019b;Lanetal.,2020)through WSs, and note that most trending work in NLP
massive data and massive models. With models operatesinthesecond(Internet-scaledata).
exceedinghumanperformanceonsuchtasks,now WedefinefivelevelsofWorldScope:
isanexcellenttimetoreflectonakeyquestion: WS1. Corpus(ourpast)
WS2. Internet(mostofcurrentNLP)
WhereisNLPgoing?
WS3. Perception(multimodalNLP)
Inthispaper,weconsiderhowthedataandworld WS4. Embodiment
a language learner is exposed to define and con- WS5. Social
strainsthescopeofthatlearner’ssemantics. Mean- TheseWorldScopesgobeyondtexttoconsider
ingdoesnotarisefromthestatisticaldistribution thecontextualfoundationsoflanguage: grounding,
ofwords,butfromtheirusebypeopletocommuni- embodiment,andsocialinteraction. Wedescribea
cate. Manyoftheassumptionsandunderstandings briefhistoryandongoingprogressionofhowcon-
onwhichcommunicationrelieslieoutsideoftext. textualinformationcanfactorintorepresentations
We must consider what is missing from models andtasks. Weconcludewithadiscussionofhow
thisintegrationcanmovethefieldforward. Webe- 100
Harris 1954
lievethisWorldScopeframingservesasaroadmap 80 Firth 1957
fortrulycontextuallanguageunderstanding. 60 Chomsky 1957
40
20
1 WS1: CorporaandRepresentations 0
1960 1970 1980 1990 2000 2010 2020
Year
Thestoryofdata-drivenlanguageresearchbegins
AcademicinterestinFirthandHarrisincreasesdramatically
withthecorpus. ThePennTreebank(Marcusetal.,
around2010,perhapsduetothepopularizationofFirth(1957)
1993)isthecanonicalexampleofacleansubsetof
“Youshallknowawordbythecompanyitkeeps."
naturallygeneratedlanguage,processedandanno-
tated for the purpose of studying representations.
Suchcorporaandthemodelrepresentationsbuilt ture linguistic intuitions without supervision, but
from them exemplify WS1. Community energy theyareconstrainedbythestructuretheyimpose
was initially directed at finding formal linguistic withrespecttothenumberofclasseschosen.
structure,suchasrecoveringsyntaxtrees. Recent Theintuitionthatmeaningrequiresalargecon-
successondownstreamtaskshasnotrequiredsuch text,that“Youshallknowawordbythecompany
explicitlyannotatedsignal,leaninginsteadonun- itkeeps."–Firth(1957),manifestedearlyviaLa-
structuredfuzzyrepresentations. Theserepresenta- tentSemanticIndexing/Analysis(Deerwesteretal.,
tionsspanfromdensewordvectors(Mikolovetal., 1988, 1990; Dumais, 2004) and later in the gen-
2013)tocontextualizedpretrainedrepresentations erative framework of Latent Dirichlet Allocation
(Petersetal.,2018;Devlinetal.,2019). (Bleietal.,2003). LDArepresentsadocumentas
Wordrepresentationshavealonghistorypredat- abag-of-wordsconditionedonlatenttopics,while
ing the recent success of deep learning methods. LSI/Ausesingularvaluedecompositiontoproject
OutsideofNLP,philosophy(Austin,1975)andlin- aco-occurrencematrixtoalowdimensionalword
guistics (Lakoff, 1973; Coleman and Kay, 1981) vectorthatpreserveslocality. Thesemethodsdis-
recognizedthatmeaningisflexibleyetstructured. cardsentencestructureinfavorofthedocument.
Earlyexperimentsonneuralnetworkstrainedwith Representing words through other words is a
sequences of words (Elman, 1990; Bengio et al., comfortableproposition,asitprovidestheillusion
2003)suggestedthatvectorrepresentationscould of definitions by implicit analogy to thesauri and
capture both syntax and semantics. Subsequent relatedwordsinadictionarydefinition. However,
experiments with larger models, documents, and the recent trends in deep learning approaches to
corpora have demonstrated that representations languagemodelingfavorrepresentingmeaningin
learnedfromtextcaptureagreatdealofinforma- fixed-lengthvectorswithnoobviousinterpretation.
tionaboutmeaninginandoutofcontext(Collobert Thequestionofwheremeaningresidesin“connec-
and Weston, 2008; Turian et al., 2010; Mikolov tionist”systemslikeDeepNeuralNetworksisan
etal.,2013;McCannetal.,2017). old one (Pollack, 1987; James and Miikkulainen,
1995). Areconceptsdistributedthroughedgesor
Theintuitionofsuchembeddingrepresentations,
localtounitsinanartificialneuralnetwork?
thatcontextlendsmeaning,haslongbeenacknowl-
edged(Firth,1957;TurneyandPantel,2010). Ear-
“... therehasbeenalongandunresolved
lieron,discrete,hierarchicalrepresentations,such
debatebetweenthosewhofavorlocalist
as agglomerative clustering guided by mutual in-
representations in which each process-
formation(Brownetal.,1992),wereconstructed
ingelementcorrespondstoameaningful
withsomeinnateinterpretability. Aword’sposition
conceptandthosewhofavordistributed
insuchahierarchycapturessemanticandsyntac-
representations.” Hinton(1990)
ticdistinctions. WhentheBaum–Welchalgorithm
SpecialIssueonConnectionistSymbolProcessing
(Welch,2003)isappliedtounsupervisedHidden
Markov Models, it assigns a class distribution to In connectionism, words were no longer defined
every word, and that distribution is a partial rep- over interpretable dimensions or symbols, which
resentation of a word’s “meaning.” If the set of were perceived as having intrinsic meaning. The
classes is small, syntax-like classes are induced; tensionofmodelingsymbolsanddistributedrepre-
if the set is large, classes become more semantic. sentationsisarticulatedbySmolensky(1990),and
Theserepresentationsarepowerfulinthattheycap- alternativerepresentations(Kohonen,1984;Hinton
snoitatiC
9102
fo
%
etal.,1986;Barlow,1989)andapproachestostruc- havemadeprogressbysubstantiallyincreasingthe
tureandcomposition(ErkandPadó,2008;Socher number of model parameters to better consume
etal.,2012)spandecadesofresearch. these vast quantities of data. Where Peters et al.
The Brown Corpus (Francis, 1964) and Penn (2018) introduced ELMo with ∼108 parameters,
Treebank(Marcusetal.,1993)definedcontextand Transformer models (Vaswani et al., 2017) have
structure in NLP for decades. Only relatively re- continuedtoscalebyordersofmagnitudebetween
cently(Baronietal.,2009)hasthecostofannota- papers (Devlin et al., 2019; Radford et al., 2019;
tionsdecreasedenough,andhavelarge-scaleweb- Zellersetal.,2019b)to∼1011 (Brownetal.,2020).
crawlsbecomeviable,toenabletheintroductionof
Current models are the next (impressive) step
morecomplextext-basedtasks. Thistransitionto
in language modeling which started with Good
larger,unstructuredcontext(WS2)inducedaricher
(1953), the weights of Kneser and Ney (1995);
semantics than was previously believed possible
Chen and Goodman (1996), and the power-law
underthedistributionalhypothesis.
distributions of Teh (2006). Modern approaches
to learning dense representations allow us to bet-
2 WS2: TheWrittenWorld
ter estimate these distributions from massive cor-
Corpora in NLP have broadened to include large pora. However, modeling lexical co-occurrence,
web-crawls. The use of unstructured, unlabeled, no matter the scale, is still modeling the written
multi-domain,andmultilingualdatabroadensour world. Modelsconstructedthiswayblindlysearch
world scope, in the limit, to everything humanity forsymbolicco-occurencesvoidofmeaning.
haseverwritten.1 Wearenolongerconstrainedto Howcanmodelsyieldboth“impressiveresults”
a single author or source, and the temptation for and“diminishingreturns”? Languagemodeling—
NLP is to believe everything that needs knowing themodernworkhorseofneuralNLPsystems—is
canbelearnedfromthewrittenworld. But,alarge acanonicalexample. Recentpretrainingliterature
andnoisytextcorpusisstillatextcorpus. hasproducedresultsthatfewcouldhavepredicted,
This move towards using large scale raw data crowdingleaderboardswith“super-human"accu-
hasledtosubstantialadvancesinperformanceon racy (Rajpurkar et al., 2018). However, there are
existingandnovelcommunitybenchmarks(Devlin diminishing returns. For example, on the LAM-
etal.,2019;Brownetal.,2020). Scaleindataand BADA dataset (Paperno et al., 2016), designed
modelinghasdemonstratedthatasinglerepresen- tocapturehumanintuition,GPT2(Radfordetal.,
tationcandiscoverbothrichsyntaxandsemantics 2019)(1.5B),Megatron-LM(Shoeybietal.,2019)
withoutourhelp(Tenneyetal.,2019). Thischange (8.3B),andTuringNLG(Rosset,2020)(17B)per-
is perhaps best seen in transfer learning enabled formwithinafewpointsofeachotherandveryfar
by representations in deep models. Traditionally, fromperfect(<68%). Whenaddinganotherorder
transfer learning relied on our understanding of of magnitude of parameters (175B) Brown et al.
modelclasses,suchasEnglishgrammar. Domain (2020) gain 8 percentage-points, impressive but
adaptation simply required sufficient data to cap- stillleaving25%unsolved. Continuingtoexpand
ture lexical variation, by assuming most higher- hardware, data sizes, and financial compute cost
level structure would remain the same. Unsuper- byordersofmagnitudewillyieldfurthergains,but
vised representations today capture deep associ- theslopeoftheincreaseisquicklydecreasing.
ations across multiple domains, and can be used
The aforementioned approaches for learning
successfullytransferknowledgeintosurprisingly
transferablerepresentationsdemonstratethatsen-
diversecontexts(Brownetal.,2020).
tenceanddocumentcontextprovidepowerfulsig-
Theserepresentationsrequirescaleintermsof
nalsforlearningaspectsofmeaning,especiallyse-
both data and parameters. Concretely, Mikolov
manticrelationsamongwords(Fuetal.,2014)and
et al. (2013) trained on 1.6 billion tokens, while
inferential relationships among sentences (Wang
Pennington et al. (2014) scaled up to 840 billion
et al., 2019a). The extent to which they capture
tokensfromCommonCrawl. Recentapproaches
deepernotionsofcontextualmeaningremainsan
1A parallel discussion would focus on the hardware re- openquestion. Pastworkhasfoundthatpretrained
quiredtoenableadvancestohigherWorldScopes. Playsta- word and sentence representations fail to capture
tions(Pintoetal.,2009)andthenGPUs(Krizhevskyetal.,
manygroundedfeaturesofwords(LucyandGau-
2012)mademanyWS2advancespossible.Perception,inter-
action,androboticsleverageothernewhardware. thier, 2017)and sentences, and current NLUsys-
temsfailonthethicktailofexperience-informedin-
ferences,suchashardcoreferenceproblems(Peng
etal.,2015). “Iparkedmycarinthecompactpark-
ing space because it looked (big/small) enough.”
stillpresentsproblemsfortext-onlylearners.
As text pretraining schemes seem to be reach-
ingthepointofdiminishingreturns,evenforsome
syntacticphenomena(vanSchijndeletal.,2019),
we posit that other forms of supervision, such as
multimodal perception (Ilharco et al., 2019), are EugeneCharniak(AFramedPAINTING:TheRepresentation
necessarytolearntheremainingaspectsofmean- ofaCommonSenseKnowledgeFragment1977)
ingincontext. Learningbyobservationshouldnot
beapurelylinguisticprocess,sinceleveragingand
from an exponential number of possible how-to,
combiningthepatternsofmultimodalperception
text-only guides and manuals (Bisk et al., 2020)
cancombinatoriallyboosttheamountofsignalin
ismisdirectedwithoutsomefundamentalreferents
datathroughcross-referencingandsynthesis.
towhichtogroundsymbols. Modelsmustbeable
towatchandrecognizeobjects,people,andactivi-
3 WS3: TheWorldofSightsandSounds
tiestounderstandthelanguagedescribingthem(Li
et al., 2019b; Krishna et al., 2017; Yatskar et al.,
Languagelearningneedsperception,becauseper-
2016;Perlis,2016)andaccessfine-grainednotions
ceptionformsthebasisformanyofoursemantic
ofcausality,physics,andsocialinteractions.
axioms. Learned,physicalheuristics,suchasthe
While the NLP community has played an im-
factthatafallingcatwilllandquietly,aregeneral-
portantroleinthehistoryofgrounding(Mooney,
ized and abstracted into language metaphors like
as nimble as a cat (Lakoff, 1980). World knowl- 2008), recently remarkable progress has taken
place in the Computer Vision community. It is
edgeformsthebasisforhowpeoplemakeentail-
tempting to assume that vision models trained
ment and reasoning decisions, commonly driven
toidentify1,000ImageNetclasses(Russakovsky
bymentalsimulationandanalogy(Hofstadterand
etal.,2015)2 arelimitedtoextractingabagofvi-
Sander,2013). Perceptionistheforemostsource
sualwords. Inreality,ComputerVisionhasbeen
ofreportingbias. Theassumptionthatweallsee
makingin-roadsintocomplexvisual,physical,and
andhearthesamethingsinformsnotjustwhatwe
socialphenomena,whileprovidingreusableinfras-
name,butwhatwechoosetoassumeandleaveun-
tructure.3 Thestabilityofthesearchitecturesallows
written. Further,thereexistsstrongevidencethat
fornewresearchintomorechallengingworldmod-
childrenrequiregroundedsensoryperception,not
eling. Mottaghietal.(2016)predictstheeffectsof
justspeech,tolearnlanguage(Sachsetal.,1981;
forcesonobjectsinimages. Bakhtinetal.(2019)
O’Grady,2005;Viglioccoetal.,2014).
extendsthisphysicalreasoningtocomplexpuzzles
Perceptionincludesauditory,tactile,andvisual
of cause and effect. Sun et al. (2019b,a) models
input. Even restricted to purely linguistic sig-
scripts and actions, and alternative unsupervised
nals,sarcasm,stress,andmeaningcanbeimplied
training regimes (Bachman et al., 2019) open up
throughprosody. Further,tactilesenseslendmean-
researchtowardsautomaticconceptformation.
ing,bothphysical(Sinapovetal.,2014;Thomason
Advancesincomputervisionhaveenabledbuild-
etal.,2016)andabstract,toconceptslikeheavyand
ingsemanticrepresentationsrichenoughtointer-
soft. Visualperceptionisarichsignalformodeling
act with natural language. In the last decade of
avastnessofexperiencesintheworldthatcannot
workdescendantfromimagecaptioning(Farhadi
bedocumentedbytextalone(Harnad,1990).
et al., 2010; Mitchell et al., 2012), a myriad of
For example, frames and scripts (Schank and
tasks on visual question answering (Antol et al.,
Abelson, 1977; Charniak, 1977; Dejong, 1981;
2015; Das et al., 2018; Yagcioglu et al., 2018),
Mooney and Dejong, 1985) require understand-
naturallanguageandvisualreasoning(Suhretal.,
ingoftenunstatedsetsofpre-andpost-conditions
2019b),visualcommonsense(Zellersetal.,2019a),
abouttheworld. ToborrowfromCharniak(1977),
howshouldwelearnthemeaning,method,andim- 2Orthe1,600classesofAndersonetal.(2017).
plicationsofpainting? Awebcrawlofknowledge 3Torchvision/Detectron2includedozensoftrainedmodels.
and multilingual captioning/translation via video
IfAandBhavesomeenvironmentsincommonand
(Wang et al., 2019b) have emerged. These com- somenot...wesaythattheyhavedifferentmeanings,
theamountofmeaningdifferencecorresponding
binedtextandvisionbenchmarksarerichenough
roughlytotheamountofdifferenceintheir
to train large-scale, multimodal transformers (Li environments...
et al., 2019a; Lu et al., 2019; Zhou et al., 2019)
ZelligS.Harris(DistributionalStructure1954)
withoutlanguagepretraining(e.g. viaconceptual
captions (Sharma et al., 2018)) or further broad-
enedtoincludeaudio(Tsaietal.,2019). Visioncan
4 WS4: EmbodimentandAction
alsohelpgroundspeechsignals(Srinivasanetal.,
2020;Harwathetal.,2019)tofacilitatediscovery Inhumandevelopment,interactivemultimodalsen-
oflinguisticconcepts(Harwathetal.,2020).
soryexperienceformsthebasisofaction-oriented
At the same time, NLP resources contributed categories (Thelen and Smith, 1996) as children
to the success of these vision backbones. Hierar- learn how to manipulate their perception by ma-
chical semantic representations emerge from Im- nipulatingtheirenvironment. Languagegrounding
ageNet classification pretraining partially due to enablesanagenttoconnectwordstotheseaction-
class hypernyms owed to that dataset’s WordNet orientedcategoriesforcommunication(Smithand
origins. Forexample,thepersonclasssub-divides Gasser,2005),butrequiresactiontofullydiscover
intomanyprofessionsandhobbies,likefirefighter, such connections. Embodiment—situated action
gymnast,anddoctor. Todifferentiatesuchsibling taking—isthereforeanaturalnextbroadercontext.
classes,learnedvectorscanalsoencodelower-level Anembodiedagent,whetherinavirtualworld,
characteristicslikeclothing,hair,andtypicalsur- such as a 2D Maze (MacMahon et al., 2006), a
roundingscenes. Theserepresentationsallowfor gridworld(Chevalier-Boisvertetal.,2019),asim-
pixellevelmasksandskeletalmodeling,andcanbe ulated house (Anderson et al., 2018; Thomason
extendedtozero-shotsettingstargetingall20KIm- et al., 2019b; Shridhar et al., 2020), or the real
ageNetcategories(Chaoetal.,2016;Changpinyo world(Tellexetal.,2011;Matuszek,2018;Thoma-
etal.,2017). Modernarchitecturesalsolearntodif- sonetal.,2020;Tellexetal.,2020)musttranslate
ferentiateinstanceswithinageneralclass,suchas fromlanguagetoaction. Controlandactiontaking
face. Forexample,facialrecognitionbenchmarks openseveralnewdimensionstounderstandingand
requiredistinguishingover10Kuniquefaces(Liu activelylearningabouttheworld. Queriescanbe
etal.,2015). Whilevisionisbynomeans“solved,” resolved via dialog-based exploration with a hu-
benchmarkshaveledtooff-the-shelftoolsforbuild- maninterlocutor(LiuandChai,2015),evenasnew
ingrepresentationsrichenoughtoidentifytensof objectproperties,liketextureandweight(Thoma-
thousandsofobjects,scenes,andindividuals. son et al., 2017), or feedback, like muscle activa-
tions(MoroandKennington,2018),becomeavail-
AWS3agent,havingaccesstopotentiallyend-
able. Weseetheneedforembodiedlanguagewith
less hours of video data showing the intricate de-
complexmeaningwhenthinkingdeeplyabouteven
tailsofdailycomingsandgoings,procedures,and
themostinnocuousofquestions:
events,reducessusceptibilitytothereportingbias
of WS2. An ideal WS3 agent will exhibit bet- Isanorangemorelikeabaseballormore
terlong-tailgeneralizationandunderstandingthan likeabanana?
anylanguage-onlysystemcould. Thisgeneraliza-
tion should manifest in existing benchmarks, but WS1islikelynottohaveananswerbeyondthat
wouldbemostprominentinatestofzero-shotcir- theobjectsarecommonnounsthatcanbothbeheld.
cumstances,suchas“Willthiscarfitthroughthat WS2maycapturethatorangesandbaseballsboth
tunnel?,”andrarelydocumentedbehaviorsasex- roll,butisnotthedeformationstrength,surfacetex-
aminedinscriptlearning. Yetthe WS3agentwill ture,orrelativesizesoftheseobjects(Elazaretal.,
likely fail to answer, "Would a ceramic or paper 2019). WS3mayrealizetherelativedeformability
platemakeabetterfrisbee?"Theagenthasnottried oftheseobjects,butislikelytoconfusehowmuch
tothrowvariousobjectsandunderstandhowtheir force is necessary given that baseballs are used
velocityandshapeinteractwiththeatmosphereto muchmoreroughlythanoranges. WS4canappre-
createlift. Theagentcannottestnovelhypotheses ciatethenuancesofthequestion—theorangeand
byinterventionandactionintheworld. baseballaffordsimilarmanipulationbecausethey
havesimilartextureandweight,whiletheorange
Inordertotalkaboutconcepts,wemustunderstandthe
and banana both contain peels, deform, and are importanceofmentalmodels...wesetupamodelof
theworldwhichservesasaframeworkinwhichto
edible. Peoplecanreasonoverrichrepresentations
organizeourthoughts.Weabstractthepresenceof
ofcommonobjectsthatthesewordsevoke. particularobjects,havingproperties,andenteringinto
eventsandrelationships.
Planningiswherepeoplefirstlearnabstraction
and simple examples of post-conditions through TerryWinograd-1971
trialanderror. Themostbasicscriptshumanslearn
start with moving our own bodies and achieving
simplegoalsaschildren,suchasstackingblocks.
highfidelitysimulatorsforrobotics(Todorovetal.,
Inthisspace,wehaveunlimitedsupervisionfrom
2012; Coumans and Bai, 2016–2019; NVIDIA,
theenvironmentandcanlearntogeneralizeacross
2019; Xiang et al., 2020) and the cost and avail-
plans and actions. In general, simple worlds do
abilityofcommodityhardware(Fitzgerald,2013;
notentailsimpleconcepts: eveninablockworld
Campeau-Lecoursetal.,2019;Muralietal.,2019).
conceptslike“mirroring”appear(Bisketal.,2018).
Ascomputerstransitionfromdesktopstoperva-
Humansgeneralizeandapplyphysicalphenomena
sivemobileandedgedevices,wemustmakeand
toabstractconceptswithease.
meettheexpectationthatNLPcanbedeployedin
In addition to learning basic physical proper- anyofthesecontexts. Currentrepresentationshave
ties of the world from interaction, WS4 also al- verylimitedutilityineventhemostbasicrobotic
lowstheagenttoconstructrichpre-linguisticrep- settings(Scaliseetal.,2019),makingcollaborative
resentationsfromwhichtogeneralize. Hesposand robotics(Rosenthaletal.,2010)largelyadomain
Spelke(2004)showpre-linguisticcategoryforma- ofcustomengineeringratherthanscience.
tionwithinchildrenthatarethenlatercodifiedby
socialconstructs. Mountingevidenceseemstoindi- 5 WS5: TheSocialWorld
catethatchildrenhavetroubletransferringknowl-
Interpersonal communication is the foundational
edgefromthe2Dworldofbooks(Barr,2013)and
usecaseofnaturallanguage(Dunbar,1993). The
iPads (Lin et al., 2017) to the physical 3D world.
physical world gives meaning to metaphors and
Sowhilewemightchoosetobelievethatwecanen-
instructions, but utterances come from a source
codeparameters(Chomsky,1981)moreeffectively
withapurpose. TakeJ.L.Austin’sclassicexample
andefficientlythanevolutionprovidedus,develop-
of“BULL”beingwrittenonthesideofafencein
mentalexperimentsindicatedoingsowithout3D
alargefield(Austin,1975). Itisafundamentally
interactionmayprovedifficult.
socialinferencetorealizethatthiswordindicates
Part of the problem is that much of the knowl-
thepresenceofadangerouscreature,andthatthe
edge humans hold about the world is intuitive,
word is written on the opposite side of the fence
possibly incommunicable by language, but still
fromwherethatcreaturelives.
required to understand language. Much of this
InterpersonaldialogueasagrandtestforAIis
knowledgerevolvesaroundphysicalrealitiesthat
olderthantheterm“artificialintelligence,”begin-
real-world agents will encounter. Consider how
ningatleastwithTuring(1950)’sImitationGame.
manyexplicitandimplicitmetaphorsarebasedon
Turingwascarefultoshowhoweasilyanaïvetester
the idea that far-away things have little influence
couldbetricked. Framing,suchassuggestingthata
on manipulating local space: “a distant concern”
chatbotspeaksEnglishasasecondlanguage(Sam-
and“we’llcrossthatbridgewhenwecometoit.”
pleandHern,2014),cancreatetheappearanceof
Robotics and embodiment are not available in
genuinecontentwherethereisnone(Weizenbaum,
thesameoff-the-shelfmannerascomputervision
1966). Thisphenomenonhasbeennotedcountless
models. However,thereisrapidprogressinsimu-
times, from criticisms of Speech Recognition as
latorsandcommercialrobotics,andaslanguagere-
“deceitandglamour”(Pierce,1969)tocomplaints
searchersweshouldmatchtheseadvancesatevery
ofhumanity’s“gullibilitygap”(MarcusandDavis,
step. Asactionspacesgrow,wecanstudycomplex
2019). Weinsteadfocusonwhythesocialworld
language instructions in simulated homes (Shrid-
isvitaltolanguagelearning.
haretal.,2020)ormaplanguagetophysicalrobot
control(Blukisetal.,2019;Chaietal.,2018). The Language that Does Something Work in the
lastfewyearshaveseenmassiveadvancesinboth philosophy of language has long suggested that
functionisthesourceofmeaning,asfamouslyil- persistentenoughtolearntheeffectsofactions.
lustratedthroughWittgenstein’s“languagegames”
(Wittgenstein, 1953, 1958). In linguistics, the Theory of Mind When attempting to get what
usage-based theory of language acquisition sug- wewant,weconfrontpeoplewhohavetheirown
geststhatconstructionsthatareusefularethebuild- desiresandidentities. Theabilitytoconsiderthe
ing blocks for everything else (Langacker, 1987, feelings and knowledge of others is now com-
1991). The economy of this notion of use has monly referred to as the “Theory of Mind” (Ne-
beenthesubjectofmuchinquiryanddebate(Grice, matzadeh et al., 2018). This paradigm has also
1975). Inrecentyears,thesethreadshavebegunto beendescribedunderthe“Speaker-Listener”model
shedlightonwhatuse-caseslanguagepresentsin (Stephensetal.,2010),andarichtheorytodescribe
bothacquisitionanditsinitialoriginsinourspecies this computationally is being actively developed
(Tomasello,2009;Barsalou,2008),indicatingthe undertheRationalSpeechActModel(Frankand
fundamentalroleofthesocialworld. Goodman,2012;Bergenetal.,2016).
Aseriesofchallengesthatattempttoaddressthis
WS1, WS2, WS3, and WS4 expand the fac-
fundamentalaspectofcommunicationhavebeen
torizations of information available to linguistic
introduced (Nematzadeh et al., 2018; Sap et al.,
meaning. allowslanguagetobeacauseinsteadof
2019). Theseworksareagreatstarttowardsdeeper
justasourceofdata. Thisistheultimategoalfor
understanding,butstaticdatasetscanbeproblem-
alanguagelearner: togeneratelanguagethatdoes
aticduetotheriskofembeddingspuriouspatterns
somethingtotheworld.
and bias (de Vries et al., 2020; Le et al., 2019;
Passivecreationandevaluationofgeneratedlan-
Gururangan et al., 2018; Glockner et al., 2018),
guage separates generated utterances from their
especiallybecauseexampleswhereannotatorscan-
effects on other people, and while the latter is
not agree (which are usually thrown out before
a rich learning signal it is inherently difficult to
thedatasetisreleased)stilloccurinrealusecases.
annotate. In order to learn the effects language
More flexible, dynamic evaluation (Zellers et al.,
hasontheworld,anagentmustparticipateinlin-
2020;Dinanetal.,2019)areapartialsolution,but
guistic activity, such as negotiation (Yang et al.,
truepersistenceofidentityandadaptiontochange
2019a;Heetal.,2018;Lewisetal.,2017),collab-
arebothnecessaryandstillalongwayoff.
oration(Chaietal.,2017),visualdisambiguation
Training data in WS1-4, complex and large as
(Andersonetal.,2018;Lazaridouetal.,2017;Liu
itcanbe,doesnotofferthediscriminatorysignals
and Chai, 2015), or providing emotional support
thatmakethehypothesizingofconsistentidentity
(Rashkinetal.,2019). Theseactivitiesrequirein-
ormentalstatesanefficientpathtowardslowering
ferringmentalstatesandsocialoutcomes—akey
perplexityorraisingaccuracy(Liuetal.,2016;De-
areaofinterestinitself(Zadehetal.,2019).
Vaultetal.,2006). First,thereisalackofinductive
What“lame”meansintermsofdiscriminative bias(Martinetal.,2018). Modelslearnwhatthey
informationisalwaysatquestion: itcanbedefined needtodiscriminatebetweenpotentiallabels,and
as “undesirable,” but what it tells one about the itisunlikelythatuniversalfunctionapproximators
processes operating in the environment requires suchasneuralnetworkswouldeverreliablyposit
social context to determine (Bloom, 2002). It is thatpeople,events,andcausalityexistwithoutbe-
thetoddler’ssocialexperimentationwith“You’re ingbiasedtowardssuchsolutions(Mitchell,1980).
solame!” thatgivesthewordweightanddefinite Second, current cross entropy training losses ac-
intent (Ornaghi et al., 2011). In other words, the tively discourage learning the tail of the distribu-
discriminativesignalforthemostfoundationalpart tionproperly,asstatisticallyinfrequenteventsare
ofaword’smeaningcanonlybeobservedbyitsef- drowned out (Pennington et al., 2014; Holtzman
fectontheworld,andactiveexperimentationiskey et al., 2020). Meanwhile, it is precisely human’s
tolearningthateffect. Activeexperimentationwith abilitytodrawonpastexperienceandmakezero-
language starkly contrasts with the disembodied shotdecisionsthatAIaimstoemulate.
chatbotsthatarethefocusofthecurrentdialogue
community(Rolleretal.,2020;Adiwardanaetal., Language in a Social Context Whenever lan-
2020;Zhouetal.,2020;Chenetal.,2018;Serban guageisusedbetweenpeople,itexistsinaconcrete
etal.,2017),whichoftendonotlearnfromindivid- socialcontext: status,role,intention,andcountless
ual experiences and whose environments are not othervariablesintersectataspecificpoint(Ward-
haugh,2011). Thesecomplexitiesareoverlooked
Theseproblemsincludetheneedtobringmeaning
throughselectinglabelsonwhichcrowdworkers andreasoningintosystemsthatperformnatural
languageprocessing,theneedtoinferand
agree. Current notions of ground truth in dataset
representcausality,theneedtodevelop
constructionarebasedoncrowdconsensusbereft computationally-tractablerepresentationsof
ofsocialcontext. Wepositthatecologicallyvalid uncertaintyandtheneedtodevelopsystemsthat
formulateandpursuelong-termgoals.
evaluation of generative models will require the
constructionofsituationswhereartificialagentsare MichaelJordan(Artificialintelligence–the
revolutionhasn’thappenedyet,2019)
considered to have enough identity to be granted
socialstandingfortheseinteractions.
Social interaction is a precious signal, but ini-
WhereShouldWeStart? Manyinourcommu-
tial studies have been strained by the training-
nity are already examining phenomena in WSs
validation-test set scenario and reference-backed
3-5. Note that research can explore higher WS
evaluations. Collectingdataaboutrichnaturalsit-
phenomenawithoutaresultantlearnerbeingina
uations is often impossible. To address this gap,
higherWS.Forexample,achatbotcaninvestigate
learning by participation, where users can freely
principlesofthesocialworld,butstilllacktheun-
interact with an agent, is a necessary step to the
derlying social standing required for WS5. Next
ultimately social venture of communication. By
wedescribefourlanguageusecontextswhichwe
exhibitingdifferentattributesandsendingvarying
believe are both research questions to be tackled
signals,thesociolinguisticconstructionofidentity
andhelpillustratetheneedtomovebeyond WS2.
(Ochs,1993)couldbeexaminedmoredeeply. Such
experimentationinsocialintelligenceissimplynot Second language acquisition when visiting a
possiblewithafixedcorpus. Oncemodelsareex- foreign country leverages a shared, social world
pectedtobeinteractedwithwhentested,probing modelthatallowspointingtoreferentobjectsand
theirdecisionboundariesforsimplificationsofre- miminginternalstateslikehunger. Theinterlingua
alityandalackofcommonsenseknowledgeasin is physical and experiential. Such a rich internal
Gardneretal.;Kaushiketal. willbecomenatural. worldmodelshouldalsobethegoalforMTmodels:
startingwithimages(Huangetal.,2020),moving
6 Self-Evaluation
throughsimulation,andthentotherealworld.
We use the notion of World Scopes to make the CoreferenceandWSDleverageasharedscene
followingconcreteclaims: and theory of mind. To what extent are current
coreferenceresolutionissuesresolvedifanagent
Youcan’tlearnlanguage...
modelsthelistener’sdesiresandexperiencesexplic-
... fromtheradio(Internet). WS2⊂WS3 itlyratherthanlookingsolelyforadjacentlexical
items? Thissettingiseasiesttoexploreinembod-
A task learner cannot be said to be in
iedenvironments,butisnotexclusivetothem(e.g.,
WS3ifitcansucceedwithoutperception
TextWorld(Côtéetal.,2018)).
(e.g.,visual,auditory).
Novel word learning from tactile knowledge
... fromatelevision. WS3⊂WS4
anduse: Whatistheinstrumentthatyouwearlike
A task learner cannot be said to be in aguitarbutplaylikeapiano? Objectscanbede-
WS4 if the space of its world actions scribedwithbothgesturesandwordsaboutappear-
andconsequencescanbeenumerated. ance and function. Such knowledge could begin
totacklephysicalmetaphorsthatcurrentNLPsys-
... byyourself. WS4⊂WS5
temsstrugglewith.
A task learner cannot be said to be in
Personally charged language: How should a
WS5unlessachievingitsgoalsrequires
dialogue agent learn what is hurtful to a specific
cooperatingwithahumanintheloop.
person? To someone who is sensitive about their
Bythesedefinitions,mostofNLPresearchstill grades because they had a period of struggle in
residesin WS2. Thisfactdoesnotinvalidatethe school,thesentimentof“Don’tbeafool!” canbe
utilityorneedforanyoftheresearchwithinNLP, hurtful,whileforothersitmayseemplayful. Social
butitistosaythatmuchofthatexistingresearch knowledgeisrequisiteforrealisticunderstanding
targetsadifferentgoalthanlanguagelearning. ofsentimentinsituatedhumancontexts.
Relevant recent work The move from WS2 to tionshipbetweenmeaningandcontext(Benderand
WS3requiresrethinkingexistingtasksandinvesti- Koller,2020)andhowpretrainingobfuscatesour
gatingwheretheirsemanticscanbeexpandedand abilitytomeasuregeneralization(Linzen,2020).
grounded. Thisideaisnotnew(ChenandMooney,
2008; Feng and Lapata, 2010; Bruni et al., 2014; 7 Conclusions
Lazaridouetal.,2016)andhasacceleratedinthe
Our World Scopes are steep steps. WS5 implies
last few years. Elliott et al. (2016) reframes ma-
apersistentagentexperiencingtimeandaperson-
chinetranslationwithvisualobservations,atrend
alizedsetofexperiences. confinedtoIIDdatasets
extendedintovideos(Wangetal.,2019b). Regneri
thatlackthestructureintimefromwhichhumans
etal.(2013)introduceafoundationaldatasetalign-
drawcorrelationsaboutlong-rangecausaldepen-
ingtextdescriptionsandsemanticannotationsof
dencies. What happens if a machine is allowed
actionswithvideos. Visioncaneveninformcore
toparticipateconsistently? Thisisdifficulttotest
tasks like syntax (Shi et al., 2019) and language
under current evaluation paradigms for general-
modeling(Ororbiaetal.,2019). Carefuldesignis
ization. Yet, this is the structure of generaliza-
key,asvisuallyaugmentedtaskscanfailtorequire
tioninhumandevelopment: drawinganalogiesto
sensoryperception(Thomasonetal.,2019a).
episodicmemoriesandgatheringnewdatathrough
Language-guided,embodiedagentsinvokemany
non-independentexperiments.
of the challenges of WS4. Language-based nav-
As with many who have analyzed the history
igation (Anderson et al., 2018) and task comple-
of NLP, its trends (Church, 2007), its maturation
tion(Shridharetal.,2020)insimulationenviron-
towardascience(Steedman,2008),anditsmajor
ments ground language to actions, but even com-
challenges (Hirschberg and Manning, 2015; Mc-
plex simulation action spaces can be discretized
Clellandetal.,2019),wehopetoprovidemomen-
and enumerated. By contrast, language-guided
tumforadirectionmanyarealreadyheading. We
robotsthatperformtaskcompletion(Tellexetal.,
callforandembracetheincremental,butpurpose-
2014) and learning (She et al., 2014) in the real
ful,contextualizationoflanguageinhumanexpe-
worldfacechallenging,continuousperceptionand
rience. With all that we have learned about what
control (Tellex et al., 2020). Consequently, re-
wordscantellusandwhattheykeepimplicit,now
searchinthisspaceeffectivelyrestrictsunderstand-
isthetimetoask: Whattasks,representations,and
ing to small grammars (Paul et al., 2018; Walter
inductive-biaseswillfillthegaps?
etal.,2013)orcontrolleddialogresponses(Thoma-
Computervisionandspeechrecognitionarema-
sonetal.,2020). Theseeffortstotranslatelanguage
tureenoughforinvestigationofbroaderlinguistic
instructionstoactionsbuildtowardsusinglanguage
contexts (WS3). The robotics industry is rapidly
forend-to-end,continuouscontrol(WS4).
developingcommodityhardwareandsophisticated
Collaborative games have long served as a software that both facilitate new research and ex-
testbed for studying language (Werner and Dyer, pecttoincorporatelanguagetechnologies(WS4).
1991) and emergent communication (Schlangen, Simulatorsandvideogamesprovidepotentialenvi-
2019a; Lazaridou et al., 2018; Chaabouni et al., ronmentsforsociallanguagelearners(WS5). Our
2020). Suhretal.(2019a)introducedanenviron- calltoactionistoencouragethecommunitytolean
mentforevaluatinglanguageunderstandinginthe intotrendsprioritizinggroundingandagency,and
service of a shared goal, and Andreas and Klein explicitlyaimtobroadenthecorrespondingWorld
(2016)useavisualparadigmforstudyingpragmat- Scopesavailabletoourmodels.
ics. Such efforts help us examine how inductive
biasesandenvironmentalpressuresbuildtowards
Acknowledgements
socialization(WS5),eveniffullsocialcontextis
stilltoodifficultandexpensivetobepractical.
ThankstoRaymondMooneyforsuggestions,Paul
Mostofthisresearchprovidesresourcessuchas Smolenskyfordisagreements,CatrionaSilveyfor
data,code,simulatorsandmethodologyforevaluat- developmentalpsychologyhelp,andtoasuperset
ingthemultimodalcontentoflinguisticrepresenta- of: Emily Bender, Ryan Cotterel, Jesse Dunietz,
tions(Schlangen,2019b;SilbererandLapata,2014; EdwardGrefenstette,DirkHovy,CaseyKenning-
Brunietal.,2012). Movingforward,weencourage ton,AjayDivakaran,DavidSchlangend,DiyiYang,
abroadre-examinationofhowNLPframestherela- andSemihYagciogluforpointersandsuggestions.
References Lawrence W Barsalou. 2008. Grounded cognition.
Annu.Rev.Psychol.,59:617–645.
Daniel Adiwardana, Minh-Thang Luong, David R So,
JamieHall,NoahFiedel,RomalThoppilan,ZiYang, Emily M Bender and Alexander Koller. 2020. Climb-
Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, ingtowardsnlu: Onmeaning,form,andunderstand-
et al. 2020. Towards a human-like open-domain ingintheageofdata. InAssociationforComputa-
chatbot. arXivpreprintarXiv:2001.09977. tionalLinguistics(ACL).
PeterAnderson,XiaodongHe,ChrisBuehler,Damien YoshuaBengio,RéjeanDucharme,PascalVincent,and
Teney, Mark Johnson, Stephen Gould, and Lei Christian Jauvin. 2003. A neural probabilistic lan-
Zhang.2017. Bottom-upandtop-downattentionfor guage model. Journal of Machine Learning Re-
imagecaptioningandvisualquestionanswering. Vi- search,3:1137–1155.
sualQuestionAnsweringChallengeatCVPR2017.
Leon Bergen, Roger Levy, and Noah Goodman. 2016.
Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Pragmatic reasoning through semantic inference.
MarkJohnson,NikoSünderhauf,IanReid,Stephen SemanticsandPragmatics,9.
Gould, and Anton van den Hengel. 2018. Vision-
and-Language Navigation: Interpreting visually- Yonatan Bisk, Kevin Shih, Yejin Choi, and Daniel
grounded navigation instructions in real environ- Marcu. 2018. Learning Interpretable Spatial Oper-
ments. In Proceedings of the IEEE Conference on ationsinaRich3DBlocksWorld. InProceedings
ComputerVisionandPatternRecognition(CVPR). oftheThirty-SecondConferenceonArtificialIntelli-
gence(AAAI-18).
JacobAndreasandDanKlein.2016. Reasoningabout
pragmatics with neural listeners and speakers. In Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jian-
Proceedings of the 2016 Conference on Empirical fengGao, andYejinChoi.2020. PIQA:Reasoning
Methods in Natural Language Processing, pages aboutphysicalcommonsenseinnaturallanguage. In
1173–1182,Austin,Texas. Thirty-Fourth AAAI Conference on Artificial Intelli-
gence.
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-
garet Mitchell, Dhruv Batra, C Lawrence Zitnick, David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
and Devi Parikh. 2015. Vqa: Visual question an- 2003. Latent dirichlet allocation. Journal of Ma-
swering. In Proceedings of the IEEE international chineLearningResearch,3:993–1022.
conferenceoncomputervision,pages2425–2433.
Paul Bloom. 2002. How children learn the meanings
John Langshaw Austin. 1975. How to do things with ofwords. MITpress.
words. Oxforduniversitypress.
Valts Blukis, Yannick Terme, Eyvind Niklasson,
Philip Bachman, R Devon Hjelm, and William Buch- RossA.Knepper,andYoavArtzi.2019. Learningto
walter.2019. Learningrepresentationsbymaximiz- map natural language instructions to physical quad-
ing mutual information across views. In Advances coptercontrolusingsimulatedflight. In3rdConfer-
inNeuralInformationProcessingSystems32. enceonRobotLearning(CoRL).
Anton Bakhtin, Laurens van der Maaten, Justin John- PeterFBrown,PeterVdeSouza,RobertLMercer,Vin-
son, Laura Gustafson, and Ross Girshick. 2019. cent J Della Pietra, and Jenifer C Lai. 1992. Class-
Phyre: Anewbenchmarkforphysicalreasoning. In based n-gram models of natural language. Compu-
AdvancesinNeuralInformationProcessingSystems tationalLinguistics,18.
32(NIPS2019).
TomB.Brown,BenjaminMann,NickRyder,Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
DareA.Baldwin,EllenM.Markman,BrigitteBill,Re-
Neelakantan,PranavShyam,GirishSastry,Amanda
nee N. Desjardins, Jane M. Irwin, and Glynnis Tid-
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
ball.1996. Infants’relianceonasocialcriterionfor
establishing word-object relations. Child Develop- Gretchen Krueger, Tom Henighan, Rewon Child,
ment,67(6):3135–3153. Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen,
H.B. Barlow. 1989. Unsupervised learning. Neural Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin
Computation,1(3):295–311. Chess, Jack Clark, Christopher Berner, Sam Mc-
Candlish, Alec Radford, Ilya Sutskever, and Dario
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, Amodei.2020. Languagemodelsarefew-shotlearn-
andErosZanchetta.2009. Thewackywideweb: a ers. Inpreprint.
collectionofverylargelinguisticallyprocessedweb-
crawled corpora. Language resources and evalua- Elia Bruni, Gemma Boleda, Marco Baroni, and Nam-
tion,43(3):209–226. KhanhTran.2012. Distributionalsemanticsintech-
nicolor. In Proceedings of the 50th Annual Meet-
RachelBarr.2013. Memoryconstraintsoninfantlearn- ingoftheAssociationforComputationalLinguistics
ingfrompicturebooks,television,andtouchscreens. (Volume 1: Long Papers), pages 136–145, Jeju Is-
ChildDevelopmentPerspectives,7(4):205–210. land,Korea.
EliaBruni,NamKhanhTran,andMarcoBaroni.2014. NoamChomsky.1965. AspectsoftheTheoryofSyntax.
Multimodaldistributionalsemantics. JournalofAr- MITPress.
tificialIntelligenceResearch,49:1–47.
NoamChomsky.1980. Languageandlearning:thede-
Alexandre Campeau-Lecours, Hugo Lamontagne, Si- batebetweenJeanPiagetandNoamChomsky. Har-
mon Latour, Philippe Fauteux, Véronique Maheu, vardUniversityPress.
François Boucher, Charles Deguire, and Louis-
Joseph Caron L’Ecuyer. 2019. Kinova modular Noam Chomsky. 1981. Lectures on Government and
robot arms for service robotics applications. In Binding. MoutondeGruyter.
RapidAutomation: Concepts,Methodologies,Tools,
andApplications,pages693–719.IGIGlobal. Kenneth Church. 2007. A pendulum swung too far.
LinguisticIssuesinLanguageTechnology–LiLT,2.
RahmaChaabouni,EugeneKharitonov,DianeBoucha-
court,EmmanuelDupoux,andMarcoBaroni.2020. L.ColemanandP.Kay.1981. Theenglishword“lie".
Compositionality and generalization in emergent Linguistics,57.
languages. In Association for Computational Lin-
guistics(ACL). Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: deep
Joyce Y. Chai, Rui Fang, Changsong Liu, and Lanbo
neuralnetworkswithmultitasklearning. InICML.
She. 2017. Collaborative language grounding to-
ward situated human-robot dialogue. AI Magazine,
Marc-AlexandreCôté,ÁkosKádár,XingdiYuan,Ben
37(4):32–45.
Kybartas,TavianBarnes,EmeryFine,JamesMoore,
Ruo Yu Tao, Matthew Hausknecht, Layla El Asri,
JoyceY.Chai,QiaoziGao,LanboShe,ShaohuaYang,
Mahmoud Adada, Wendy Tay, and Adam Trischler.
Sari Saba-Sadiya, and Guangyue Xu. 2018. Lan-
2018. Textworld: A learning environment for text-
guage to action: Towards interactive task learning
basedgames. ArXiv,abs/1806.11532.
withphysicalagents. InProceedingsoftheTwenty-
SeventhInternationalJointConferenceonArtificial
ErwinCoumansandYunfeiBai.2016–2019. Pybullet,
Intelligence(IJCAI-18).
a python module for physics simulation for games,
SoravitChangpinyo,Wei-LunChao,andFeiSha.2017. roboticsandmachinelearning. http://pybullet.
Predicting visual exemplars of unseen classes for org.
zero-shotlearning. InICCV.
Abhishek Das, Samyak Datta, Georgia Gkioxari, Ste-
Wei-Lun Chao, Soravit Changpinyo, Boqing Gong, fan Lee, Devi Parikh, and Dhruv Batra. 2018. Em-
andFeiSha.2016. Anempiricalstudyandanalysis bodied question answering. In Proceedings of the
of generalized zero-shot learning for object recog- IEEE Conference on Computer Vision and Pattern
nition in the wild. In ECCV, pages 52–68, Cham. RecognitionWorkshops,pages2054–2063.
SpringerInternationalPublishing.
ScottDeerwester,SusanT.Dumais,GeorgeW.Furnas,
Eugene Charniak. 1977. A framed painting: The rep- ThomasK.Landauer,andRichardHarshman.1988.
resentationofacommonsenseknowledgefragment. Improvinginformationretrievalwithlatentsemantic
CognitiveScience,1(4):355–394. indexing. In Proceedings of the 51st Annual Meet-
ingoftheAmericanSocietyforInformationScience
Chun-Yen Chen, Dian Yu, Weiming Wen, Yi Mang
25,pages36–40.
Yang, JiapingZhang, MingyangZhou, KevinJesse,
Austin Chau, Antara Bhowmick, Shreenath Iyer,
Scott Deerwester, Susan T. Dumais, George W. Fur-
etal.2018. Gunrock: Buildingahuman-likesocial
nas, Thomas K. Landauer, and Richard Harshman.
bot by leveraging large scale real user data. Alexa
1990. Indexing by latent semantic analysis. Jour-
PrizeProceedings.
naloftheAmericanSocietyforInformationScience,
41(6):391–407.
DavidL.ChenandRaymondJ.Mooney.2008. Learn-
ing to sportscast: A test of grounded language ac-
GeraldDejong.1981. Generalizationsbasedonexpla-
quisition. In Proceedings of the 25th International
nations. InProceedingsofthe7thinternationaljoint
ConferenceonMachineLearning(ICML),Helsinki,
conferenceonArtificialintelligence(IJCAI).
Finland.
SF Chen and Joshua Goodman. 1996. An empirical David DeVault, Iris Oved, and Matthew Stone. 2006.
study of smoothing techniques for language model- Societal grounding is essential to meaningful lan-
ing. In Association for Computational Linguistics, guage use. In Proceedings of the National Confer-
pages310–318. enceonArtificialIntelligence,volume21,page747.
Maxime Chevalier-Boisvert, Dzmitry Bahdanau, Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Salem Lahlou, Lucas Willems, Chitwan Saharia, Kristina Toutanova. 2019. BERT: Pre-training of
Thien Huu Nguyen, and Yoshua Bengio. 2019. Deep Bidirectional Transformers for Language Un-
Babyai: First steps towards grounded language derstanding. In North American Chapter of the As-
learningwithahumanintheloop. InICLR’2019. sociationforComputationalLinguistics(NAACL).
Emily Dinan, Samuel Humeau, Bharath Chintagunta, Michael C Frank and Noah D Goodman. 2012. Pre-
and Jason Weston. 2019. Build it break it fix it for dictingpragmaticreasoninginlanguagegames. Sci-
dialoguesafety:Robustnessfromadversarialhuman ence,336(6084):998–998.
attack. In Proceedings of the 2019 Conference on
EmpiricalMethodsinNaturalLanguageProcessing RuijiFu,JiangGuo,BingQin,WanxiangChe,Haifeng
andthe9thInternationalJointConferenceonNatu- Wang,andTingLiu.2014. Learningsemantichier-
ralLanguageProcessing(EMNLP-IJCNLP),pages archiesviawordembeddings. InProceedingsofthe
4529–4538. 52ndAnnualMeetingoftheAssociationforCompu-
tationalLinguistics(Volume1: LongPapers),pages
SusanT.Dumais.2004. Latentsemanticanalysis. An- 1199–1209.
nualReviewofInformationScienceandTechnology,
38(1):188–230. MattGardner,YoavArtzi,VictoriaBasmova,Jonathan
Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi,
Robin IM Dunbar. 1993. Coevolution of neocortical Dheeru Dua, Yanai Elazar, Ananth Gottumukkala,
size, group size and language in humans. Behav- Nitish Gupta, Hanna Hajishirzi, Gabriel Ilharco,
ioralandbrainsciences,16(4):681–694. Daniel Khashabi, Kevin Lin, Jiangming Liu, Nel-
son F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer
YanaiElazar,AbhijitMahabal,DeepakRamachandran,
Singh, Noah A. Smith, Sanjay Subramanian, Reut
Tania Bedrax-Weiss, and Dan Roth. 2019. How
Tsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou.
large are lions? inducing distributions over quanti-
2020. Evaluating NLP Models via Contrast Sets.
tativeattributes. InProceedingsofthe57thAnnual
arXiv:2004.02709.
Meeting of the Association for Computational Lin-
guistics,pages3973–3983. Max Glockner, Vered Shwartz, and Yoav Goldberg.
2018. Breaking nli systems with sentences that re-
DesmondElliott,StellaFrank,KhalilSima’an,andLu-
quire simple lexical inferences. In Proceedings of
cia Specia. 2016. Multi30k: Multilingual english-
the56thAnnualMeetingoftheAssociationforCom-
germanimagedescriptions. InWorkshoponVision
putational Linguistics (Volume 2: Short Papers),
andLangaugeatACL’16.
pages650–655.
J Elman. 1990. Finding structure in time. Cognitive
I J Good. 1953. The population frequencies of
Science,14(2):179–211.
speciesandtheestimationofpopulationparameters.
Katrin Erk and Sebastian Padó. 2008. A structured Biometrika,40:237–264.
vector space model for word meaning in context.
Herbert P Grice. 1975. Logic and conversation. In
In Proceedings of the 2008 Conference on Empiri-
Speechacts,pages41–58.Brill.
calMethodsinNaturalLanguageProcessing,pages
897–906,Honolulu,Hawaii.
Suchin Gururangan, Swabha Swayamdipta, Omer
Levy,RoySchwartz,SamuelBowman,andNoahA
SusanErvin-Tripp.1973. Somestrategiesforthefirst
Smith. 2018. Annotation artifacts in natural lan-
two years. In Timothy E. Moore, editor, Cognitive
guage inference data. In Proceedings of the 2018
Development and Acquisition of Language, pages
Conference of the North American Chapter of the
261–286.AcademicPress,SanDiego.
Association for Computational Linguistics: Human
AliFarhadi,MHejrati,MSadeghi,PeterYoung,Cyrus Language Technologies, Volume 2 (Short Papers),
Rashtchian, Julia Hockenmaier, and David Forsyth. pages107–112.
2010. Every picture tells a story: Generating sen-
tences from images. In European Conference on StevanHarnad.1990. Thesymbolgroundingproblem.
ComputerVision.Springer. PhysicaD,42:335–346.
YansongFengandMirellaLapata.2010. Topicmodels Zellig S Harris. 1954. Distributional structure. Word,
forimageannotationandtextillustration. InHuman 10:146–162.
Language Technologies: The 2010 Annual Confer-
DavidHarwath,Wei-NingHsu,andJamesGlass.2020.
enceoftheNorthAmericanChapteroftheAssocia-
Learning hierarchical discrete linguistic units from
tion for Computational Linguistics, pages 831–839,
visually-groundedspeech. InICLR2020.
LosAngeles,California.
David Harwath, Adrià Recasens, Dídac Surís, Galen
J.R.Firth.1957. Asynopsisoflinguistictheory,1930-
Chuang, Antonio Torralba, and James Glass. 2019.
1955. StudiesinLinguisticAnalysis.
Jointlydiscoveringvisualobjectsandspokenwords
Cliff Fitzgerald. 2013. Developing baxter. In 2013 from raw sensory input. International Journal of
IEEE Conference on Technologies for Practical ComputerVision.
RobotApplications(TePRA).
He He, Derek Chen, Anusha Balakrishnan, and Percy
W. Nelson Francis. 1964. A standard sample of Liang.2018. Decouplingstrategyandgenerationin
present-day english for use with digital computers. negotiation dialogues. In Proceedings of the 2018
Report to the U.S Office of Education on Coopera- Conference on Empirical Methods in Natural Lan-
tiveResearchProjectNo.E-007. guageProcessing,pages2333–2343.
Susan J. Hespos and Elizabeth S. Spelke. 2004. Con- Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin John-
ceptualprecursorstolanguage. Nature,430. son, Kenji Hata, Joshua Kravitz, Stephanie Chen,
Yannis Kalantidis, Li-Jia Li, David A Shamma,
G. E. Hinton, J. L. McClelland, and D. E. Rumelhart. Michael S. Bernstein, and Fei-Fei Li. 2017. Vi-
1986. Distributed representations. Parallel Dis- sual genome: Connecting language and vision us-
tributedProcessing:ExplorationsintheMicrostruc- ingcrowdsourceddenseimageannotations. Interna-
tureofCognition,Volume1: Foundations. tionalJournalofComputerVision,123(1):32–73.
GeoffreyE.Hinton.1990. Prefacetothespecialissue Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-
onconnectionistsymbolprocessing. ArtificialIntel- ton. 2012. Imagenet classification with deep con-
ligence,46(1):1–4. volutional neural networks. In F. Pereira, C. J. C.
Burges, L. Bottou, and K. Q. Weinberger, editors,
Julia Hirschberg and Christopher D Manning. 2015. AdvancesinNeuralInformationProcessingSystems
Advances in natural language processing. Science, 25,pages1097–1105.CurranAssociates,Inc.
349(6245):261–266.
George Lakoff. 1973. Hedges: A study in meaning
DouglasHofstadterandEmmanuelSander.2013. Sur- criteria and the logic of fuzzy concepts. Journal of
faces and essences: Analogy as the fuel and fire of PhilosophicalLogic,2:458–508.
thinking. BasicBooks.
GeorgeLakoff.1980. MetaphorsWeLiveBy. Univer-
Ari Holtzman, Jan Buys, Maxwell Forbes, and Yejin sityofChicagoPress.
Choi.2020. Thecuriouscaseofneuraltextdegener-
Zhenzhong Lan, Mingda Chen, Sebastian Goodman,
ation. InICLR2020.
Kevin Gimpel, Piyush Sharma, and Radu Soricut.
Po-YaoHuang,JunjieHu,XiaojunChang,andAlexan- 2020. Albert:Alitebertforself-supervisedlearning
der Hauptmann. 2020. Unsupervised multimodal of language representations. In International Con-
neural machine translation with pseudo visual piv- ferenceonLearningRepresentations.
oting. In Proceedings of the 58th Annual Meet-
Ronald W Langacker. 1987. Foundations of cogni-
ingoftheAssociationforComputationalLinguistics,
tive grammar: Theoretical prerequisites, volume 1.
pages8226–8237,Online.
Stanforduniversitypress.
Gabriel Ilharco, Yuan Zhang, and Jason Baldridge.
RonaldWLangacker.1991. FoundationsofCognitive
2019. Large-scalerepresentationlearningfromvisu-
Grammar: descriptiveapplication.,volume2. Stan-
allygroundeduntranscribedspeech. InProceedings
forduniversitypress.
of the 23rd Conference on Computational Natural
Language Learning (CoNLL), pages 55–65, Hong AngelikiLazaridou,KarlMoritzHermann,KarlTuyls,
Kong,China. and Stephen Clark. 2018. Emergence of linguis-
ticcommunicationfromreferentialgameswithsym-
Daniel L. James and Risto Miikkulainen. 1995. Sard-
bolicandpixelinput. InInternationlConferenceon
net:Aself-organizingfeaturemapforsequences. In
LearningRepresentations.
AdvancesinNeuralInformationProcessingSystems
7 (NIPS’94), pages 577–584, Denver, CO. Cam- Angeliki Lazaridou, Alexander Peysakhovich, and
bridge,MA:MITPress. Marco Baroni. 2017. Multi-agent cooperation and
theemergenceof(natural)language. InICLR2017.
MichaelIJordan.2019. Artificialintelligence–therev-
olutionhasn’thappenedyet. HarvardDataScience Angeliki Lazaridou, Nghia The Pham, and Marco Ba-
Review. roni. 2016. The red one!: On learning to refer to
things based on discriminative properties. In Pro-
DivyanshKaushik, EduardHovy, andZacharyLipton. ceedingsofthe54thAnnualMeetingoftheAssocia-
2020. Learning the difference that makes a differ- tionforComputationalLinguistics(Volume2:Short
encewithcounterfactually-augmenteddata. InInter- Papers),pages213–218,Berlin,Germany.
nationalConferenceonLearningRepresentations.
Matthew Le, Y-Lan Boureau, and Maximilian Nickel.
Nitish Shirish Keskar, Bryan McCann, Lav R 2019. Revisiting the evaluation of theory of mind
Varshney, Caiming Xiong, and Richard Socher. through question answering. In Proceedings of the
2019. CTRL: A conditional transformer language 2019 Conference on Empirical Methods in Natu-
model for controllable generation. arXiv preprint ral Language Processing and the 9th International
arXiv:1909.05858. Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), pages 5871–5876, Hong Kong,
Reinhard Kneser and Hermann Ney. 1995. Improved China.
backing-offform-gramlanguagemodeling. InPro-
ceedings of the IEEE International Conference on MikeLewis,DenisYarats,YannDauphin,DeviParikh,
Acoustics,SpeechandSignalProcessing. andDhruvBatra.2017. Dealornodeal?end-to-end
learningofnegotiationdialogues. InProceedingsof
TeuvoKohonen.1984. Self-OrganizationandAssocia- the2017ConferenceonEmpiricalMethodsinNatu-
tiveMemory. Springer. ralLanguageProcessing,pages2443–2453.
Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Lara J Martin, Prithviraj Ammanabrolu, Xinyu Wang,
Hsieh,andKai-WeiChang.2019a. VisualBERT:A WilliamHancock,ShrutiSingh,BrentHarrison,and
SimpleandPerformantBaselineforVisionandLan- Mark O Riedl. 2018. Event representations for au-
guage. InWorkinProgress. tomated story generation with deep neural nets. In
Thirty-SecondAAAIConferenceonArtificialIntelli-
Yong-LuLi,LiangXu,XinpengLiu,XijieHuang,Yue gence.
Xu,MingyangChen,ZeMa,ShiyiWang,Hao-Shu
Fang, and Cewu Lu. 2019b. HAKE: Human Activ-
Cynthia Matuszek. 2018. Grounded language learn-
ityKnowledgeEngine. arXiv:1904.06539.
ing: Whereroboticsandnlpmeet(earlycareerspot-
light). InProceedingsofthe27thInternationalJoint
Ling-Yi Lin, Rong-Ju Cherng, and Yung-Jung Chen.
ConferenceonArtificialIntelligence(IJCAI),Stock-
2017. Effectoftouchscreentabletuseonfinemotor
holm,Sweden.
developmentofyoungchildren. Physical&Occupa-
tionalTherapyInPediatrics,37(5):457–467. PMID:
BryanMcCann,JamesBradbury,CaimingXiong,and
28071977.
RichardSocher.2017. Learnedintranslation: Con-
TalLinzen.2020. Howcanweaccelerateprogressto- textualizedwordvectors. InAdvancesinNeuralIn-
wards human-like linguistic generalization? In As- formationProcessingSystems,pages6297–6308.
sociationforComputationalLinguistics(ACL).
James L. McClelland, Felix Hill, Maja Rudolph, Ja-
Changsong Liu and Joyce Yue Chai. 2015. Learning son Baldridge, and Hinrich Schütze. 2019. Ex-
tomediateperceptualdifferencesinsituatedhuman- tending Machine Language Models toward Human-
robot dialogue. In Proceedings of the 29th AAAI LevelLanguageUnderstanding. arXiv:1912.05877.
Conference on Artificial Intelligence, pages 2288–
2294. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, andJeffreyDean.2013. Distributedrepresen-
Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Nose-
tationsofwordsandphrasesandtheircomposition-
worthy, Laurent Charlin, and Joelle Pineau. 2016.
ality. Advances in Neural Information Processing
How not to evaluate your dialogue system: An em-
Systems,26.
piricalstudyofunsupervisedevaluationmetricsfor
dialogueresponsegeneration. InProceedingsofthe
MargaretMitchell,JesseDodge,AmitGoyal,KotaYa-
2016 Conference on Empirical Methods in Natural
maguchi, Karl Stratos, Xufeng Han, Alyssa Men-
LanguageProcessing,pages2122–2132.
sch, Alexander C. Berg, Tamara L. Berg, and Hal
DauméIII.2012. Midge:Generatingimagedescrip-
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou
tionsfromcomputervisiondetections. InEuropean
Tang.2015. Deeplearningfaceattributesinthewild.
Chapter of the Association for Computational Lin-
InProceedingsofInternationalConferenceonCom-
guistics(EACL).
puterVision(ICCV).
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan TomMMitchell.1980. Theneedforbiasesinlearning
Lee. 2019. Vilbert: Pretraining task-agnostic visi- generalizations. Department of Computer Science,
olinguistic representations for vision-and-language LaboratoryforComputerScienceResearch.
tasks. In Advances in Neural Information Process-
ingSystems,pages13–23. Raymond J. Mooney. 2008. Learning to connect lan-
guage and perception. In Proceedings of the 23rd
Li Lucy and Jon Gauthier. 2017. Are distributional AAAI Conference on Artificial Intelligence (AAAI),
representations ready for the real world? evaluat- pages1598–1601,Chicago,IL. SeniorMemberPa-
ing word vectors for grounded perceptual meaning. per.
In Proceedings of the First Workshop on Language
Grounding for Robotics, pages 76–85, Vancouver, RaymondJMooneyandGeraldDejong.1985. Learn-
Canada.AssociationforComputationalLinguistics. ing schemata for natural language processing. In
ProceedingsoftheNinthInternationalJointConfer-
Matt MacMahon, Brian Stankiewicz, and Benjamin
enceonArtificialIntelligence(IJCAI-85).
Kuipers.2006. Walkthetalk: Connectinglanguage,
knowledge,andactioninrouteinstructions. InPro-
Daniele Moro and Casey Kennington. 2018. Multi-
ceedings of the 21st National Conference on Artifi-
modal visual and simulated muscle activations for
cialIntelligence(AAAI-2006),Boston,MA,USA.
groundedsemanticsofhand-relateddescriptions. In
Workshop on the Semantics and Pragmatics of Dia-
Gary Marcus and Ernest Davis. 2019. Rebooting AI:
Building Artificial Intelligence We Can Trust. Pan-
logue.SEMDIAL.
theon.
Roozbeh Mottaghi, Mohammad Rastegari, Abhinav
MitchellPMarcus, BeatriceSantorini, and Mary Ann Gupta, and Ali Farhadi. 2016. “what happens if...”
Marcinkiewicz. 1993. Building a large annotated learning to predict the effect of forces in images.
corpus of english: The penn treebank. Computa- In Computer Vision – ECCV 2016, pages 269–285,
tionalLinguistics,19:313–330. Cham.SpringerInternationalPublishing.
Adithyavairavan Murali, Tao Chen, Kalyan Vasudev Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Alwala,DhirajGandhi,LerrelPinto,SaurabhGupta, Gardner, Christopher Clark, Kenton Lee, and Luke
andAbhinavGupta.2019. Pyrobot:Anopen-source Zettlemoyer.2018. Deepcontextualizedwordrepre-
roboticsframeworkforresearchandbenchmarking. sentations. InNorthAmericanChapteroftheAsso-
arXivpreprintarXiv:1906.08236. ciationforComputationalLinguistics(NAACL).
Aida Nematzadeh, Kaylee Burns, Erin Grant, Alison John R Pierce. 1969. Whither speech recognition?
Gopnik,andTomGriffiths.2018. Evaluatingtheory The journal of the acoustical society of america,
of mind in question answering. In Proceedings of 46(4B):1049–1051.
the2018ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing,pages2392–2400. Nicolas Pinto, David Doukhan, James J DiCarlo, and
David D Cox. 2009. A high-throughput screening
NVIDIA. 2019. NVIDIA Isaac software develop- approach to discovering good forms of biologically
ment kit. https://developer.nvidia.com/ inspiredvisualrepresentation. PLoScomputational
isaac-sdk. Accessed2019-12-09. biology,5(11):e1000579.
ElinorOchs.1993. Constructingsocialidentity: Alan- JordanB.Pollack.1987. OnConnectionistModelsof
guage socialization perspective. Research on lan- NaturalLanguageProcessing. Ph.D.thesis,Univer-
guageandsocialinteraction,26(3):287–306.
sityofIllinois.
William O’Grady. 2005. How Children Learn Lan-
Alec Radford, Jeff Wu, Rewon Child, David Luan,
guage. CambridgeUniversityPress.
DarioAmodei,andIlyaSutskever.2019. Language
modelsareunsupervisedmultitasklearners.
Veronica Ornaghi, Jens Brockmeier, and Ilaria Graz-
zaniGavazzi.2011. Theroleoflanguagegamesin
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
children’s understanding of mental states: A train-
Know what you don’t know: Unanswerable ques-
ing study. Journal of cognition and development,
tionsforSQuAD. InProceedingsofthe56thAnnual
12(2):239–259.
Meeting of the Association for Computational Lin-
Alexander Ororbia, Ankur Mali, Matthew Kelly, and
guistics(Volume2: ShortPapers),pages784–789.
DavidReitter.2019. Likeababy: Visuallysituated
HannahRashkin,EricMichaelSmith,MargaretLi,and
neural language acquisition. In Proceedings of the
Y-Lan Boureau. 2019. Towards empathetic open-
57th Annual Meeting of the Association for Com-
domainconversationmodels:Anewbenchmarkand
putational Linguistics, pages 5127–5136, Florence,
dataset. In Proceedings of the 57th Annual Meet-
Italy.
ingoftheAssociationforComputationalLinguistics,
Denis Paperno, Germán Kruszewski, Angeliki Lazari- pages5370–5381,Florence,Italy.
dou, Ngoc-Quan Pham, Raffaella Bernardi, San-
MichaelaRegneri,MarcusRohrbach,DominikusWet-
dro Pezzelle, Marco Baroni, Gemma Boleda, and
zel, Stefan Thater, Bernt Schiele, and Manfred
Raquel Fernández. 2016. The LAMBADA dataset:
Pinkal. 2013. Grounding action descriptions in
Wordpredictionrequiringabroaddiscoursecontext.
videos. TransactionsoftheAssociationforCompu-
In Proceedings of the 54th Annual Meeting of the
tationalLinguistics(TACL),1:25–36.
Association for Computational Linguistics (Volume
1: LongPapers),pages1525–1534.
Stephen Roller, Emily Dinan, Naman Goyal, Da Ju,
Rohan Paul, Jacob Arkin, Derya Aksaray, Nicholas Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott,
Roy, and Thomas M Howard. 2018. Efficient Kurt Shuster, Eric M. Smith, Y-Lan Boureau, and
grounding of abstract spatial concepts for nat- Jason Weston. 2020. Recipes for building an open-
ural language interaction with robot platforms. domainchatbot. InarXiv.
The International Journal of Robotics Research,
Stephanie Rosenthal, Joydeep Biswas, and Manuela
37(10):1269–1299.
Veloso. 2010. An effective personal mobile robot
Haoruo Peng, Daniel Khashabi, and Dan Roth. 2015. agent through symbiotic human-robot interaction.
Solvinghardcoreferenceproblems. InProceedings In Proceedings of the 9th International Conference
ofthe2015ConferenceoftheNorthAmericanChap- onAutonomousAgentsandMultiagentSystems:vol-
teroftheAssociationforComputationalLinguistics: ume1-Volume1,pages915–922.InternationalFoun-
HumanLanguageTechnologies,pages809–819. dationforAutonomousAgentsandMultiagentSys-
tems.
Jeffrey Pennington, Richard Socher, and Christopher
Manning.2014. Glove:Globalvectorsforwordrep- Corby Rosset. 2020. Turing-NLG: A 17-billion-
resentation. InProceedingsofthe2014Conference parameterlanguagemodelbyMicrosoft.
onEmpiricalMethodsinNaturalLanguageProcess-
ing(EMNLP),pages1532–1543,Doha,Qatar. OlgaRussakovsky,JiaDeng,HaoSu,JonathanKrause,
Sanjeev Satheesh, Sean Ma, Zhiheng Huang, An-
DonPerlis.2016. Fivedimensionsofreasoninginthe drej Karpathy, Aditya Khosla, Michael Bernstein,
wild. In Association for the Advancement of Artifi- Alexander C. Berg, and Li Fei-Fei. 2015. Ima-
cialIntelligence(AAAI). geNet Large Scale Visual Recognition Challenge.
International Journal of Computer Vision (IJCV), human-robotdialogue. InProceedingsof15thSIG-
115(3):211–252. DIALMeetingonDiscourseandDialogue.
JacquelineSachs,BarbaraBard,andMarieLJohnson. Haoyue Shi, Jiayuan Mao, Kevin Gimpel, and Karen
1981. Languagelearningwithrestrictedinput: Case Livescu.2019. Visuallygroundedneuralsyntaxac-
studiesoftwohearingchildrenofdeafparents. Ap- quisition. In Proceedings of the 57th Annual Meet-
pliedPsycholinguistics,2(1):33–54. ingoftheAssociationforComputationalLinguistics,
pages1842–1861,Florence,Italy.
Ian Sample and Alex Hern. 2014. Scientists dispute
whethercomputer‘eugenegoostman‘passedturing
Mohammad Shoeybi, Mostofa Patwary, Raul Puri,
test. TheGuardian,9.
Patrick LeGresley, Jared Casper, and Bryan Catan-
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan zaro. 2019. Megatron-lm: Training multi-billion
Le Bras, and Yejin Choi. 2019. Social IQa: Com- parameter language models using gpu model paral-
monsense reasoning about social interactions. In lelism. arXivpreprintarXiv:1909.08053.
Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the Mohit Shridhar, Jesse Thomason, Daniel Gordon,
9th International Joint Conference on Natural Lan- Yonatan Bisk, Winson Han, Roozbeh Mottaghi,
guage Processing (EMNLP-IJCNLP), pages 4462– LukeZettlemoyer,andDieterFox.2020. ALFRED:
4472,HongKong,China. Abenchmarkforinterpretinggroundedinstructions
for everyday tasks. Computer Vision and Pattern
Rosario Scalise, Jesse Thomason, Yonatan Bisk, and Recognition(CVPR).
Siddhartha Srinivasa. 2019. Improving robot suc-
cess detection using static object data. In Proceed- Carina Silberer and Mirella Lapata. 2014. Learn-
ingsofthe2019IEEE/RSJInternationalConference ing grounded meaning representations with autoen-
onIntelligentRobotsandSystems. coders. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguis-
RogerC.SchankandRobertP.Abelson.1977. Scripts, tics(Volume1: LongPapers),pages721–732,Balti-
Plans, Goals and Understanding: an Inquiry into
more,Maryland.
Human Knowledge Structures. L. Erlbaum, Hills-
dale,NJ.
Jivko Sinapov, Connor Schenck, and Alexander
Stoytchev. 2014. Learning relational object cate-
Marten van Schijndel, Aaron Mueller, and Tal
goriesusingbehavioralexplorationandmultimodal
Linzen. 2019. Quantity doesn’t buy quality syn-
perception. In IEEE International Conference on
tax with neural language models. arXiv preprint
RoboticsandAutomation.
arXiv:1909.00111.
DavidSchlangen.2019a. Groundedagreementgames: Linda Smith and Michael Gasser. 2005. The develop-
Emphasizingconversationalgroundinginvisualdia- ment of embodied cognition: Six lessons from ba-
loguesettings. arXiv. bies. Artificiallife,11(1-2):13–29.
DavidSchlangen.2019b. Languagetasksandlanguage Paul Smolensky. 1990. Tensor product variable bind-
games: Onmethodologyincurrentnaturallanguage ing and the representation of symbolic structures
processingresearch. arXiv. in connectionist systems. Artificial Intelligence,
46:159–216.
Iulian V. Serban, Chinnadhurai Sankar, Mathieu Ger-
main, SaizhengZhang, ZhouhanLin, SandeepSub-
Richard Socher, Brody Huval, Christopher Manning,
ramanian, Taesup Kim, Michael Pieper, Sarath
and Andrew Ng. 2012. Semantic compositional-
Chandar,NanRosemaryKe,SaiRajeshwar,Alexan-
ity through recursive matrix-vector spaces. In Em-
dre de Brebisson, Jose M. R. Sotelo, Dendi
pirical Methods in Natural Language Processing
Suhubdy, Vincent Michalski, Alexandre Nguyen,
(EMNLP).
Joelle Pineau, and Yoshua Bengio. 2017. A deep
reinforcement learning chatbot. arXiv preprint
T.Srinivasan, R.Sanabria, andF.Metze.2020. Look-
arXiv:1709.02349.
ing enhances listening: Recovering missing speech
usingimages. InICASSP2020-2020IEEEInterna-
Piyush Sharma, Nan Ding, Sebastian Goodman, and
tional Conference on Acoustics, Speech and Signal
Radu Soricut. 2018. Conceptual captions: A
Processing(ICASSP),pages6304–6308.
cleaned, hypernymed, image alt-text dataset for au-
tomatic image captioning. In Proceedings of the
56thAnnualMeetingoftheAssociationforCompu- MarkSteedman.2008. Lastwords:Onbecomingadis-
tationalLinguistics(Volume1: LongPapers),pages cipline. ComputationalLinguistics,34(1):137–144.
2556–2565,Melbourne,Australia.
Greg J Stephens, Lauren J Silbert, and Uri Hasson.
Lanbo She, Shaohua Yang, Yu Cheng, Yunyi Jia, 2010. Speaker–listener neural coupling underlies
Joyce Y. Chai, and Ning Xi. 2014. Back to the successful communication. Proceedings of the Na-
blocksworld:Learningnewactionsthroughsituated tionalAcademyofSciences,107(32):14425–14430.
Alane Suhr, Claudia Yan, Jack Schluger, Stanley Yu, JesseThomason,MichaelMurray,MayaCakmak,and
Hadi Khader, Marwa Mouallem, Iris Zhang, and Luke Zettlemoyer. 2019b. Vision-and-dialog navi-
Yoav Artzi. 2019a. Executing instructions in situ- gation. InConferenceonRobotLearning(CoRL).
ated collaborative interactions. In Proceedings of
the 2019 Conference on Empirical Methods in Nat- Jesse Thomason, Aishwarya Padmakumar, Jivko
uralLanguageProcessingandthe9thInternational Sinapov, Justin Hart, Peter Stone, and Raymond J.
Joint Conference on Natural Language Processing Mooney. 2017. Opportunistic active learning for
(EMNLP-IJCNLP), pages 2119–2130, Hong Kong, grounding natural language descriptions. In Pro-
China. ceedings of the 1st Annual Conference on Robot
Learning(CoRL).
Alane Suhr, Stephanie Zhou, Ally Zhang, Iris Zhang,
Huajun Bai, and Yoav Artzi. 2019b. A corpus for Jesse Thomason, Aishwarya Padmakumar, Jivko
reasoning about natural language grounded in pho- Sinapov, Nick Walker, Yuqian Jiang, Harel Yedid-
tographs. In Proceedings of the 57th Annual Meet- sion, Justin Hart, Peter Stone, and Raymond J.
ingoftheAssociationforComputationalLinguistics, Mooney. 2020. Jointly improving parsing and per-
pages6418–6428,Florence,Italy. ception for natural language commands through
human-robotdialog. TheJournalofArtificialIntel-
Chen Sun, Fabien Baradel, Kevin Murphy, and ligenceResearch(JAIR),67.
Cordelia Schmid. 2019a. Contrastive bidirectional
transformer for temporal representation learning. Jesse Thomason, Jivko Sinapov, Maxwell Svetlik, Pe-
arxiv:1906.05743. terStone,andRaymondJ.Mooney.2016. Learning
multi-modal grounded linguistic semantics by play-
Chen Sun, Austin Myers, Carl Vondrick, Kevin Mur-
ing “I spy”. In International Joint Conference on
phy, and Cordelia Schmid. 2019b. VideoBERT: A
ArtificialIntelligence(IJCAI).
JointModelforVideoandLanguageRepresentation
Learning. InInternationalConferenceonComputer Emanuel Todorov, Tom Erez, and Yuval Tassa. 2012.
vision. Mujoco: A physics engine for model-based con-
trol. In 2012 IEEE/RSJ International Conference
Yee-Whye Teh. 2006. A hierarchical bayesian lan-
onIntelligentRobotsandSystems,pages5026–5033.
guage model based on pitman-yor processes. In
IEEE.
Proceedingsofthe21stInternationalConferenceon
Computational Linguistics and 44th Annual Meet-
Michael Tomasello. 2009. Constructing a language.
ingoftheAssociationforComputationalLinguistics,
Harvarduniversitypress.
pages985–992,Sydney,Australia.
Yao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang,
Stefanie Tellex, Nakul Gopalan, Hadas Kress-Gazit,
J. Zico Kolter, Louis-Philippe Morency, and Rus-
and Cynthia Matuszek. 2020. Robots that use lan-
lan Salakhutdinov. 2019. Multimodal transformer
guage. TheAnnualReviewofControl,Robotics,and
for unaligned multimodal language sequences. In
AutonomousSystems,15.
Proceedingsofthe57thAnnualMeetingoftheAsso-
ciation for Computational Linguistics, pages 6558–
StefanieTellex,RossKnepper,AdrianLi,DanielaRus,
6569,Florence,Italy.
and Nicholas Roy. 2014. Asking for help using in-
verse semantics. In Proceedings of Robotics: Sci-
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
enceandSystems(RSS),Berkeley,California.
2010. Word representations: A simple and general
Stefanie Tellex, Thomas Kollar, Steven Dickerson, method for semi-supervised learning. In Proceed-
Matthew R Walter, Ashis Gopal Banerjee, Seth ings of the 48th Annual Meeting of the Association
Teller,andNicholasRoy.2011. Understandingnat- forComputationalLinguistics,pages384–394.
urallanguagecommandsforroboticnavigationand
AlanMTuring.1950. Computingmachineryandintel-
mobile manipulation. In Proceedings of the Na-
ligence. Mind.
tionalConferenceonArtificialIntelligence.
Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019. Peter D Turney and Patrick Pantel. 2010. From fre-
BERT rediscovers the classical NLP pipeline. In quency to meaning: Vector space models of se-
Proceedingsofthe57thAnnualMeetingoftheAsso- mantics. Journal of artificial intelligence research,
ciation for Computational Linguistics, pages 4593– 37:141–188.
4601,Florence,Italy.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Esther Thelen and Linda B. Smith. 1996. A Dynamic Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz
SystemsApproachtotheDevelopmentofCognition Kaiser, and Illia Polosukhin. 2017. Attention is all
andAction. MITPress. you need. In Advances in neural information pro-
cessingsystems,pages5998–6008.
Jesse Thomason, Daniel Gordon, and Yonatan Bisk.
2019a. Shiftingthebaseline:Singlemodalityperfor- GabriellaVigliocco,PamelaPerniss,andDavidVinson.
mance on visual navigation & QA. In North Amer- 2014. Languageasamultimodalphenomenon: im-
ican Chapter of the Association for Computational plicationsforlanguagelearning,processingandevo-
Linguistics(NAACL). lution.
Harm de Vries, Dzmitry Bahdanau, and Christopher InProceedingsofthe2019ConferenceoftheNorth
Manning. 2020. Towards ecologically valid re- American Chapter of the Association for Computa-
searchonlanguageuserinterfaces. InarXiv. tional Linguistics: Human Language Technologies,
Volume1(LongandShortPapers).
Matthew Walter, Sachithra Hemachandra, Bianca
Homberg, Stefanie Tellex, and Seth Teller. 2013. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-
Learning semantic maps from natural language de- bonell, Ruslan Salakhutdinov, and Quoc V Le.
scriptions. InProceedingsofRobotics: Scienceand 2019b. Xlnet: Generalized autoregressive pretrain-
Systems(RSS),Berlin,Germany. ingforlanguageunderstanding. InAdvancesinNeu-
ralInformationProcessingSystems32(NIPS2019).
Alex Wang, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel R Bowman. 2019a. Mark Yatskar, Luke Zettlemoyer, and Ali Farhadi.
GLUE: A multi-task benchmark and analysis plat- 2016. Situation recognition: Visual semantic role
form for natural language understanding. In Inter- labelingforimageunderstanding. InConferenceon
nationalConferenceonLearningRepresentations. ComputerVisionandPatternRecognition.
Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan- Amir Zadeh, Michael Chan, Paul Pu Liang, Edmund
FangWang,andWilliamYangWang.2019b. Vatex: Tong,andLouis-PhilippeMorency.2019. Social-iq:
A large-scale, high-quality multilingual dataset for Aquestionansweringbenchmarkforartificialsocial
video-and-languageresearch. InTheIEEEInterna- intelligence. InTheIEEEConferenceonComputer
tionalConferenceonComputerVision(ICCV). VisionandPatternRecognition(CVPR).
RonaldWardhaugh.2011. Anintroductiontosociolin- Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin
guistics,volume28. JohnWiley&Sons. Choi. 2019a. From recognition to cognition: Vi-
sualcommonsensereasoning. InTheIEEEConfer-
Joseph Weizenbaum. 1966. Eliza – a computer pro- ence on Computer Vision and Pattern Recognition
gram for the study of natural language communica- (CVPR).
tionbetweenmanandmachine. Communicationsof
theACM,9(1):36–45. RowanZellers,AriHoltzman,ElizabethClark,Lianhui
Qin,AliFarhadi,andYejinChoi.2020. Evaluating
LloydRWelch.2003. Hiddenmarkovmodelsandthe machines by their real-world language use. arXiv
baum-welch algorithm. IEEE Information Theory preprintarXiv:2004.03607.
SocietyNewsletter,53(4):1–24.
Rowan Zellers, Ari Holtzman, Hannah Rashkin,
GregoryMWernerandMichaelGDyer.1991. Evolu- Yonatan Bisk, Ali Farhadi, Franziska Roesner, and
tionofcommunicationinartificialorganisms. ALife. Yejin Choi. 2019b. Defending against neural fake
news. In Thirty-third Conference on Neural Infor-
TerryWinograd.1971. Proceduresasarepresentation mationProcessingSystems.
for data in a computer program for understanding
natural language. Technical report, Massachusetts LiZhou,JianfengGao,DiLi,andHeung-YeungShum.
InstituteofTechnology,ProjectMAC. 2020. Thedesignandimplementationofxiaoice,an
empathetic social chatbot. Computational Linguis-
Ludwig Wittgenstein. 1953. Philosophical Investiga- tics,46(1):53–93.
tions. Macmillan.
Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong
LudwigWittgenstein.1958. Theblueandbrownbooks. Hu, Jason J. Corso, and Jianfeng Gao. 2019. Uni-
BasilBlackwell. fiedvision-languagepre-trainingforimagecaption-
ing and vqa. In Thirty-Fourth AAAI Conference on
Fanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia,
ArtificialIntelligence.
Hao Zhu, Fangchen Liu, Minghua Liu, Hanxiao
Jiang,YifuYuan,HeWang,LiYi,AngelX.Chang,
Leonidas J. Guibas, and Hao Su. 2020. SAPIEN:
A simulated part-based interactive environment. In
ComputerVisionandPatternRecognition(CVPR).
SemihYagcioglu,AykutErdem,ErkutErdem,andNa-
zli Ikizler-Cinbis. 2018. RecipeQA: A challenge
dataset for multimodal comprehension of cooking
recipes. In Proceedings of the 2018 Conference on
EmpiricalMethodsinNaturalLanguageProcessing,
pages1358–1368,Brussels,Belgium.
DiyiYang,JiaaoChen,ZichaoYang,DanJurafsky,and
EduardHovy.2019a. Let’smakeyourrequestmore
persuasive: Modelingpersuasivestrategiesviasemi-
supervised neural nets on crowdfunding platforms.
