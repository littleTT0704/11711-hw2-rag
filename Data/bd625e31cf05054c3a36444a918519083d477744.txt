Aspectuality Across Genre: A Distributional Semantics Approach
ThomasKober MaliheAlikhani
Rasa UniversityofPittsburgh
t.kober@rasa.com malihe@pitt.edu
MatthewStone MarkSteedman
RutgersUniversity UniversityofEdinburgh
mdstone@rutgers.edu steedman@inf.ed.ac.uk
Abstract
The interpretation of the lexical aspect of verbs in English plays a crucial role for recognizing
textualentailmentandlearningdiscourse-levelinferences. Weshowthattwoelementarydimen-
sionsofaspectualclass,statesvs. events,andtelicvs. atelicevents,canbemodelledeffectively
withdistributionalsemantics. Wefindthataverb’slocalcontextismostindicativeofitsaspectual
class, and demonstrate that closed class words tend to be stronger discriminating contexts than
contentwords. Ourapproachoutperformspreviousworkonthreedatasets. Lastly,wecontribute
adatasetofhuman–humanconversationsannotatedwithlexicalaspectandpresentexperiments
thatshowthecorrelationoftelicitywithgenreanddiscoursegoals.
1 Introduction
One of the fascinating aspects of studying aspectual class of verbs in English is its relation with non-
verbal categories. Thus, although in origin a property of the verb, the aspectual class interacts in a
tight-knit fashion with other words in a sentence. Previous research has discussed the importance of
predictingtheaspectualclassesofverbsforpredictingcoherencerelationsintextandimagery(Alikhani
and Stone, 2019), predicting links in entailment graphs (Hosseini et al., 2019) and interpreting sign
languages (Wilbur, 2003). In addition, knowledge about the aspectual class of a verb phrase, and its
influence on the temporal extent and entailments that it licenses, has been leveraged in the past for a
numberofnaturallanguageunderstandingtaskssuchastemporalrelationextraction(CostaandBranco,
2012), event ordering (Chambers et al., 2014; Modi and Titov, 2014), and statistical machine transla-
tion(Loa´icigaandGrisot,2016).
TheAktionsart (Vendler,1957)ofaverbdeterminesthetemporalextentofthepredicationaswellas
whetheritcausesachangeofstatefortheentitiesinvolved(Filip, 2012). AsAktionsart typicallyrefers
tothelexicalaspectofaverbinisolation, weadopttheterminologyofVerkuyl(2005), andrefertothe
compositionallyformedAktionsartofaverbphraseaspredicationalaspect.
One of the most important distinctions of the predicational aspect of a verb is between states, such
as to know or to love, and events, such as visit or swim. This distinction is important for identifying
theentailmentsthatagivenverbphraselicenses,asstativepredicationsdonot,bydefinition,entailany
changeofstate. Thispropertyhasimportantconsequencesforanumberofnaturallanguageunderstand-
ing tasks such as question answering. For example, if it is known that John has arrived in Vienna, a
systemleveragingaspectualinformationwillbeabletoinferthatthecompletionoftheeventofarriving
in Vienna, indicated by the perfect VP having arrived in, has caused a change of state which entails
beingin. Therefore,whenaskedWhereisJohn?,thesystemwillbeabletoproducethecorrectanswer:
Vienna. On the other hand, a predominantly stative verb such as to know, as in Eve knows a lot about
quantummechanics,doesnotcauseachangeofstateforeitherEveorquantummechanics.
Telic predicates do not license consequent state inferences from their progressive VP forms to corre-
spondingnon-progressiveforms.1 Thus,telic/atelicclassificationsaresupportedbycontrastivepairslike
thefollowing:
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://
creativecommons.org/licenses/by/4.0/.
1ThisisalsoknownastheImperfectiveParadox(Dowty,1979).
(1) Marywasdrawingacircle(cid:57)Marydrewacircle(telic)
(2) Marywaspushingacart→Marypushedacart(atelic)
Inthispaperweproposetoapproachtheproblemofclassifyingpredicationalaspectwithdistributional
semantics. Our hypothesis is that the meaning distinctions of a verb that relate to its aspectual class
should be reflected in its distribution when composed with its context. We therefore intersect word
vectors with their context in order to determine a VP’s predicational aspect, and show that we achieve
a new state-of-the-art on two datasets. We further evaluate our approach on two new genres: image
captionsandsituatedhuman–humanconversations,therebyextendingthevalidityofourfindingsacross
avarietyofgenres.
2 RelatedWork
An early approach to classifying the lexical aspectual class of a verb in context was proposed by Pas-
sonneau(1988),whoappliedadecompositionalanalysisoftheverbtodeterminetheaspectualclassfor
verb occurrences in a restricted domain. The first general-purpose study was conducted by Siegel and
McKeown(2000),whobuiltuponearlierworkbyKlavansandChodorov(1992),andcollectedlinguis-
ticindicatorsforlexicalaspectfromalargecorpus. Theseincludethepresenceofin-orfor-adverbials,
thetenseoftheverboritsfrequency. SiegelandMcKeown(2000)subsequentlyapplieddifferentsuper-
vised machine learning algorithms to classify the extracted feature vectors into either states or events,
or telic or atelic events. Siegel and McKeown (2000) show that their method substantially improves
over a majority-class baseline. The first approach to include features derived from a distributional se-
mantic model has beenproposed by Friedrich and Palmer (2014). Inaddition to the linguistic indicator
featuresofSiegelandMcKeown(2000), FriedrichandPalmer(2014)extractrepresentativestative, dy-
namicormixedverbsfromthelexicalconceptualstructure(LCS)database(DorrandOlsen,1997)and
subsequentlyusedistributionalrepresentationstoderivesimilarityscoresfortheminedverbs.
AnotherextensiontotheworkofFriedrichandPalmer(2014)hasbeenproposedbyHeuschkel(2016),
who refines the distributional similarity features by first contextualising a target verb with its subject or
object,andonlythencomputingthedistributionalsimilaritiestothesetofrepresentativeverbsfromthe
LCS database as in Friedrich and Palmer (2014). All else being equal, Heuschkel (2016) shows that
contextualising the distributional representations improves performance on the Asp-ambig dataset of
FriedrichandPalmer(2014).
Incontrasttothislineofresearchwedonotmakeexplicituseofanyhand-engineeredlinguisticindi-
catorfeaturesbutshowthatthesecanbepickedupinanunsupervisedwaybycomposingdistributional
semanticwordrepresentations. Thelinguisticindicatorsarefurthermorefrequentlycollectedontheverb
type level instead of on the token level. Similar to Falk and Martin (2016), we are concerned with clas-
sifying verb readings; however, we do not use engineered features as Falk and Martin (2016) do, but
directlyleveragelocalcontextualinformationintheformofdistributionalrepresentations. Ourapproach
is also not reliant on the availability of a parallel corpus as in Friedrich and Gateva (2017). The major
difference between our approach of using distributional word representations and previous approaches
isthatweareusingthewordrepresentationsdirectlyforclassification,ratherthanindirectlybycomput-
ing similarity scores and using these as features. This furthermore liberates us from the requirement of
havingarepresentativeseedsetofverbsperclasstocomputethedistributionalsimilaritiesfrom.
3 Dataset
Weintroduceanewdataset,DIASPORA,2 ofhuman-humanconversationsannotatedwithpredicational
aspect,representingthefirstdialoguedatasetannotatedwithaspectualinformation. AsreviewedinSec-
tion 2, what partly makes computational research on predicational aspect difficult is the lack of diverse
annotatedcorpora. WiththereleaseofDIASPORAweprovideasituatedconversationalperspectiveon
2DIalogue ASPectuality from ORAl conversations. The dataset is publicly available from https://go.rutgers.
edu/cb6le5c1.
predicational aspect research, and thereby extend the existing evaluation repertoire by a very important
genre.
Annotation effort. As our starting point, we sampled 2000 utterances from the Walking Around cor-
pus (Brennan et al., 2013) uniformly at random. The Walking Around corpus is a dataset of human–
humanphoneconversationswhereonepartyneedstofindcertainlandmarksonauniversitycampusand
receivesdirectionsviaphonefromtheotherparty. Table1listspartofaconversationfromtheWalking
Aroundcorpus,wherethespeakersidentifyalandmarkthatthesecondspeakerneedstoreach.
...
Speaker1 You’relookingfortheshipscul-sculpture
Speaker2 Okay
Speaker1 itshouldbe(..)yeah
Speaker2 IthinkIseeitbutI’mnotcloseenoughyet
Speaker1 ItshouldberightinfrontoftheHeavyEngineeringBuilding
Speaker2 It’saship?
Speaker1 Yeahitlookslikeone(..)likeit’sgot(..)howdoyoudescribei-itlooksreallyweird
...
Table1: PartofanexampledialoguefromtheWalkingAroundcorpus(Brennanetal.,2013).
We chose the Walking Around corpus because its conversations are situated and in real-time, and
becauseitcontainsagooddistributionofstative,telic,andatelicverbphrases. Aftersamplingtheinitial
set of 2000 utterances, we filtered multi-sentence utterances and utterances that did not contain a verb.
Wefurthermoreremovedanyfilledpauses(indicatedby“(..)”inTable1)thathavebeentranscribedand
markedinthedataset. FollowingAlikhaniandStone(2019),weannotatedthefirstVPforpredicational
aspectinallutterances. Forexample,thelastutteranceofSpeaker1inTable1containsmultipleverbs,
andwehaveannotatedthephraseYeahitlookslikeone—thefirstVPintheutterance.
The study has been approved by Rutgers’s IRB. Expert annotators annotated the whole dataset and
were paid an hourly rate of 15 USD. They were final year linguistics undergraduate students and were
provided with an annotation protocol for their task.3 To assess the inter-annotator agreement, we de-
termine Cohen’s κ value. We randomly selected 200 sentences and assigned each to two annotators,
obtainingaCohen’sκ of0.81,whichindicatesalmostperfectagreement(VieraandGarrett,2005).
Overallstatistics. ThefinalDIASPORAdatasetcontains927annotatedutterances,consistingof400
utteranceslabelledasexpressingstativepredicationalaspect(43%),279labelledastelic(30%),and248
labelled as atelic (27%). The overall average utterance length is 15.58. Table 2 lists length statistics
Label Mean Median Min Max
State 16.34 13 4 94
Telic 14.65 11 3 80
Atelic 15.38 12 2 74
Table2: UtterancelengthstatisticsperlabelinDIASPORA.
for DIASPORA per individual label. The means and medians are relatively similar across all classes,
suggestingthatthereisnobiasintermsofutterancelengthsforanyindividualclass.
The DIASPORA dataset contains 98 unique verb forms, spanning 69 lemmas, with the top 10 most
frequentverblemmasmakingup≈78%ofallverbsinthecorpus.
The characteristic of few verbs making up a large proportion of the overall data has already been
observed for captions (Alikhani and Stone, 2019). This is an expected property in DIASPORA and is
duetothesingle-domainnatureoftheWalkingAroundcorpus. Figure1showsthefrequencydistribution
ofthetop10mostfrequentverbsandtheirassociatedlabeldistribution. Thelargeproportionofvarious
forms of be is due to many utterances of either speaker referring to the current location of the subject
lookingforthelandmark(e.g. utteranceslikeIamcurrentlyat...). Thelabeldistributionofthe10most
frequent verbs shows that there are some highly skewed verbs, such as get, see or know, which have a
3Theannotationprotocolispublishedwiththedatasetathttps://go.rutgers.edu/cb6le5c1.
Figure1: Frequencydistributionofthe10mostfrequentverbs(left)andassociatedlabeldistributionforthe10mostfrequent
verbs(right).
clear majority class, whereas do or look exhibit a much more balanced, and therefore ambiguous label
distribution.
4 Experiments
The utility of distributional semantic word representations has been shown in a large body of works in
recentyears(Weedsetal.(2014),Nguyenetal.(2017),Socheretal.(2013),Bowmanetal.(2015);pas-
sim). Inordertocomposeaverbwithitscontextweapplypointwiseadditionasasimpledistributional
composition function. Pointwise addition in neural word embeddings approximates the intersection of
their contexts4 (Tian et al., 2017), and has been shown to be an efficient function for contextualising a
wordinaphrase(Aroraetal.,2016;Koberetal.,2017).
4.1 DistributionalModelsforPredicationalAspect
Following previous work on modelling the aspectual class of a verb (Siegel and McKeown, 2000;
Friedrich and Palmer, 2014), we treat the problem as a supervised classification task, y= f(x), where
y represents the aspectual class of a verb, f represents a classification algorithm, and x an input vector
representationofaverbincontext. Forallofourexperiments, f isalogisticregressionclassifier,5 with
default hyperparameter settings. In all our experiments, the input vector x is based on 300-dimensional
pre-trainedskip-gramword2vec(Mikolovetal.,2013)vectors.6 Welowercaseallwords,butdonotap-
plyanyotherformofmorphologicalpreprocessing,whichmeansthatweretaindifferentrepresentations
fordifferentinflectedformsofaverb—i.e. look,looks,looking,andlookedarerepresentedby4distinct
vectors.
4.1.1 ClassifyingAspectwithDistributionalSemantics
For this approach we obtain a word2vec representation x for a given verb v and feed x into a logistic
regression classifier in order to predict the aspectual class of v. This approach represents a rather na¨ıve
baselinethatassumesthattheaspectualclassofaverbisapurelylexicalphenomenononthetypelevel
andcanbedeterminedindependentofanycontext.
4.1.2 IncorporatingContextwithDistributionalComposition
Let x be a word2vec representation for a given verb v, andC be the set of context words extracted for
v, with c ∈C denoting the vector representation for an extracted context word of v. The composed
4Note that for sparse count-based distributional representations, addition would correspond to a union of contexts and
multiplicationtoanintersection(Kober,2018).
5Weusescikit-learn(Pedregosaetal.,2011)—which,muchlikeourselves,isrelyingonnumpy(Harrisetal.,2020).
6The pre-trained vectors are availble from https://code.google.com/archive/p/word2vec/, and we used
gensim(Rˇehu˚ˇrekandSojka,2010)forprocessingtheword2vecrepresentations.
representationofv,denotedbyx(cid:48),canthenbeexpressedasasimplesum:
x(cid:48)=x+∑c (1)
c∈C
Subsequently, x(cid:48) is passed through a logistic regression classifier in order to predict the aspectual class
of v. This model aims to capture the compositional nature of predicational aspect by integrating local
contextualinformationintothemodel.
TypesofContext
Weinvestigatetwodifferentkindsofcontext: simplelinearcontextwindowsofvaryinglengthandfirst-
orderdependencycontexts. ForexampleforthesentenceinFigure2,alinearcontextwindowofsize1
wouldextractJaneandtoforthetargetverbdecided,whereasadependency-basedcontextwouldextract
Jane and leave. We used the Stanford NLP pipeline (Manning et al., 2014) with default settings for
parsingthesentencesinourdatasets.
root
xcomp
nsubj aux advmod
Jane decided to leave early
Figure2: Withalinearcontextwindowofsize1, Janeandtowouldbeextractedascontextsfortheverbdecided. Witha
dependency-basedcontext,Janeandleavewouldbeextracted.
Forlinearcontextwindowsweusesizes{1,2,3,5,10},andforfirst-orderdependency-basedcontexts
weexperimentwithusingonlythehead7 oftheverb,onlyitschildren,orthefullfirst-ordercontext.
IncorporatingtheFullSentence
We furthermore test a model that incorporates the whole sentential context into a vector representation.
Theapproachsimplyusesallwordsfromagivensentenceandcomposestheircorrespondingword2vec
representations as in Equation 1 above to create an embedding for the whole sentence. Embedding a
sentencebyaddingwordvectorshasbeenshowntobeaneffectivemethodforotherNLPtaskssuchas
sentimentanalysis(Iyyeretal.,2015)andrecognisingtextualentailment(Wietingetal.,2016).
Theunderlyingrationalebehindthisapproachisthattheaspectualclassofaverbisafunctionofthe
sentenceasawhole,ratherthandependentonlocalcontextalone(Moens,1987; MoensandSteedman,
1988;Dowty,1991).
5 Experiments
We perform experiments that assess the suitability of distributional representations for distinguishing
statesfromevents(§5.1),andtelicfromatelicevents(§5.2). Onlyacompletedandteliceventlicenses
a new consequent state. Therefore, modelling predicational aspect is important for deeper text under-
standing,forexampleformodellingcauseandeffect,andespeciallyforinferringconsequentstates.
5.1 Experiment1—Statesvs. Events
Forthedistinctionbetweenstatesandeventsweperformexperimentson5datasetsintotal. Weusethe
Asp-ambig dataset by Friedrich and Palmer (2014), the SitEnt dataset by Friedrich et al. (2016), our
ownsub-sampledversionoftheSitEntdataset,theCaptionsdatasetbyAlikhaniandStone(2019),and
ourownDIASPORAdataset,proposedinthiswork.
TheAsp-ambigdatasetissampledfromtheBrowncorpus(FrancisandKucera,1979)andisbasedon
20frequentlyoccurringverbswhosepredicationalaspectchangesdependingoncontext. Foreachverb,
Friedrich and Palmer (2014) collected 138 sentences, resulting in 2760 examples in total. The dataset
7Ifthetargetverbistheroot,thennocontextisusedforthatverb.
contains the annotations of whether the verb in context expresses a state, event, or whether it could be
both.8 FollowingFriedrichandPalmer(2014),wereportaccuracyusingleave-one-outcross-validation.9
We furthermore evaluate our approach on the SitEnt dataset (Friedrich et al., 2016). The SitEnt
dataset contains 40k sentences from the MASC corpus (Ide et al., 2008) and English Wikipedia, split
into separate training and test sets. We evaluate our approach on the test set, using the original split of
Friedrichetal.(2016). TheSitEntdatasetcontainsannotationsforverbsincontextaseitherexpressing
astateoranevent,butnotboth. FollowingFriedrichetal.(2016),wereportclass-basedF1-scores.
During model development we noticed an idiosyncrasy in the SitEnt dataset, where only 900 verb
typesoutof 4.5koccurredwithbothclasslabels,andonly267ofthemhadabalanced(i.e. ambiguous)
classdistribution. Weconsideredthisaslikelyproblematicasaclassifiermightjustpickupthisartefact.
We therefore created a downsampled dataset — SitEnt-ambig — that only contains verb types with a
balancedclassdistribution,randomlysub-samplingthemajorityclassforverbtypeswithanimbalanced
classdistribution10. Theresultingdatasetconsistsof6547examplesinthetrainingsetand1402examples
inthetestset.11 AsfortheoriginalSitEntdataset,wereportclass-basedF1-scoresforSitEnt-ambig.
Inordertocoverawidervarietyofgenres,wealsoevaluateourapproachontheCaptionsdatasetof
Alikhani and Stone (2019). The dataset is based on a number of image captions corpora and contains
annotations for verbs being used as states, telic events and atelic events. For this experiment we merge
the telic and atelic class, resulting in a 2-class problem with 2687 instances with a class distribution of
22:78 (state:event). The dataset does not contain pre-defined training/evaluation splits. We therefore
evaluateusing10-foldcross-validationandreportclass-basedF1-scores.
Finally, we evaluate on our proposed DIASPORA dataset, again merging the telic and atelic classes
for this experiment, resulting in a class distribution of 43:57 (state:event). We again report class-based
F1-scoresover10-foldcross-validation.
5.1.1 Results
Table 3 below shows the results on all datasets. We compare classifying the representation of a verb
withoutanycontext,theverbwithlocalcontext,andthefullsentence,withamajority-classbaselineand
previous results in the literature. The results of using a local context are based on the best performing
context window around the verb, an overview of the effect of the size of the context window is shown
in Figure 3. A result table comparing the best linear context window window with the best performing
dependencycontextwindowispresentedinTable8inAppendixC.
Dataset Verbonly LocalContext FullSentence Maj.Class FP14 H16 F16
Asp-ambigAccuracy 65.9 74.2 60.0 65.9 72.0 72.8 -
SitEntF1(State) 84.0 81.3 26.4 0.0 - - 80.6
SitEntF1(Event) 86.6 84.5 71.9 68.9 - - 78.6
SitEnt-ambigF1(State) 44.0 62.6 0.0 0.0 - - -
SitEnt-ambigF1(Event) 62.4 66.2 68.3 68.4 - - .-
CaptionsF1(State) 0.1(±0.07) 58.8(±0.05) 23.4(±0.06) 0.0 - - -
CaptionsF1(Event) 87.3(±0.01) 89.7(±0.02) 86.7(±0.02) 87.6 - - -
DIASPORAF1(State) 76.4(±0.07) 86.5(±0.04) 80.1(±0.06) 0.0 - - -
DIASPORAF1(Event) 83.5(±0.03) 89.8(±0.03) 84.8(±0.03) 72.5 - - -
Table 3: Results on classifying states vs. events. FP14 refers to Friedrich and Palmer (2014), H16 to
Heuschkel(2016),andF16toFriedrichetal.(2016).
Ingeneral,alocalcontextwindowexhibitsthestrongestperformance,evenachievinganewstate-of-
the-artontheAsp-ambigdataset,despitethesimplicityofoursetup. Thestrongresultsoftheverb-only
modelontheSitEntdataset,thatsubstantiallyoutperformsthesequencemodelofFriedrichetal.(2016)
and the local context model, confirms our suspicion that the classifier learnt the fact that most verbs in
8Theinstanceslabelledasbothhaveeitherbeenlabelledbytheannotatorsasbothbecausebothreadingsarepossible,or
havebeenlabelledasbothwhentheannotatorsdisagreedintheirjudgement(FriedrichandPalmer,2014).
9AperformanceoverviewperverbtypeisincludedinAppendixA
10Weallowedtheimbalancetobeatmost60:40.
11Thesub-sampleddatasetisavailablefromhttps://go.rutgers.edu/cb6le5c1
thedatasetoccurunambiguouslywiththeirtargetlabel. Thisisfurthermorereflectedintheresultsonthe
SitEnt-ambig dataset, where using only the verb leads to considerably worse performance than when
taking a local context window around the verb into account. While the results on SitEnt-ambig are
generally low, this reflects the increased difficulty of the task as well as the simplicity of our setup, and
weexpecttoimproveontheseresultswithhighercapacitymodelsinfuturework.
5.1.2 Analysis
InFigure3weshowclass-basedF1-scoreperformancetrajectoriesforvaryingsizesofthelinearcontext
window and the dependency context across all datasets. We observe that performance typically peaks
at a narrow context window of taking 1-3 surrounding words into account, with performance dropping
steeply when increasing the context window.12 Our results also exhibit that linear window contexts are
typicallybetterpredictorsforpredicationalaspectthandependencycontexts.
Figure3:Class-basedF1-scoreperformancetrajectoriesforvaryingsizesofthecontextwindowacrossalldatasets.
This is an interesting result as dependency contexts are more likely to yield content words, such as
nouns,adjectivesorotherverbsascontext,13 asopposedtolinearcontextwindowsyieldingmoreclosed
class words. We investigate this effect further by comparing the general overall performance of closed
classwordswithcontentwords. Figure4providesempiricalevidencethatclosedclasswordsarestrong
predictorsofpredicationalaspect. ThefigureshowsaccuraciesforPoStagsbelongingtoaclosed-class
group,incomparisontoonesbelongingtoopenclasscontentwords. WecalculatedPoS-basedaccuracy
bycountinghowoftenawordwithagivenPoStagcontributedtoacorrectclassificationasopposedto
an incorrect one. For example if the PoS tag IN14 occurs 8 times as part of correctly classified context
windowsand2timesaspartofincorrectlyclassifiedones,weestimateitsaccuracyas0.8. Wecountthe
participationofaPoStagforacorrectorincorrectclassificationdecisionasevidencethatthegivenword
is a reliable predictor for a given class. We expect that words with high predictive capacity will more
oftenoccurincorrectlyclassifiedcontextwindowsthaninincorrectlyclassifiedones.
Figure 4 highlights that closed class words are typically more reliable predictors for predicational
aspect than content words. This is a very interesting result, given our model solely operates on the
basisofcomposedwordvectors,thusindicatingthatdistributionalrepresentationsforclosedclasswords
encodeasubstantialamountofinformationthatcanpotentiallybeleveragedforfine-graineddirectional
inferences. Inordertoassessthegeneralisationcapabilityofdistributionalrepresentationsweperformed
azero-shotexperimentontheAsp-ambigdatasetwhereweheldoutallannotateddataforaspecificverb
forevaluation,andtrainedthemodelontheremainingdata. Table10inAppendixDprovidesevidence
thatdistributionalrepresentationscapturepredicationalaspectofunseenverbstoasurprisingextent.
Table 4 shows example sentences for two ambiguous verbs from our datasets. In the first and third
sentence the preposition at and the particle up, respectively, cause the predicate to express an event.
Without a preposition, verbs such as look can express stative aspect as in the second sentence. The
12WenotethattheF1-scoreforeventontheSitEnt-ambigdatasetsappearstopeakbytakingthewholesentenceasinput,
howeverthisisaneffectofitsperformancedegradingtothatofthemajorityclassbaseline,ascanalsobeseenonitsnear-0
performanceforpredictingstates.
13Asoneofourreviewerspointedout,thislikelyisduetoouruseofUniversalDependencies(OsborneandGerdes,2019).
WeshowthedistributionofextractedcontextwordsforthelinearanddependencycontextwindowsperPoStaginAppendixB.
14INreferstoaprepositionorsubordinatingconjunction.
Figure4:Averagedaccuracyscoresforclosedclasscontextwordsincomparisontocontentwordcontexts.
Aspect Verb ExampleSentences
Event look (1)Shanelookedathiswatch.
State look (2)Shesurelooksgood.
Event stand (3)Jeffersonshookhisheadandstoodup.
State stand (4)Ametaltableandfourchairsstoodinthecenter.
Table4: ExampleSentencesfromthestatevs. eventdatasets.
last sentence is an interesting case where the verb stand occurs in the context of a preposition, yet the
combinationremainsstative,asthesentencedescribesthearrangementofinanimateobjects.
5.2 Experiment2—Telicvs. AtelicEvents
For classifying telic and atelic events we are using the Telicity dataset of Friedrich and Gateva (2017),
theCaptionsdatasetofAlikhaniandStone(2019),aswellasourownproposedDIASPORAdataset.
TheTelicitydatasetcontains1863sentencesextractedfromtheMASCcorpus,whereaverbincontext
islabelledaseithertelicoratelic. Thedatasetisimblancedwith82%ofverboccurrencesbeinglabelled
as telic. We follow the experimental protocol of Friedrich and Gateva (2017) and report accuracy and
class-basedF1-scores, usingdocument-basedcross-validation. Duringourexperimentalworkweagain
noticedthatonly70outofapproximately570distinctverbsinthedatasetoccurwithbothlabels. How-
ever,applyingthesamestrategyasfortheSitEnt-ambigdatasetwouldhaveresultedintoolittledata.15
Therefore, given thischaracteristic, we again expectthe classifier usingthe verb withoutany context to
achieveartificiallyhighperformance.
For the Captions dataset, we omit the examples labelled as stative, leaving us with 2092 captions
in total, of which 800 are annotated as telic (38%), and 1292 as atelic (62%). We perform 10-fold
cross-validationandreportaccuracyandclass-basedF1-scores.
Finally,forourDIASPORAdataset,wealsoomittheutterancesannotatedasexpressingstativepredi-
cationalaspect,leavingus527examplesintotal,279instanceslabelledastelic(53%),and248instances
labelledasatelic(47%),thusrepresentingthemostbalanceddatasetamongthethree.
5.2.1 Results
Table 5 shows the results for all three datasets, comparing a model that only has access to the distribu-
tionalrepresentationofthetargetverbitself,withmodelsthathaveaccesstoalocalcontextwindowand
thefullsentence,aswellastopreviousresultsintheliterature. Aresulttablecomparingthebestlinear
contextwindowwindowwiththebestperformingdependencycontextwindowispresentedinTable9in
AppendixC.
15Using only sentences with verbs that occur with both labels regardless of their class distribution resulted in only 295
examplesintotal.
Dataset Verbonly LocalContext FullSentence Maj.Class FG17 FG17+IC
TelicityAccuracy 87.2 86.4 85.8 82.0 86.7 82.3
TelicityF1(Telic) 92.1 91.6 91.1 90.1 92.2 88.6
TelicityF1(Atelic) 62.6 60.3 60.6 0.0 53.7 61.4
CaptionsAccuracy 78.8(±0.03) 79.1(±0.02) 78.8(±0.02) 61.8 - -
CaptionsF1(Telic) 70.7(±0.05) 72.3(±0.03) 71.2(±0.04) 55.3 - -
CaptionsF1(Atelic) 83.3(±0.03) 83.0(±0.02) 83.1(±0.02) 0.0 - -
DialogueAccuracy 64.3(±0.04) 69.3(±0.05) 65.1(±0.05) 52.9 - -
DIASPORAF1(Telic) 64.5(±0.06) 70.3(±0.06) 66.5(±0.05) 69.2 - -
DIASPORAF1(Atelic) 63.3(±0.05) 67.8(±0.05) 62.9(±0.07) 0.0 - -
Table 5: Results on classifying telic vs. atelic events. FG17 refers to the best performing model of
Friedrich and Gateva (2017), and FG17+IC refers to the model of Friedrich and Gateva (2017) with
accesstoadditionaldata.
Ourpurelydistributionalmodelsachievecompetitiveresults,withtheexpectedstrongperformancefor
the verb-only model, that is even beating the current state-of-the-art in terms of accuracy and F1-score
fortheatelicclass. FortheCaptionsandDIASPORAdatasetsweobservesimilartrendsasforthestate
vs. event datasets above, with the models that operate over a local context window typically achieving
the strongest performance. Notably, the verb-only models are able to perform competitively with local
contextwindowsacrossalldatasets. WhiletelicityitselfisnotpartofthemorphologyofEnglishverbs,
telic events frequently correlate with the past tense, such that the distributional representation for the
inflectedverbalreadyencodesasubstantialamountofinformation.
5.2.2 Analysis
Figure 5 shows a class-based F1-score performance trajectory across all datasets and varying context
windowsizes. UnlikefordistinguishingstatesfromeventsinFigure3above,predictingtelicityappears
to be less dependent on a small local context window surrounding the target verb. This is reflected in
Figure5whichdoesnotcontainsuchclearperformancepeaks,butismoreuniformacrossdifferentsizes
ofcontextwindows.
Figure5:Class-basedF1-scoreperformancetrajectoriesforvaryingsizesofthecontextwindowacrossalldatasets.
WefurthermoreshowtheaveragedPoS-basedaccuracyplotinFigure6. Forpredictingtelicity,closed
class words are less reliable predictors in comparison to content words than for modelling states and
eventsabove.
Thisresultbecomesmoretransparentwhenanalysingactualsentencesfromourdataset.
Aspect Verb ExampleSentences
Telic leave (1)Okay,Ihaveleftthebuilding.
Atelic walk (2)Okay,I’mstillwalkingtowar-ohisitblue?
Telic turn (3)Fansturned ontheplayersandmanager.
Atelic paddle (4)Fourkayakerspaddlethroughthewater.
Table6: ExampleSentencesfromthetelicvs. atelicdatasets.
Figure6:Averagedaccuracyscoresforclosedclasscontextwordsincomparisontocontentwordcontexts.
Table 6 shows some example sentences from the datasets annotated for telicity. The sentences show
thattelicityinEnglishisfrequentlyassociatedwithtense,withpresenttensesindicatingateliceventual-
ities and past tense indicating a completed event. This suggests that frequently the verb by itself might
besufficientforinferringtelicityasinsentences(3)and(4). Inmanyothercases,theverbinteractswith
itsauxiliaryinatensedconstructionasinsentences(1)and(2).
6 Conclusion
Inthiswork,wehaveproposedthefirstdatasetofhuman-humandialoguesannotatedwiththeaspectual
class of verbs. We have proposed a compositional distributional approach for modelling the aspectual
classofEnglishverbsincontext. Ourresultsindicatethatdistributionalmodelsareabletolearnconcise
representationsforclosedclasswordssuchasparticlesandprepositions,andthatclassifiersusingcom-
posed distributional representations achieve a new state-of-the-art on three recently proposed datasets.
Wehavefurthermorecontributedaqualitativeanalysis,providingempiricalevidenceforthelongstand-
inginsightofsemanticiststhatthepresenceofprepositionsorparticlesinaverbphrase,tendtobevery
reliable indicators of the verb’s aspectual class (Vendler (1957), Dowty (1979), Moens and Steedman
(1988), passim). Our model setup was intentionally kept simple as we were primarily concerned with
the question whether predicational aspect can be captured with a distributional semantics approach in
principle. We note that using more sophisticated models might yield even stronger results, although in
preliminary tests, we did not observe any meaningful performance difference when replacing our bag-
of-embeddingsapproachwithELMo(Petersetal.,2018)orBERT(Devlinetal.,2019).
WhilethisworkwasdoneonEnglish,weaimtouseourmethodologyinamultilingualsetupinfuture
workasdistributionalapproachesscalewellwithgrowingamountsofdataandacrosslanguages.
Aspect,alongsidetense,isacrucialindicatorofthetemporalextentofaverbaswellastheentailments
itlicenses. Infutureworkweplantointegrateaspectualinformationforimprovingtheunsupervisedcon-
structionofentailmentgraphs(Berantetal.,2010;Hosseinietal.,2018),aswellastemporalreasoning,
whichhasbeenshownrecentlytobedifficultfordistributionalsemanticmodels(Koberetal.,2019).
Aspectual information can be utilised for directional entailment detection by inferring that the event
of buying something entails the state of owning that thing, but not the other way round. Determining
the telicity of an event also enables fine-grained inferences about whether an event caused a change of
state. Forexample,whiletheteliccontextofwritingasonnetinfifteenminutesentailsachangetoastate
whereafinishedsonnetexists,theateliccontextofwritingasonnetforfifteenminutesdoesnot.
Acknowledgements
The research presented here is supported by NSF IIS-1526723 and CCF-19349243 and in part by ERC
AdvancedFellowship742137SEMANTAX.
References
Malihe Alikhani and Matthew Stone. 2019. “caption” as a coherence relation: Evidence and implications. In
Proceedings of the Second Workshop on Shortcomings in Vision and Language, pages 58–67, Minneapolis,
Minnesota,June.AssociationforComputationalLinguistics.
SanjeevArora,YuanzhiLi,YingyuLiang,TengyuMa,andAndrejRisteski. 2016. Linearalgebraicstructureof
wordsenses,withapplicationstopolysemy. CoRR,abs/1601.03764.
Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2010. Global learning of focused entailment graphs. In
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1220–1229,
Uppsala,Sweden,July.AssociationforComputationalLinguistics.
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated
corpusforlearningnaturallanguageinference. InProceedingsofthe2015ConferenceonEmpiricalMethods
inNaturalLanguageProcessing,pages632–642,Lisbon,Portugal,September.AssociationforComputational
Linguistics.
Susan Brennan, Katharina Schuhmann, and Karla Batres. 2013. Entrainment on the move and in the lab: The
walkingaroundcorpus. InProceedingsofthe35thAnnualMeetingoftheCognitiveScienceSociety.
Nathanael Chambers, Taylor Cassidy, Bill McDowell, and Steven Bethard. 2014. Dense event ordering with a
multi-passarchitecture. TransactionsoftheAssociationforComputationalLinguistics,2:273–284.
FranciscoCostaandAnto´nioBranco. 2012. Aspectualtypeandtemporalrelationclassification. InProceedingsof
the13thConferenceoftheEuropeanChapteroftheAssociationforComputationalLinguistics,pages266–275,
Avignon,France,April.AssociationforComputationalLinguistics.
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. 2019. BERT:Pre-trainingofdeepbidirec-
tionaltransformersforlanguageunderstanding. InProceedingsofthe2019ConferenceoftheNorthAmerican
ChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(Longand
ShortPapers),pages4171–4186,Minneapolis,Minnesota,June.AssociationforComputationalLinguistics.
Bonnie J. Dorr and Mari Broman Olsen. 1997. Deriving verbal and compositonal lexical aspect for nlp appli-
cations. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages
151–158,Madrid,Spain,July.AssociationforComputationalLinguistics.
DavidDowty. 1979. WordMeaningandMontagueGrammar. Dordrecht,Holland.
DavidDowty. 1991. Thematicproto-rolesandargumentselection. Language,67:547–619.
Ingrid Falk and Fabienne Martin. 2016. Automatic identification of aspectual classes across verbal readings.
In Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics, pages 12–22, Berlin,
Germany,August.AssociationforComputationalLinguistics.
HanaFilip,2012. TheOxfordHandbookofTenseandAspect,chapterLexicalAspect. OxfordUniversityPress.
W.N.FrancisandH.Kucera. 1979. Browncorpusmanual. Technicalreport,DepartmentofLinguistics,Brown
University,Providence,RhodeIsland,US.
AnnemarieFriedrichandDamyanaGateva. 2017. Classificationoftelicityusingcross-linguisticannotationpro-
jection. InProceedingsofthe2017ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages
2559–2565,Copenhagen,Denmark,September.AssociationforComputationalLinguistics.
Annemarie Friedrich and Alexis Palmer. 2014. Automatic prediction of aspectual class of verbs in context. In
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short
Papers),pages517–523,Baltimore,Maryland,June.AssociationforComputationalLinguistics.
AnnemarieFriedrich, AlexisPalmer, andManfredPinkal. 2016. Situationentitytypes: automaticclassification
of clause-level aspect. In Proceedings of the 54th Annual Meeting of the Association for Computational Lin-
guistics(Volume1: LongPapers),pages1757–1768,Berlin,Germany,August.AssociationforComputational
Linguistics.
Charles R. Harris, K. Jarrod Millman, Ste´fan J van der Walt, Ralf Gommers, Pauli Virtanen, David Courna-
peau,EricWieser,JulianTaylor,SebastianBerg,NathanielJ.Smith,RobertKern,MattiPicus,StephanHoyer,
MartenH.vanKerkwijk,MatthewBrett,AllanHaldane,JaimeFerna´ndezdelR´ıo,MarkWiebe,PearuPeterson,
PierreGe´rard-Marchant,KevinSheppard,TylerReddy,WarrenWeckesser,HameerAbbasi,ChristophGohlke,
andTravisE.Oliphant. 2020. ArrayprogrammingwithNumPy. Nature,585:357–362.
Liesa Heuschkel. 2016. Automatic classification of lexical aspectual class using distributional and rule-based
methods. Master’sthesis,SaarlandUniversity.
Mohammad Javad Hosseini, Nathanael Chambers, Siva Reddy, Xavier R. Holt, Shay B. Cohen, Mark Johnson,
andMarkSteedman. 2018. Learningtypedentailmentgraphswithglobalsoftconstraints. Transactionsofthe
AssociationforComputationalLinguistics,6:703–717.
MohammadJavadHosseini,ShayBCohen,MarkJohnson,andMarkSteedman. 2019. Dualityoflinkprediction
and entailment graph induction. In Proceedings of the 57th Annual Meeting of the Association for Computa-
tionalLinguistics,pages4736–4746.
Nancy Ide, Collin Baker, Christiane Fellbaum, Charles Fillmore, and Rebecca Passonneau. 2008. Masc: the
manually annotated sub-corpus of american english. In Proceedings of the Sixth International Conference on
Language Resources and Evaluation (LREC’08), Marrakech, Morocco, may. European Language Resources
Association(ELRA). http://www.lrec-conf.org/proceedings/lrec2008/.
Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber, and Hal Daume´ III. 2015. Deep unordered composition
rivalssyntacticmethodsfortextclassification. InProceedingsofthe53rdAnnualMeetingoftheAssociationfor
ComputationalLinguisticsandthe7thInternationalJointConferenceonNaturalLanguageProcessing(Volume
1: LongPapers),pages1681–1691,Beijing,China,July.AssociationforComputationalLinguistics.
Judith Klavans and Martin Chodorov. 1992. Degrees of stativity: The lexical representation of verb aspect. In
InProceedingsofthe14thInternationalConferenceonCompoutationalLinguistics,pages1126–1131,Nantes,
France.AssociationforComputationalLinguistics.
Thomas Kober, Julie Weeds, John Wilkie, Jeremy Reffin, and David Weir. 2017. One representation per word
- does it make sense for composition? In Proceedings of the 1st Workshop on Sense, Concept and Entity
RepresentationsandtheirApplications,pages79–90,Valencia,Spain,April.
ThomasKober,SanderBijldeVroe,andMarkSteedman. 2019. Temporalandaspectualentailment. InProceed-
ingsofthe13thConferenceonComputationalSemantics(IWCS2019),Gothenburg,Sweden.
Thomas Kober. 2018. Inferring Unobserved Co-occurrence Events in Anchored Packed Trees. Ph.D. thesis,
UniversityofSussex.
Sharid Loa´iciga and Cristina Grisot. 2016. Predicting and using a pragmatic component of lexical aspect of
simple past verbal tenses for improving english-to-french machine translation. Linguistic Issues in Language
Technology,13(3):1–34.
Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky.
2014. TheStanfordCoreNLPnaturallanguageprocessingtoolkit. InAssociationforComputationalLinguistics
(ACL)SystemDemonstrations,pages55–60.
TomasMikolov, IlyaSutskever, KaiChen, GregSCorrado, andJeffDean. 2013. Distributedrepresentationsof
words and phrases and their compositionality. In C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and
K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 3111–3119. Curran
Associates,Inc.
AshutoshModiandIvanTitov. 2014. Inducingneuralmodelsofscriptknowledge. InProceedingsoftheEigh-
teenth Conference on Computational Natural Language Learning, pages 49–57, Ann Arbor, Michigan, June.
AssociationforComputationalLinguistics.
MarcMoensandMarkSteedman. 1988. Temporalontologyandtemporalreference. ComputationalLinguistics,
14(2):15–28.
MarcMoens. 1987. Tense,AspectandTemporalReference. Ph.D.thesis,UniversityofEdinburgh.
Kim Anh Nguyen, Maximilian Ko¨per, Sabine Schulte im Walde, and Ngoc Thang Vu. 2017. Hierarchical em-
beddings for hypernymy detection and directionality. In Proceedings of the 2017 Conference on Empirical
MethodsinNaturalLanguageProcessing,pages233–243,Copenhagen,Denmark,September.Associationfor
ComputationalLinguistics.
Timothy Osborne and Kim Gerdes. 2019. The status of function words in dependency grammar: A critique of
universaldependencies(ud). Glossa: AJournalofGeneralLinguistics,1(4):516–547.
RebeccaPassonneau. 1988. Acomputationalmodelofthesemanticsoftenseandaspect. ComputationalLinguis-
tics,14(2):44–60.
FabianPedregosa,Gae¨lVaroquaux,AlexandreGramfort,VincentMichel,BertrandThirion,OlivierGrisel,Math-
ieuBlondel,PeterPrettenhofer,RonWeiss,VincentDubourg,JakeVanderplas,AlexandrePassos,DavidCour-
napeau,MatthieuBrucher,MatthieuPerrot,andE´douardDuchesnay. 2011. Scikit-learn: Machinelearningin
python. JournalofMachineLearningResearch,12:2825–2830,November.
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettle-
moyer. 2018. Deepcontextualizedwordrepresentations. InProceedingsofthe2018ConferenceoftheNorth
AmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,Volume1
(LongPapers),pages2227–2237.AssociationforComputationalLinguistics.
RadimRˇehu˚ˇrekandPetrSojka. 2010. SoftwareFrameworkforTopicModellingwithLargeCorpora. InProceed-
ingsoftheLREC2010WorkshoponNewChallengesforNLPFrameworks,pages45–50,Valletta,Malta,May.
ELRA.
EricSiegelandKathleenMcKeown. 2000. Learningmethodstocombinelinguisticindicators: Improvingaspec-
tualclassificationandrevealinglinguisticinsights. ComputationalLinguistics,26(4):595–628,December.
RichardSocher,AlexPerelygin,JeanWu,JasonChuang,ChristopherD.Manning,AndrewNg,andChristopher
Potts. 2013. Recursivedeepmodelsforsemanticcompositionalityoverasentimenttreebank. InProceedings
of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631–1642, Seattle,
Washington,USA,October.AssociationforComputationalLinguistics.
RanTian,NaoakiOkazaki,andKentaroInui. 2017. Themechanismofadditivecomposition. MachineLearning,
106(7):1083–1130.
ZenoVendler. 1957. Verbsandtimes. LinguisticsinPhilosophy,pages97–121.
HenkVerkuyl. 2005. How(in-)sensitiveistensetoaspectualinformation? InBertHollerbrandse,Angeliekvan
Hout,andCoVet,editors,CrosslinguisticViewsonTense,AspectandModality,pages145–169.Rodopi.
Anthony J. Viera and Joanne M. Garrett. 2005. Understanding interobserver agreement: The kappa statistic.
Familymedicine,37:360–3,06.
JulieWeeds,DaoudClarke,JeremyReffin,DavidWeir,andBillKeller. 2014. Learningtodistinguishhypernyms
andco-hyponyms. InProceedingsofCOLING2014,the25thInternationalConferenceonComputationalLin-
guistics: TechnicalPapers,pages2249–2259,Dublin,Ireland,August.DublinCityUniversityandAssociation
forComputationalLinguistics.
JohnWieting, MohitBansal, KevinGimpel, andKarenLivescu. 2016. Towardsuniversalparaphrasticsentence
embeddings. InProceedingsoftheInternationalConferenceonLearningRepresentations.
RonnieWilbur. 2003. Representationsoftelicityinasl. InProceedingsfromtheannualmeetingoftheChicago
LinguisticSociety,volume39,pages354–368.ChicagoLinguisticSociety.
A SupplementalMaterial—PerformanceperVerbTypeinAsp-ambig
Table7belowliststheresultsperverbtypeforall20ambiguousverbsintheAsp-ambigdataset,com-
paring the majority class baseline, the models of Friedrich and Palmer (2014) and Heuschkel (2016) to
ourwindow-1anddependency(full)approaches.
Verb Majorityclass FriedrichandPalmer(2014) Heuschkel(2016) window-1 dependency(full)
feel 96.1 93.8 95.5 94.2 93.5
say 94.9 93.5 94.2 94.9 94.9
make 91.9 91.2 92.0 90.6 90.6
come 88.0 87.2 88.0 85.5 86.2
take 85.4 85.4 85.5 85.5 87.0
meet 83.9 87.7 85.9 87.7 90.6
stand 80.0 83.1 81.8 87.7 82.6
find 74.5 68.8 76.6 75.4 69.6
accept 70.9 65.7 67.4 68.8 61.6
hold 56.0 49.3 57.8 62.3 55.8
carry 55.9 58.1 60.3 58.0 63.8
look 55.8 74.6 65.9 79.7 61.6
show 54.9 68.4 65.9 67.4 65.2
appear 52.2 61.0 56.6 70.3 62.3
follow 51.6 65.6 61.8 61.6 69.6
consider 50.7 70.3 67.4 77.5 59.4
cover 50.4 54.5 55.0 57.2 50.0
fill 47.8 62.7 69.4 60.1 48.6
bear 47.4 67.4 77.2 68.1 63.8
allow 37.8 51.9 51.1 50.7 44.9
Average 66.3 72.0 72.8 74.2 70.1
Table7:PerverbAccuraciesontheAsp-ambigdataset(FriedrichandPalmer,2014).
For strongly imbalanced classes as in the case of feel, which almost always functions as a state, the
majoritybaselineisverydifficulttobeat. Interestingly,thewindow-1anddependency(full)approaches
frequently exhibit complementary performance. For example, while for stand or look a window-based
contextworkssubstantiallybetter,forfolloworcarryadependency-basedcontextispreferable. Oneex-
planationforthisbehaviouristhatforstandorlookprepositionsarefrequentlythemostsalientindicator
ofaspectualclassasshowninSection5. Ontheotherhand,forfolloworcarryacontentword,suchas
thesubjectordirectobject,isfrequentlymoresalient.
B SupplementalMaterial—PoSTagDistributionofExtractedContexts
Figure7showsthePoStagdistributionofextractedcontextsofthelinearcontextwindowincomparison
to dependency contexts. Dependency contexts, based on Universal Dependencies, overwhelmingly ex-
tractcontentwords,whereasthelinearcontextwindowpredominantlytendstoextractmoreclosedclass
words.
Figure7:PoStagdistributionoftheextractedcontextsofthelinearcontextwindowvs.dependencycontexts.
C SupplementalMaterial—WindowContextsvs. DependencyContexts
Tables 8 & 9 present the performance of the best performing linear context window in comparison to
thebestperformingdependencycontextwindow,aswellastheverb-onlyandfull-sentenceandmajority
classbaselines.
Dataset BestLinear BestDependency Verbonly FullSentence MajorityClass
Asp-ambigAccuracy 74.2 70.1 65.9 60.0 65.9
SitEntF1(State) 81.2 81.3 84.0 26.4 0.0
SitEntF1(Event) 84.1 84.5 86.6 71.9 68.9
SitEnt-ambigF1(State) 62.6 60.1 44.0 0.0 0.0
SitEnt-ambigF1(Event) 66.2 65.3 62.4 68.3 68.4
CaptionsF1(State) 58.8 55.9 0.1 23.4 0.0
CaptionsF1(Event) 89.7 89.2 87.3 86.7 87.6
DIASPORAF1(State) 86.5 85.9 76.4 80.1 0.0
DIASPORAF1(Event) 89.6 89.8 83.5 84.8 72.5
Table8: Comparisonbetweenlinearcontextswindowsanddependencycontextsonclassifyingstatesvs.
events.
Overalllinearcontextwindowperformslightlybetteronaveragethandependencycontextwindows—
andashighlightedinSection5—thiscanbeexplainedbylinearcontextwindowextractingmoreclosed
classcontextwords(seeFigure7inAppendixB),whichtendtobestrongerdisambiguationsignalsthan
contentwords.
Dataset BestLinear BestDependency Verbonly FullSentence MajorityClass
TelicityF1(Telic) 91.6 90.7 92.1 91.1 90.1
TelicityF1(Atelic) 60.3 57.8 62.6 60.6 0.0
CaptionsF1(Telic) 71.6 72.3 70.7 71.2 55.3
CaptionsF1(Atelic) 82.6 83.0 83.3 83.1 0.0
DIASPORAF1(Telic) 70.3 69.6 64.5 66.5 69.2
DIASPORAF1(Atelic) 67.8 65.4 63.3 62.9 0.0
Table9: Comparisonbetweenlinearcontextswindowsanddependencycontextsonclassifyingtelicvs.
atelicevents.
D SupplementalMaterial—ZeroShotGeneralization
For assessing the generalisation capabilities of our methodology we are performing a zero-shot setup
on the Asp-ambig dataset. Instead of running an evaluation for each verb individually as originally
proposedbyFriedrichandPalmer(2014),weareevalutingthemodelonthedataforoneparticularverb,
saylook,andtrainthemodelonallavailabledata,exceptthedatafortheheldoutverblook. Thisway,we
investigatewhetherdistributionalrepresentationstrulycapturetheunderlyingsemanticsofpredicational
aspect.
We use the same simple setup as in Section 5, with a linear regression classifier that operates on the
basisofaveragedword2vecembeddings. Weusedalinearcontextwindowofsize1forthisexperiments
asthiswasthebestperformingsetupfortheAsp-ambigdatasetintheevaluationinSection5. Table10
Verb Majorityclass ZeroShot
feel 96.1 43.0
say 94.9 55.8
make 91.9 86.2
come 88.0 78.1
take 85.4 82.6
meet 83.9 76.8
stand 80.0 22.5
find 74.5 69.6
accept 70.9 68.1
hold 56.0 26.3
carry 55.9 54.0
look 55.8 77.5
show 54.9 52.2
appear 52.2 51.4
follow 51.6 39.9
consider 50.7 50.7
cover 50.4 41.6
fill 47.8 48.2
bear 47.4 47.1
allow 37.8 39.4
Average 66.3 55.5
Table10:PerverbAccuraciesontheAsp-ambigdataset(FriedrichandPalmer,2014).
shows the results of the zero-shot experiment in comparison to the majority class baseline. While for
the majority of verbs, our model underperforms the majority class baseline — which is difficult to beat
especiallyfortheveryskewedverbssuchasfeelorsay,ourapproachbeatsthebaselinefor3verbsand
achieves comparable performance for more than half of the verbs, while not having encountered any
annotateddataforthetargetverbduringtrainingatall.
Giventhesimplicityofoursetup,weregardthatasstrongevidencethatamodelbasedondistributional
semanticsdoesindeedcaptureasubstantialamountofpredicationalaspectinitsrepresentations.
