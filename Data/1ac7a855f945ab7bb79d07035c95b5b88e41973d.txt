Speechalator: two-way speech-to-speech translation on a consumer PDA
AlexWaibel ,AhmedBadran ,AlanWBlack ,RobertFrederking ,Donna Gates ,
AlonLavie , LoriLevin ,KevinLenzo ,LauraMayfieldTomokiyo,
Ju¨rgenReichert ,Tanja Schultz ,DorcasWallace ,MonikaWoszczyna ,Jing Zhang
LanguageTechnologiesInstitute, Carnegie MellonUniversity, Pittsburgh,PA
Cepstral,LLC, Multimodal TechnologiesInc, Mobile TechnologiesInc.
speechalator@speechinfo.org
Abstract 2. Data Collection
This paper describes a working two-way speech-to-speech
TheArabiclanguagewasmostlynewtothisgroup. Although
translation system that runs in near real-time on a consumer
we had some experience and resources from Tunisian Arabic
handheldcomputer.ItcantranslatefromEnglishtoArabicand
inrecognitionaspartoftheGlobalPhoneproject[3],wewere
ArabictoEnglishinthedomainofmedicalinterviews.
essentiallystartinginanewlanguage. Thiswasagoodtestof
Wedescribethegeneralarchitectureandframeworkswithin
ourexistingspeech-to-speechtranslationframework.
which we developed each of the components: HMM-based
recognition, interlingua translation (both rule and statistically
The normal Arabic script does not include all vowels, al-
based),andunitselectionsynthesis.
thoughtherearediacriticswhichcanbeusedtospecifyallvo-
calization, these only appear in childrens’ books and the Ko-
1. Background
rananddonotappearinconventionaltext. Thusnormalscript
would be hard to use for speech processing. There are statis-
AsaninitialpartoftheDARPABabylonprojectweweretasked
tical techniques (e.g. [4]) that can be used to predict vocal-
with building an interlingua-based two-way speech-to-speech
ization but it is much easier if we could use a script with all
translationsystemonasmalldeviceinalanguagethatourgroup
vowelsfullyspecified. Therehavebeensuccessfulattemptsto
hadno(significant)previousexperiencein. Thisrequiredusto
do Arabic speech recognition without explicit vowels [5], but
solvethreespecificproblems:
for synthesis this would be much harder if actually possible.
Howtocollectsufficientandappropriatedatafortrans- ThereforebecauseweareembeddingthisuseofArabicwithin
lation, recognition, and synthesis, in the most efficient speech-to-speechtranslationwherewecontrolintheinputand
way.Usingforeignlanguageexpertswedesignedproto- output mechanisms we are in a position to stipulate that the
colstodefinethetranslationdomainandcollectexam- internal form may be a romanization which contains full vo-
plestoallowanappropriateinterlinguatobedesigned. calization. TransliteratingfromaromanizedscriptintoArabic
scriptiseasy(itinvolvesremovinginformation)sowecanstill
How to take advantage of both knowledge-based tech- displaythetranslationinArabicscript,butinternallypreserve
niques in defining an interlingua; and statistical tech-
thevowelinformation. Othershavenotedthisproblemandwe
niques, in learning the relationship between surface
basedourromanizationontheArabicCallHome[6]romaniza-
formsandthatinterlingua;insuchawaytomaketrans-
tion,butmadeseveralrefinements,fromwhichphoneticforms
fertonewdomainsandlanguagesefficient.
canbeeasilyderived.
Howtofittworecognizers,twosynthesizersandatwo-
way translation system on a device with only 40Mb of ThesecondmajorissuewaswhatdialectofArabictouse.
available space and limited CPU power. This required AlthoughthereisastandardwrittenformforArabic, Modern
addressingengineeringissues:lackoffloatingpointsup- StandardArabic, (MSA)thisisnotusedfornormalconversa-
port, synthesisdatabasecompression, efficientrecogni- tion.Aswearespecificallyinterestedinspokenlanguagetrans-
tion decoding algorithm; as well as research issues in lation we decided to chose a major spoken dialect for which
modeldesignforsizeandefficientaccess. localexpertswereavailable. ThuswesettledonEgyptianAra-
bic.
TheendresultisaworkingprototypeonaCompaqiPaqwhich
canrecognize,translateandsynthesizebi-directionallybetween There were three areas for which data had to be col-
twolanguages,EnglishandEgyptianArabic,anddosoinarea- lected: recognition, synthesis and translation. From an exist-
sonabletime. Althoughthisprototypeislimited,itwasaimed ing database of English medical expressions used for another
at medical interviews, and deals with only many hundreds of speech-to-speech translation system, Arabic foreign language
sentencetypes,itshowsthefeasibilityofsuchasystem. experts(FLE)handtranslatedeachutteranceintoanumberof
Thisparticularsystemwasbuiltoveraperiodofsixmonths, differentparaphrasesinEgyptianArabic(upto10differentex-
usingthetoolsandtechniqueswehavedevelopedoveranum- amples). TheFLEswerethenaskedtospeakeachoftheutter-
ber years in rapid development for speech-to-speech transla- ances.Sothatwecollectedrecordingsofsome7500in-domain
tionssystems[1],[2]. utteranceswithromanizedtranscriptions.
(cid:8)
(cid:8)
(cid:8)
(cid:0)
(cid:6)
(cid:0) (cid:2) (cid:4)
(cid:4)
(cid:0)
(cid:7)
(cid:0)
(cid:0)
(cid:0)
(cid:0) (cid:2)
(cid:6)
(cid:6)
(cid:0)
(cid:4)
(cid:0)
(cid:7)
(cid:6)
(cid:0)
(cid:4)
3. Recognition Ihaveahusbandandtwochildrenagestwoandeleven.
SpeechRecognitionisthemostcomputationallyexpensivepart give-information+personal-data
ofthespeech-to-speechtranslationprocess.Unlessadecoderis (family=
speciallydesignedtorunonaPDAplatformwhichhaslimited spec=(conj=and,
memorybandwidthandnofloatingpoint, therecognitionwill (spouse, sex=male),
likelybetooslowforpracticaluse. (offspring,
quantity=2,
MultimodalTechnologiesInc,hasbeenworkingonasmall
age=(quantity=(conj=and,2,11)),
footprintfastdecoderHMM-basedrecognitionforsomeyears
experiencer=i)
andhashadsignificantexperienceinworkingwithmultiplelan-
guagesandspeech-to-speechtranslationsystems.
Doyouhaveanypaininyourarm?
The audio input device on PDAs is not of high quality.
Giventhesizeofthehardwareitiscommonthattheaudiochan- request-information+experience+health-status
nelhaslotsofelectricalnoisefromthepowersupplyandmoth- (health-status=pain,
erboard, thus recordings on these devices are not clean. Fur- body-location=arm,
thermoreinourexperiencetheamountofnoisethattheaudio experiencer=you)
channel maydifferfromdevice todevice. Externaldigitizing
ofaudiomightbeanoptioninthelongterm,suchasoff-device Icouldexamineyourshoulder.
USBaudio,ordesignofbettershieldingaroundtheaudiohard-
offer+give-medical-procedure+body-object
ware,butourgoalwastousestandardPDAssosuchalternatives
(who=i,
werenotavailable.
medical-procedure-spec=medical-examination,
The acoustic models were bootstrapped from the Global-
body-object-spec=(whose=you, shoulder))
Phone[3]Arabiccollectionaswellastherecordingsdescribed
above. The data contains both male and female examples
thoughwehavetestedmorewithmalespeakersthanfemale.
Figure1:ExamplesofSpeechActsandDomainActions
AstheSpeechalatorisadomain-basedtranslationsystem,
wewanttousethatadvantagetoconstraintherecognitionen-
gines. Ratherthanhavingaseparatelanguagemodelandsub-
investigate porting the existing generator system to the PDA,
sequentparseraswehavedoneinothertranslationsystemswe
butasitwasinC++thatwasgoingtotaketime. Thesecond
havebuilt[7],wehaveintegratedtheparsingpartofthesystem
routewastouseastatisticalbasedtranslationmechanism.
withintherecognizerlanguagemodel. Thisallowsthedecoder
Statisticalmachinetranslationhasbecomemorepopularas
tobemoreefficientallowingustodealwithlargervocabularies
itsperformancehasimproved. Normallymodelsaretrainedon
and more utterance types than we would be able to do other-
corpora of parallel text, with each utterance in one language
wise.
correspondingtoatranslationinthetargetlanguage. Thisba-
Thefinalpartoftherecognitionsystemistheadaptationto
sicmodelhoweverwouldremovetheadvantagesofinterlingua,
theacousticenvironment, andspeaker. Thisisfairlystandard
asconventionalstatisticalMTtechniqueswouldrequireparal-
inmostrecognitionenginesandweadoptthesetechniqueshere
lelcorporaforeachlanguagepairwewishedtosupport. Thus
too.
instead of having the two sides be textual utterances we used
aparallelcorporaofinterlinguarepresentationsandtheirreal-
4. Translation izationastextualutterancesinthetargetlanguage. Thismodel
doesintroducedifferentproblems,astheinterlinguarepresen-
Our translation uses an explicit language-independent inter-
tationiseffectivelyatreestructure. Thesetechniquesarerela-
lingua formalism, so that support of new languages can be
tivelynewandwillbepublishedelsewhere. Butbecausethey
achieved without affecting existing supported languages. De-
were successful and because we had an efficient implementa-
signoftheinterlinguaformalismisnoteasybutwealreadyhave
tionoftheengineonthePDA,itwaspossibletousethisengine
experienceinthatarea,[8].
withtheSpeechalatorandafullyuntetheredtranslationdevice.
Ourinterlinguarepresentationisbasedonspeakerintention
Thuswehavetwomethods,onesolelyonthedevice,anda
rather than literal meaning. The speaker’s intention is repre-
secondclearmethodtocovermuchlargertranslationproblem
sentedasadomain-independentspeechactfollowedbydomain
ifawirelessconnecttoaserverisavailable.
dependentconcepts. Weusethetermdomainactiontoreferto
Onlybasicevaluationwascarriedoutonthesegeneration
thecombinationofaspeechactwithdomainspecificconcepts.
models,andthisisstillcontinuingwork.
ExamplesofdomainactionsandspeechactsareshowninFig-
ure 1. Domain actions are constructed compositionally from
5. Synthesis
aninventoryofspeechactsandaninventoryofconcepts. Spe-
cificinformationconcerningpredicateparticipantsandobjects ThespeechsynthesiswasconstructedbyCepstral,LLCusing
etc. is represented by arguments and values. The allowable techniques that allow high quality unit selection synthesis on
combinations of speech acts, concepts, arguments and values smallfootprintasdemandedbytheintendedplatform.
areformalizedinahuman-andmachine-readablespecification The English male voice (a female voice is also available)
document. offers clear speech in a command-like style. This voice had
Ourinitialsystemusedanoff-deviceinterlinguatotextgen- beencreatedforpreviousprojectsandwasspecificallydesigned
erationsystemasthegeneratorhadnotyetbeenportedtothe fordeliveryshortdialogutterancessuchaswouldbeneededin
PDAdevice.Thisworkedwell,butgiventhenetworkoverhead, thisapplication.
wasslowerthanwewished,butcoulddealwithlargegrammars. Thevoiceisageneralspeechsynthesizerthatcansayany-
We took two parallel tracks to solve this, this first was to thing, and is not limited to a particular domain. At 11KHz,
asuitablesamplerateforthePDAhardware,thevoiceplusthe architecture would allow us develop and test the components
languagefrontend(includingthelexicon)isabout9megabytes. beforetheywereportedtothePDAitself.
TheArabicsynthesizerwasbuiltspeciallyforthisproject. Cepstral and Multimodal Technologies had already spent
AninitialtestvoicewasbuiltintheFestivalSpeechSynthesis significanteffortinproducespeechsynthesizersandspeechrec-
System[9]. Thisallowedacertainamountoftuningbeforea ognizersrespectively,thatwereoptimizedfortheStrongARM
smallfootprintdeliverywasattempted. platform. The process available on most PDAs today is the
Weusedtheromanizationdecidedonfortherecognizerand StrongARMSA1110(206MHz)ortheXScale,useddirectlyas
translation engine, as predicting vowels in Arabic script is a aStrongARMreplacement.Neitheroftheseprocessorsarepar-
non-trivialproblem.Usingthegeneratedlistoftranslationscre- ticularlyfastandneitherofferfloatingpoint. Althoughfloating
atedforthetranslationpartofthesystemweuseamethodas pointinstructionscanbeemulatedthisisfartooslowforcore
describedin[10]toselectanoptimalsubsetoftheseutterances functions. AlthoughtheArabicspeechmodelswerebuiltjust
that best cover the acoustic phonetic space. Thus from a list forthisprojects,andtheEnglishspeechmodelswereadapted,
ofaround7500sentencesweselected666sentences,102sen- itwasnecessarytohavealreadydevelopedthecoreenginesand
tenceshandconstructedtocovernumbers,and52twogeneral relatedmodelbuildingsystemsbeforehandinordertodelivery
greetings(forbothmaleandfemalespeakers). afulltwowaysysteminanewlanguageinsuchashorttime.
One notableaspectofthebuildingofanArabicvoicefor The engines used for interlingua translation had not yet
this system was that we found our native speaker slightly re- been ported to Windows CE. Thus at first we used a wireless
luctanttohavetheirvoiceusedinadevicethatcouldlaterbe connectionbetweenthePDAandaLinuxservertoprovidethe
usedbythemilitaryforunspecifieduse,potentiallyintheirown interlingua-to-textpartoftheboththeEnglishandArabicgen-
country. Withtheimprovementinspeechsynthesistothelevel eration.Welaterreplacedthiswithanon-devicestatisticalgen-
wheretheoutputvoiceisrecognizableastheparticularperson eratorthatwascomputationallylightenoughtorunonthede-
whorecordedthedatabase,wemustbesensitivetotheusesof viceitself. Thatthisstatisticalgenerationcouldberunonthe
thesystemwebuild.Althoughweareverycarefultoexplainto devicewasnotbecausestatisticalgenerationisinherentlymore
allourvoicetalentwhattheconsequencesofrecordingasyn- lesscomputationallyintensivethantherulebasedgeneratorbut
thesisvoiceare,peoplemaynotbefullyawareuntiltheyseethe thatthestatisticalgeneratorwasdevelopedwithaportofWin-
completesystem. Becauseofthis,weusedadifferentspeaker dowsCEinmind.
forthefinalrecordings. Theparserpartofthesystemwasmovedintotherecognizer
Evaluationofspeechsynthesisisalwayshardbutthereare so that the parsing restrictions could better constrain recogni-
simplediagnosticteststhatcanberuntoidentifyproblemsin tion.Onsuchalimiteddeviceefficientrecognitionisimportant
thesynthesizer. Inthiscasewecarriedoutthreespecifictests. andlinkingtheASRdecoderwithastrongappropriatelanguage
BasedontheDiagnosticRhymeTest[11],andModifiedRhyme modelisagoodthingtodo.
Testweconstructedsimplemono-syllabicwordswhichdiffered The whole system was built as a single binary, being the
inonephoneticfeature. ForEnglishthistesttypicallyincludes bestuseoftheprocessmodelunderWindowsCE.Eachmodule
aspectslikevoicing,nasality,sustenationetc. Wemodifiedthis mapsinitsappropriatelanguagedatafiles.Althoughatpresent
listforArabicandincludedemphaticnesstotheclass.Asecond weonlyhaveexamplesinEnglishandArabicthereisnothing
leveltestinvolvedsentencesthatwerenotpartoftherecorded languagespecificinthebasicengines.
databasebutstillconsidered“in-domain”. TheDRT/MRTand Atruntimethesystemusesaround28Mbofmemoryand
in-domainsentenceswerethenplayedtonativeArabicspeakers hence can comfortably run on a 64Mb PDA. However as the
andtheywereaskedtomarkanywordswhich“soundedbad” run-timememoryandthestoragememoryaredistinctonmost
for any reason, a deliberately vague term. The results are as PDAs we also need a separate storage card installed to hold
follows show percentage of “good” words in the synthesized thesystem(about30Mb). WehavebeenusingCompaq(HP)
utterances iPaq 3800 series machines (StrongARM 206MHz) and 3900
series machines (XScale 400MHz) for basic development but
DRT MRT Sentence
alsohaveportedthesystemtotheDellAximandtheone-way
78.3 72.0 84.7
Phraselator hardware. The Dell Axim (XScale 300MHz) has
ThesenumbersarecomparabletoEnglishvoices,ofsimilarsize only 32Mb, but we found the system ran well, though slower
anddegreeofdevelopment. thanon64Mbmachines.
6. SystemIntegration 7. Performance
Theaimofthisworkwastodelivertwo-wayspeech-to-speech We have not yet, at this stage in the project, been able to run
translationonahandheld. TheoriginalBabylonprojectinten- formalevaluationtests,thoughthroughoutthesixmonthsthat
tionwastouseanupdatedplatformthatwascurrentlyusedin theprojectwasactivewedidcarryoutcomponent-basedtests.
theone-wayPhraselatorsystem[12]. Butasthatplatformwas The whole system (running in unthethered mode) takes
not yet ready we decided to aim for a consumer off-the-shelf around2-3secondstotranslateatypicalutterancefromwhen
(COTS)PDA. thespeakerstopsspeaking,towhenthesystemstartsspeaking
Fromourexperienceinotherprojectindeliveringonlim- thetranslation.Thus,theperformancecanbesaidtobejustover
ited hardware platforms we have felt it better to aim for the real-time. However,recognitioncantake1-2secondslongerin
intendedhardwareplatformatthestartratherthanassumethe adverseacousticenvironments.
platformwillimproveofthelengthoftheproject. InspiteofPDAshavingpooraudioinputhardwarethesys-
Ourfirstintentionwastodesignaarchitecturethatwould temworkswellinvariousenvironments,includingofficesand
allowcomponenttoresideeitheronthedeviceitselforonex- outside. Thoughinsomeharsherenvironmentsthesystemca-
ternal servers accessed through a wireless link. Although the pabilityimprovesifgivenafewutterancestoadaptto.Wehave
ultimateresultshouldnotrelyonwirelesslinkstoserver, this foundthatinenvironmentswithlotsofhumanspeecharound,
suchasbarsandrestaurants,performancegoesdown. 9. Summary
Ininformaltestswehavefoundagreaterthan80%accu- This paper describes a two-way speech-to-speech translation
racy. systemthatrunsonaconventionalPDA.IttranslatesfromEn-
Thesystemissetupforthedomainofmedicalinterviews, glish to Arabic and Arabic to English in the medical domain.
andhasonlybasicvocabularyforgreetingsandnumbersout- The system was build over a period of about 6 months. Al-
sidethatdomain.Althoughthereissharedcoverageitisassume thoughwebuiltuponexistingenginesandtechniques,theAra-
thattheEnglishspeakerisadoctorandtheArabicspeakeristhe biclanguageaspectsofthisworkwereallcarriedoutwithinthe
patient. courseofthe6months.
Although difficult to fully quantify the coverage, for En-
10. Acknowledgments
glish the language model covers many hundreds of sentence
types, with as many as dozens of possible variations, such as
This work was partially funded by a grant N66001-00-C-
diseases,ailmentsandbodyparts.TheArabicsideismorecon-
8007undertheDARPABabylonprogram:“MobileSpeech-to-
strained,butstilldealswithafewhundredsentencetypes.
SpeechTranslationforMilitaryFieldApplication.” Theopin-
ionsexpressedinthispaperdonotnecessarilyreflectthoseof
8. UserInterface DARPA.
11. References
[1] A.Lavie,L.Levin,T.Schultz,andA.Waibel, “Domain
portabilityinspeech-to-speechtranslation,” inHLT2001,
SanDiego,California,2001.
[2] A.Black,R.Brown,R.Frederking,R.Singh,J.Moody,
andE.Steinbrecher, “Tongues: Rapiddevelopmentofa
speech-to-speech translation system,” in HLT2002, San
Diego,California,2002,pp.2051–2054.
[3] T. Schultz and A. Waibel, “Language independent and
languageadaptiveacousticmodelingforspeechrecogni-
tion,”SpeechCommunication,vol.35,no.1-2,pp.31–51,
2001.
[4] K. Kirchhoff, et al., “Novel speech recognition models
forArabic.,” Technicalreport,JohnsHopkinsUniversity,
2003.
[5] J.Billa,M.Noamany,A.Srivasta,D.Liu,R.Stone,J.Xu,
J.Makhoul,andF.Kubala, “Indexingofarabicbroadcast
news,” inICASSP,Orlando,Florida,2003.
[6] LinguisticDataConsortium, “Callhomeegyptianarabic
speech,”1997.
[7] A. Lavie, et al. “A multi-perspective evaluation of the
NESPOLE!speech-to-speechtranslationsystem,”inPro-
ceedings of ACL 2002 workshop on Speech-to-speech
Translation: AlgorithmsandSystems, Philadelphia, PA.,
2002.
[8] L. Levin, D. Gates, D. Wallace, K. Peterson, A. Lavie,
F. Pianesi, E. Pianta, R. Cottoni, and N. Mana, “Bal-
ArabicinputScreen ancingexpressivenessandsimplicityinaninterlinguafor
Speechalatorsnapshot taskbaseddialogue,” inProceedingsofACL2002work-
shop on Speech-to-speech Translation: Algorithms and
Theuserinterfaceissimple, butstillrequirestheusersto
Systems,Philadelphia,PA.,2002.
knowsomethingabouttheoperationofthemachine. Thereis
apush-to-talkbutton,andtherecognizedutteranceisdisplayed [9] A.Black, P.Taylor, andR.Caley, “TheFestivalspeech
theupperwindow.Thesecondwindowthendisplaysthetrans- synthesissystem,” http://festvox.org/festival,1998.
lation as it is spoken. The utterance may be repeated at the [10] A.BlackandK.Lenzo, “Optimaldataselectionforunit
pressofabutton. Theinputlanguagemaybechangepressing selection synthesis,” in 4th ESCA Workshop on Speech
anotherbutton. Thedisplayusesthenativecharacterscriptfor Synthesis,Scotland.,2001.
thelanguagethatistoberecognized.
[11] J. Logan, B. Greene, and D. Pisoni, “Segmental intelli-
There are however usability issues with such a system gibility of synthetic speech produced by rule,” Journal
which we have not yet addressed. We currently have no ex- oftheAcousticalSocietyofAmerica,vol.86(2),pp.566–
plicitwayofinstructinganon-Englishspeakingpersoninhow 581,1989.
to use the device. In close conversation the audio output vol-
[12] Sarich,A., “Phraselator,one-wayspeechtranslationsys-
umeisadequatebutinlargergroupsoroutsidemorevolumeis
tem,”http://www.sarich.com/translator/,2001.
requiredthanthestandardPDAspeakercandeliver.
