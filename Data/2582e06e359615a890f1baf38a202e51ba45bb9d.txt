Automatic Keyword Extraction on Twitter
Lu´ısMarujo1,2,3,WangLing1,2,3,IsabelTrancoso2,3,ChrisDyer1,AlanW.Black1,
AnatoleGershman1,DavidMartinsdeMatos2,3,Joa˜oP.Neto2,3,andJaimeCarbonell1
1 LanguageTechnologiesInstitute,CarnegieMellonUniversity,Pittsburgh,PA,USA
2 InstitutoSuperiorTe´cnico,UniversidadedeLisboa,Lisbon,Portugal;
3 INESC-ID,Lisbon,Portugal
{luis.marujo,wang.ling,isabel.trancoso,david.matos,joao.neto}@inesc-id.pt
{cdyer,awb,anatoleg,jgc}@cs.cmu.edu,
Abstract Thesemessagestendtobeshorterthanwebpages,
especially on Twitter, where the content has to be
In this paper, we build a corpus of tweets
limited to 140 characters. The language is also
fromTwitterannotatedwithkeywordsus-
more casual with many messages containing or-
ing crowdsourcing methods. We iden-
thographical errors, slang (e.g., cday), abbrevia-
tify key differences between this domain
tionsamongdomainspecificartifacts. Inmanyap-
andtheworkperformedonotherdomains,
plications, that existing datasets and models tend
such as news, which makes existing ap-
to perform significantly worse on these domains,
proachesforautomatickeywordextraction
namely in Part-of-Speech (POS) Tagging (Gim-
not generalize well on Twitter datasets.
pel et al., 2011), Machine Translation (Jelh et al.,
Thesedatasetsincludethesmallamountof
2012; Ling et al., 2013), Named Entity Recogni-
content in each tweet, the frequent usage
tion (Ritter et al., 2011; Liu et al., 2013), Infor-
oflexicalvariantsandthehighvarianceof
mation Retrieval (Efron, 2011) and Summariza-
thecardinalityofkeywordspresentineach
tion(Duanetal.,2012;Changetal.,2013).
tweet. Weproposemethodsforaddressing
As automatic keyword extraction plays an im-
theseissues,whichleadstosolidimprove-
portantroleinmanyNLPtasks,buildinganaccu-
mentsonthisdatasetforthistask.
rate extractor for the Twitter domain is a valuable
1 Introduction
asset in many of these applications. In this pa-
Keywords are frequently used in many occasions per, we propose an automatic keyword extraction
as indicators of important information contained system for this end and our contributions are the
in documents. These can be used by human read- followingones:
erstosearchfortheirdesireddocuments, butalso
in many Natural Language Processing (NLP) ap- 1. Provide a annotated keyword annotated
plications,suchasTextSummarization(Paletal., dataset consisting of 1827 tweets. These
2013), Text Categorization (O¨zgu¨r et al., 2005), tweets are obtained from (Gimpel et al.,
InformationRetrieval(Marujoetal.,2011a;Yang 2011),andalsocontainPOSannotations.
and Nyberg, 2015) and Question Answering (Liu
and Nyberg, 2013). Many automatic frame- 2. Improveastate-of-the-artkeywordextraction
works for extracting keywords have been pro- system (Marujo et al., 2011b; Marujo et al.,
posed (Riloff and Lehnert, 1994; Witten et al., 2013) for this domain by learning additional
1999; Turney, 2000; Medelyan et al., 2010; Lit- featuresinanunsupervisedfashion.
vakandLast,2008). Thesesystemswerebuiltfor
more formal domains, such as news data or Web The paper is organized as follows: Section 2
data, where the content is still produced in a con- describes the related work; Section 3 presents the
trolledfashion. annotation process; Section 4 details the architec-
The emergence of social media environments, ture of our keyword extraction system; Section 5
suchasTwitterandFacebook,hascreatedaframe- presents experiments using our models and we
work for more casual data to be posted online. concludeinSection6.
637
Proceedingsofthe53rdAnnualMeetingoftheAssociationforComputationalLinguistics
andthe7thInternationalJointConferenceonNaturalLanguageProcessing(ShortPapers),pages637–643,
Beijing,China,July26-31,2015.(cid:13)c2015AssociationforComputationalLinguistics
2 RelatedWork formation(e.g.,retweet). Theannotationsofeach
annotatorarecombinedbyselectingkeywordsthat
Both supervised and unsupervised approaches
arechosenbyatleastthreeannotators. Wealsodi-
have been explored to perform key word extrac-
videdthe1827tweetsinto1000trainingsamples,
tion. Most of the automatic keyword/keyphrase
327 development samples and 500 test samples,
extraction methods proposed for social media
usingthesplitsasin(Gimpeletal.,2011).
data, such as tweets, are unsupervised meth-
ods (Wu et al., 2010; Zhao et al., 2011; 4 AutomaticKeywordExtraction
Bellaachia and Al-Dhelaan, 2012). However,
the TF-IDF across different methods remains There are many methods that have been proposed
a strong unsupervised baseline (Hasan and Ng, forkeywordextraction. TF-IDFisoneofthesim-
2010). These methods include adaptations to plestapproachesforthisend(Saltonetal.,1975).
the PageRank method (Brin and Page, 1998) in- The k words with the highest TF-IDF value are
cluding TextRank (Mihalcea and Tarau, 2004), chosen as keywords, where k is optimized on the
LexRank (Erkan and Radev, 2004), and Topic development set. This works quite well in text
PageRank(Liuetal.,2010). documents, such as news articles, as we wish to
Supervised keyword extraction methods for- find terms that occur frequently within that docu-
malizethisproblemasabinaryclassificationprob- ment,butarenotcommonintheotherdocuments
lem of two steps (Riloff and Lehnert, 1994; Wit- in that domain. However, we found that this ap-
ten et al., 1999; Turney, 2000; Medelyan et al., proach does not work well in Twitter as tweets
2010; Wang and Li, 2011): candidate generation tend to be short and generally most terms occur
andfilteringofthephrasesselectedbefore. MAUI only once, including their keywords. This means
toolkit-indexer (Medelyan et al., 2010), an im- that the term frequency component is not very in-
proved version of the KEA (Witten et al., 1999) formativeastheTF-IDFmeasurewillsimplyben-
toolkit including new set of features and more ro- efit words that rarely occur, as these have a very
bust classifier, remains the state-of-the-art system lowinversedocumentfrequencycomponent.
inthenewsdomain(Marujoetal.,2012). A strong baseline for Automatic Key-
To the best of our knowledge, only (Li et word Extraction is the MAUI toolkit-indexer
al., 2010) used a supervised keyword extraction toolkit (Medelyan et al., 2010). The system
framework (based on KEA) with additional fea- extracts a list of candidate keywords from a
tures,suchasPOStagstoperformedkeywordex- document and trains a decision tree over a large
tractiononFacebookposts. However,atthattime set of hand engineered features, also including
Facebookstatusupdatesorpostsdidnotcontained TF-IDF, in order to predict the correct keywords
eitherhashtagsorusermentions. ThesizeofFace- on the training set. Once trained, the toolkit
bookpostsisfrequentlylongerthantweetsandhas extractsalistofkeywordcandidatesfromatweet
lessabbreviationssinceitisnotlimitedbynumber and returns a ranked list of candidates. The top k
ofcharacterasintweets. keywords are selected as answers. The parameter
k ismaximizedonthedevelopmentset.
3 Dataset From this point, we present two extensions to
the MAUI system to address many challenges
Thedataset1contains1827tweets,whicharePOS
foundinthisdomain.
tagged in (Gimpel et al., 2011). We used Ama-
zon Mechanical turk, an crowdsourcing market, 4.1 UnsupervisedFeatureExtraction
to recruit eleven annotators to identify keywords
The first problem is the existence of many lexical
in each tweet. Each annotator highlighted words
variants in Twitter (e.g., “cats vs. catz”). While
that he would consider a keyword. No specific
variants tend to have the same meaning as their
instructions about what words can be keywords
standardized form, the proposed model does not
(e.g.,“urlsarenotkeywords”),aswewishtolearn
have this information and will not be able to gen-
what users find important in a tweet. It is also
eralizeproperly. Forinstance,iftheterm”John”is
acceptable for tweets to not contain keywords, as
labelled as keyword in the training set, the model
some tweets simply do not contain important in-
wouldnotbeabletoextract”Jooohn”askeyword
1Thecorpusissubmittedassupplementarymaterial. as it is in a different word form. One way to ad-
638
dress this would be using a normalization system uments, such as a news article, contain approx-
either built using hand engineered rules (Gouws imately 3-5 keywords, so extracting 3 keywords
et al., 2011) or trained using labelled data (Han per document is a reasonable option. However,
and Baldwin, 2011; Chrupała, 2014). However, this would not work in Twitter, since the number
these systems are generally limited as these need of keywords can be arbitrary small. In fact, many
supervision and cannot scale to new data or data tweetscontainlessthanthreewords,inwhichcase
in other languages. Instead, we will used unsu- the extractor would simply extract all words as
pervised methods that leverage large amounts of keywords, which would be incorrect. One alter-
unannotated data. We used two popular methods native is to choose a ratio between the number of
for this purpose: Brown Clustering and Continu- wordsandnumberofkeywords. Thatis,wedefine
ousWordVectors. thenumberofkeywordsinatweetastheratiobe-
tweennumberofwordsinthetweetandk, which
4.1.1 BrownClustering
is maximized on the development set. That is, if
It has been shown in (Owoputi et al., 2013) that
we set k = 3, then we extract one keyword for
Brown clusters are effective for clustering lexi-
everythreewords.
cal variants. The algorithm attempts to find a
Finally, abetterapproachistolearnamodelto
clusters distribution to maximize the likelihood
predictthenumberofkeywordsusingthetraining
of each cluster predicting the next one, under the
set. Thus, we introduced a model that attempts
HMM assumption. Thus, words ”yes”, ”yep” and
to predict the number of keywords in each tweet
”yesss” are generally inserted into the same clus-
based on a set of features. This is done using lin-
ter as these tend occur in similar contexts. It also
earregression,whichextractsafeaturesetfroman
buildsanhierarchicalstructureofclusters. Forin-
input tweet f ,...,f and returns y, the expected
1 n
stance, the clusters 11001 and 11010, share the
number of keywords in the tweet. As features we
firstthreenodesinthehierarchically110. Sharing
selected the number of words in the input tweet
more tree nodes tends to translate into better sim-
with the intuition that the number of keywords
ilarity between words within the clusters. Thus,
tends to depend on the size of the tweet. Further-
a word a 11001 cluster is simultaneously in clus-
more, (2) we count the number of function words
ters 1, 11, 110, 1100 and 11001, and a feature
andnon-functionwordsinthetweet,emphasizing
can be extracted for each cluster. In our experi-
thefactthatsometypesofwordstendtocontribute
ments,weusedthedatasetwith1,000Brownclus-
moretothenumberofkeywordsinthetweet. The
tersmadeavailablebyOwoputietal.(Owoputiet
sameisdonefor(3)hashtagsandatmentions. Fi-
al.,2013)2.
nally, (4) we also count the number of words in
4.1.2 ContinuousWordVectors eachclusterusingthetrainedBrownclusters.
Word representations learned from neural lan-
5 Experiments
guage models are another way to learn more gen-
eralizable features for words (Collobert et al.,
Experiments are performed on the annotated
2011; Huang et al., 2012). In these models, a
datasetusingthetrain,developmentandtestsplits
hidden layer is defined that maps words into a
defined in Section 3. As baselines, we reported
continuous vector. The parameters of this hidden
results using a TF-IDF, the default MAUI toolkit,
layer are estimated by maximizing a goal func-
and our own implementation of (Li et al., 2010)
tion, such as the likelihood of each word predict-
framework. In all cases the IDF component was
ingsurroundingwords(Mikolovetal.,2013;Ling
computed over a collection of 52 million tweets.
et al., 2015). In our work, we used the structured
Results are reported on rows 1 and 2 in Table 1,
skip-ngramgoalfunctionproposedin(Lingetal.,
respectively. The parameter k (column Nr. Key-
2015) and for each word we extracted its respec-
words) defines the number of keywords extracted
tivewordvectorasfeatures.
for each tweet and is maximized on the devel-
opment set. Evaluation is performed using F-
4.2 KeywordLengthPrediction
measure (column F1), where the precision (col-
The second problem is the high variance in terms
umn P) is defined as the ratio of extracted key-
of number of keywords per tweet. In larger doc-
words that are correct and the number of ex-
2http://www.ark.cs.cmu.edu/TweetNLP/clusters/50mpaths2 tractedkeywords,andtherecall(columnR)isde-
639
Dev Test
System Nr. Keywords P R F1 P R F1
1 TF-IDF 15 19.31 83.58 29.97 20.21 85.17 31.16
2 (Lietal.,2010) 4 48.81 50.05 49.42 51.78 50.92 51.35
3 MAUI(Default) 4 51.31 52.47 51.88 53.97 53.15 53.56
4 MAUI(WordVectors) 4 52.70 53.50 53.10 55.80 54.45 55.12
5 MAUI(Brown) 4 68.08 74.11 70.97 71.95 75.01 73.45
6 MAUI(Brown+WordVectors) 4 68.46 75.05 71.61 72.05 75.16 73.57
7 MAUI(TrainedonNews) 4 49.12 49.71 49.41 52.40 51.19 51.79
Table 1: F-measure, precision and recall results on the Twitter keyword dataset using different feature
sets.
Dev Test
Selection Nr. Keywords P R F1 P R F1
1 Fixed 4 68.46 75.05 71.61 72.05 75.16 73.57
2 Ratio N//3 65.70 82.69 73.22 69.48 83.8 75.97
3 Regression y+k 67.55 80.9 73.62 71.81 82.55 76.81
Table2: F-measure,precisionandrecallresultsontheTwitterkeyworddatasetusingdifferentkeyword
selectionmethods.
finedastheratiobetweenthenumberofkeywords of-domain keyword extraction corpus composed
correctly extracted and the total number of key- bynewsdocuments(Marujoetal.,2012). Results
words in the dataset. We can see that the TF- arereportedonrow6,wherewecanobserveasig-
IDF, which tends to be a strong baseline for key- nificant domain mismatch problem between these
word/keyphraseextraction(HasanandNg,2010), twodomainsasresultsdropsignificantly.
yields poor results. In fact, the best value for k is
Weexploreddifferentmethodsforchoosingthe
15, which means that the system simply retrieves
number of keywords to be extracted in Table 2.
all words as keywords in order to maximize re-
The simplest way is choosing a fixed number of
call. This is because most keywords only occur
keywordskandtunethisvalueinthedevelopment
once3, which makes the TF component not very
set. Next, we can also define the number of key-
informative. On the other hand, the MAUI base-
words as the ratio N, where N is the number of
lineperformssignificantlybetter,thisisbecauseof k
wordsinthetweet,andk istheparameterthatwe
theusageofmanyhandengineeredfeaturesusing
wishtooptimize. Finally,thenumberofkeywords
lists of words and Wikipedia, rather than simply
can also be estimated using a linear regressor as
relyingonwordcounts.
y = f w1,...,f w , where f ,...,f denote the
Next, we introduce features learnt using an un- 1 n n 1 n
featuresetandw ,...,w aretheparametersofthe
supervisedsetup,namely,wordvectorsandbrown 1 n
modeltrainedonthetrainingset. Oncethemodel
clustersinrows3and4,respectively. Thesewere
is trained, the number of keywords selected for
trained on the same 52 million tweets used for
eachtweetisdefinedasy+k,wherek isinserted
computing the IDF component. Due to the large
to adjust y to maximize F-measure on the devel-
size of the vocabulary, word types with less than
opment set. Results using the best system using
40 occurrences were removed. We observe that
Brown clusters and word vectors are described in
while both features yield improvements over the
Table2. Wecanobservethatdefiningthenumber
baseline model in row 2, the improvements ob-
of keywords as a fraction of the number of words
tained using Brown clustering are far more sig-
in the tweet, yields better results (row 2) yields
nificant. Combining both features yields slightly
betteroverallresultsthanfixingthenumberofex-
higherresults,reportedonrow5. Finally,wealso
tracted keywords (row 1). Finally, training a pre-
testtrainingthesystemwithallfeaturesonanout-
dictor for the number of keywords yields further
36856outof7045keywordsaresingletons improvements (row 3) over a simple ratio of the
640
numberofinputwords. scratch. The Journal of Machine Learning Re-
search,12.
6 Conclusions
Yajuan Duan, Zhumin Chen, Furu Wei, Ming Zhou,
Inthiswork,webuiltacorpusoftweetsannotated andHeung-YeungShum. 2012. Twittertopicsum-
marizationbyrankingtweetsusingsocialinfluence
withkeywords,whichwasusedtobuiltandevalu-
and content quality. In Proceedings of COLING
ateasystemtoautomaticallyextractkeywordson
2012,pages763–780.TheCOLING2012Organiz-
Twitter. A baseline system is defined using exist- ingCommittee.
ing methods applied to our dataset and improve-
Miles Efron. 2011. Information search and re-
ment significantly using unsupervised feature ex-
trievalinmicroblogs. J.Am.Soc.Inf.Sci.Technol.,
tractionmethods. Furthermore,anadditionalcom-
62(6):996–1008,June.
ponent to predict the number of keywords in a
tweet is also built. In future work, we plan to Gu¨nes¸ErkanandDragomirR.Radev. 2004. LexRank:
Graph-basedCentralityasSalienceinTextSumma-
use the keyword extraction to perform numerous
rization. JournalofArtificialIntelligenceResearch,
NLP tasks on the Twitter domain, such as Docu-
22:457–479.
mentSummarization.
KevinGimpel, NathanSchneider, BrendanO’Connor,
Acknowledgements Dipanjan Das, Daniel Mills, Jacob Eisenstein,
MichaelHeilman,DaniYogatama,JeffreyFlanigan,
This work was partially supported by Fundac¸a˜o and Noah A. Smith. 2011. Part-of-speech tagging
para a Cieˆncia e Tecnologia (FCT) through the fortwitter:annotation,features,andexperiments. In
Proceedingsofthe49thAnnualMeetingoftheAsso-
grants CMUP-EPB/TIC/0026/2013, SFRH/BD/
ciationforComputationalLinguistics: HumanLan-
51157/2010, and the Carnegie Mellon Portugal
guageTechnologies: shortpapers-Volume2, HLT
Program. The authors also wish to thank the ’11,Stroudsburg,PA,USA.AssociationforCompu-
anonymousreviewersfortheirhelpfulcomments. tationalLinguistics.
Stephan Gouws, Dirk Hovy, and Donald Metzler.
2011. Unsupervisedminingoflexicalvariantsfrom
References
noisy text. In Proceedings of the First Workshop
on Unsupervised Learning in NLP, EMNLP ’11,
Abdelghani Bellaachia and Mohammed Al-Dhelaan.
pages 82–90, Stroudsburg, PA, USA. Association
2012. Ne-rank: Anovelgraph-basedkeyphraseex-
forComputationalLinguistics.
traction in twitter. In Proceedings of the The 2012
IEEE/WIC/ACMInternationalJointConferenceson
BoHanandTimothyBaldwin. 2011. Lexicalnormal-
WebIntelligenceandIntelligentAgentTechnology-
isation of short text messages: Makn sens a #twit-
Volume 01, WI-IAT ’12, pages 372–379, Washing-
ter. In Proceedings of the 49th Annual Meeting of
ton,DC,USA.IEEEComputerSociety.
theAssociationforComputationalLinguistics: Hu-
Sergey Brin and Lawrence Page. 1998. The anatomy man Language Technologies - Volume 1, HLT ’11,
of a large-scale hypertextual Web search engine. pages368–378,Stroudsburg,PA,USA.Association
Computer Networks and ISDN Systems, 30:107– forComputationalLinguistics.
117.
KaziSaidulHasanandVincentNg. 2010. V.: Conun-
YiChang,XuanhuiWang,QiaozhuMei,andYanLiu. drums in unsupervised keyphrase extraction: Mak-
2013. Towards twitter context summarization with ing sense of the state-of-the-art. In In: COLING,
user influence models. In Proceedings of the Sixth pages365–373.
ACM International Conference on Web Search and
Data Mining, WSDM ’13, pages 527–536, New Eric H Huang, Richard Socher, Christopher D Man-
York,NY,USA.ACM. ning, and Andrew Y Ng. 2012. Improving word
representationsviaglobalcontextandmultipleword
Grzegorz Chrupała. 2014. Normalizing tweets with prototypes. InProceedingsofthe50thAnnualMeet-
edit scripts and recurrent neural embeddings. In ing of the Association for Computational Linguis-
Proceedingsofthe52ndAnnualMeetingoftheAs- tics: LongPapers-Volume1, pages873–882.Asso-
sociationforComputationalLinguistics(Volume2: ciationforComputationalLinguistics.
Short Papers), pages 680–686, Baltimore, Mary-
land, June. Association for Computational Linguis- Laura Jelh, Felix Hiebel, and Stefan Riezler. 2012.
tics. Twitter translation using translation-based cross-
lingual retrieval. In Proceedings of the Sev-
RonanCollobert,JasonWeston,Le´onBottou,Michael enth Workshop on Statistical Machine Translation,
Karlen, Koray Kavukcuoglu, and Pavel Kuksa. Montre´al, Canada, June. Association for Computa-
2011. Natural language processing (almost) from tionalLinguistics.
641
Zhenhui Li, Ding Zhou, Yun-Fang Juan, and Jiawei normalization. In Proceedings of the 8th Interna-
Han. 2010. Keywordextractionforsocialsnippets. tionalConferenceonLanguageResourcesandEval-
InProceedingsofthe19thInternationalConference uation(LREC2012).
onWorldWideWeb,WWW’10,pages1143–1144,
NewYork,NY,USA.ACM. Lu´ıs Marujo, Ricardo Ribeiro, David Martins
deMatos,Joa˜oPauloNeto,AnatoleGershman,and
WangLing,GuangXiang,ChrisDyer,AlanBlack,and Jaime G. Carbonell. 2013. Key phrase extraction
IsabelTrancoso. 2013. Microblogsasparallelcor- oflightlyfilteredbroadcastnews. InProceedingsof
pora. In Proceedings of the 51st Annual Meeting the 15th International Conference on Text, Speech
onAssociationforComputationalLinguistics,ACL andDialogue(TSD).
’13.AssociationforComputationalLinguistics.
Olena Medelyan, Vye Perrone, and Ian H. Witten.
Wang Ling, Chris Dyer, Alan Black, and Isabel 2010. Subject metadata support powered by maui.
Trancoso. 2015. Two/too simple adaptations of In Jane Hunter, Carl Lagoze, C. Lee Giles, and
word2vec for syntax problems. In Proceedings of Yuan-FangLi,editors,JCDL,pages407–408.ACM.
the 2015 Conference of the North American Chap-
Rada Mihalcea and Paul Tarau. 2004. Textrank:
ter of the Association for Computational Linguis-
Bringingorderintotexts. InDekangLinandDekai
tics: Human Language Technologies. Association
Wu, editors, Proceedings of EMNLP 2004, pages
forComputationalLinguistics.
404–411, Barcelona, Spain, July. Association for
Marina Litvak and Mark Last. 2008. Graph-based ComputationalLinguistics.
keywordextractionforsingle-documentsummariza-
TomasMikolov,IlyaSutskever,KaiChen,GregSCor-
tion. In Proceedings of the Workshop on Multi-
rado, and Jeff Dean. 2013. Distributed representa-
source Multilingual Information Extraction and
tionsofwordsandphrasesandtheircompositional-
Summarization,MMIES’08,pages17–24,Strouds-
ity. In Advances in Neural Information Processing
burg,PA,USA.AssociationforComputationalLin-
Systems,pages3111–3119.
guistics.
Olutobi Owoputi, Brendan O’Connor, Chris Dyer,
Rui Liu and Eric Nyberg. 2013. A phased ranking
Kevin Gimpel, Nathan Schneider, and Noah A
modelforquestionanswering. InProceedingsofthe
Smith. 2013. Improved part-of-speech tagging for
22Nd ACM International Conference on Informa-
online conversational text with word clusters. In
tion & Knowledge Management, CIKM ’13, pages
HLT-NAACL,pages380–390.
79–88,NewYork,NY,USA.ACM.
Arzucan O¨zgu¨r, Levent O¨zgu¨r, and Tunga Gu¨ngo¨r.
Zhiyuan Liu, Wenyi Huang, Yabin Zheng, and
2005. Text categorization with class-based and
Maosong Sun. 2010. Automatic keyphrase extrac-
corpus-based keyword selection. In Proceedings
tionviatopicdecomposition. InProceedingsofthe
of the 20th International Conference on Computer
2010 Conference on Empirical Methods in Natural
and Information Sciences, ISCIS’05, pages 606–
LanguageProcessing,EMNLP’10,pages366–376,
615,Berlin,Heidelberg.Springer-Verlag.
Stroudsburg, PA, USA. Association for Computa-
tionalLinguistics.
Alok Ranjan Pal, Projjwal Kumar Maiti, and Diganta
Saha. 2013. Anapproachtoautomatictextsumma-
Xiaohua Liu, Furu Wei, Shaodian Zhang, and Ming
rization using simplified lesk algorithm and word-
Zhou. 2013. Named entity recognition for tweets.
net. International Journal of Control Theory &
ACMTransactionsonIntelligentSystemsandTech-
ComputerModeling,3.
nology(TIST),4(1):3.
Ellen Riloff and Wendy Lehnert. 1994. Information
Lu´ıs Marujo, Miguel Bugalho, Joa˜o P. Neto, Anatole
extractionasabasisforhigh-precisiontextclassifi-
Gershman, and Jaime Carbonell. 2011a. Hourly
cation. ACM Transactions on Information Systems
trafficpredictionofnewsstories. InProceedingsof
(TOIS),12(3):296–333,July.
the 3rd International Workshop on Context- Aware
RecommenderSystemsheldaspartofthe5th ACM Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011.
RecSysConference,October. Namedentityrecognitionintweets:anexperimental
study. InProceedingsoftheConferenceonEmpiri-
Lu´ıs Marujo, Ma´rcio Viveiros, and Joa˜o P. Neto. calMethodsinNaturalLanguageProcessing,pages
2011b. Keyphrase Cloud Generation of Broadcast 1524–1534.AssociationforComputationalLinguis-
News. In Proceedings of the 12th Annual Con- tics.
ferenceoftheInternationalSpeechCommunication
Association(INTERSPEECH2011).ISCA,Septem- G.Salton, A.Wong, andC.S.Yang. 1975. AVector
ber. SpaceModelforAutomaticIndexing. Communica-
tionsoftheACM,18(11):613–620.
Lu´ıs Marujo, Anatole Gershman, Jaime Carbonell,
RobertFrederking,andJoa˜oP.Neto. 2012. Super- Peter D. Turney. 2000. Learning algorithms
vised topical key phrase extraction of news stories for keyphrase extraction. Information Retrieval,
usingcrowdsourcing,lightfilteringandco-reference 2(4):303–336.
642
Chen Wang and Sujian Li. 2011. Corankbayes:
Bayesian learning to rank under the co-training
framework and its application in keyphrase extrac-
tion. InProceedingsofthe20thACMInternational
Conference on Information and Knowledge Man-
agement, CIKM ’11, pages 2241–2244, New York,
NY,USA.ACM.
Ian H. Witten, Gordon W. Paynter, Eibe Frank, Carl
Gutwin,andCraigG.Nevill-Manning. 1999. Kea:
practical automatic keyphrase extraction. In Pro-
ceedings of the 4th ACM conference on Digital li-
braries, DL ’99, pages 254–255, New York, NY,
USA.ACM.
Wei Wu, Bin Zhang, and Mari Ostendorf. 2010. Au-
tomatic generation of personalized annotation tags
fortwitterusers. InHumanLanguageTechnologies:
The2010AnnualConferenceoftheNorthAmerican
Chapter of the Association for Computational Lin-
guistics,HLT’10,pages689–692,Stroudsburg,PA,
USA.AssociationforComputationalLinguistics.
Zi Yang and Eric Nyberg. 2015. Leveraging proce-
dural knowledge base for task-oriented search. In
Proceedings of the 38th international ACM SIGIR
conferenceonResearch&developmentininforma-
tionretrieval.ACM.
Wayne Xin Zhao, Jing Jiang, Jing He, Yang Song,
PalakornAchananuparp,Ee-PengLim,andXiaom-
ing Li. 2011. Topical keyphrase extraction from
twitter. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies - Volume 1,
HLT ’11, pages 379–388, Stroudsburg, PA, USA.
AssociationforComputationalLinguistics.
643
