Event-Related Bias Removal for Real-time Disaster Events
EvangeliaSpiliopoulou∗ SalvadorMedinaMaza∗ EduardHovy AlexanderHauptmann
LanguageTechnologiesInstitute
CarnegieMellonUniversity
{espiliop,salvadom,ehovy,alex}@cs.cmu.edu
tractandanalyzethedatastream,sinceitisimpossi-
Abstract bletomanuallyprocesstheamountofinformation
sharedinsocialmediainreal-time. Therefore,itis
Social media has become an important tool
importanttodetectdatathatcontainusefulinforma-
to share information about crisis events such
tionfordecision-makingandautomaticallyextract
as natural disasters and mass attacks. Detect-
it (Sutton et al., 2008; Palen et al., 2010). Even
ing actionable posts that contain useful infor-
though sentence classification is a well-studied
mation requires rapid analysis of huge vol-
ume of data in real-time. This poses a com- NLP problem, common approaches do not bring
plexproblemduetothelargeamountofposts theexpectedresults(Reuteretal.,2018).
thatdonotcontainanyactionableinformation. Themainreasonwhycommonapproachesfailis
Furthermore, the classification of information
thelackofin-domaindata(Mccreadieetal.,2019;
in real-time systems requires training on out-
Hiltzetal.,2014). Mostemergingcrisisareunex-
of-domain data, as we do not have any data
pected and data analysis must be done real-time,
from a new emerging crisis. Prior work fo-
within a small time-frame (Plotnick et al., 2015).
cuses on models pre-trained on similar event
types. However, those models capture unnec- Evenifwemighthavehighqualityannotateddata
essary event-specific biases, like the location fromprevioussimilarcrisissituations,wewillnot
of the event, which affect the generalizability havedatafromtheemergingeventthatwewantto
and performance of the classifiers on new un- classify. Forexample,letusassumeanearthquake
seen data from an emerging new event. In
in Seattle happens right now. Although we may
ourwork,wetrainanadversarialneuralmodel
have annotated data from a previous earthquake
to remove latent event-specific biases and im-
inLosAngeles,mostoftheparameterswouldbe
prove the performance on tweet importance
classification. entirely different (e.g. location names, damages,
times, etc) since the cities and populations differ.
1 Introduction Furthermore, because some of those parameters
might indeed play an important role in the clas-
Effectivemanagementofcrisissituationslikenat-
sification of a tweet from the specific event (e.g.
uraldisasters(e.g. earthquakes,floods)orattacks
location,ifMonroeistheepicenteroftheSeattle
(e.g. bombings, shootings) is an extremely sensi-
earthquake),atraditionalmodelwouldlearnthem
tive and complex phenomenon that requires effi-
asimportantfeatures. Thiscreatesahighly-biased
cient coordination of people from multiple disci-
model that does not generalize on future events,
plinesalongwithproperallocationoftimeandre-
sincewecannotfine-tuneproperlyon-the-fly. On
sources(Tapiaetal.,2011a;Maitlandetal.,2009).
the other hand, some other features are actually
Given that we live in the era of information and
importantinthegeneralsetting(e.g. severityofthe
socialmedia,filteringimportantnuggetsofinfor-
earthquake,casualtiesetc.). Theproblemwetackle
mation from real-time data and using them into
inthisworkishowtoconstructanevent-basedzero-
decision-makingconstitutesacrucialresearchdi-
shotlearningmodelthatcanlearnunbiasedrepre-
rection(Tapiaetal.,2011b).
sentations,insteadofrelyingonahighly-biasedset
Criticalinformationfromsocialmediaisfound
offeaturesfromseendata.
onlyinsmallamounts. Henceitisdifficulttoex-
Inthispaperweexploreatechniquethathelps
*Equalcontribution. aneuralmodeltodistinguishanddiscardinforma-
tionthatisrelatedonlytospecificevents,resulting Munro(2011)proposesasystembasedonasetof
inamoregeneralizablemodelwithimprovedper- features(location,time,n-grams)tolabeltextmes-
formanceonunseeneventswithoutanyfine-tuning. sagesasactionable/non-actionable. Mostrecently,
Since the main task is to classify the importance theTREC-ISchallengebyMccreadieetal.(2019)
of the information contained in a tweet (critical- proposesalabelingschemewheretheactionability
ity), we use an adversarial classifier that intends ofatweetisreplacedbytheinformationtypeand
to learn which specific event the tweet refers to, thecriticalityscore. Highercriticalityindicatesa
henceremovetheeventspecificbiasthroughare- postcontainsmorerelevantinformationthatcould
versalgradient. Ourexperimentsrepresentareal- beusefulforpublicsafetyofficersduringanemer-
lifecrisismanagementscenario,wherethemodelis gency. Although Miyazaki et al. (2019) shows a
evaluatedonanewincomingeventthroughaleave- greatimprovementoninformationtypeextraction
one-outexperimentalsetup,andshowsubstantial byusingBi-LSTMattentiononBERTembeddings,
improvementoverbaselineclassificationmethods. identifyingcriticalandactionableinformationisa
Finally,weshareourcodeforreproducibilityand muchhardertask(Mccreadieetal.,2019).
easeofuse1.
2 RelatedWork
Recent work on crisis informatics focuses on de-
Processinginformationwithoutthecontextofa
velopingNLPsolutionstoclassifyandextractin-
crisiseventisabottleneckforbigdatacrisisana-
formation from Twitter streams and other social
lytics,asdiscussedbyQadiretal.(2016). Thelack
mediadatarelatedtoanemergencyevent(e.g. at-
of context makes the classification of messages
tacks, natural disasters). As discussed by Tapia
verydifficult,sincethemodelsarepronetoevent-
etal.(2011b),thereareseveralproblemsunderthe
specific biases. Due to the fact that we deal with
umbrellaofcrisisinformatics,suchasdetermining
real-timedata,adomain-adaptationapproachcan-
ifasnippetoftextisrelatedtoaspecificevent,ifit
notusefine-tuninginazero-shotscenario,which
isreliableandtrustworthy,thetypeofinformation
resultsinhighly-biasedmodels. Mostrecentwork
itcontains,whethertheinformationisactionable,
on bias removal (Elazar and Goldberg, 2018) fo-
etc. Mostpreviousworkfocusesontherelevance
cusesonusingadversariallearningtoremovede-
problem: given a set of tweets or other source of
mographic bias from representations. Examples
information and a specific event, classify which
include adversarial generative networks that cre-
datarefertothatevent. Carageaetal.(2016)uses
atefairrepresentations(Madrasetal.,2018),met-
a CNN model to classify tweets related to flood
rics to quantify unintended biases (Borkan et al.,
events,whileKruspe(2019)usesafew-shotlearn-
2019) and applications that show substantial im-
ingmodelbasedonaCNN.Nguyenetal.(2016)
provementsontraditionalNLPtaskslikeNLI(Lu
alsousesaCNNmodeltoclassifyrelatedtweets
et al., 2018), Coreference Resolution (Belinkov
andthetypeofinformationcontained(e.g. infras-
et al., 2019) and text classification (Zhang et al.,
tructuredamage,affectedindividualsetc)fromthe
2018)byusingunbiasedrepresentations. Ourap-
Nepal2015earthquake. Neubigetal.(2011)intro-
proachisinspiredbytheworkofElazarandGold-
ducesareal-timesystemfortheJapan2011earth-
berg(2018)onbiasremovalthroughanadversarial
quake that classifies the relatedness of the posts
attack. The authors use an adversarial setting to
and extracts surface information like named enti-
remove demographic information from text and
ties. OtherapproachesincludeBiLSTMmodelsfor
constructcleanerrepresentations. Inourcase,the
tweetclassification(Ma),eventdetectionbasedon
adversarialclassifierattemptstopredicttheeventto
Twitter streams (Sakaki et al., 2010), adversarial
whichthetweetbelongs. Anotherdifferencewith
dataaugmentationforimageclassification(Pouyan-
ourworkistheimbalanceddatausedfortraining
faretal.,2019)anddomain-adaptationacrossdif-
theclassifierofthemaintask. Otherrelatedwork
ferenteventsusinganadversarialnetwork.
includes domain adaptation based on a gradient-
It is particularly important to first responders
reversallayer(Ganinetal.,2016), textclassifica-
theidentificationofactionableinformationfroma
tionbasedonadversarialmulti-tasklearning(Liu
streamofmessagesastheoneprovidedbyTwitter.
etal.,2017),andmulti-adversarialdomainadapta-
1https://salmedina.github.io/EventBiasRemoval/ tionacrossmulti-modaldata(Peietal.,2018).
2015 Nepal Earthquake
Wildfires 2014 Chile Earthquake
2012 Costa Rica earthquake
2012 Guatemala earthquake
Attacks 2012 Italy earthquake
Earthquakes 2013 Alberta floods
2013 Queensland floods
2012 Philipinnes floods
2013 Manila floods
2013 Colorado floods
2014 Philippines Typhoon Hagupit
2013 Typhoon Yolanda
Typhoons 2012 Typhoon Pablo
2015 Paris attack
Floods 2013 Boston_bombings
2018 Florida shooting
2013 West Texas explosion
2013 LA airport shootings
2013 Australia bushfire
2012 Colorado wildfires
Figure1: CrisisNLPDatasetDistribution. Outercircle: Colordefineseachoftheeventcategories. Innercircle:
Theshadeofcolorsdescribethedifferenteventswithinacategory.
3 Approach high,andcritical. Thedistributionofthelabelsis
highlyskewedtowardsthelowandmediumlabels
InthisworkweuseddatafromtheTREC2018Inci-
asshowninFigure2a. Thesetypesoftweetsdonot
dentStreamschallenge2,whichcontainslabelson
provideimportantinformationfordecision-making
criticalityandinformationtypes(Mccreadieetal.,
during a disaster event. Since we are aiming to
2019). Theydefinecriticalityasascoretoidentify
sieve the actionable tweets, we grouped together
poststhatneedtobeshowntoanofficerimmedi-
thelowandmediumlabelsasnon-critical,andthe
ately as an alert. The raw data and information
highandcriticalascritical. Thenewdistributionof
about the specific event each tweet belongs to is
thedataafterrelabelingisshowninFigure2b. As
extractedfromtheCrisisNLP(Imranetal.,2016)
weseeontheexamplesshowninTable1,thelatter
dataset,whichcontainstweetsinEnglishfromdis-
haveactionableinformationfortheauthorities,first
astereventsthatoccurredduring2012-2018. The
responders,andpopulationondistress.
crisis events in our dataset can be split into five
maingroups: earthquakes,floods,typhoons,wild- 3.2 DataPre-processing
firesandattacks. InFigure1,weshowthatthedata
mainlyconsistsofmultipleearthquake,flood,and
typhoonevents,onlytwowildfireevents,andfive
low non-critical
diverseattacksoriginatedbyhumans.
3.1 DataDescription
medium high critical
critical
Table1: ExamplesofCriticalandNon-CriticalTweets 12978 2836 2334 135 15870 2413
(a)Originallabels (b)Newlabels
Label Event Tweet
non-critical 2014PhilippinesTyphoon Goodmorning!keepsafeeveryone! Figure2: Datasetlabeldistribution. (a)Labeldistribu-
RT:Seekhighergroundimmediately tionoforiginaldataset,(b)Distributionofthelabelsaf-
critical 2013ColoradoFloods wallofwatercomingdownBoulderCanyon
moveawayfromBoulderCreek tergrouping{low,medium}asnon-criticaland{high,
Iamhonestlysickwhocouldbeso
non-critical 2013BostonBombings disgustingtodothistosomeonewewillget critical}ascritical
answersandfindyou#prayforboston
RT:NewsatepicenterofNepaltragedy
critical 2015NepalEarthquake
localchurchmissionoffershelp! Our target dataset comes from Twitter. There-
fore,weperformedaseriesofpre-processingsteps
Inourexperimentsweusedalabeledsubsetof
for data-cleaning. First, we removed links, hash-
the data formed by 18,283 tweets which are la-
tags and mentions, since most of them are event
beledintofourcategoriesaccordingtotheirlevel
specific. Wealsoremovednon-Englishwordstore-
of importance for the authorities: low, medium,
ducethenoise. Next,weremovedallnon-English
2http://dcs.gla.ac.uk/richardm/TREC IS/2020/oldindex.htmlcharacters and emojis. Finally, we observed that
many times white spaces were omitted between encodedthroughanLSTM(Gravesetal.,2013)en-
words,whichresultedinmultiplewordsbeingclus- coderh. Thenthegeneratedembeddingh(t )isfed
i
teredasasingletoken. Tosolvethat,westripped toabinaryclassifierc thatlearnstopredictifthe
r
thetextfrompunctuationmarksand,subsequently, tweetiscriticalornon-critical. Thearchitectureof
usedaheuristicforwordsegmentation,wherewe thismodelisshowninFigure3.
split the token into the least number of possible The training loss L used across all the models
Englishwordsviagreedysearch. andexperimentsiscross-entropy. Theoptimization
ofthebaselinemodelisdescribedineq. 1.
3.3 Models
argminL(c (h(t )),y ) (1)
r i ri
h,cr
critical
TwTwTe wee eets etsts (E Bn iLc So Td Mer ) R Ce lale sv sa ifin ec re 3.3.2 Multi-taskModel
non-critical
Baseline Model ThemultitasklearningsetupdescribedbyCaruana
Event
ev …ent 1 (1997)aimstoimprovetheperformanceofamodel
Classifier eventn bylearningmultipletasksatthesametime. Since
TwTwTe wee eets etsts (E Bn iLc So Td Mer ) critical the dataset is divided per disaster event, we take
Relevance
Classifier
Multi-task Model non-critical advantage of this information given by the struc-
ture of the dataset, and define event detection as
TwTTwe wee eets etsts (E Bn iLc So Td Mer )
R Ge rav de ir es na tl ClE av se sn ifit e r cee rivv t… iee cnn att ln1 t ch lae ss se ific co an td iol ne .ar Hn ein ng cet ,a ts hk ea mlo un lg titw asi kth mth oe dec lri at dic da sli at ny
Relevance
Classifier eventclassifierc ontheencodingoftheincoming
Adversarial Model non-critical e
tweet h(t ) which trains simultaneously with the
i
Figure 3: Evaluated Model Architectures. The adver- classifierc r,asseeninFigure3.
sarial model was compared against the baseline and The optimization procedure for this model is
multitaskmodelstoshowtheremovalofeventspecific describedineq. 2.
biases.
Our experimental setup consists of a dataset argminL(c r(h(t i)),y ri)+L(c e(h(t i)),y ei) (2)
D composed of tweets t ,...,t and two sets h,cr,ce
1 n
of labels; y ,...,y representing the event that
e1 en 3.3.3 AdversarialModel
the tweet belongs to and y ,...,y represent-
r1 rn The adversarial model used in this work follows
ing the importance of the tweet, where y ∈
ri theadversarialtrainingsetupproposedbyGoodfel-
{non-critical,critical}. For this task we want
lowetal.(2014),Ganinetal.(2016),andXieetal.
tofindtheoptimalclassifierf forpredictinglabels
(2017). Inessence,theadversarialmodelissimi-
y . In this work we compared three models to
ri lartothemultitaskmodelexceptfortheaddition
measureifanadversarialtrainingcontributestothe
ofagradient-reversallayerg (Ganinetal.,2016)
λ
detectionofcriticaltweetsonunseenevents.
betweentheencoderhandtheeventclassifierc .
e
Our main hypothesis states that an adversari-
Thegradient-reversallayerduringaforwardstep
allytrainedmodelremovesevent-specificinforma-
works as the identity function I, but during the
tion,whilefocusingonfeaturesthatdeterminehow
back-propagation step the gradient from c is re-
e
important the tweet is. For our experiments we
versed and scaled by a value λ. In our work, we
compare the adversarially trained model against
intend to achieve domain adaptation from previ-
a binary classifier and a multi-task model. The
ouseventstoanewincomingeventbyminimizing
comparison between the multitask and the adver-
the information related to previously seen events
sarialmodelshelpsusevaluatewhethertheexplicit
providedbyc ,whilemaximizingtheinformation
e
removalofbias-relatedinformationbenefitstherel-
gainobtainedfromclassifierc ,asdescribedineq.
r
evance classifier or if using a model that jointly
3.
learnsbothtaskssuffices.
3.3.1 BaselineModel
argminL(c (h(t )),y )+L(c (g (h(t ))),y )
In our baseline model setup, a tweet t is a se- r i ri e λ i ei
i h,cr,ce
quenceofwordembeddingsw ,...,w whichare (3)
1 mi
4 Experiments data consists of all the events of the same disas-
ter type except one, as it is used for testing the
Forourexperimentsweusedtwoofthemainpop-
model. Wegeneratednsplitsforeacheventtype,
ular word embeddings to represent the tokens of
wherenistheamountofeventspereventtype. We
thetweetsinthetargetdataset: GloVe(Pennington
evaluatedthethreemodelsoneachsplitobtaining
etal.,2014)embeddings,andBERT(Devlinetal.,
the macro-F1 and the micro-F1 scores from the
2019)embeddings.
c predictions. Finally,wecalculatedthemeanof
r
We used the 100-dimensional GloVe embed- these metrics, which we can see in Table 2. The
dings pre-trained on Wikipedia and Gigaword, bestmodelsforeacheventtypearehighlightedin
which were made publicly available by the therepresentativecoloroftheevent, asshownin
authors3. For extracting BERT embeddings we Figure1.
usedthePythonpackagebert-embeddings4 aswe
Since we follow a leave-one-out testing proce-
builtthenetworksforourexperimentsinPyTorch.
dure,wecouldnotincludethewildfireseventtype
Thispackageoffersapre-trained768-dimensional
since this category only has two instances. This
hiddenstatetransformermodelwith12-layersand
makesitimpossibletotrainthemultitaskandad-
12-headedattention. Inourexperiments,theBERT
versarialmodelsonthistypeofevent.
modelwasfrozenwithnofine-tuningduringtrain-
Our experiments show an improvement of the
ing.
F1scoreforalldisastereventsthatuseadversarial
Throughoutallofourexperimentsthetweeten-
training except for the attacks group, where the
coderhisanLSTMwithtwolayers. Eachofthe
improvementisnotconsistentwiththerestofthe
LSTMs have a hidden dimension of 100, which
events. The earthquake and flood events show a
results in a tweet embedding of size 200. Both
significantlybetterperformanceoftheadversarial
classifiers c and c are linear layers with output
r e modelwhencomparedtoboththebaselineandthe
size2andthenumberofeventsperexperiment,re-
multitaskmodel. Forthetyphooneventsthemul-
spectively. Duringourinitialexperimentation,we
titask model improves slightly over the baseline,
setthegradient-reversallayerscalingvaluelambda
but the adversarial model is thebest for bothem-
todifferentvalueswithintherange[0.1−10]. The
beddingtypes,whileBERThasbetterresultsthan
most stable result throughout the whole experi-
GloVebyalargemargin.
mentswasobtainedwithλ = 1.
Mostsimilartooursetting,Nguyenetal.(2016)
The models were trained using the Adam op-
performsanexperimentinanonlinetrainingsce-
timizer (Kingma and Ba, 2014), with an initial
nariousingtheNepal2015Earthquakeastestset,
learning rate 0.01, batch size 16 and trained for
whilemorethan10,000tweetsfromthedatasetare
40 epochs. We employed dynamic batching by
usedforpre-trainingthemodel. Theirworkreports
padding each batch to the sequence length of the
anAUCof0.73atthebeginningoftheevent,which
longestsampleinthebatch.
wouldbecomparabletoourzero-shotlearningsce-
To test the performance of the model at every
nario. To compare our model to their work, we
epoch we calculated the micro F1 on the critical
usedthedatasplitwheretheNepalearthquakewas
classfromc andconsideredasthebestmodelthe
r leftoutfortestingthemodel. Onthisdatasplit,the
one which showed the highest Critical-F1 score,
adversarialmodelusingBERTembeddingsobtains
sincefordisastersitisimportanttorecallasmany
anAUCof0.62forthecriticalclasswhiletraining
criticaltweetswiththehighestpossibleprecision.
withonly815tweetsfromalltheotherearthquake
events.
4.1 ModelEvaluation
Sinceweintendtoevaluatethemodelsforareal- 4.2 EventTypesDataMix
lifescenario,weuseddatafromeachdisastertype
InFigure1,weobservethattheattackeventsgroup
separately(e.g. modeltrainedandtestedonlyon
consists of diverse types of events such as shoot-
floodevents),toperformananalysisinadisaster-
ings, bombings, andexplosions. Eventhoughall
basedzero-shotlearningscenariosimulatinganin-
ofthoseeventscontainviolence-relatedincidents,
comingunseenevent. Toachievethis,thetraining
theadversarialmodelwithBERTembeddingshas
3https://nlp.stanford.edu/projects/glove/ lowerperformancethanthebaselineandthemulti-
4https://github.com/imgarylai/bert-embedding task learning model, as shown in the results on
Table2: Eventbasedzero-shottestresults. Thebestmodelperdisastertypeishighlightedwiththecolorassigned
tothedisastertype. Thebestmodelperembeddingtypeishighlightedinbold.
Macro Non-Critical Critical
EventType Embedding Model
F1 F1 F1
Baseline 0.6432 0.9082 0.3782
GloVe Multitask 0.5890 0.8960 0.2819
Adversarial 0.6602 0.9170 0.4034
Earthquakes
Baseline 0.6138 0.9062 0.3213
BERT Multitask 0.5844 0.8863 0.2826
Adversarial 0.6154 0.8888 0.3420
Baseline 0.6010 0.8674 0.3346
GloVe Multitask 0.6130 0.8679 0.3581
Adversarial 0.6326 0.8454 0.4198
Floods
Baseline 0.6145 0.8834 0.3455
BERT Mulitask 0.6062 0.8793 0.3331
Adversarial 0.6403 0.8642 0.4164
Baseline 0.5714 0.8965 0.2462
GloVe Multitask 0.5832 0.8961 0.2702
Adversarial 0.5887 0.8916 0.2858
Typhoons
Baseline 0.6249 0.9189 0.3310
BERT Mulitask 0.6291 0.9091 0.3491
Adversarial 0.6302 0.9086 0.3517
Baseline 0.6049 0.9047 0.3052
GloVe Multitask 0.5994 0.8917 0.3071
Adversarial 0.6056 0.8975 0.3137
Attacks
Baseline 0.5744 0.8840 0.2649
BERT Multitask 0.6165 0.9009 0.3322
Adversarial 0.5492 0.8511 0.2472
Table3: Mixedfloodandtyphoontestresults citiesandtowns. Werepeatedthesameexperimen-
talprocedurebyleavingoutoneeventfortesting
Model MacroF1 Non-CriticalF1 CriticalF1
andobtainedthemeanscoresacrossallsplits,asre-
Baseline-GloVe 0.5376 0.7602 0.3150
portedinTable3. Theresultsfromthisexperiment
MultiTask-GloVe 0.5331 0.7529 0.3133
Adversarial-GloVe 0.5157 0.7428 0.2885 verifyourhypothesisthattheadversarialtraining
Baseline-BERT 0.5593 0.7602 0.3584 of the classifier is sensitive to the entanglement
MultiTask-BERT 0.5625 0.7558 0.3692
of events in the training data. This supports our
Adversarial-BERT 0.5539 0.7500 0.3578
claimonwhywehavelowperformanceonattacks
andhighlightstheimportanceofnotmixingdiffer-
enteventtypeswhentrainingunderanadversarial
Table 2. Our hypothesis is that the adversarial
setup.
modelfailstoremovetheevent-specificbiasesin
theAttackgroup,becauseofthemixtureofdiffer-
5 QualitativeAnalysis
enteventtypes. Apotentialsolutiontothisproblem
would be to include more events to facilitate the We took a deeper look into our experimental re-
disentanglementoftheAttacksgroup. sults by comparing which patterns are learnt by
To test this hypothesis, we created a synthetic the adversarial model but not the baseline. For
eventtypewherewemixfloodandtyphoonevents, thisanalysis,wefocusedonfloodandearthquake
sincebotharedisastersthatwouldresultinflooded eventtypes,astheyshowthegreatestdifferencein
Table4: Examplescapturedbytheadversarialmodel(true-positives),butnotthebaseline(false-negatives).
TrueLabel TweetText
rtfloodintheusthospitalisnowonthe2ndfloor
Critical
nofoodforthepatients&staffplshelp...
Critical rtpleasehelprtrtthosewhoareinuermthefloodisnowgoi...
usthospitalanduerminneedofimmediatehelpusts
Critical
morgueisfloodeduermsnurseryisnearbeingfloodedpleaseplease
Critical philippinefloodfatalitieshit23
metromanilafloodupdatesnlexisnownorthluzonexpressriver
Non-Critical
plsrtandspread
ndrrmcnearly50ofmetromanilasubmergedinfloodwater
Non-Critical
duetoheavymonsoonrains
rtletsallprayforthosewholosttheirhomesandnowlivingin
Non-Critical
coldandstarving...
rtpalpassengersto/frommanilawhoareunabletotake
Non-Critical
theirflightsduetofloodsmayrebooktheirticketswithrebookingc...
Table5: Testresultson2012PhilippinesFlood elstrainedonprevioussimilarscenariosperform
poorlyduetoeventbiasfoundinthedata. Through
Model MacroF1 Non-CriticalF1 CriticalF1
thoseexamplesweseethatourapproachsuccess-
Baseline-BERT 0.5844 0.8413 0.3274
fullyremovespartofthatbiasthroughadversarial
MultiTask-BERT 0.5875 0.8766 0.2985
Adversarial-BERT 0.6535 0.8832 0.4238 learning.
5.2 ModelComparisonviaSaliencyMaps
F1scorebetweenthebaselineandtheadversarial
For the second part of our analysis, we used
model.
saliency maps to visualize the relevance of each
wordinatweetforthemodels. Weselectedtweets
5.1 CriticalDetectionComparison
thatcontainnamedentities(e.g. locations,names)
For the first part of the qualitative analysis, we orinformationthatisgenerallyimportanttoclas-
examinedtweetswherethebaselineandtheadver- sify a tweet, such as casualties. For this part,
sarial models disagree upon. We looked at both we only used GloVe embeddings, since BERT is
criticalandnon-criticaltweetsinordertofindcom- context-based and each embedding may encode
monpatternswherethemodelsfail. InTable4we informationfromtherestofthetweet.
showsomeexamplesoftweetswherethebaseline Inordertoconstructthesaliencymap,weused
model failed, but were correctly classified by the back-propagationtoestimatethefirst-orderderiva-
adversarialmodel. Theexamplesusedcomefrom tivesfromeachword,asameasureoftheircontri-
thePhilippinesflood(performanceshowninTable butiontothemodel’sdecision. Thisstrategywas
5). adoptedfromthevisioncommunity(Erhanetal.,
A consistent pattern observed for the critical 2009;Simonyanetal.,2013),andrecentlyadapted
tweetsisthattheymostlycontaininformationabout inNLPresearch(Lietal.,2016).
a need for emergent help or a situation currently In Figure 4 we visualize the saliency map of
happening. Furthermore,weseeastrongsentiment eachwordembeddingforthebaselineandadver-
ofdespair,wherewemayassumethattheusersare sarial models. The higher the absolute value of
directlyaffectedbytheevent. Ontheotherhand, thefirst-orderderivative(darkblueandwhite),the
if we look at the non-critical tweets that were in- more important role it plays into the classifier’s
correctlyclassifiedascriticalbythebaseline,they decision. Weobservethat,forthefirstandsecond
mostlycontainlocationinformationandnameden- sentences, the baseline puts more weight on the
tities. Asmentionedearlier,inazero-shotscenario location, which is a strong event-bias since it in-
upon the development of a crisis event, the mod- cludesinformationonlyforaparticulareventand
Baseline Model Adversarial Model
0.015
ordering
0.02
mandatory 0.010
evacuations 0.005 0.01
in
0.000
0.00
the
0.005
southmoor
0.01
park 0.010
neighborhood 0.015 0.02
Baseline Model Adversarial Model
colorado 0.020
0.03
flooding 0.015
0.02
evacuations 0.010
0.01
broken 0.005
oil 0.000 0.00
pipeline 0.005 0.01
in 0.010 0.02
weld 0.015
0.03
county
0.020
0.04
Baseline Model Adversarial Model
president
updates 0.0008 0.006
death 0.0006
0.004
toll
0.0004
in
0.002
0.0002
after
52 0.0000 0.000
dead 0.0002
and 0.002
0.0004
22
0.0006 0.004
missing
Figure4: Saliencymapvisualizationoftweetswithstrongevent-bias.
notadisastertype(e.g. floods). Ontheotherhand, aresult,itdoesnotshowanyimprovementoverthe
theadversarialmodelfocusesmoreonimportant baseline. Moreover,insomecasesmodelstrained
sub-events,likemandatoryevacuationsandbroken withGloVeachievedbetterperformancecompared
pipeline,whichwedesiretocaptureinazero-shot to those trained with BERT. For this reason, it
scenario,andisgenerallyignoredbythebaseline seemsappropriatetofine-tunetransformer-based
model. Wefurtherobserveasimilartrendforthe language models so we could take advantage of
third sentence, where the baseline gives mostly thelargeamountofunlabeleddataprovidedbythe
uniform weight with a small focus on president CrisisNLPdatasetthatwasnotusedinthiswork.
updatesdeath,whiletheadversarialmodelfocuses
Given that our ultimate goal is to detect and
moreongenerallyinformativetextthatdescribes
useactionableinformationduringcrisiseventsto
casualties.
informlife-savingactions,anessentialpartoffu-
tureresearchistodesigninterpretablemodels. An
6 FutureWork
interestingworkproposesanewapproachtointer-
Ourexperimentsshowthatmixingdatafromevents pretableclassificationnameddeepweightedaver-
whosesemanticsaresimilar,liketheviolentmass agingclassifiers(DWAC)(Cardetal.,2019),which
attacksandthesyntheticallygeneratedsetoffloods givesanexplanationofthepredictionintermsof
andtyphoons,confusestheadversarialmodel. As the weighted sum of training instances. DWAC
could replace the importance classifier c in our clusionscontainedhereinarethoseoftheauthors
r
proposedadversarialmodel. Anadvantageofus- andshouldnotbeinterpretedasnecessarilyrepre-
ingDWACisthatitwoulddeliverthemostrelevant sentingtheofficialpoliciesorendorsements,either
tweetsfromthetrainingdatawhichcontributedto expressed or implied, of NIST, DOI/IBC, or the
thedetectionofacriticaltweet. U.S.Government.
Finally,sincewedealwithareal-timeinforma-
tion stream it seems appropriate to evaluate this
References
modelinanonlinelearningscenario(Nguyenetal.,
2016).
Yonatan Belinkov, Adam Poliak, Stuart M Shieber,
BenjaminVanDurme,andAlexanderMRush.2019.
7 Conclusion On adversarial removal of hypothesis-only bias in
natural language inference. In Proceedings of the
Inthiswork,wecomparedanadversarialytrained Eighth Joint Conference on Lexical and Computa-
modelagainstabaselineclassifierandamultitask tionalSemantics(*SEM2019),pages256–262.
learningmodel. Themaintaskforallthemodels
DanielBorkan,LucasDixon,JeffreySorensen,Nithum
wastopredictifatweetiscriticalornon-critical
Thain,andLucyVasserman.2019. Nuancedmetrics
over four types of disaster events: earthquakes,
formeasuringunintendedbiaswithrealdatafortext
floods,typhoons,andmassattacksinpublicspaces. classification. In Companion Proceedings of The
We presented a thorough analysis on how a sim- 2019 World Wide Web Conference, pages 491–500.
ACM.
pleclassificationmodeltrainedoncrisiseventdata
canbeimprovedthroughadversarialtraining. Our
Cornelia Caragea, Adrian Silvescu, and Andrea H
results showed how the addition of an adversar- Tapia. 2016. Identifying informative messages in
ialnetworkremovesthebiasfromspecificevents, disastereventsusingconvolutionalneuralnetworks.
allowingthenetworktoputmoreattentionindis-
InInternationalConferenceonInformationSystems
for Crisis Response and Management, pages 137–
asterrelatedinformationratherthanspecificitiesof
147.
aparticularevent. Inmostofourexperimentsthe
adversariallytrainedmodelobtainedthehighestF1 DallasCard,MichaelZhang,andNoahA.Smith.2019.
score. Deepweightedaveragingclassifiers. InProceedings
ofACMFAT*.
Our experimental results demonstrate the rel-
evance of using micro-F1 scores for evaluating
Rich Caruana. 1997. Multitask learning. Machine
thedetectionofcriticalpostsfromaninformation learning,28(1):41–75.
streamsuchasTwitter. Theimpactoffalsenega-
tiveswhiledetectingcriticaltweetsislargerthan Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. Bert: Pre-training of
thefalsepositives,sincewewouldbemissingde-
deep bidirectional transformers for language under-
cisive information from the data stream. Hence,
standing. InProceedingsofthe2019Conferenceof
micro-F1 score is a more informative metric to the North American Chapter of the Association for
consider instead of accuracy, or even the overall ComputationalLinguistics: HumanLanguageTech-
nologies, Volume1(LongandShortPapers), pages
F1 score since event crisis detection usually suf-
4171–4186.
fersfromhighlyskeweddatatowardstheirrelevant
samplesofthedataset. Yanai Elazar and Yoav Goldberg. 2018. Adversarial
removalofdemographicattributesfromtextdata. In
Acknowledgments Proceedings of the 2018 Conference on Empirical
MethodsinNaturalLanguageProcessing,pages11–
ThisresearchwaspartiallysupportedbyDARPA 21.
grant no HR001117S0017-World-Mod-FP-036
DumitruErhan, YoshuaBengio, AaronCourville, and
funded under the World Modelers program,
Pascal Vincent. 2009. Visualizing higher-layer fea-
as well as by the financial assistance award
turesofadeepnetwork.
60NANB17D156fromU.S.DepartmentofCom-
merce,NationalInstituteofStandardsandTechnol- Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan,
ogy (NIST). The U.S. Government is authorized Pascal Germain, Hugo Larochelle, Franc¸ois Lavi-
olette, Mario Marchand, and Victor Lempitsky.
to reproduce and distribute reprints for Govern-
2016. Domain-adversarial training of neural net-
mentalpurposesnotwithstandinganycopyrightan-
works. TheJournalofMachineLearningResearch,
notation/herein. Disclaimer: The views and con- 17(1):2096–2030.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, TaroMiyazaki,KiminobuMakino,YukaTakei,Hiroki
BingXu,DavidWarde-Farley,SherjilOzair,Aaron Okamoto,andJunGoto.2019. Labelembeddingus-
Courville,andYoshuaBengio.2014. Generativead- inghierarchicalstructureoflabelsfortwitterclassi-
versarial nets. In Advances in neural information fication. InProceedingsofthe2019Conferenceon
processingsystems,pages2672–2680. EmpiricalMethodsinNaturalLanguageProcessing
andthe9thInternationalJointConferenceonNatu-
Alex Graves, Navdeep Jaitly, and Abdel-rahman Mo- ralLanguageProcessing(EMNLP-IJCNLP),pages
hamed.2013. Hybridspeechrecognitionwithdeep 6318–6323.
bidirectionallstm. In2013IEEEworkshoponauto-
matic speech recognition and understanding, pages Robert Munro. 2011. Subword and spatiotemporal
273–278.IEEE. models for identifying actionable information in
haitian kreyol. In Proceedings of the fifteenth con-
Starr Roxanne Hiltz, Jane A Kushma, and Linda Plot- ferenceoncomputationalnaturallanguagelearning,
nick.2014. Useofsocialmediabyuspublicsector pages 68–77. Association for Computational Lin-
emergencymanagers: Barriersandwishlists. InIS- guistics.
CRAM.
Graham Neubig, Yuichiroh Matsubayashi, Masato
MuhammadImran,PrasenjitMitra,andCarlosCastillo. Hagiwara, and Koji Murakami. 2011. Safety infor-
2016. Twitterasalifeline:Human-annotatedtwitter mationmining—whatcannlpdoinadisaster—. In
corpora for nlp of crisis-related messages. In Pro- Proceedings of 5th International Joint Conference
ceedings of the Tenth International Conference on onNaturalLanguageProcessing,pages965–973.
Language Resources and Evaluation (LREC 2016),
Paris, France. European Language Resources Asso- DatTienNguyen,ShafiqJoty,MuhammadImran,Has-
ciation(ELRA). san Sajjad, and Prasenjit Mitra. 2016. Applica-
tions of online deep learning for crisis response
Diederik P Kingma and Jimmy Ba. 2014. Adam: A using social media information. arXiv preprint
method for stochastic optimization. arXiv preprint arXiv:1610.01030.
arXiv:1412.6980.
Leysia Palen, Kenneth M Anderson, Gloria Mark,
Anna Kruspe. 2019. Few-shot tweet detection James Martin, Douglas Sicker, Martha Palmer, and
in emerging disaster events. arXiv preprint Dirk Grunwald. 2010. A vision for technology-
arXiv:1910.02290. mediated support for public participation & assis-
tance in mass emergencies & disasters. ACM-BCS
JiweiLi,XinleiChen,EduardHovy,andDanJurafsky.
VisionsofComputerScience2010,pages1–12.
2016. Visualizingandunderstandingneuralmodels
in nlp. In Proceedings of NAACL-HLT, pages 681– ZhongyiPei,ZhangjieCao,MingshengLong,andJian-
691. min Wang. 2018. Multi-adversarial domain adapta-
tion. In Thirty-Second AAAI Conference on Artifi-
PengfeiLiu,XipengQiu,andXuan-JingHuang.2017. cialIntelligence.
Adversarial multi-task learning for text classifica-
tion. InProceedingsofthe55thAnnualMeetingof JeffreyPennington,RichardSocher,andChristopherD.
the Association for Computational Linguistics (Vol- Manning.2014. Glove:Globalvectorsforwordrep-
ume1: LongPapers),pages1–10. resentation. In Empirical Methods in Natural Lan-
guageProcessing(EMNLP),pages1532–1543.
KaijiLu,PiotrMardziel,FangjingWu,PreetamAman-
charla, and Anupam Datta. 2018. Gender bias in Linda Plotnick, Starr Roxanne Hiltz, Jane A Kushma,
neural natural language processing. arXiv preprint andAndreaHTapia.2015. Redtape: Attitudesand
arXiv:1807.11714. issues related to use of social media by us county-
levelemergencymanagers. InISCRAM.
GuoqinMa. Tweetsclassificationwithbertinthefield
ofdisastermanagement. Samira Pouyanfar, Yudong Tao, Saad Sadiq, Haiman
Tian, Yuexuan Tu, Tianyi Wang, Shu-Ching Chen,
David Madras, Elliot Creager, Toniann Pitassi, and and Mei-Ling Shyu. 2019. Unconstrained flood
Richard Zemel. 2018. Learning adversarially fair eventdetectionusingadversarialdataaugmentation.
and transferable representations. In International In 2019 IEEE International Conference on Image
Conference on Machine Learning, pages 3384– Processing(ICIP),pages155–159.IEEE.
3393.
Junaid Qadir, Anwaar Ali, Raihan ur Rasool, Andrej
Carleen Maitland, L Ngamassi, and Andrea Tapia. Zwitter, Arjuna Sathiaseelan, and Jon Crowcroft.
2009. Information management and technology is- 2016. Crisis analytics: big data-driven crisis re-
sues addressed by humanitarian relief coordination sponse. Journal of International Humanitarian Ac-
bodies. In Proceedings of the 6th International IS- tion,1(1):1–21.
CRAMConference.Gothenburg,Sweden.
Christian Reuter, Gerhard Backfried, Marc-Andre´
Richard Mccreadie, Cody Buntain, and Ian Soboroff. Kaufhold,andFabianSpahr.2018. Iscramturns15:
2019. Trecincidentstreams: Findingactionablein- A trend analysis of social media papers 2004-2017.
formationonsocialmedia. ProceedingsofISCRAM.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes twitter users: real-time
event detection by social sensors. In Proceedings
of the 19th international conference on World wide
web,pages851–860.
KarenSimonyan,AndreaVedaldi,andAndrewZisser-
man.2013. Deepinsideconvolutionalnetworks: Vi-
sualising image classification models and saliency
maps. arXivpreprintarXiv:1312.6034.
JeannetteNSutton, LeysiaPalen, andIrinaShklovski.
2008. Backchannels on the front lines: Emergency
usesofsocialmediainthe2007southerncalifornia
wildfires.
Andrea Tapia, Louis-Marie Ngamassi Tchouakeu,
Edgar Maldonado, Kang Zhao, Harold Robinson,
andCarleenMaitland.2011a. Exploringbarriersto
coordinationbetweenhumanitarianngos:Acompar-
ativecasestudyoftwongo’sinformationtechnology
coordinationbodies. InternationalJournalofInfor-
mationSystemsandSocialChange,2(2):1–25.
Andrea H Tapia, Kartikeya Bajpai, Bernard J Jansen,
John Yen, and Lee Giles. 2011b. Seeking the trust-
worthy tweet: Can microblogged data fit the infor-
mation needs of disaster response and humanitar-
ian relief organizations. In Proceedings of the 8th
International ISCRAM Conference, pages 1–10. IS-
CRAMLisbon,Portugal.
Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy, and
Graham Neubig. 2017. Controllable invariance
throughadversarialfeaturelearning. InAdvancesin
NeuralInformationProcessingSystems,pages585–
596.
Brian Hu Zhang, Blake Lemoine, and Margaret
Mitchell. 2018. Mitigating unwanted biases with
adversarial learning. In Proceedings of the 2018
AAAI/ACM Conference on AI, Ethics, and Society,
pages335–340.ACM.
