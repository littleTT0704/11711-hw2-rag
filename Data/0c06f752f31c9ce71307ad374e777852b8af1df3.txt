LangResources&Evaluation(2021)55:661–688
https://doi.org/10.1007/s10579-020-09517-1
ORIGINAL PAPER
AI2D-RST: a multimodal corpus of 1000 primary
school science diagrams
Tuomo Hiippala1 • Malihe Alikhani2 •
Jonas Haverinen1 • Timo Kalliokoski1 •
Evanfiya Logacheva1 • Serafina Orekhova1 •
Aino Tuomainen1 • Matthew Stone3 •
John A. Bateman4
Accepted:28October2020/Publishedonline:5December2020
(cid:2)TheAuthor(s)2020
Abstract ThisarticleintroducesAI2D-RST,amultimodalcorpusof1000English-
language diagrams thatrepresent topics inprimary school natural sciences,such as
foodwebs,lifecycles,moonphasesandhumanphysiology.Thecorpusisbasedon
the Allen Institute for Artificial Intelligence Diagrams (AI2D) dataset, a collection
of diagrams with crowdsourced descriptions, which was originally developed to
support research on automatic diagram understanding and visual question answer-
ing. Building on the segmentation of diagram layouts in AI2D, the AI2D-RST
corpuspresentsanewmulti-layerannotationschemathatprovidesarichdescription
of their multimodal structure. Annotated by trained experts, the layers describe (1)
the grouping of diagram elements into perceptual units, (2) the connections set up
by diagrammatic elements such as arrows and lines, and (3) the discourse relations
between diagram elements, which are described using Rhetorical Structure Theory
(RST).EachannotationlayerinAI2D-RSTisrepresentedusingagraph.Thecorpus
is freely available for research and teaching.
& TuomoHiippala
tuomo.hiippala@helsinki.fi
MaliheAlikhani
malihe@pitt.edu
MatthewStone
mdstone@cs.rutgers.edu
JohnA.Bateman
bateman@uni-bremen.de
1 DepartmentofLanguages,UniversityofHelsinki,P.O.Box24,00014Helsinki,Finland
2 SchoolofComputingandInformation,UniversityofPittsburgh,Pittsburgh,USA
3 DepartmentofComputerScience,RutgersUniversity,NewBrunswick,USA
4 Faculty10:LinguisticsandLiteraryStudies,BremenUniversity,Bremen,Germany
123
662 T.Hiippalaetal.
Keywords Diagrams (cid:2) Multimodality (cid:2) Rhetorical Structure Theory (cid:2)
Graphs
1 Introduction
Diagrams are a common feature of many everyday media: they can be found
everywherefromscientific publicationsandinstruction manualstonewspapersand
school textbooks. Barbara Tversky, a cognitive psychologist who has made
pioneering contributions to the study of diagrams, observes that their generic
purpose is ‘‘to structure information to enable comprehension, inference and
discovery’’ (Tversky 2017, p. 350). Due to their widespread use, diagrams have
beenstudiedfromvariousperspectives.Previousresearchhasexaminedtheirvisual
perception(HegartyandJust1993;Ware2012),structureandfunctions(Engelhardt
2002; Purchase 2014; Engelhardt and Richards 2018) and their role as a tool for
supporting thinking and reasoning (Tversky 2015) and use in education and
instruction (Tippett 2016), to name but a few examples.
In this article, we make a novel contribution to the study of diagrams by
presenting AI2D-RST, a corpus of 1000 English-language diagrams that represent
topics in primary school natural sciences. The diagrams are described using a new
multi-layerannotationschemathatseekstocapturetheirmultimodalstructure.Our
approach to multimodality is linguistically-inspired and semiotically-oriented, that
is, we seek to systematically describe how expressive resources such as natural
language,illustrations,lineart,photographs,lines,arrowsandlayoutarecombined
in diagrams to make and exchange meanings. To do so, we build on the general
framework for multimodal communication proposed in Bateman et al. (2017) and
its application to diagrams as set out in Hiippala and Bateman (2020).
The current work is situated within the emerging field of multimodality research,
which studies how appropriate combinations of expressive resources emerge in
communicative situations (see e.g. Wildfeuer et al. 2020). Despite their growing
influenceinvariousfieldsofstudybroadlyconcernedwithhumancommunication,many
approaches to multimodality remain without adequate empirical support. Although
buildingmultimodalcorporaisoftenpresentedasasolutiontothisshortcomingduetothe
success of corpus-based methods in linguistics, developing and applying complex
multimodalannotationframeworksrequiresampletimeandresources,andconsequently
theresultingcorporaremainsmall(Waller2017;Huang2020).
AI2D-RSTseekstoreducetheneedfortimeandresourcesandtoscaleupthevolume
of data by building multimodally-informed expert annotations on top of pre-existing
crowdsourcedannotationsfromtheAllenInstituteforArtificialIntelligenceDiagrams
(AI2D) dataset (Kembhavi et al. 2016). The second part of the name, RST, refers to
RhetoricalStructureTheory,atheoryofdiscoursestructurewhichweusetodescribehow
diagrams combine multiple expressive resources to fulfil their communicative goals
(MannandThompson1988;TaboadaandMann2006;HiippalaandOrekhova2018).
Overall,theAI2D-RSTcorpusisintendedtoserveadualpurpose:tosupportempirical
researchonthemultimodalityofdiagramsandtheircomputationalprocessing.
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 663
2 Developing multimodal resources for diagrams research
There is a long-standing interest in the computational processing and generationof
diagrammatic representations (Andre´ and Rist 1995; Watanabe and Nagao 1998;
Bateman et al. 2001; Carberry et al. 2003; Bateman and Henschel 2007), which is
now resurfacing as recent advances in computer vision and natural language
processing are brought to bear on diagrammatic representations (Seo et al. 2015;
Sachan et al. 2018, 2019; Choi et al. 2018; Kim et al. 2019; Haehn et al. 2019).
Much of this work is driven by research on well-defined tasks such as information
retrieval and question answering, whose scope is increasingly extended beyond
natural language to cover other modes of expression as well.
Just how these other modes of expression and their combinations should be
described in order to create multimodal resources that can support further research
onmultimodalityremainsanopenquestion.Thisrequiresanempiricalapproach,as
creating multimodal resources for modes of expression beyond natural language
raisesquestionsaboutfundamentalissuessuchassegmentation:howtodecompose
modesofexpressionsuchasdiagramsintotheirconstituentparts?Wehaverecently
arguedinHiippalaandBateman(2020)thatanyattemptatasystematicdescription
of diagrams must acknowledge the specific characteristics of the diagrammatic
mode—an abstract system capable of instantiating various types of diagrams
appropriate for their context of occurrence (cf. e.g. Bateman and Henschel 2007).
Previousresearchpointsattwokeycharacteristicsofthediagrammaticmodethat
need to be accounted for: the use of layout space (Watanabe and Nagao 1998) and
theirmultimodaldiscoursestructure(Carberryet al.2003),whichareoftenstrongly
intertwined in multimodal artefacts with a 2D spatial extent, such as entire page-
based documents (Hiippala 2013). Firstly, diagrams have a spatial organisation in
the form of a layout, which can be used to set up discourse relations between
instances of expressive resources, including natural language, arrows, lines,
illustrations, photographs, line drawings and potentially any resource that may be
realised in 2D space (Watanabe and Nagao 1998). How these expressive resources
areorganisedinthelayoutspacecanalsoserveasastrongsignalaboutthepurpose
and structure of the diagram by generating expectations towards its discourse
structure (Holsanova et al. 2009).
This brings us to the second point: diagrams combine expressive resources into
discoursestructures,whichmustberesolvedtomakesenseofwhatthediagramin
questionattemptstocommunicate.Forthisreason,Carberryet al.(2003)arguethat
understandingdiagramsshouldbeframedadiscourse-levelproblem,aviewthathas
foundsupportinourrecentworkonthediagrammaticmode(HiippalaandBateman
2020).This,however,raisesanotherissuerelatedtosegmentation:manytheoriesof
discourse assume that discourse segments are identified before determining their
interrelations (Grosz and Sidner 1986; Mann and Thompson 1988).
Establishing an inventory of discourse segments for diagrams is a particularly
challenging task, as the level of detail needed for segmentation varies from one
diagram to another, depending on the combination of expressive resources present
andthediscoursestructurestheyparticipatein.Toexemplify,a2Dcross-sectionof
123
664 T.Hiippalaetal.
1. Original image
Diagram elements are Graph edges encode information about
mapped to nodes in the relationships between nodes, such as
inter-object linkage between B2 & A10.
2. Layout segmentation 3. Diagram Parse Graph (DPG)
Fig.1 (1)Athumbnailoftheoriginaldiagramimagescrapedfromtheweb,(2)itscrowdsourcedlayout
segmentation(convertedintogreyscaletobringouttheannotation)and(3)aDiagramParseGraph(DPG)
for diagram #274 in AI2D. Diagram element types are coded using same colours in both layout
segmentationandDPG:textblocks(blue),blobs(red),arrows(green),arrowheads(orange)andimage
constant(Navajowhite)
anobject,whosestructureispickedoutanddescribedusingtextual labels,mustbe
decomposedintoanalyticalunitstoprovideasufficientlyaccuratedescriptionofits
multimodalstructure,whereasanillustrationofanentireobjectdoesnotneedtobe
decomposed to the same extent (for a detailed discussion of challenges related to
diagram segmentation, see Hiippala and Bateman 2020).
Keepingtheroleoflayoutanddiscoursestructureinmind,thefollowingsections
explicate how we built a new, multimodally-informed annotation schema with
multiple layers of description on top of existing crowdsourced annotations for
expressive resources and their placement in the diagram layout. To do so, we start
byintroducingtheAI2Ddataset,whichprovidedthecrowdsourcedannotations.We
thenaddresscertainissueswiththeAI2Dannotationschemabeforemotivatingour
decisiontoadoptRhetoricalStructureTheoryfordescribingthediscoursestructure
of diagrams in AI2D-RST.
3 TheAllenInstituteforArtificialIntelligenceDiagrams(AI2D)dataset
The AI2D dataset (Kembhavi et al. 2016)1 was developed to support research on
computational tasks such as automatic diagram understanding and visual question
answering (see e.g. Kim et al. 2018). The dataset contains 4903 English-language
diagramsthatrepresenttopicsinprimaryschoolnaturalsciences,suchaslifecycles,
food webs and circuits. Each diagram is assigned to one of 17 semantic categories
that correspond to topics in this domain.
1 The AI2D dataset is publicly available from the Allen Institute for Artificial Intelligence at https://
allenai.org/plato/diagram-understanding/(AccessedSeptember3,2020).
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 665
Fig. 2 Layout segmentation (left) and Diagram Parse Graph (DPG, right) for diagram #2728. The
numerous disconnections in the DPG result from the lack of relation definitions for describing how
groups of diagram elements, such as those formed by illustrations of moon phases and their verbal
descriptions(e.g.illustrationB3andthetext‘waninggibbous’inT13),relatetoeachotherasapartofthe
globaldiscoursestructureofthediagram
Building on Engelhardt’s (2002) framework for describing diagrammatic
representations, Kembhavi et al. (2016, p. 239) model four types of diagram
elements:‘blobs’(e.g.illustrations,lineart,photographsandothervisualexpressive
resources),writtentext,arrowsandarrowheads.Inaddition,Kembhaviet al.(2016)
define ten potential relationships that can hold between individual diagram
elements, which are also drawn from the framework proposed by Engelhardt
(2002). These include, among others, relations such as INTRA-OBJECT LABEL, INTRA-
OBJECTLINKAGEandARROWDESCRIPTOR,whichseektocapturehowdiagramelements
relate to each other (for a full list of relations, see Kembhavi et al. 2016, p. 239)
AI2D represents diagram structure using a Diagram Parse Graph (DPG), in which
the nodes stand for diagram elements whereas the edges encode information about
therelationsthatholdbetweenthem.Forcomputationaltasks,thenodefeaturescan
be populated using word embeddings or visual features extracted using object
detectors, depending on the diagram element type in question.
Figure1showsthecrowdsourcedlayoutsegmentationandDPGfordiagram274
in the AI2D dataset. The diagrams were scraped from Google Image Search by
using chapter titles in primary school science textbooks (for ages 6–11) as search
terms. The annotations were crowdsourced using Amazon Mechanical Turk by
breaking down the process of segmenting the layout and constructing a DPG into
piecemeal annotation tasks. These tasks involved identifying diagram elements,
categorising them and defining their interrelations (Kembhavi et al. 2016, p. 243).
Kembhavi et al. (2016, p. 242) report that the 4903 diagrams in AI2D contain
approximately 118,000 diagram elements and 53,000 relationships.
PreviousresearchusingtheAI2Ddatasethasshownthatinferringthemeaningof
arrowsandlinesiscontext-dependent,andtheviewersconsistentlymapthearrows
to real-world processes (Alikhani and Stone 2018). Hiippala and Orekhova (2018),
inturn,considertheAI2Dannotationschemafromtheperspectiveofmultimodality
research and argue that DPGs conflate the description of various multimodal
123
666 T.Hiippalaetal.
structures, such as the visual grouping of diagram elements and connections
expressed using arrows and lines. Pulling these structures apart could help
understandhowdiagramsoperatemultimodally,e.g.whetherdiscourserelationsare
typically signalled explicitly using arrows and lines or implicitly using the layout
space (Watanabe and Nagao 1998; Carberry et al. 2003).
Moreover, the relation definitions drawn from Engelhardt (2002) cover mainly
localrelationsbetweendiagramelements,asexemplifiedbyrelationssuchasINTRA-
OBJECTLABEL,whichisusedtodescribeinstancesinwhichonediagramelementacts
asalabelforanother.Thefocusonsuchlocalrelationsbetweenindividualdiagram
elements causes the AI2D annotation schema to fall short in describing the global
organisationofadiagram,orhowlargerunitsformedbymultiplediagramelements
relate to each other (see Fig. 2).
To summarise, the motivation for developing AI2D-RST can be traced back to
two observations. First, the limited scope of relation definitions drawn from
Engelhardt(2002)inAI2DledustoconsiderRhetoricalStructureTheory(RST)as
an alternative for describing discourse relations in diagrams, given its previous
successfulapplicationstomultimodal discourse(see e.g.Taboada andHabel 2013;
Thomas 2014; Hiippala 2015). However, during the exploratory work reported in
Hiippala and Orekhova (2018), it became evident that a direct conversion to RST
was not feasible, but required introducing additional annotation layers to establish
the units of analysis, as proposed in Bateman (2008).
Second, combining a theory of discourse structure with local and global reach,
such as RST, with a multi-layer annotation schema that captures the combinations
ofexpressiveresourcesandtheirspatialorganisationcouldbeusedtostudywhether
diagramssignaldiscourserelationsexplicitlye.g.usingarrowsandlines,orwhether
they are implicit and require the viewers to draw on world knowledge (see also
Hiippala and Bateman 2020). Furthermore, access to crowdsourced layout
segmentations allows scaling up corpus size. With these two observations in mind,
wenowturntodescribetheAI2D-RSTannotationschemaanditsapplicationtothe
AI2D diagrams.
4 Developing the AI2D-RST corpus
4.1 The AI2D-RST annotation schema
The AI2D-RST annotation schema describes the multimodal structure of diagrams
using four annotation layers. These layers, named grouping, macro-grouping,
connectivity and discourse structure, are introduced in the following sections. The
annotation layers are represented using graphs, which are populated using diagram
elementsfromtheAI2Dlayoutsegmentation(seeFig.1).Theuniqueidentifiersfor
diagram elements are also carried over from the AI2D layout segmentation to the
AI2D-RSTgraphs,inordertoenablecross-referencesacrossannotationlayers.This
kind of stand-off approach to annotation separates the description of different
multimodal structures, but allows combining them as necessary using the unique
identifiers, which are shared across annotation layers.
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 667
1. Original image
Diagram elements that are likely to be perceived
as belonging together are placed under the same
parent node in the grouping graph.
2. AI2D layout segmentation 3. AI2D-RST grouping graph
Fig.3 (1)Athumbnailoftheoriginaldiagramimagescrapedfromtheweb,(2)itscrowdsourcedlayout
segmentation(convertedintogreyscaletobringouttheannotation)and(3)theAI2D-RSTgroupinggraph
for diagram #274. The grouping graph organises diagram elements that are likely to be perceived as
belongingtogetherintogroups.Thesegroupsareaddedtothegroupinggraphasparentnodesforthe
diagramelementsthatbelongtogether.Foranexample,seetheillustrationofawolf(B2)andthetext
‘Graywolf’(T3)inthelayoutsegmentationandtheircorrespondingnodesintheAI2D-RSTgrouping
graph).BothB2andT3arechildrenofthegroupingnodeG7,whichcanbeusedtorefertobothdiagram
elementsintheannotationlayersforconnectivityanddiscoursestructure
4.1.1 Grouping
The grouping layer describes which diagram elements form visual groups, that is,
which elements are likely to be perceived as belonging together. The principles
behind the grouping layer correspond loosely to Gestalt principles of perception,
which often guide the design of diagrams and other visualisations (Ware 2012, p.
179). To exemplify, the principle of proximity states that elements close to each
otherareconsideredtobelongtogether.AbriefintroductiontoGestaltprinciplesof
pattern perception and how they influence the process of interpretation is provided
in Bateman (2008, pp. 58–61).
In AI2D-RST, the grouping annotation is represented using an undirected,
acyclictreegraph,suchastheoneshownontheright-handsideinFig.3.InFig.3,
the root node of the graph is the image constant I0, which stands for the entire
diagram.IncontrasttoAI2D,theAI2D-RSTgroupinglayerincludesnodesforonly
three types of diagram elements, namely blobs, text and arrows, but introduces
another node type: groups. Diagram elements that form a visual unit in the layout
areplacedunderthesameparentnodeinthegroupinggraph.Thesenodeshavethe
prefix G in their identifier, which stands for a group.
Conversely, besides grouping elements together, the grouping graph also
represents which elements are considered independent, or in other words, do not
belong to any visual groups. In Fig. 3, such independent units include the arrows
A0–15thatsetupthenetworkofconnectionsbetweenthegroupsofillustrationsand
123
668 T.Hiippalaetal.
table 2D cross-section
(49, 4.3%) (196, 17.3%)
horizontal cut-out
(82, 7.2%) (105, 9.3%)
3D
vertical
exploded
(39, 3.4%)
(2, 0.1%)
depiction
photograph
network
(19, 1.7%)
(140, 12.3%)
pictorial
illustration
cycle
(293, 25.8%)
(187, 16.5%)
diagrammatic
(22, 1.9%)
Fig.4 Atypologyofmacro-groups.Thenumbersin parenthesesgivetherawcountforeachmacro-
groupandtheirproportionoftheAI2D-RSTcorpus(N¼1134)
their labels G2–13. These connections are described in the connectivity layer in
order to avoid making arbitrary decisions about whether arrows should be grouped
with their sources or targets (see Sect. 4.1.3).
To summarise, the grouping graph provides a foundation for the subsequent
annotation layers, namely macro-grouping, connectivity and discourse structure by
providing the necessary units of analysis. In practice, the grouping graph allows
diagram elements that form visual groups to be picked up for description in other
annotation layers by referring to the identifiers of their grouping nodes.
4.1.2 Macro-grouping
Macro-groupingcapturesthegenericprinciplesthatgoverndiagramstructureabove
the level of visual groups identified in the grouping layer, in order to describe why
suchvisualgroupingsofexpressiveresourcesexistinthefirstplace.Todrawonan
example,thegroupinggraphshowninFig.3consistsofthegroupsG2–G13,which
combineanillustrationandawrittenlabel,andthearrowsA0–15.Bothgroupsand
arrows form a single visual group, G14, which may be appropriately characterised
as a network. We term such constellations of visual groups macro-groups, because
they combine multiple visual groups and diagram elements into larger structures.
Due to its close relation to the grouping layer, macro-grouping annotation is
incorporated into the grouping graph. If the diagram consists of a single macro-
group, macro-grouping information is assigned to the root node of the grouping
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 669
graph (the image constant I0), but if the diagram features multiple macro-groups,
thisinformationmaybeassignedtogroupingnodesaswell.Figure3exemplifiesa
diagram with multiple macro-groups. The food web under grouping node G14 is
assigned the macro-group network, whereas the categories on the left under the
grouping node G1 forma vertical organisation,whosefunctionis to provide labels
for visual groups that constitute the network.
Figure4showsatypologyofmacro-groupsdevelopedonthebasisofourinitial
analysis of diagram types in the AI2D-RST corpus. As such, the scope of the
typology is not intended to cover the space of possibilities within the entire
diagrammatic mode, but is limited to the domain represented by the diagrams in
AI2D-RST. In addition to describing the larger organisations of visual groups,
macro-groups are intended to provide a set of structural categories that correspond
todifferentdiagramtypes,incontrasttothesemanticcategoriesinAI2D,whichare
based on the subject matter of the diagram. In this way, the macro-groups can also
be used as target labels for training classifiers.
4.1.3 Connectivity
The connectivity layer describes connections between diagram elements and their
groups, which are signalled visually using arrows, lines and other diagrammatic
elements capable of expressing connectivity (Tversky et al. 2000). In AI2D-RST,
the connectivity annotation covers visually explicit connections between diagram
elementsonly,thatis,thearrowsandlinesmusthaveaclearsourceandatarget,in
order to allow the connections to be represented using graphs (cf. Alikhani and
Stone 2018, p. 3554). The AI2D-RST annotation schema defines three types of
connections based on directionality: undirected, directed and bidirectional.
The connectivity annotation is represented using a cyclic mixed graph, which
means that the graph may feature both undirected and directed edges. Figure 5
exemplifiesaconnectivitygraph,whosevisualizationhasbeenenhancedwithedges
from the grouping graph (for the original grouping graph, see Fig. 3), because the
connections in Fig. 5 are likely to be perceived to hold between visual groups of
elements,ratherthanindividualelements,suchaslabelsorillustrations.Annotating
connectivity according to visually explicit connections between individual
elements, which originate and terminate in both labels and illustrations, as
exemplifiedbythedirectedconnectionbetweenthetextblockT3(‘Graywolf’)and
the illustration of a hare in B9, results in an incomplete representation of
connectivity.Thisshowswhyvisualgroupsareneededasbasicunitsofanalysisfor
a graph-based representation of connectivity, which also illustrates how the
grouping layer supports otherannotationlayers by providingthe necessary unitsof
analysis.
4.1.4 Discourse structure
Whereas the grouping and connectivity layers seek to capture diagrammatic
structures that are explicitly available for visual inspection, the discourse structure
123
670 T.Hiippalaetal.
Connections are drawn Edges with solid lines
between visual groups represent visual con-
that consist of an nections in the diagram.
illustration and a label.
2. AI2D layout segmentation 3. AI2D-RST connectivity graph
Fig.5 (1)Athumbnailoftheoriginaldiagramimagescrapedfromtheweb,(2)itscrowdsourcedlayout
segmentation(convertedintogreyscaletobringouttheannotation)and(3)theAI2D-RSTconnectivity
graphfordiagram#274.Intheconnectivitygraph,theedgeswithsolidlinescorrespondtoarrowsinthe
layoutsegmentation,whereasedgeswithdashedlinesrepresentedgesinthegroupinggraph,whichjoin
diagramelementsintovisualgroups
1. Original image
Rhetorical relations are Edges encode information
added to the graph as
satellite.
2. AI2D layout segmentation 3. AI2D-RST discourse structure graph
Fig.6 (1)Athumbnailoftheoriginaldiagramimagescrapedfromtheweb,(2)itscrowdsourcedlayout
segmentation (converted into greyscale to bring out the annotation) and (3) the AI2D-RST discourse
structuregraphfordiagram#0.ThemultinuclearJOINTrelationR1joinstogetherthelabelsT0–2andT4–
5,whichserveasimilarcommunicativepurposeinthediagram,thatis,pickoutpartsoftheillustration
B0fordescription.Part-wholerelationsaredescribedusingtheELABORATION relationR2,inwhichthe
JOINTrelationR1actsasasatelliteandtheillustrationB0asthenucleus.Anotherrelationonthehighest
levelofthehierarchyisdrawnbetweentheillustrationB0andthetextT3(‘FACE’)thatdescribesthe
entirediagram,whichisannotatedasPREPARATION(R3).Theedgelabels‘n’and‘s’standfornucleusand
satellite,respectively
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 671
1. Original image
Diagram elements that form RST provides abstract relations
visual groups often participate needed for describing the global
in local discourse structures. discourse structure.
2. AI2D layout segmentation 3. AI2D-RST discourse structure graph
Fig.7 (1)Athumbnailoftheoriginaldiagramimagescrapedfromtheweb,(2)itscrowdsourcedlayout
segmentation (converted into greyscale to bring out the annotation) and (3) the AI2D-RST discourse
structure graph for diagram #2185. The diagram features three distinct types of rhetorical relations.
WhereastheIDENTIFICATIONrelations(R1–6)aremainlylocalinthesensethattheparticipatingdiagram
elementsformvisualgroups,theCYCLICSEQUENCE(R7)andPREPARATION(R8)describetheglobaldiscourse
organisationofthediagram,orhowlargerformationsofdiscourseunitsrelatetoeachother
layerattemptstodescribetheimplicitdiscourserelationsthatholdbetweendiagram
elements and their groups, which viewers may recover from the diagram structure.
Assuch,thediscoursestructurelayerprovidesthecruciallinkbetweenmultimodal
structure and communicative intentions in the AI2D-RST corpus.
For describing the discourse structure of diagrams, AI2D-RST uses Rhetorical
Structure Theory (RST; see e.g. Mann and Thompson 1988; Taboada and Mann
2006), a theory of textual organisation and coherence which has been previously
extended to diagrams in natural language generation (Andre´ and Rist 1995;
Bateman et al. 2001; Bateman and Henschel 2007) and for describing discourse
relations in research on multimodal documents and other artefacts (Bateman 2008;
Thomas 2009; Taboada and Habel 2013; Hiippala 2015). This extension of RST,
which may be described as multimodal RST, provides the foundation for discourse
structure annotation in AI2D-RST, as exemplified in Fig. 6.
Both ‘classical’ and multimodal RST provide a set of discourse relations with
criteria for their application (Mann and Thompson 1988; Bateman 2008). For
annotating discourse relations in the AI2D-RST corpus, we used the relation
definitionspresentedinHiippala(2015,pp.221–223)whichcombinestheclassical
RST relations from Mann and Thompson (1988) with the multimodal extension
proposed in Bateman (2008). We also introduced an additional relation, CYCLIC
SEQUENCE,whichisusedtodescriberepeatingsequences(seetheexampleinFig.7).
OurapplicationofRSTrelationsisdescribedingreatdetailintheannotationguide
that accompanies the AI2D-RST corpus (see Sect. 4.4).
We drew on these relation definitions to describe how elementary discourse
units—whichinAI2D-RSTcorrespondtodiagramelementsortheirgroups—relate
123
672 T.Hiippalaetal.
1. Original image
The label Perianth (T7) is used to describe two
other labels, T10 and T11. To maintain tree
structure in the graph, the node is split into
two nodes in the discourse structure graph.
2. AI2D layout segmentation 3. AI2D-RST discourse structure graph
Fig.8 (1)Athumbnailoftheoriginaldiagramimagescrapedfromtheweb,(2)itscrowdsourcedlayout
segmentationand(3)theAI2D-RSTdiscoursestructuregraphfordiagram#3194.Thediagramfeatures
threedistincttypesofrhetoricalrelations:IDENTIFICATION(R1–5,R8–11),ELABORATION(R7,R13)andJOINT
(R6, R12). To preserve the tree structure of the graph, several diagram elements are represented by
multiple nodes in the discourse structure graph, as these elements participate in multiple rhetorical
relations. To exemplify,the label Perianth (T7) describes two other labels, Petal (Corolla) (T10) and
Sepal(Calyx)(T11).WedescribethisrelationasIDENTIFICATION,asthelabelT7identifiesthatthelabels
T10andT11collectivelyformapartnamedPerianth.Inthediscoursestructuregraph,theIDENTIFICATION
relations(R10andR11)bothfeatureacopyofT7asasatellitetopreservethetreestructure
to each other. Depending on the relation, one discourse unit may be considered
nuclear, or more important, whereas other units act as satellites that play a
secondary role. RST terms such relations asymmetric. Symmetric relations, in turn,
may have multiple nuclei, indicating equal status among discourse units. The
example in Fig. 6 exemplifies both symmetric (R2, R3) and asymmetric (R1)
relationsandillustrateshowRSTrelationsarerepresentedinthediscoursestructure
graph. Relations are added to the graph as nodes whose identifier has the prefix R,
whereas the edges between these nodes carry information on nuclearity, that is,
whether the participating diagram elements act as nuclei or satellites.
Figure 7 shows a more complex example, which illustrates the benefit of
adopting RST for describing the discourse structure of diagrams. As pointed out
aboveinSect.3,therelation definitions intheAI2Dannotationschema arelargely
constrained to local relations between adjacent elements. RST, in turn, provides
abstractrelationsthatcanhandlethedescriptionofglobaldiscourseorganisationas
well, or how larger constellations of diagram elements relate to each other.
RSTanalysesarecommonlyrepresentedusingrecursivetreediagrams,although
thisisnotarequirement setbythe theory (TaboadaandMann 2006, p.435). Wolf
and Gibson (2005) have argued that tree structures are too constrained for an
accurate representation of discourse structure, because a single discourse unit may
bepickedupasapartofmultiplediscourserelations.Theyproposeusinggraphsas
an alternative data structure, which would allow discourse units to participate in
multiple relations and abolish the hierarchical tree structure.
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 673
The discourse structure layer, however, preserves the hierarchical structure and
uses a directed acyclic tree graph to represent RST analyses. This decision is
motivatedby the use oflayout space indiagrams, which is regularly used toset up
discourse relations between diagram elements (Waller 2012; Watanabe and Nagao
1998). The inherently spatial organisation of diagrams makes constraining the
applicationofdiscourserelationsdifficult,particularlyintermsofspatialadjacency,
that is, limiting relations to elements that are positioned close to each other (cf.
Bateman 2008, p. 158). We argue that preserving the tree structure imposes
additional control on the application of RST relations.
We do, however, acknowledge that like multimodal documents, diagrams can
‘re-use’discourse unitsindifferent rhetoricalrelations(Bateman2008, p.159). To
accountfordiagramelementsthattakeontheroleofsatellitesornucleiinmultiple
rhetorical relations, we split the diagram elements to preserve the hierarchical
structure, as shown in Fig. 8. This involves creating copies of a node in the graph,
which are identified using a decimal in the node name, such as T7.1 or T7.2. Each
copy of the node may be then picked up in the RST analysis while preserving the
treestructure.Becausetheoriginalidentifiersarepreservedasattributesofthesplit
nodes in the discourse structure graph, the acyclic tree graphs can be easily
converted into cyclic graphs favoured by Wolf and Gibson (2005), if necessary.
4.2 Annotators and training
The AI2D-RST diagrams were annotated by five students pursuing BA or MA
degrees inEnglish, who received approximately 10 h of initial training in the form
ofintroductorysessionscoveringeachannotationlayer.Theyalsoreceiveddetailed
feedbackontheirinitialworkandcouldposequestionsabouttheapplicationofthe
annotationschemausinganonlinetoolforteamcollaboration.Theannotatorswere
also supported by a document that provided guidelines and preferred solutions to
common annotation problems, which is available in the repository associated with
thisarticle.Wereturntodiscusstheimpactthatthecollaborativeannotationprocess
mayhavehadonthereproducibilityoftheannotationframeworkattheendofSect.
5. Annotating the corpus took approximately 6 months and cost 50,000€.
4.3 The annotation tool
We developed an in-house tool to annotate the diagrams. The tool provides a
commandline interface for building graphs,which are initially populated bynodes
from the original AI2D layout segmentation. The tool is written in Python 3.6 and
makes extensive use of the matplotlib (Hunter 2007), NetworkX (Hagberg et al.
2008),OpenCV(BradskiandKaehler2013)andpandas(McKinney2010)libraries.
Thetoolanditssourcecodeareavailablewithanopenlicenseathttps://doi.org/10.
5281/zenodo.3384751.
123
674 T.Hiippalaetal.
4.4 Acquiring the corpus
The AI2D-RST corpus is available for download as JSON files in the Language
Bank of Finland: http://urn.fi/urn:nbn:fi:lb-2020060101. Python functions for
loading and processing the corpus are provided separately at https://doi.org/10.
5281/zenodo.3384751.
5 Measuring the reliability of the annotation
Wemeasuredinter-annotatoragreementwhen355diagramshadbeenannotated.At
this stage, the annotators were assumed to have familiarised themselves with the
annotation schema. Because the data was annotated by five annotators, we used
Fleiss’ kappa (j) as implemented in the statsmodels Python library (Seabold and
Perktold 2010) as the metric for measuring inter-annotator agreement. We report
boththeoriginaljstatistic,asproposedbyFleiss(1971),whichiscalculatedusing
marginal probabilities for each category, and the free-marginal j proposed by
Randolph (2005), which assumes a uniform distribution over all categories. We
refer to Fleiss’ original definition as marginal j and Randolph’s alternative as
uniform j. In addition, we used the irr library (Gamer et al. 2019) for the R
programming language (R Core Team 2019) to calculate class-wise marginal j
scores for grouping, macro-grouping, connectivity and discourse structure annota-
tions.TheresultsarereportedinSects.5.1,5.2,5.3and5.4.Finally,inSect.5.5we
model annotator reliability using MACE (Hovy et al. 2013). The raw annotations
are provided as CSV files at https://doi.org/10.5281/zenodo.3384751.
5.1 Grouping
ToevaluatethereliabilityofgroupinglayerannotationintroducedinSect.4.1.1,we
sampledthe355diagramswithoutreplacementfor10%ofvisualgroupscomposed
of diagram elements only, excluding groups whose child nodes included other
groupingnodes.Thisamountedto256groups,whoseelementswerehighlightedin
theAI2Dlayoutsegmentationandpresentedtotheannotators.Theannotatorswere
then asked whether the elements form a visual group, as defined in the AI2D-RST
annotation schema. If the annotators considered the grouping valid, a follow-up
questionrequestedtheannotators tonameGestaltprincipleorannotation guideline
that justified their choice. If multiple principles or guidelines were applicable, the
annotators were asked to choose the most prominent one. For inter-annotator
agreementbetweenfiveannotatorsand256groups,themarginaljwas0.836,while
the uniform j was 0.894.
Table 1 shows class-wise agreement for Gestalt principles and annotation
guidelines, which are sorted in descending order based on their marginal j values.
Theresultssuggestthattheannotationguidesupportedtheconsistentdescriptionof
thedata.Mostcasesintheguidelinecategoryconsistedoflabel—linecombinations,
such as those shown in Fig. 6. In principle, such combinations could be grouped
together based on several Gestalt principles, such as proximity, continuity and
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 675
123
senilediugnoitatonnadnaselpicnirptlatseGrofserocsjlanigramesiw-ssalC
1elbaT
eulav-p
erocs-z
j
noitpircseD
yrogetaC
100.0<
800.74
929.0
rehtegotdepuorgerastnemeleehttahtetatssenilediugTSR-D2IAehT
enilediuG
100.0<
640.34
158.0
ecapstuoyalehtnirehtohcaeotesolcdecalperastnemelemargaidehT
ytimixorP
100.0<
342.93
677.0
tnemelerehtoehtsesolcnetnemeleehT
erusolC
100.0<
354.13
226.0
.ecnaraeppalausivriehtfosmretniralimiserastnemeleehT
ytiralimiS
100.0<
667.02
014.0
amehcsTSR-D2IAehtotgnidroccapuorgdilavamroftonodstnemeleehT
puorg-oN
100.0<
326.01
012.0
tinusuounitnocamrofstnemeleehT
ytiunitnoC
478.0
951.0-
300.0-
rehtohcaeotdetcennocerastnemeleehT
ssendetcennoC
739.0
970.0-
200.0-
epahslacirtemmysamrofstnemeleehT
yrtemmyS
676 T.Hiippalaetal.
Table2 Class-wisemarginalj
Macro-group j z-score p-value Frequencyincorpus
scoresformacro-groups
Network 0.884 30.480 \0:001 0.123
Cycle 0.876 30.204 \0:001 0.165
Cut-out 0.849 29.271 \0:001 0.093
Slice 0.754 25.996 \0:001 0.173
Horizontal 0.726 25.031 \0:001 0.072
Diagrammatic 0.718 24.785 \0:001 0.019
Illustration 0.709 24.458 \0:001 0.258
Vertical 0.702 24.228 \0:001 0.034
Table 0.247 8.537 \0:001 0.043
Photograph 0.162 5.604 \0:001 0.017
connectedness, but explicating annotation patterns for common diagrammatic
structuressuchaslabelsandtheirconnectinglinesseemstomakethedecisionsless
arbitrary. In addition, common spatial- and attribute-based relations that build on
Gestalt principles such as proximity, closure and similarity (Engelhardt 2002, p.
30), are annotated consistently in the AI2D-RST corpus.
5.2 Macro-grouping
For measuring inter-annotator agreement on the macro-groups introduced in Sect.
4.1.2,wesampledthe355diagramswithoutreplacementfor33%ofmacro-groups,
which amounted to 119 macro-groups. The annotators were presented with the
AI2D layout segmentation and the AI2D-RST grouping graph, which highlighted
the node that had been assigned with macro-grouping information. The annotators
werethenaskedwhichmacro-grouptheywouldassigntothenodeinquestion.For
inter-annotator agreement on macro-groups, the marginal j was 0.784 and the
uniform j was 0.800.
Table2givesclass-wisemarginaljvaluesformacro-groupsindescendingorder.
Agreement is particularly high for visually distinctive macro-groups such as
networks,cyclesandcut-outs,whichoccurfrequentlyintheAI2D-RSTcorpus(see
alsoFig.4).Thevaluesareconsiderablylowerforlesscommonmacro-groupssuch
as tables and photographs. Photographs, in particular, are rarely preferred as the
mainvisualexpressiveresourceintheAI2D-RSTcorpus,asdiagramsinthecorpus
favour illustrations, cut-outs and cross-sections for depiction. For these prominent
macro-groups, agreement remains substantial.
5.3 Connectivity
Forconnectivityannotation(seeSect.4.1.3),wesampledthe355diagramswithout
replacement for 10% of connections holding between diagram elements or their
groups,whichresultedin239connections.Thesourceandtargetofeachconnection
were highlighted in the AI2D layout segmentation and presented to the annotators,
who were then asked to place the connection into one of four categories: directed,
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 677
Table3 Class-wisemarginalj
Connection j z-score p-value Frequencyincorpus
scoresforconnectivity
Directed 0.910 44.512 \0:001 0.511
Bidirectional 0.908 44.402 \0:001 0.004
Undirected 0.900 44.003 \0:001 0.485
Noconnection 0.192 9.392 \0:001 N/A
Table4 Class-wisemarginaljscoresfordiscourserelations
Discourserelation j z-score p-value Frequencyincorpus
CYCLICSEQUENCE 0.924 44.029 <0.001 0.033
PREPARATION 0.870 41.471 <0.001 0.054
PROPERTY-ASCRIPTION 0.870 41.468 <0.001 0.070
JOINT 0.827 39.419 <0.001 0.109
IDENTIFICATION 0.798 37.998 <0.001 0.439
CONNECTED 0.766 36.492 <0.001 0.030
SEQUENCE 0.689 32.844 <0.001 0.015
ELABORATION 0.620 29.540 <0.001 0.134
CIRCUMSTANCE 0.449 21.388 <0.001 0.029
CONTRAST 0.308 14.656 <0.001 0.024
CLASS-ASCRIPTION 0.266 12.680 <0.001 0.028
CONJUNCTION 0.249 11.848 <0.001 0.003
DISJUNCTION 0.249 11.848 <0.001 0.003
LIST 0.182 8.659 <0.001 0.007
NONVOLITIONALCAUSE 0.138 6.553 <0.001 0.004
NONVOLITIONALRESULT 0.078 3.738 <0.001 0.006
MEANS 0.066 3.129 0.002 0.003
CONDITION -0.001 -0.042 0.966 0.001
PURPOSE -0.001 -0.042 0.966 N/A
RESTATEMENT -0.003 -0.126 0.900 0.004
undirected, bidirectional or no connection. Measuring inter-annotator agreement
returned a marginal j of 0.878 and uniform j of 0.916. Table 3 gives class-wise
marginaljvaluesforeachconnectiontype.Apartfromnoconnection,agreementis
high across all types of connectivity, as might be expected with a low number of
categories, which are also visually distinctive and whose structural features are
relatively easy to formalise (see Alikhani and Stone 2018, p. 3554).
5.4 Discourse structure
Forevaluatinginter-annotatoragreementonthediscoursestructurelayerintroduced
in Sect. 4.1.4, we sampled the 355 diagrams without replacement for 10% of the
relations,amountingtoatotalof227RSTrelations.TheAI2Dlayoutsegmentation
123
678 T.Hiippalaetal.
Starting from relation R7,
four hops are needed to
reach the furthermost
relations below, R3 or R5.
1
2
3 3
4 4
Fig. 9 Fleiss’ marginal and uniform j for RST relations at different depths of the RST tree. We
measuredthepositionofRSTnodesinthetreebycalculatingthenumberofhopsneededtoreachthe
furthermostRSTnodeinthesubtreebelow,asillustratedontheleft-handside.Ontheright-handside,the
balloonsgivethenumberofsamplesobservedforeachhop.TheX-axisgivesthenumberofhops:avalue
ofzeroindicatesthattheRSTrelationisclosetotheedgeofthetree
and the AI2D-RST discourse structure graph were presented side-by-side to the
annotators, highlighting the RST relation node to be annotated in the discourse
structure graph. Measuring overall agreement on the RST relations returned a
marginal j of 0.733 and a uniform j of 0.783.
Table 4 provides class-wise marginal j scores for RST relations that the
annotators used during the inter-annotator agreement experiment in a descending
order.TheresultsshowthatannotatorsconsistentlyagreeoncommonRSTrelations
such as CYCLIC SEQUENCE, which is used to annotate recurring cycles formed by
diagram elements, and PREPARATION, which is used to describe the relationship
between a title and an entire diagram. These RST relations are associated with
visually distinctive macro-groups (cycles) and relatively fixed diagram elements
(titles), which is likely to increase agreement. The same applies to frequently
occurring relations defined between a label and an object or its part, such as
PROPERTY-ASCRIPTION,IDENTIFICATIONandELABORATION,whosespecificusecaseswere
defined in the annotation guide. In short, the development of an annotation guide
seemedtosupporttheconsistentannotationofRSTrelations.Comparedtoprevious
studies of inter-annotator agreement using multimodal RST (e.g. Taboada and
Habel2013),thejscoresfortheAI2D-RSTdiscoursestructurelayerarepromising,
as relations with a j[0:62 cover 88.4% of RST relations in the corpus.
Figure 9 provides an alternative view to the reliability of the discourse structure
annotation by measuring inter-annotator agreement at different depths of the RST
treegraph.Notsurprisingly,agreementishighestattheleavesofthetreegraph(hop
0)withamarginalkof0.767andauniformkof0.832.Theseconsistentlyannotated
relationsmainlycoverlocaldiscoursestructuresillustratedinFig.7,asexemplified
by IDENTIFICATION (N ¼81), JOINT (N ¼21) and PROPERTY-ASCRIPTION (N ¼21). As
the j values for hops 1–3 show, agreement decreases for relations that are
positionedupthetree,whichrepresentthemoreabstractrelationsthatholdbetween
larger discourse units. Surprisingly, annotators consistently agree on how the
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 679
Table5 MACEreliability
Task Ann.1 Ann.2 Ann.3 Ann.4 Ann.5
estimatesforannotatorsand
specifictasks
Grouping 0.9133 0.9378 0.9040 0.9601 0.9430
Macro-grouping 0.8851 0.8052 0.9351 0.8574 0.8954
Connectivity 0.9478 0.9382 0.9531 0.9364 0.9631
Discoursestructure 0.8452 0.8698 0.8912 0.8021 0.9249
relations closest to the root (hop 4) should be annotated. It should be noted,
however, that sample sizes are very small for hops 3 and 4 and therefore warrant
caution.
5.5 Modelling annotator reliability
In addition to measuring inter-annotator agreement, we estimated annotator
reliability using MACE (Hovy et al. 2013). MACE, which stands for Multi-
Annotator Competence Estimation, models the annotation process by treating the
labels as latent variables and uses unsupervised learning to estimate the model
parameters.Themodelseekstopredictwhethertheannotatorisansweringdutifully
or choosing the answers at random. Hovy et al. (2013, p. 1124) show that MACE
reliability estimates correlate strongly with annotator proficiency. Table 5 shows
MACEreliabilityestimatesusingdefaultsettings,whichsuggestsdutifulannotation
with slightly varying competences between annotators.
5.6 On the reliability and reproducibility of the AI2D-RST annotation
schema
Overall, the inter-annotator agreement measures suggest that the AI2D-RST
annotation is applied consistently to the diagrams. The results are particularly
promising given that inter-annotator agreement was measured between five
annotators.However,itisimportanttoacknowledgethatmeasuringinter-annotator
agreementusingmetricssuchasFleiss’jofteninvolvecompromises.Inthecaseof
RST, for instance, measuringagreement over asingle relation inagiven context is
very different from constructing entire RST trees and comparing them between
annotators. To improve the evaluation of annotation reliability, future studies
applying multimodal RST should follow up on recent developments in research on
theautomaticcomparisonofRSTtrees(seee.g.Wanet al.2019).Alternatively,the
approach illustratedinFig.9 could beused samplerelations along the depthofthe
RST tree in a balanced manner, in order to ensure that agreement is evaluated for
both local and global discourse structures.
In terms of the annotation schema, it should be noted that the expert annotators
helped to develop the AI2D-RST annotation schema by discussing specific
examples with each other, which were then documented in the annotation guide.
This violates several principles of reproducibility set out for content analysis in
Krippendorff (2013). However, as Artstein and Poesio (2008, p. 575) point out,
contentanalysistreatstheannotationprocessasanexperimentaboutwhethersome
123
680 T.Hiippalaetal.
Grouping and
Original diagram Connectivity macro-grouping Discourse structure
Network density: the
proportion of actual Number of text Number of
connections out of all blocks in the
possible connections diagram relations
[ 0.12, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0,
12.0, 16.0, 17.0, 14.0, 0.0, 0.0, 12.0, 0.0, 1.0, 0.0, 1.0, 0.0,
1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 14.0, 0.0, 16.0, 0.0]
value (0.12) mean (0.157)
Z-score normalisation makes the counts
standard deviation (0.154) comparable across the AI2D-RST corpus.
[-0.23, -0.45, -0.31, -0.44, -0.15, -0.04, -0.25, 2.46, -0.11, -0.47, -0.23, 3.65,
1.76, 1.42, 1.58, 1.24, -0.83, -0.67, 2.26, -0.25, 1.15, -0.44, 1.83, -0.33,
0.73, -0.34, -0.25, -0.21, -0.16, -0.1 , -0.13, -0.13, -0.07, -0.12, -0.1 , -0.07,
-0.04, -0.03, -0.03, -0.03, -0.03, 1.53, 1.72, -0.61, 2.3, -0.05]
Network density is slightly Number of text blocks is Number of relations is
below the average (= 0.0) above the mean (= 0.0)
Fig.10 ExtractingsimplefeaturesfromdiagramsintheAI2D-RSTcorpusbycountingtheinstancesof
differentfeaturesacrosstheannotationlayers.Thefeaturesarethennormalisedtomakethemcomparable
properties may be consistently detected in a text, whose success is determined by
reproducibility of the annotation. In computational linguistics, annotation serves
differentpurposes,suchascreatingresourcesfortrainingandevaluatingalgorithms,
which differs from the goals set for content analysis (Reidsma and Carletta 2007).
Riezler (2014, p. 240), however, also calls for attention to the consequences of
violating the requirement of independence, that is, allowing the annotators to
discuss annotation tasks. This is likely to generate implicit knowledge among the
annotators, which increases agreement among annotators but hinders reproducibil-
ity. This kind of implicit knowledge gives rise to circularity in annotation, which
has been acknowledged as a problem in multimodality research (Thomas 2014).
Given the collaborative annotation procedure, it is likely that the AI2D-RST
annotations exhibit a degree of circularity.
ToevaluateandimprovethereproducibilityoftheAI2D-RSTframework,future
work should employ naive annotators, who are assigned tasks that do not build on
concepts introduced in the annotation framework (see e.g. Asheghi et al. 2016).
This kind of non-theoretical grounding (Riezler 2014) could help to break
circularity by evaluating, for instance, whether naive annotators perceive diagram
elements to form visual groups (grouping) or whether arrows and lines are
considered to signal connections between individual diagram elements or visual
groups (connectivity). For discourse structure annotation, Yung et al. (2019)
introduce a multi-step procedure for sourcing descriptions of discourse relations
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 681
Fig. 11 A visualization showing 2-dimensional UMAP embeddings learned from the 46-dimensional
featurevectorsextractedusingthetechniqueinFig.10.Eachpointcorrespondstoasinglediagraminthe
AI2Dcorpus,whicharecolouredaccordingtotheirmacro-groups
fromnaiveannotators.AdoptingthisapproachinmultimodalRST,however,would
require additional efforts to accommodate the presence of multiple expressive
resources.
6 Exploring the AI2D-RST corpus
Inthissection,wepresentabriefexploratoryanalysisoftheAI2D-RSTcorpus.We
begin with a rather straightforward approach illustrated in Fig. 10, which makes
minimal use of the graph-based representations by simply counting instances of
diagram elements, macro-groups, rhetorical relations, nuclei and satellites, and
typesofconnectionsineachdiagram.Finally,wealsocalculatenetworkdensityfor
theconnectivitygraph,whichmeasurestheproportionofactualedgespresentinthe
graph outofallpossibleedges.We concatenate these values intoa46-dimensional
feature vector and use z-score normalization to scale the values of each dimension
tohaveameanof0andastandarddeviationof1.Thisprovideseachdiagraminthe
AI2D-RST corpus with a normalised 46-dimensional feature vector that represents
its multimodal structure.
Figure 11 shows a visualisation that uses the Uniform Manifold Approximation
and Projection algorithm (UMAP; see McInnes et al. 2018) to reduce the 46-
dimensionalfeaturevectorstotwodimensionsforavisualexplorationoftheAI2D-
RST corpus. When mapping points between high- and low-dimensional spaces,
UMAPseekstopreservebothlocalandglobalstructureofthepointsacrossthetwo
123
682 T.Hiippalaetal.
spaces. In other words, points that are close to each other in the 46-dimensional
space should be close to each other in the two-dimensional space, whereas points
thataredistantfromeachotherinthe46-dimensionalspaceshouldremaindistantin
the two-dimensional space as well.
The UMAP embeddings in Fig. 11 show distinct clusters that correspond to
specificmacro-groups,suchascycles,cross-sections,cut-outsandnetworks,which
illustratethespaceofstructuralvariationamongtheAI2D-RSTdiagrams.Itshould
benoted,however,thatthemacro-groupingannotationisexplicitlyencodedintothe
46-dimensionalfeaturevector.ThisinformationisthusdirectlyavailabletoUMAP
for learning the 2-dimensional embeddings, which the algorithm leverages when
clustering points in the low-dimensional space.
Nevertheless, the visualisation in Fig. 11 can yield valuable insights into the
structural variation among the AI2D-RST diagrams. Firstly, diagrams that feature
severalmacro-groups(seeSect.4.1.2)canbefoundwithinallmajorclusters,which
suggeststhatevensimplecount-basedfeaturescancapturestructuraldistinctionsin
diagrams.Thediagramslabelledas‘mixed’areparticularlyinteresting,astheymay
yield information on which macro-groups are readily combined with each other in
the AI2D-RST corpus. The clusters for individual macro-groups, in turn, appear to
capture variation within macro-groups, as exemplified by the clusters for networks
and cross-sections, which seem to form two parts. Whether such formations within
clusters reflect alternative structural configurations of expressive resources within
specific macro-groups warrants further analysis.
Secondly, diagrams that feature rigid layouts, such as tabular, horizontal and
vertical macro-groups, are not only positioned close to each other, but also form a
continuationoftheclusterforillustrations.Thisisnotsurprising,astabular,vertical
and horizontal macro-groups are typically used to organise multiple instances of
visual depictions and their verbal descriptions for presentation, in which the local
discourse structures are similar to individual illustrations (for examples of local
discoursestructures,seeFig.7).Theclustersforcut-outsandcross-sections,inturn,
are distinct from illustrations, which may be traced back to differences in their
discoursestructure.Whereascut-outsandcross-sectionstypicallyuselabelstopick
outpartsorregionsofavisualdepiction,illustrationsuselabelstoidentifytheentire
object. This distinction is captured by their discourse structure annotation.
Thirdly, the diagrammatic macro-group forms a tight cluster, which is clearly
separatefromothermacro-groups.Althoughthesamplesizeforthismacro-groupis
fairly small (N ¼22), this is an interesting observation as the UMAP embeddings
seem to capture a fundamental difference between the diagrammatic macro-group
and other macro-groups in the corpus, which may be traced back to their discourse
structure. The diagrammatic macro-group features schematic diagrams such as
circuit diagrams, whose elements have fixed meanings, as exemplified by
standardised symbols for switches, connections, circuit breakers and the like.
Because their diagram elements have fixed meanings that do not need to be
recovered discursively from their context of occurrence, schematic diagrams resist
RST analysis. Put differently, there is no need for the viewer to resolve discourse
relationsbetweendiagramelements,asalltheinformationneededformakingsense
of the diagram is communicated using arrows and lines that signal connections
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 683
between diagram elements with fixed meanings. Although these connections are
captured by the AI2D-RST connectivity layer, this raises questions about the need
to revise the AI2D-RST annotation schema, if it were to be extended to domains
featuringmanytypesofschematicdiagrams,inordertodrawouttheirdifferences.
This brief exploratory analysis has illustrated how the AI2D-RST corpus can be
usedtosupportempiricalresearchonthemultimodalityofdiagrams.Aspointedout
above,thefeaturesextractedfromthecorpusmademinimaluseofthepropertiesof
the graph-based representations (see Fig. 10). The properties of graphs could be
exploited to a much larger extent using algorithms such as graph neural networks,
which learn representations of graph-structured data by passing and receiving
featuresbetweenneighbouringnodes(seee.g.Wuetal.2019).Suchmethodscould
beparticularlyusefulforlearningrepresentationsofdiscoursestructureindiagrams,
allowingtheircomputationalrepresentationtoencodeinteractionsbetweendiagram
elements. However, learning these representations directly from the data can be
complicated by the relatively small number diagrams in AI2D-RST.
7 Discussion
Developing the AI2D-RST corpus showed that exploiting readily-available
annotations can be used to increase the size of richly-annotated multimodal
corpora, but this comes at a cost, particularly for annotating their discourse
structure.AsexplicatedinHiippalaandBateman(2020),identifyingtheelementary
discourse units required by RST and other discourse annotation frameworks is
particularlycomplicatedfordiagrams,becausetheextenttowhichdiagramsneedto
be decomposed to achieve a sufficient inventory of elementary discourse units
varies from one diagram to another. In short, the level of detail needed for
decomposition depends on the combination of expressive resources and the
discourse relations they participate in (see Sect. 2).
Because the AI2D layout segmentation does not provide this kind of discourse-
driven decomposition at various levels of detail, the AI2D-RST annotation schema
hadtomakecompromisesinthedescriptionofdiscoursestructure.Theexamplein
Fig.6 illustrates thisissue aptly: the writtenlabels are used topick out parts of the
illustration, and to achieve a maximally accurate RST analysis of the diagram, the
illustration should be decomposed into its component parts. However, as the
crowdsourced annotators were not instructed to decompose visual expressive
resources during layout segmentation, the elementary discourse units needed for a
maximally coherent representation of discourse structure within RST are not
available (for a discussion of similar problems in annotating comics, see Bateman
and Wildfeuer 2014).
Thisshortcomingalsocarriesimplicationsforcrowdsourcingannotationsforthe
diagrammatic mode in any domain. Because the discourse structure determines to
what extent the diagram must be decomposed, defining crowdsourcing tasks
developed for the annotation of photographic images is unlikely to work for
identifying the ‘buildingblocks’ ofdiagrams (cf. Kovashka et al. 2016).Instead of
defining semantic object classes (i.e. what the diagram element represents), these
123
684 T.Hiippalaetal.
building blocks should correspond to expressive resources available to the
diagrammaticmode,suchaswrittenlanguage,arrows,linesandotherdiagrammatic
elements. Crucially, these expressive resources must be complemented by
sufficiently fine-grained descriptions of graphic expressive resources, such as line
drawings, coloured illustrations, cut-outs, cross-sections and exploded views, and
photographs, toname just a few examples. In short, pre-theoretical notions such as
‘language’and‘image’arenotsufficientlyfine-grainedtocapturethemotivateduse
of distinctive graphic expressive resources in diagrams (cf. Bateman 2014).
Although the development of AI2D-RST revealed various challenges discussed
above, we argue that the corpus is still a valuable resource for studying how the
diagrammatic mode is used in the domain of primary school natural sciences and
beyond. In the study of multimodal discourse, the corpus could be used for
investigating whether discourse relations between diagram elements are signalled
visually using arrows and lines or spatially using layout (cf. Watanabe and Nagao
1998), thus complementing the linguistic research on signalling of discourse
relations by Das and Taboada (2018). Such empirically-backed insights could be
particularly valuable to educational research on the visual perception of diagram-
matic representations, and their role in constructing mental models and learning
more generally (Tippett 2016; Menendez et al. 2020). Another avenue of further
research involves the automatic annotation of diagram corpora. The AI2D-RST
corpuscoversjustover20%oftheAI2Ddataset,whichraisesthequestionwhether
the 1000 diagrams in AI2D-RST are sufficient for teaching algorithms to generate
AI2D-RST annotations for the remaining 3900 diagrams in AI2D.
8 Concluding remarks
InthisarticleweintroducedAI2D-RST,anewmultimodalcorpusof1000English-
language primary school science diagrams, which combines crowdsourced and
expert annotations to provide a rich description of their multimodal structure. The
multi-layered, stand-off annotation schema developed for AI2D-RST accounts for
(1)thevisualgroupingofdiagramelements,(2)howtheirconnectionsaresignalled
using arrows and lines, and (3) the discourse relations between diagram elements
using Rhetorical Structure Theory. We measured agreement between five annota-
tors: the results suggest that the annotation schema may be reliably applied to
describe diagrams in the AI2D-RST corpus.
As our brief exploratory analysis of the AI2D-RST corpus showed, the
combination of multiple annotation layers and graph-based representations can
yield valuable insights into the multimodal structure of diagrams. As such, the
corpus can support empirical research on diagrams as a mode of expression and
theircomputationalprocessing.Intermsofmethodology,developingtheAI2D-RST
corpus illustrated how crowdsourcing low-level annotations and building expert
descriptionsontopofthemcanbeusedtoincreasethesizeofcorporainthefieldof
multimodality research. Insights from linguistically-inspired multimodality
research, in turn, can also inform the creation of resources for research on the
computational processing and generation of diagrams.
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 685
OpenAccess ThisarticleislicensedunderaCreativeCommonsAttribution4.0InternationalLicense,
whichpermitsuse,sharing,adaptation,distributionandreproductioninanymediumorformat,aslongas
you give appropriate credit to the original author(s) and the source, provide a link to the Creative
Commonslicence,andindicateifchangesweremade.Theimagesorotherthirdpartymaterialinthis
articleareincludedinthearticle’sCreativeCommonslicence,unlessindicatedotherwiseinacreditline
tothematerial.Ifmaterialisnotincludedinthearticle’sCreativeCommonslicenceandyourintended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder. To view a copy of this licence, visit http://
creativecommons.org/licenses/by/4.0/.
Funding OpenaccessfundingprovidedbyUniversityofHelsinkiincludingHelsinkiUniversityCentral
Hospital.
References
Alikhani, M., & Stone, M. (2018). Arrows are the verbs of diagrams. In Proceedings of the 27th
International Conference on Computational Linguistics,Santa Fe, New Mexico, USA, pp.3552–
3563.
Andre´,E.,&Rist,T.(1995).Generatingcoherentpresentationsemployingtextualandvisualmaterial.
ArtificialIntelligenceReview,9,147–165.
Artstein,R.,&Poesio,M.(2008).Inter-coderagreementforcomputationallinguistics.Computational
Linguistics,34(4),555–596.
Asheghi,N.R.,Sharoff,S.,&Markert,K.(2016).Crowdsourcingforwebgenreannotation.Language
Resources&Evaluation,50(3),603–641.
Bateman, J. A. (2008). Multimodality and Genre: A Foundation for the Systematic Analysis of
MultimodalDocuments.London:PalgraveMacmillan.
Bateman, J. A. (2014). Text and image: A critical introduction to the visual/verbal divide. London:
Routledge.
Bateman,J.A.&Henschel,R.(2007).Generatingtext,layoutanddiagramsappropriatelyforgenre,in
I.van der Sluis, M.Theune, E.Reiter and E.Krahmer, eds, ‘Proceedings of the Workshop on
Multimodal Output Generation MOG 2007’, Centre for Telematics and Information Technology
(CTIT),UniversityofTwente,pp.29–40.
Bateman,J.A.,Kamps,T.,Reichenberger,K.,&Kleinz,J.(2001).Towardsconstructivetext,diagram,
andlayoutgenerationforinformationpresentation.ComputationalLinguistics,27(3),409–449.
Bateman,J.A.,&Wildfeuer,J.(2014).Definingunitsofanalysisforthesystematicanalysisofcomics:A
discourse-basedapproach.StudiesinComics,5(2),373–403.
Bateman,J.A.,Wildfeuer,J.,&Hiippala,T.(2017).Multimodality:Foundations,ResearchandAnalysis
–AProblem-orientedIntroduction.Berlin:DeGruyterMouton.
Bradski,G.,&Kaehler,A.(2013).LearningOpenCV:ComputervisioninC??withtheOpenCVlibrary
(2nded.).Sebastopol:O’Reilly.
Carberry,S.,Elzer,S.,Green,N.,McCoy,K.,&Chester,D.(2003).Understandinginformationgraphics:
A discourse-level problem. In ‘Proceedings of the Fourth SIGdial Workshop of Discourse and
Dialogue’.https://www.aclweb.org/anthology/W03-2101
Choi,J.,Krishnamurthy,J.,Kembhavi,A.,&Farhadi,A.(2018).Structuredsetmatchingnetworksfor
one-shotpartlabeling.In‘Proceedingsofthe2018IEEE/CVFConferenceonComputerVisionand
PatternRecognition’,pp.3627–3636.
Das, D., & Taboada, M. (2018). RST Signalling Corpus: A corpus of signals of coherence relations.
LanguageResourcesandEvaluation,52(1),149–184.
Engelhardt,Y.(2002).TheLanguageofGraphics:AFrameworkfortheAnalysisofSyntaxandMeaning
in Maps, Charts and Diagrams. Institute for Logic, Language and Computation: University of
Amsterdam.PhDthesis.
Engelhardt,Y.,&Richards,C.(2018).Aframeworkforanalyzinganddesigningdiagramsandgraphics,
in P.Chapman, A.Moktefi, S.Perez-Kriz and F.Bellucci, eds, ‘Diagrams 2018: Diagrammatic
Representation and Inference’, Vol. 10871 of Lecture Notes in Computer Science, Springer,
pp.201–209.
123
686 T.Hiippalaetal.
Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin,
76(5),378–382.
Gamer,M.,Lemon,J.,Fellows,I.,&Singh,P.(2019).irr:Variouscoefficientsofinterraterreliabilityand
agreement.Rpackageversion0.84.1.https://CRAN.R-project.org/package=irr
Grosz,B.J.,&Sidner,C.L.(1986).Attention,intentions,andthestructureofdiscourse.Computational
Linguistics,12(3),175–204.
Haehn, D., Tompkin, J., & Pfister, H. (2019). Evaluating ‘graphical perception’ with CNNs. IEEE
TransactionsonVisualizationandComputerGraphics,25(1),641–650.
Hagberg,A.,Swart,P.&Schult,D.(2008).Exploringnetworkstructure,dynamics,andfunctionusing
NetworkX.InProceedingsofthe7thPythoninScienceConference,pp.11–15.
Hegarty,M., &Just,M. A.(1993).Constructingmental modelsofmachinesfromtextanddiagrams.
JournalofMemoryandLanguage,32(6),717–742.
Hiippala, T. (2013). The interface between rhetoric and layout in multimodal artefacts. Literary and
LinguisticComputing,28(3),461–471.
Hiippala, T. (2015). The structure of multimodal documents: An empirical approach. New York:
Routledge.
Hiippala,T.,&Bateman,J.A.(2020)Introducingthediagrammaticmode.arXiv2001.11224.https://
arxiv.org/abs/2001.11224
Hiippala, T. and Orekhova, S. (2018). Enhancing the AI2 diagrams dataset using rhetorical structure
theory. in Proceedings of the Eleventh International Conference on Language Resources and
Evaluation (LREC 2018), European Language Resources Association (ELRA), Paris, pp.1925–
1931.
Holsanova,J.,Holmberg,N.,&Holmqvist,K.(2009).Readinginformationgraphics:Theroleofspatial
contiguityanddualattentionalguidance.AppliedCognitivePsychology,23,1215–1226.
Hovy,D.,Berg-Kirkpatrick,T.,Vaswani,A.,&Hovy,E.(2013).LearningwhomtotrustwithMACE.In
Proceedings of the 2013 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Association for Computational
Linguistics,Atlanta,Georgia,pp.1120–1130.
Huang, L. (2020). Toward multimodal corpus pragmatics: Rationale, case, and agenda. Digital
ScholarshipintheHumanities.https://doi.org/10.1093/llc/fqz080.
Hunter,J.(2007).matplotlib:A2Dgraphicsenvironment.ComputinginScience&Engineering,9(3),
90–95.
Kembhavi, A.,Salvato, M., Kolve, E., Seo, M.J., Hajishirzi, H., & Farhadi,A. (2016).A diagram is
worthadozenimages.InProceedingsofthe14thEuropeanConferenceonComputerVision(ECCV
2016),Springer,Cham,pp.235–251.
Kim,D.,Kim,S.,&Kwak,N.(2019),Textbookquestionansweringwithmulti-modalcontextgraph
understanding and self-supervised open-set comprehension. In Proceedings of the 57th Annual
Meeting of the Association for Computational Linguistics (ACL 2019), Association for Compu-
tationalLinguistics,Florence,Italy,pp.3568–3584.
Kim,D.,Yoo,Y.,Kim,J.,Lee,S.&Kwak,N.(2018).Dynamicgraphgenerationnetwork:Generating
relational knowledge from diagrams. In Proceedings of the 2018 IEEE/CVF Conference on
ComputerVisionandPatternRecognition(CVPR2018),pp.4167–4175.
Kovashka,A.,Russakovsky,O.,Fei-Fei,L.,&Grauman,K.(2016).Crowdsourcingincomputervision.
FoundationsandTrendsinComputerGraphicsandVision,10(3),177–243.
Krippendorff,K.(2013).ContentAnalysis:AnIntroductiontoitsMethodology(3rded.).ThousandOaks,
CA:Sage.
Mann,W.C.,&Thompson,S.A.(1988).RhetoricalStructureTheory:Towardafunctionaltheoryoftext
organization.Text,8(3),243–281.
McInnes,L.,Healy,J.,Saul,N.,&Grossberger,L.(2018).UMAP:Uniformmanifoldapproximationand
projection.TheJournalofOpenSourceSoftware,3(29),861.
McKinney, W. (2010). Data structures for statistical computing in Python. In S.vander Walt and
J.Millman,eds,Proceedingsofthe9thPythoninScienceConference,pp.51–56.
Menendez,D.,Rosengren,K.S., &Alibali,M.W.(2020).Dodetailsbugyou?Effectsofperceptual
richnessinlearningaboutbiologicalchange.AppliedCognitivePsychology,34(5),1101–1117.
Purchase,H.C.(2014).Twelveyearofdiagramsresearch.JournalofVisualLanguagesandComputing,
25(2),57–75.
123
AI2D-RST:amultimodalcorpusof1000primaryschoolsciencediagrams 687
R Core Team. (2019). R: A Language and Environment for Statistical Computing, R Foundation for
StatisticalComputing,Vienna,Austria.https://www.R-project.org/
Randolph,J.J.(2005).Free-marginalmultiraterkappa(multiraterj-free):AnalternativetoFleiss’fixed-
marginalmultiraterkappa.In:ProceedingsoftheJoensuuLearningandInstructionSymposium.
Reidsma,D.,&Carletta,J.(2007).Reliabilitymeasurementwithoutlimits.ComputationalLinguistics,
34(3),319–326.
Riezler, S. (2014). On the problem of theoretical terms in empirical computational linguistics.
ComputationalLinguistics,40(1),235–245.
Sachan, M., Dubey, A., Hovy, E. H., Mitchell, T. M., Roth, D., & Xing, E. P. (2019). Discourse in
multimedia: A case study in extracting geometry knowledge from textbooks. Computational
Linguistics,45(4),627–665.
Sachan, M., Dubey, K.A., Mitchell, T.M., Roth, D., & Xing, E.P. (2018). Learning pipelines with
limiteddataanddomainknowledge:Astudyin parsingphysicsproblems.InProceedingsofthe
32ndConferenceonNeuralInformationProcessingSystems(NeurIPS2018).
Seabold,S.,&Perktold,J.(2010).Statsmodels:EconometricandstatisticalmodelingwithPython.In9th
PythoninScienceConference.pp.57–61.
Seo, M., Hajishirzi, H., Farhadi, A., Etzioni, O., & Malcolm, C. (2015). Solving geometry problems:
Combiningtextanddiagraminterpretation.InProceedingsofthe2015ConferenceonEmpirical
Methods in Natural Language Processing (EMNLP 2015)’, Association for Computational
Linguistics,Lisbon,Portugal,pp.1466–1476.
Taboada, M., & Habel, C. (2013). Rhetorical relations in multimodal documents. Discourse Studies,
15(1),65–89.
Taboada, M., & Mann, W. C. (2006). Rhetorical structure theory: Looking back and moving ahead.
DiscourseStudies,8(3),423–459.
Thomas,M.(2009).Localizingpackmessages:Aframeworkforcorpus-basedcross-culturalmultimodal
analysis,PhDthesis,UniversityofLeeds.
Thomas,M.(2014).Evidenceandcircularityinmultimodaldiscourseanalysis.VisualCommunication,
13(2),163–189.
Tippett,C.D.(2016).Whatrecentresearchondiagramssuggestsaboutlearningwithratherthanlearning
fromvisualrepresentationsinscience.InternationalJournalofScienceEducation,38(5),725–746.
Tversky,B.(2015).Thecognitivedesignoftoolsofthought.ReviewofPhilosophyandPsychology,6(1),
99–116.
Tversky,B.(2017).Diagrams:Cognitivefoundationsfordesign.InA.Black,P.Luna,O.Lund,&S.
Walker(Eds.),Informationdesign:Researchandpractice(pp.349–360).London:Routledge.
Tversky, B., Zacks, J., Lee, P., & Heiser, J. (2000). Lines, blobs, crosses and arrows: Diagrammatic
communicationwithschematicfigures.Diagrams2000:TheoryandApplicationofDiagrams(pp.
221–230).Berlin:Springer.
Waller,R. H.W.(2012).Graphic literaciesfor a digitalage: Thesurvivaloflayout.The Information
Society,28(4),236–252.
Waller, R. H. W. (2017). Practice-based perspectives on multimodal documents: Corpora vs
connoisseurship.Discourse,Context&Media,20,175–190.
Wan,S.,Kutschbach,T.,Lu¨deling,A.,&Stede,M.(2019).RST-Tace:Atoolforautomaticcomparison
andevaluationofRSTtrees.InProceedingsoftheWorkshoponDiscourseRelationParsingand
Treebanking2019,AssociationforComputationalLinguistics,Minneapolis,MN,pp.88–96.
Ware,C.(2012).InformationVisualization:PerceptionforDesign(3rded.).Amsterdam:Elsevier.
Watanabe,Y.,&Nagao,M.(1998).Diagramunderstandingusingintegrationoflayoutinformationand
textual information. In ‘Proceedings of the 36th Annual Meeting of the Association for
Computational Linguistics and 17th International Conference on Computational Linguistics
(ACL’98/COLING’98)’, Association for Computational Linguistics, Montreal, Quebec, Canada,
pp.1374–1380.
Wildfeuer, J., Pflaeging, J., Bateman, J. A., Seizov, O., & Tseng, C. (Eds.). (2020). Multimodality:
DisciplinaryThoughtsandtheChallengeofDiversity.Berlin:DeGruyter.
Wolf,F.,&Gibson,E.(2005).Representingdiscoursecoherence:Acorpus-basedstudy.Computational
Linguistics,31(2),249–288.
Wu,Z.,Pan,S.,Chen,F.,Long,G.,Zhang,C.,&Yu,P.S.(2019).Acomprehensivesurveyongraph
neuralnetworks.http://arxiv.org/abs/1901.00596
123
688 T.Hiippalaetal.
Yung,F.,Demberg,V.,&Scholman,M.(2019).Crowdsourcingdiscourserelationannotationsbyatwo-
step connective insertion task. In: Proceedings of the 13th Linguistic Annotation Workshop,
AssociationforComputationalLinguistics,Florence,Italy,pp.16–25.
Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published
mapsandinstitutionalaffiliations.
123
