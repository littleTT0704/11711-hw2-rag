Multilingual Relation Extraction using Compositional Universal Schema
PatrickVerga,DavidBelanger,EmmaStrubell,BenjaminRoth&AndrewMcCallum
CollegeofInformationandComputerSciences
UniversityofMassachusettsAmherst
{pat, belanger, strubell, beroth, mccallum}@cs.umass.edu
Abstract One challenge in AKBC is aligning knowledge from
a structured KB with a text corpus in order to perform
supervisedlearningthroughdistantsupervision. Univer-
Universalschemabuildsaknowledgebase(KB)of
entities and relations by jointly embedding all re- sal schema (Riedel et al., 2013) along with its exten-
lation types from input KBs as well as textual pat- sions(Yaoetal.,2013;Gardneretal.,2014;Neelakantan
ternsobservedinrawtext. Inmostpreviousappli- et al., 2015; Rocktaschel et al., 2015), avoids alignment
cationsofuniversalschema, eachtextualpatternis by jointly embedding KB relations, entities, and surface
representedasasingleembedding,preventinggen- text patterns. This propagates information between KB
eralizationtounseenpatterns.Recentworkemploys annotationandcorrespondingtextualevidence.
aneuralnetworktocapturepatterns’compositional
The above applications of universal schema express
semantics, providing generalization to all possible
input text. In response, this paper introduces sig- eachtextrelationasadistinctitemtobeembedded. This
nificant further improvements to the coverage and harmsitsabilitytogeneralizetoinputsnotpreciselyseen
flexibility of universal schema relation extraction: at training time. Recently, Toutanova et al. (2015) ad-
predictions for entities unseen in training and mul- dressedthisissuebyembeddingtextpatternsusingadeep
tilingual transfer learning to domains with no an- sentence encoder, which captures the compositional se-
notation. Weevaluateourmodelthroughextensive mantics of textual relations and allows for prediction on
experimentsontheEnglishandSpanishTACKBP
inputsneverseenbefore.
benchmark,outperformingthetopsystemfromTAC
This paper further expands the coverage abilities of
2013slot-fillingusingnohandwrittenpatternsorad-
ditionalannotation. Wealsoconsideramultilingual universalschemarelationextractionbyintroducingtech-
settinginwhichEnglishtrainingdataentitiesover- niquesforformingpredictionsfornewentitiesunseenin
lap with the seed KB, but Spanish text does not. trainingandevenfornewdomainswithnoassociatedan-
Despite having no annotation for Spanish data, we notation. In the extreme example of domain adaptation
trainanaccuratepredictor,withadditionalimprove- toacompletelynewlanguage, wemayhavelimitedlin-
ments obtained by tying word embeddings across guistic resources or labeled data such as treebanks, and
languages. Furthermore, we find that multilingual
only rarely a KB with adequate coverage. Our method
training improves English relation extraction accu-
performsmultilingualtransferlearning,providingapre-
racy. Ourapproachisthussuitedtobroad-coverage
dictivemodelforalanguagewithnocoverageinanexist-
automatedknowledgebaseconstructioninavariety
ingKB,byleveragingcommonrepresentationsforshared
oflanguagesanddomains.
entitiesacrosstextcorpora. AsdepictedinFigure1, we
simply require that one language have an available KB
ofseedfacts. Wecanfurtherimproveourmodelsbyty-
1 Introduction
ingasmallsetofwordembeddingsacrosslanguagesus-
ingonlysimpleknowledgeaboutword-leveltranslations,
The goal of automatic knowledge base construction
learning to embed semantically similar textual patterns
(AKBC) is to build a structured knowledge base (KB)
fromdifferentlanguagesintothesamelatentspace.
of facts using a noisy corpus of raw text evidence, and
perhaps an initial seed KB to be augmented (Carlson et InextensiveexperimentsontheTACKnowledgeBase
al., 2010; Suchaneketal., 2007; Bollackeretal., 2008). Population (KBP) slot-filling benchmark we outperform
AKBC supports downstream reasoning at a high level the top 2013 system with an F1 score of 40.7 and per-
about extracted entities and their relations, and thus has form relation extraction in Spanish with no labeled data
broad-reachingapplicationstoavarietyofdomains. ordirectoverlapbetweentheSpanishtrainingcorpusand
886
ProceedingsofNAACL-HLT2016,pages886–896,
SanDiego,California,June12-17,2016.(cid:13)c2016AssociationforComputationalLinguistics
thetrainingKB,demonstratingthatourapproachiswell- et al., 2015; Bordes et al., 2013; Wang et al., 2014; Lin
suited for broad-coverage AKBC in low-resource lan- etal.,2015),ornon-linearinteractionsbetweens,r,and
guages and domains. Interestingly, joint training with o(Socheretal.,2013).Otherapproachesmodelthecom-
SpanishimprovesEnglishaccuracy. positionality of multi-hop paths, typically for question
answering (Bordes et al., 2014; Gu et al., 2015; Nee-
lakantanetal.,2015).
English Low-resource
2.2 RelationExtractionasSentenceClassification
Here, the training data consist of (1) a text corpus, and
inKB
(2) a KB of seed facts with provenance, i.e. supporting
evidence, in the corpus. Given individual an individual
notinKB sentence, and pre-specified entities, a classifier predicts
whether the sentence expresses a relation from a target
schema. To train such a classifier, KB facts need to be
Figure 1: Splitting the entities in a multilingual AKBC
aligned with supporting evidence in the text, but this is
trainingsetintoparts. Weonlyrequirethatentitiesinthe
often challenging. For example, not all sentences con-
two corpora overlap. Remarkably, we can train a model
taining Barack and Michelle Obama state that they are
forthelow-resourcelanguageevenifentitiesinthelow-
married.Avarietyofone-shotanditerativemethodshave
resourcelanguagedonotoccurintheKB.
addressedthealignmentproblem(BunescuandMooney,
2007; Mintz et al., 2009; Riedel et al., 2010; Yao et al.,
2 Background 2010;Hoffmannetal.,2011;Surdeanuetal.,2012;Min
et al., 2013; Zeng et al., 2015). An additional degree
AKBCextractsunaryattributesoftheform(subject, at- of freedom in these approaches is whether they classify
tribute),typedbinaryrelationsoftheform(subject,rela- individual sentences or predicting at the corpus level by
tion, object), or higher-order relations. We refer to sub- aggregating information from all sentences containing a
jects and objects as entities. This work focuses solely given pair of entities before prediction. The former ap-
onextractingbinaryrelations, thoughmanyofourtech- proachisoftenpreferableinpractice,duetothesimplic-
niques generalize naturally to unary prediction. Gener- ityofindependentlyclassifyingindividualsentencesand
ally, for example in Freebase (Bollacker et al., 2008), theeaseofassociatingeachpredictionwithaprovenance.
higher-order relations are expressed in terms of collec- Priorworkhasapplieddeeplearningtosmall-scalerela-
tionsofbinaryrelations. tion extraction problems, where functional relationships
WenowdescribepriorworkonapproachestoAKBC. aredetectedbetweencommonnouns(Lietal.,2015;dos
Theyallaimtopredict(s,r,o)triples,butdifferinterms Santos et al., 2015). Xu et al. (2015) apply an LSTM
of: (1) input data leveraged, (2) types of annotation re- to a parsepath, while Zenget al. (2015) use aCNN on
quired, (3) definition of relation label schema, and (4) therawtext,withaspecialtemporalpoolingoperationto
whether they are capable of predicting relations for en- separatelyembedthetextaroundeachentity.
tities unseen in the training data. Note that all of these
methods require pre-processing to detect entities, which 2.3 Open-DomainRelationExtraction
mayresultinadditionalKBconstructionerrors. In the previous two approaches, prediction is carried
out with respect to a fixed schema R of possible rela-
2.1 RelationExtractionasLinkPrediction
tions r. This may overlook salient relations that are ex-
A knowledge base is naturally described as a graph, pressed in the text but do not occur in the schema. In
in which entities are nodes and relations are labeled response, open-domain information extraction (OpenIE)
edges (Suchanek et al., 2007; Bollacker et al., 2008). letsthetextspeakforitself: Rcontainsallpossiblepat-
In the case of knowledge graph completion, the task is ternsoftextoccurringbetweenentitiessando(Bankoet
akin to link prediction, assuming an initial set of (s, r, al., 2007; Etzioni et al., 2008; Yates and Etzioni, 2007).
o) triples. See Nickel et al. (2015) for a review. No These are obtained by filtering and normalizing the raw
accompanying text data is necessary, since links can be text. The approach offers impressive coverage, avoids
predictedusingpropertiesofthegraph,suchastransitiv- issues of distant supervision, and provides a useful ex-
ity. Inordertogeneralizewell,predictionisoftenposed ploratory tool. On the other hand, OpenIE predictions
as low-rank matrix or tensor factorization. A variety of aredifficulttouseindownstreamtasksthatexpectinfor-
model variants have been suggested, where the proba- mationfromafixedschema.
bilityofa givenedgeexistingdepends onamulti-linear Table1providesexamplesofOpenIEpatterns.Theex-
form(Nickeletal.,2011;Garc´ıa-Dura´netal.,2015;Yang amplesinrowtwoandthreeillustraterelationalcontexts
887
forwhichsimilarityisdifficulttobecapturedbyanOpe- theotherfactorizationsdescribedin Riedeletal.(2013).
nIEapproachbecauseoftheirsyntacticallycomplexcon- Note that learning unique embeddings for OpenIE rela-
structions. This motivates the technique in Section 3.2, tionsdoesnotguaranteethatsimilarpatterns,suchasthe
whichusesadeeparchitectureappliedtorawtokens,in- finaltwoinTable1,willbeembeddedsimilarly.
steadofrigidrulesfornormalizingtexttoobtainpatterns. AswithmostofthetechniquesinSection2.1,thedata
onlyconsistofpositiveexamplesofedges. Theabsence
Sentence(contexttokensitalicized) OpenIEpattern ofanannotatededgedoesnotimplythattheedgeisfalse.
Khan ’s younger sister, Annapurna arg1’s * sister Infact,weseektopredictsomeofthesemissingedgesas
Devi, who later married Shankar, de- arg2 true. Riedel et al. (2013) employ the Bayesian Person-
velopedintoanequallyaccomplished alized Ranking (BPR) approach of Rendle et al. (2009),
masterofthesurbahar,butcustompre-
which does not explicitly model unobserved edges as
ventedherfromperforminginpublic.
negative,butinsteadseekstoranktheprobabilityofob-
AprofessoremeritusatYale,Mandel- arg1*movedwith
servedtriplesaboveunobservedtriples.
brotwasborninPolandbutasachild *familytoarg2
Recently, Toutanova et al. (2015) extended USchema
movedwithhisfamilytoPariswhere
tonotlearnindividualpatternembeddingsv ,butinstead
hewaseducated. r
Kissel was born in Provo, Utah, but arg1 * lived in to embed text patterns using a deep architecture applied
herfamilyalsolivedinReno. arg2 to word tokens. This shares statistical strength between
OpenIEpatternswithsimilarwords. Weleveragethisap-
Table 1: Examples of sentences expressing relations.
proachinSection3.2. Additionalworkhasmodeledthe
Context tokens (italicized) consist of the text occurring
regularitiesofmulti-hoppathsthroughknowledgegraph
betweenentities(bold)inasentence.OpenIEpatternsare
augmentedwithtextpatterns(Laoetal.,2011;Laoetal.,
obtained by normalizing the context tokens using hand-
2012;Gardneretal.,2014;Neelakantanetal.,2015).
codedrules. Thetopexample expressestheper:siblings
relation and the bottom two examples both express the
2.5 MultilingualEmbeddings
per:cities of residencerelation.
Muchworkhasbeendoneonmultilingualwordembed-
dings. Most of this work uses aligned sentences from
2.4 UniversalSchema
theEuroparldataset(Koehn,2005)toalignwordembed-
When applying Universal Schema (Riedel et al., 2013) dingsacrosslanguages(Gouwsetal.,2015;Luongetal.,
(USchema) to relation extraction, we combine the Ope- 2015; Hermann and Blunsom, 2014). Others (Mikolov
nIE and link-prediction perspectives. By jointly mod- et al., 2013; Faruqui et al., 2014) align separate single-
eling both OpenIE patterns and the elements of a target language embedding models using a word-level dictio-
schema,themethodcapturesbroaderrelationalstructure nary. Mikolovetal.(2013)usetranslationpairstolearn
thanmulti-classclassificationapproachesthatjustmodel alineartransformfromoneembeddingspacetoanother.
the target schema. Furthermore, the method avoids the
However, very little work exists on multilingual re-
distantsupervisionalignmentdifficultiesofSection2.2.
lation extraction. Faruqui and Kumar (2015) perform
Riedeletal.(2013)augmentaknowledgegraphfrom multilingualOpenIErelationextractionbyprojectingall
a seed KB with additional edges corresponding to Ope- languages to English using Google translate. However,
nIEpatternsobservedinthecorpus.Eveniftheuserdoes as explained in Section 2.3 the OpenIE paradigm is not
notseektopredictthesenewedges,ajointmodeloverall amenable to prediction within a fixed schema. Further,
edgescanexploitregularitiesoftheOpenIEedgestoim- their approach does not generalize to low-resource lan-
provemodelingofthelabelsfromthetargetschema. guages where translation is unavailable – while we use
The data still consist of (s,r,o) triples, which can be translationdictionariestoimproveourresults,ourexperi-
predicted using link-prediction techniques such as low- mentsdemonstratethatourmethodiseffectiveevenwith-
rank factorization. Riedel et al. (2013) explore a variety outthisresource.
of approximations to the 3-mode (s,r,o) tensor. One
suchprobabilisticmodelis: 3 Methods
   
P((s,r,o))=  u> v , (1)
s,o r 3.1 UniversalSchemaasSentenceClassifier
where ()isasigmoidfunction,u isanembedding Similartomanylinkpredictionapproaches,(Riedeletal.,
s,o
of the entity pair (s,o), and v is an embedding of the 2013) perform transductive learning, where a model is
r
relation r, which may be an OpenIE pattern or a rela- learned jointly over train and test data. Predictions are
tionfromthetargetschema. Alloftheexpositionandre- madebyusingthemodeltoidentifyedgesthatwereun-
sultsinthispaperusethisfactorization,thoughmanyof observed in the test data but likely to be true. The ap-
thetechniqueswepresentlatercouldbeappliedeasilyto proachisvulnerabletothecoldstart problemincollab-
888
Figure2: UniversalSchemajointlyembedsKBandtextualrelationsfromSpanishandEnglish,learningdenserepre-
sentationsforentitypairsandrelationsusingmatrixfactorization.Cellswitha1indicatetriplesobservedduringtrain-
ing(left). Theboldscorerepresentsatest-timepredictionbythemodel(right). UsingtransitivitythroughKB/English
overlap and English/Spanish overlap, our model can predict that a text pattern in Spanish evidences a KB relation
despitenooverlapbetweenSpanish/KBentitypairs. AttraintimeweuseBPRlosstomaximizetheinnerproductof
entitypairswithKBrelationsandtextpatternsencodedusingabidirectionalLSTM.Attesttimewescorecompati-
bilitybetweenembeddedKBrelationsandencodedtextualpatternsusingcosinesimilarity. InourSpanishmodelwe
treatembeddingsforasmallsetofEnglish/Spanishtranslationpairsasasingleword,e.g. casadoandmarried.
English Spanish
Input :
[per:spouse]
[María Múnera está casado con Juan M Santos]
.93
per:spouse ... per:born_in ... arg1 ‘s wife ar .g ..2 arg1 iw na s a rb go r 2n ... arg1 e es sl pa osa de arg .2 .. arg1 n ea nc i aó r g2 ... sic mo is li an re it y
Barack Obama/
Michelle Obama 1 1
Bernie Sanders/ 1 1 max pool
Jane O'Meara
María Múnera/ .93
Juan M Santos
...
bidirectional LSTM
Barack Obama/ 1 1
Hawaii
María Múnera/
1
Colombia per:spouse arg1 está casado/married con arg2
...
orative filtering (Schein et al., 2002): it is unclear how ing USchema to train a relation classifier that can take
to form predictions for unseen entity pairs, without re- arbitrarycontexttokens(Section2.3)asinput.
factorizingtheentirematrixorapplyingheuristics. Fortunately,thecoldstartproblemforcontexttokensis
In response, this paper re-purposes USchema as a morebenignthanthatofentitiessincewecanexploitsta-
means to train a sentence-level relation classifier, like tistical regularities of text: similar sequences of context
thoseinSection2.2. Thisallowsustoavoiderrorsfrom tokensshouldbeembeddedsimilarly. Therefore,follow-
aligningdistantsupervisiontothecorpus,butismorede- ingToutanovaetal.(2015),weembedrawcontexttokens
ployableforrealworldapplications. Italsoprovidesop- compositionallyusingadeeparchitecture. UnlikeRiedel
portunitiesinSection3.4toimprovemultilingualAKBC. etal.(2013),thisrequiresnomanualrulestomaptextto
Weproducepredictionsusingaverysimpleapproach: OpenIEpatternsandcanembedanypossibleinputstring.
(1) scan the corpus and extract a large quantity of ThemodifiedUSchemalikelihoodis:
triplets (s,r ,o), where r is an OpenIE pattern.    
text text P((s,r,o))=  u> Encoder(r) . (2)
For each triplet, if the similarity between the embed- s,o
ding of r and the embedding of a target relation Here, if r is raw text, then Encoder(r) is parameterized
text
r is above some threshold, we predict the triplet by a deep architecture. If r is from the target schema,
schema
(s,r ,o), and its provenance is the input sentence Encoder(r) is a produced by a lookup table (as in tradi-
schema
containing(s,r ,o). Werefertothistechniqueaspat- tionalUSchema). Thoughsuchanencoderincreasesthe
text
ternscoring. Inourexperiments, weusethecosinedis- computational cost of test-time prediction over straight-
tance between the vectors (Figure 2). In Section 7.3, forwardpatternmatching,evaluatingadeeparchitecture
we discuss details for how to make this distance well- canbedoneinlargebatchesinparallelonaGPU.
defined. Both convolutional networks (CNNs) and recurrent
networks (RNNs) are reasonable encoder architectures,
3.2 UsingaCompositionalSentenceEncoderto
and we consider both in our experiments. CNNs have
PredictUnseenTextPatterns
been useful in a variety of NLP applications (Col-
The pattern scoring approach is subject to an additional lobert et al., 2011; Kalchbrenner et al., 2014; Kim,
cold start problem: input data may contain patterns un- 2014). UnlikeToutanovaetal.(2015), wealsoconsider
seenintraining. Thissectiondescribesamethodforus- RNNs,specificallyLong-ShortTermMemoryNetworks
889
(LSTMs) (Hochreiter and Schmidhuber, 1997). LSTMs ableKBofseedfactsthathavesupportingevidenceinthe
have proven successful in a variety of tasks requiring corpus. Unfortunately, available KBs have low overlap
encoding sentences as vectors (Sutskever et al., 2014; withcorporainmanylanguages,sinceKBshavecultural
Vinyals et al., 2014). In our experiments, LSTMs out- and geographical biases. In response, we perform mul-
performCNNs. tilingual relation extraction by jointly modeling a high-
There are two key differences between our sentence resource language, such as English, and an alternative
encoder and that of Toutanova et al. (2015). First, we language with no KB annotation. This approach pro-
usetheencoderattesttime,sinceweprocessthecontext vides transfer learning of a predictive model to the al-
tokens for held-out data. On the other hand, Toutanova ternativelanguage,andgeneralizesnaturallytomodeling
et al. (2015) adopt the transductive approach where the morelanguages.
encoder is only used to help train better representations ExtendingthetrainingtechniqueofSection3.1tocor-
fortherelationsinthetargetschema; itisignoredwhen porainmultiplelanguagescanbeachievedbyfactorizing
formingpredictions.Second,weapplytheencodertothe amatrixthatmixesdatafromaKBandfromthetwocor-
raw text between entities, while Toutanova et al. (2015) pora. In Figure 1 we split the entities of a multilingual
first perform syntactic dependency parsing on the data trainingcorpusintosetsdependingonwhethertheyhave
and then apply an encoder to the path between the two annotationinaKBandwhatcorporatheyappearin. We
entitiesintheparsetree. Weavoidparsing,sinceweseek can perform transfer learning of a relation extractor to
toperformmultilingualAKBC,andmanylanguageslack thelow-resourcelanguageifthereareentitypairsoccur-
linguisticresourcessuchastreebanks. Evenparsingnon- ringinthetwocorpora,evenifthereisnoKBannotation
newswireEnglishtext,suchastweets,isextremelychal- for these pairs. Note that we do not use the entity pair
lenging. embeddings at test time: They are used only to bridge
thelanguagesduringtraining. Toformpredictionsinthe
3.3 ModelingFrequentTextPatterns low-resource language, we can simply apply the pattern
Despite the coverage advantages of using a deep sen- scoringapproachofSection3.1.
tence encoder, separately embedding each OpenIE pat- InSection5,wedemonstratethatjointlylearningmod-
tern, as in Riedel et al. (2013), has key advantages. In els for English and Spanish, with no annotation for the
practice, we have found that many high-precision pat- Spanish data, provides fairly accurate Spanish AKBC,
terns occur quite frequently. For these, there is suffi- andevenimprovestheperformanceoftheEnglishmodel.
cient data to model them with independent embeddings Note that we are not performing zero-shot learning of a
perpattern,whichimposesminimalinductivebiasonthe Spanish model (Larochelle et al., 2008). The relations
relationship between patterns. Furthermore, some dis- inthetargetschemaarelanguage-independentconcepts,
criminative phrases are idiomatic, i.e.. their meaning is andwehavesupervisionfortheseinEnglish.
not constructed compositionally from their constituents.
3.5 TiedSentenceEncoders
Forthese,asentenceencodermaybeinappropriate.
The sentence encoder approach of Section 3.2 is com-
Therefore, pattern embeddings and deep token-based
plementary to our multilingual modeling technique: we
encoders have very different strengths and weaknesses.
simply use a separate encoder for each language. This
One values specificity, and models the head of the text
approachissub-optimal,however,becauseeachsentence
distribution well, while the other has high coverage and
encoderwillhaveaseparatematrixofwordembeddings
capturesthetail. Inexperimentalresults,wedemonstrate
foritsvocabulary,despitethefactthattheremaybecon-
that an ensemble of both models performs substantially
siderable shared structure between the languages. In re-
betterthaneitherinisolation.
sponse, we propose a straightforward method for tying
3.4 MultilingualRelationExtractionwithZero theparametersofthesentenceencodersacrosslanguages.
Annotation Drawingonthedictionary-basedtechniquesdescribed
inSection2.5,wefirstobtainalistofword-wordtransla-
The models described in previous two sections provide
tionpairsbetweenthelanguagesusingatranslationdic-
broad-coveragerelationextractionthatcangeneralizeto
tionary. Thefirstlayerofourdeeptextencoderconsists
all possible input entities and text patterns, while avoid-
ofawordembeddinglookuptable. Forthealignedword
ingerror-pronealignmentofdistantsupervisiontoacor-
types, we use a single cross-lingual embedding. Details
pus. Next,wedescribetechniquesforanevenmorechal-
ofourapproacharedescribedinAppendix7.5.
lenginggeneralizationtask: relationclassificationforin-
putsentencesincompletelydifferentlanguages.
4 TaskandSystemDescription
Training a sentence-level relation classifier, either us-
ingthealignment-basedtechniquesofSection2.2,orthe We focus on the TAC KBP slot-filling task. Much re-
alignment-free method of Section 3.1, requires an avail- lated work on embedding knowledge bases evaluates on
890
theFB15kdataset(Bordesetal.,2013;Wangetal.,2014; entitymentionsfromourtextcorporatoaFreebaseentity
Linetal.,2015;Yangetal.,2015;Toutanovaetal.,2015). bythefollowingprocess: First,asetofcandidateentities
Here, relationextractionisposedaslinkpredictionona isobtainedbyfollowingfrequentlinkanchortextstatis-
subset of Freebase. This task does not capture the par- tics. We then select that candidate entity for which the
ticular difficulties we address: (1) evaluation on entities cosine similarity between the respective Wikipedia and
and text unseen during training, and (2) zero-annotation thesentencecontextofthementionishighest,andlinkto
learningofapredictorforalow-resourcelanguage. thatentityifathresholdisexceeded.
Also, note both Toutanova et al. (2015) and Riedel et An entity pair qualifies as a candidate prediction if it
al. (2013) explore the pros and cons of learning embed- meets the type criteria for the slot.2 The TAC 2013 En-
dings for entity pairs vs. separate embeddings for each glish and Spanish newswire corpora each contain about
entity. Asthisisorthogonaltoourcontributions,weonly 1 million newswire documents from 2009–2012. The
considerentitypairembeddings,whichperformedbestin document retrieval and entity matching components of
bothworkswhengivensufficientdata. ourrelationextractionpipelinearebasedonRelationFac-
tory(Rothetal.,2014),thetop-rankedsystemofthe2013
4.1 TACSlot-FillingBenchmark
Englishslot-fillingtask.WealsousetheEnglishdistantly
The aim of the TAC benchmark is to improve both cov- supervised training data from this system, which aligns
erage and quality of relation extraction evaluation com- theTAC2012corpustoFreebase. Moredetailsonalign-
paredtojustcheckingtheextractedfactsagainstaknowl- mentaredescribedinAppendix7.4.
edgebase,whichcanbeincompleteandwheretheprove- AsdiscussedinSection3.3,modelsusingadeepsen-
nancesarenotverified. Intheslot-fillingtask,eachsys- tenceencoderandusingapatternlookuptablehavecom-
tem is given a set of paired query entities and relations plementary strengths and weaknesses. In response, we
or ‘slots’ to fill, and the goal is to correctly fill as many presentresultswhereweensembletheoutputsofthetwo
slotsaspossiblealongwithprovenancefromthecorpus. modelsbysimplytakingtheunionoftheirindividualout-
Forexample,giventhequeryentity/relationpair(Barack puts. Slightly higher results might be obtained through
Obama,per:spouse),thesystemshouldreturntheentity moresophisticatedensemblingschemes.
Michelle Obama along with sentence(s) whose text ex-
presses that relation. The answers returned by all par- 4.3 ModelDetails
ticipating teams, along with a human search (with time-
All models are implemented in Torch (code publicly
out), are judged manually for correctness, i.e. whether
available3). Models are tuned to maximize F1 on the
theprovenancespecifiedbythesystemindeedexpresses
2012 TAC KBP slot-filling evaluation. We additionally
therelationinquestion.
tunethethresholdsofourpatternscoreronaper-relation
In addition to verifying our models on the 2013 and
basistomaximizeF1using2012TACslot-fillingforEn-
2014 English slot-filling task, we evaluate our Spanish
glish and the 2012 Spanish slot-filling development set
modelsonthe2012TACSpanishslot-fillingevaluation.
for Spanish. As in Riedel et al. (2013), we train using
BecausethisTACtrackwasneverofficiallyrun,thecov-
the BPR loss of Rendle et al. (2009). Our CNN is im-
erage of facts in the available annotation is very small,
plementedasdescribedinToutanovaetal.(2015),using
resulting in many correct predictions being marked in-
width-3convolutions,followedbytanhandmaxpoollay-
correctly as precision errors. In response, we manually
ers. The LSTM uses a bi-directional architecture where
annotatedallresultsreturnedbythemodelsconsideredin
theforwardandbackwardrepresentationsofeachhidden
Table4. Precisionandrecallarecalculatedwithrespect
state are averaged, followed by max pooling over time.
totheunionoftheTACannotationandournewlabeling1.
SeeSection7.2
We also report results including an alternate names
4.2 RetrievalPipeline
(AN)heuristic,whichusesautomatically-extractedrules
Our retrieval pipeline first generates all valid slot filler
to detect the TAC ‘alternate name’ relation. To achieve
candidates for each query entity and slot, based on en-
this, we collect frequent Wikipedia link anchor texts for
tities extracted from the corpus using FACTORIE (Mc-
Callum et al., 2009) to perform tokenization, segmenta-
2Duetothedifficultyofretrievalandentitydetection,themaximum
tion,andentityextraction. Weperformentitylinkingby recallforpredictionsislimited.Forthisreason,Surdeanuetal.(2012)
heuristicallylinkingallentitymentionsfromourtextcor- restrict the evaluation to answer candidates returned by their system
andeffectivelyrescalingrecall.Wedonotperformsuchare-scalingin
poratoaFreebaseentityusinganchortextinWikipedia.
ourEnglishresultsinordertocomparetootherreportedresults. Our
MakinguseofthefactthatmostFreebaseentriescontain
Spanishnumbersarerescaled.Allscoresreflectthe‘anydoc’(relaxed)
a link to the corresponding Wikipedia page, we link all scoringtomitigatepenalizingeffectsforsystemsnotincludedinthe
evaluationpool.
1FollowingSurdeanuetal.(2012)weremovefactsaboutundiscov- 3https://github.com/patverga/
eredentitiestocorrectforrecall. torch-relation-extraction
891
Model Recall Precision F1 Model Recall Precision F1
CNN 31.6 36.8 34.1 LSTM 9.3 12.5 10.7
LSTM 32.2 39.6 35.5 LSTM+Dict 14.7 15.7 15.2
USchema 29.4 42.6 34.8 USchema 15.2 17.5 16.3
USchema+LSTM 34.4 41.9 37.7 USchema+LSTM 21.7 14.5 17.3
USchema+LSTM+Es 38.1 40.2 39.2 USchema+LSTM+Dict 26.9 15.9 20.0
USchema+LSTM+AN 36.7 43.1 39.7 Table 4: Zero-annotation transfer learning F1 scores on
USchema+LSTM+Es+AN 40.2 41.2 40.7 2012SpanishTACKBPslot-fillingtask. Addingatrans-
Rothetal.(2014) 35.8 45.7 40.2 lationdictionaryimprovesallencoder-basedmodels.En-
Table 2: Precision, recall and F1 on the English TAC semblingLSTMandUSchemamodelsperformsthebest.
2013 slot-filling task. AN refers to alternative names
heuristic and Es refers to the addition of Spanish text at
train time. LSTM+USchema ensemble outperforms any
single model, including the highly-tuned top 2013 sys- 5.1 EnglishTACSlot-fillingResults
tem of Roth et al. (2014), despite using no handwritten
patterns.
Tables 2 and 3 present the performance of our models
on the 2013 and 2014 English TAC slot-filling tasks.
Model Recall Precision F1 Ensembling the LSTM and USchema models improves
CNN 28.1 29.0 28.5 F1 by 2.2 points for 2013 and 1.7 points for 2014 over
LSTM 27.3 32.9 29.8 the strongest single model on both evaluations, LSTM.
USchema 24.3 35.5 28.8 Adding the alternative names (AN) heuristic described
in Section 4.3 increases F1 by an additional 2 points on
USchema+LSTM 34.1 29.3 31.5
2013, resulting in an F1 score that is competitive with
USchema+LSTM+Es 34.4 31.0 32.6
the state-of-the-art. We also demonstrate the effect of
Table 3: Precision, recall and F1 on the English TAC
jointly learning English and Spanish models on English
2014 slot-filling task. Es refers to the addition of Span-
slot-filling performance. Adding Spanish data improves
ish text at train time. The AN heuristic is ineffective on
ourF1scoresby1.5pointson2013and1.1on2014over
2014addingonly0.2toF1. Oursystemwouldrank4/18
usingEnglish alone. Thisplacesare systemhigherthan
intheofficialTAC2014competitionbehindsystemsthat
the top performer at the 2013 TAC slot-filling task even
usehand-writtenpatternsandactivelearningdespiteour
thoughoursystemusesnohand-writtenrules.
systemusingneitheroftheseadditionalannotations(Sur-
deanuandJi.,2014). The state of the art systems on this task all rely on
matchinghandwrittenpatternstofindadditionalanswers
whileourmodelsuseonlyautomaticallygenerated,indi-
each query entity. If a high probability anchor text co-
rectsupervision;evenourANheuristics(Section4.2)are
occurswiththecanonicalnameofthequeryinthesame
automaticallygenerated. Thetoptwo2014systemswere
document,wereturntheanchortextasaslotfiller.
Angeli et al. (2014) and RPI Blender (Surdeanu and Ji.,
2014) who achieved F1 scores of 39.5 and 36.4 respec-
tively.Bothofthesesystemsusedadditionalactivelearn-
5 ExperimentalResults
ing annotation. The third place team (Lin et al., 2014)
reliedonhighlytunedpatternsandrulesandachievedan
In experiments on the English and Spanish TAC KBC
F1scoreof34.4.
slot-fillingtasks, wefindthatbothUSchemaandLSTM
models outperform the CNN across languages, and that Ourmodelperformssubstantiallybetteron2013than
theLSTMtendstoperformslightlybetterthanUSchema 2014 for two reasons. First, our RelationFactory (Roth
astheonlymodel. EnsemblingtheLSTMandUSchema etal.,2014)retrievalpipelinewasatopretrievalpipeline
models further increases final F1 scores in all experi- onthe2013task,butwasoutperformedonthe2014task
ments, suggesting that the two different types of model whichintroducednewchallengessuchasconfusableen-
compliment each other well. Indeed, in Section 5.3 we tities. Second, improved training using active learning
presentquantitativeandqualitativeanalysisofourresults gave the top 2014 systems a boost in performance. No
which further confirms this hypothesis: the LSTM and 2013systems,includingours,useactivelearning. Bentor
USchemamodelseachperformbetterondifferentpattern et al. (2014), the 4th place team in the 2014 evaluation,
lengthsandarecharacterizedbydifferentprecision-recall usedthesameretrievalpipeline(Rothetal.,2014)asour
tradeoffs. modelandachievedanF1scoreof32.1.
892
LSTM+USchema: Recallvs. Precision CEO
0.7
Dictionary NoTies
LSTM
jefe(chief) CEO
0.6 USchema
CEO director(principle)
ejecutivo(executive) directora(director)
0.5
cofundador(co-founder) firma(firm)
president(chairman) magnate(tycoon)
0.4
headquartered
Dictionary NoTies
0.3
sede(headquarters) Geolo´gico(Geological)
situado(located) Treki(Treki)
0.2
selectivo(selective) Geof´ısico(geophysical)
profesional(vocational) Normand´ıa(Normandy)
0.1
basa´ndose(based) emplea(uses)
0.1 0.2 0.3 0.4 0.5 hubby
Recall Dictionary NoTies
Figure 3: Precision-Recall curves for USchema and matrimonio(marriage) esposa(wife)
LSTM on 2013 TAC slot-filling. USchema achieves casada(married) esposo(husband)
esposa(wife) casada(married)
higherprecisionvalueswhereasLSTMhashigherrecall.
caso´(married) embarazada(pregnant)
embarazada(pregnant) embarazo(pregnancy)
alias
Dictionary NoTies
5.2 SpanishTACSlot-fillingResults simplificado(simplified) Weaver(Weaver)
Table4presents2012SpanishTACslot-fillingresultsfor sabido(known) interrogacio´n(question)
seudo´nimo(pseudonym) alias
our multilingual relation extractors trained using zero-
privatizacio´n(privatization) reelecto(reelected)
annotationtransferlearning. Tyingwordembeddingsbe-
nombre(name) conocido(known)
tween the two languages results in substantial improve-
Table5:ExampleEnglishquerywords(notintranslation
ments for the LSTM. We see that ensembling the non-
dictionary)inboldwiththeirtopnearestneighborsbyco-
dictionary LSTM with USchema gives a slight boost
sinesimilaritylistedforthedictionaryandnotiesLSTM
overUSchemaalone,butensemblingthedictionary-tied
variants. Dictionary-tied nearest neighbors are consis-
LSTM with USchema provides a significant increase of
tentlymorerelevanttothequerywordthanuntied.
nearly4F1pointsoverthehighest-scoringsinglemodel,
USchema. Clearly, grounding the Spanish data using a
translationdictionaryprovidesmuchbetterSpanishword
LSTM+USchemaF1: VaryingPatternLength
representations.Theseimprovementsarecomplementary 0.35
tothebaselineUSchemamodel,andyieldimpressivere- LSTM
0.30
sultswhenensembled. USchema
Inadditiontoembeddingsemanticallysimilarphrases 0.25
from English and Spanish to have high similarity, our
modelsalsolearnhigh-qualitymultilingualwordembed- 0.20
dings. InTable5wecompareSpanishnearestneighbors
0.15
ofEnglishquerywordslearnedbytheLSTMwithdictio-
narytiesversustheLSTMwithnoties,usingnounsuper-
0.10
vised pre-training for the embeddings. Both approaches
jointly embed Spanish and English word types, using 0.05
shared entity embeddings, but the dictionary-tied model
0.00
learnsqualitativelybettermultilingualembeddings. <3 <5  5  10
PatternLength
5.3 USchemavsLSTM
Figure 4: F1 achieved by USchema vs. LSTM mod-
We further analyze differences between USchema and
els for varying pattern token lengths on 2013 TAC slot-
LSTM in order to better understand why ensembling
filling.LSTMperformsbetteronlongerpatternswhereas
the models results in the best performing system. Fig-
USchemaperformsbetteronshorterpatterns.
ure 3 depicts precision-recall curves for the two mod-
els on the 2013 slot-filling task. As observed in earlier
results, the LSTM achieves higher recall at the loss of
893
noisicerP
1F
some precision, whereas USchema can make more pre- 6 Conclusion
cise predictions at a lower threshold for recall. In Fig-
ByjointlyembeddingEnglishandSpanishcorporaalong
ure 4 we observe evidence for these different precision-
withaKB,wecantrainanaccurateSpanishrelationex-
recall trade-offs: USchema scores higher in terms of F1
tractionmodelusingnodirectannotationforrelationsin
on shorter patterns whereas the LSTM scores higher on
theSpanishdata. Thisapproachhastheaddedbenefitof
longerpatterns. Asonewouldexpect,USchemasuccess-
providingsignificantaccuracyimprovementsfortheEn-
fully matches more short patterns than the LSTM, mak-
glish model, outperforming the top system on the 2013
ing more precise predictions at the cost of being unable
TACKBCslotfillingtask,withoutusingthehand-coded
topredictonpatternsunseenduringtraining. TheLSTM
rulesoradditionalannotationsofalternativesystems. By
can predict using any text between entities observed at
usingdeepsentenceencoders,wecanperformprediction
testtime,gainingrecallatthelossofprecision. Combin-
for arbitrary input text and for entities unseen in train-
ingthetwomodelsmakesthemostoftheirstrengthsand
ing.Sentenceencodersalsoprovidesopportunitiestoim-
weaknesses,leadingtothehighestoverallF1.
provecross-lingualtransferlearningbysharingwordem-
Qualitative analysis of our English models also sug-
beddingsacrosslanguages. Infutureworkwewillapply
gests that our encoder-based models (LSTM) extract re-
thismodeltomanymorelanguagesanddomainsbesides
lations based on a wide range of semantically similar
newswiretext. Wewouldalsoliketoavoidtheentityde-
patterns that the pattern-matching model (USchema) is
tectionproblembyusingadeeparchitecturetobothiden-
unable to score due to a lack of exact string match in
tifyentitymentionsandidentifyrelationsbetweenthem.
the test data. For example, Table 6 lists three exam-
ples of the per:children relation that the LSTM finds Acknowledgments
which USchema does not, as well as three patterns that Many thanks to Arvind Neelakantan for good ideas
USchema does find. Though the LSTM patterns are all and discussions. We also appreciate a generous hard-
semanticallyandsyntacticallysimilar,theyeachcontain ware grant from nVidia. This work was supported
different specific noun phrases, e.g. Lori, four children, in part by the Center for Intelligent Information Re-
toddlerdaughter,LeeandAlbert,etc.Becausethesespe- trieval, in part by Defense Advanced Research Projects
cific nouns weren’t seen during training, USchema fails Agency(DARPA)underagreement#FA8750-13-2-0020
tofindthesepatternswhereastheLSTMlearnstoignore andcontract#HR0011-15-2-0036,andinpartbytheNa-
the specific nouns in favor of the overall pattern, that tional Science Foundation (NSF) grant numbers DMR-
of a parent-child relationship in an obituary. USchema 1534431, IIS-1514053 and CNS-0958392. The U.S.
is limited to finding the relations represented by pat- Government is authorized to reproduce and distribute
terns observed during training, which limits the patterns reprintsforGovernmentalpurposesnotwithstandingany
matched at test-time to short and common patterns; all copyright notation thereon, in part by DARPA via
the USchema patterns matched at test time were similar agreement #DFA8750-13-2-0020 and NSF grant #CNS-
tothoselistedinTable6: variantsof’sson,’. 0958392. Anyopinions,findingsandconclusionsorrec-
ommendationsexpressedinthismaterialarethoseofthe
LSTM authors and do not necessarily reflect those of the spon-
McGregorissurvivedbyhiswife,Lori,andfourchildren, sor.
daughtersJordan, TaylorandLandri,andason,Logan.
Inadditiontohiswife,Maysissurvivedbyatoddlerdaugh-
terandason,BillyMaysJr.,whoisinhis20s. References
AndersonissurvivedbyhiswifeCarol,sonsLeeandAlbert,
[Angelietal.2014] Gabor Angeli, Sonal Gupta, Melvin Jose,
daughterShirleyEnglebrechtandninegrandchildren.
Christopher D Manning, Christopher Re´, Julie Tibshirani,
USchema
JeanYWu,SenWu,andCeZhang. 2014. Stanfords2014
Dio’sson, DanPadavona, cautionedthememorialcrowd
slotfillingsystems. TACKBP.
tobescreenedregularlybyadoctorandtakecareofthem-
[Bankoetal.2007] Michele Banko, Michael J Cafarella,
selves,somethinghesaidhisfatherdidnotdo.
Stephen Soderland, Matt Broadhead, and Oren Etzioni.
ButMarshall’sson,Philip,toldadifferentstory.
2007. Open information extraction from the web. In
“I’dratherhaveSullydoingthisthansomestranger,orsome
InternationalJointConferenceonArtificialIntelligence.
hotshottryingtobethenextBillyMays,”saidtheguywho
[Bentoretal.2014] Yinon Bentor, Vidhoon Viswanathan, and
actuallyisthenextBillyMays,hissonBillyMaysIII.
RaymondMooney. 2014. Universityoftexasataustinkbp
Table6:Examplesoftheper:childrenrelationdiscovered 2014 slot filling system: Bayesian logic programs for tex-
by the LSTM and Universal Schema. Entities are bold tualinference. InProceedingsoftheSeventhTextAnalysis
andpatternsitalicized. TheLSTMmodelsarichersetof Conference:KnowledgeBasePopulation(TAC2014).
patterns [Bollackeretal.2008] Kurt Bollacker, Colin Evans, Praveen
Paritosh,TimSturge,andJamieTaylor. 2008. Freebase: a
894
collaborativelycreatedgraphdatabaseforstructuringhuman [HochreiterandSchmidhuber1997] SeppHochreiterandJu¨rgen
knowledge. InProceedingsoftheACMSIGMODInterna- Schmidhuber. 1997. Long short-term memory. In Neural
tionalConferenceonManagementofData. Computation.
[Bordesetal.2013] Antoine Bordes, Nicolas Usunier, Alberto [Hoffmannetal.2011] RaphaelHoffmann,CongleZhang,Xiao
Garc´ıa-Dura´n,JasonWeston,andOksanaYakhnenko. 2013. Ling, Luke Zettlemoyer, and Daniel S Weld. 2011.
Translating embeddings for modeling multi-relational data. Knowledge-basedweaksupervisionforinformationextrac-
InAdvancesinNeuralInformationProcessingSystems. tionofoverlappingrelations. InProceedingsofthe49thAn-
[Bordesetal.2014] Antoine Bordes, Sumit Chopra, and Jason nualMeetingoftheAssociationforComputationalLinguis-
Weston. 2014. Questionansweringwithsubgraphembed- tics: HumanLanguageTechnologies-Volume1,pages541–
dings. arXivpreprintarXiv:1406.3676. 550.AssociationforComputationalLinguistics.
[BunescuandMooney2007] Razvan Bunescu and Raymond [Kalchbrenneretal.2014] Nal Kalchbrenner, Edward Grefen-
Mooney. 2007. Learningtoextractrelationsfromtheweb stette, and Phil Blunsom. 2014. A convolutional neural
using minimal supervision. In Annual meeting-association network for modelling sentences. Proceedings of the 52nd
forComputationalLinguistics,volume45,page576. Annual Meeting of the Association for Computational Lin-
[Carlsonetal.2010] Andrew Carlson, Justin Betteridge, Bryan guistics,June.
Kisiel, Burr Settles, Estevam R. Hruschka, and A. 2010. [Kim2014] Yoon Kim. 2014. Convolutional neural networks
Towardanarchitecture fornever-endinglanguagelearning. forsentenceclassification. EMNLP.
InInAAAI. [KingmaandBa2015] DiederikKingmaandJimmyBa. 2015.
Adam: Amethodforstochasticoptimization. In3rdInter-
[Collobertetal.2011] Ronan Collobert, Jason Weston, Le´on
nationalConferenceforLearningRepresentations(ICLR).
Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel
[Koehn2005] PhilippKoehn. 2005. Europarl:Aparallelcorpus
Kuksa. 2011. Natural language processing (almost)
forstatisticalmachinetranslation. InMTsummit,volume5,
from scratch. The Journal of Machine Learning Research,
pages79–86.Citeseer.
12:2493–2537.
[Laoetal.2011] NiLao,TomMitchell,andWilliamW.Cohen.
[dosSantosetal.2015] Cıcero Nogueira dos Santos, Bing Xi-
2011. Randomwalkinferenceandlearninginalargescale
ang,andBowenZhou. 2015. Classifyingrelationsbyrank-
knowledge base. In Conference on Empirical Methods in
ing with convolutional neural networks. In Proceedings of
NaturalLanguageProcessing.
the 53rd Annual Meeting of the Association for Computa-
[Laoetal.2012] Ni Lao, Amarnag Subramanya, Fernando
tionalLinguisticsandthe7thInternationalJointConference
Pereira,andWilliamW.Cohen. 2012. Readingthewebwith
onNaturalLanguageProcessing,volume1,pages626–634.
learnedsyntactic-semanticinferencerules. InJointConfer-
[Etzionietal.2008] Oren Etzioni, Michele Banko, Stephen
enceonEmpiricalMethodsinNaturalLanguageProcessing
Soderland, and Daniel S Weld. 2008. Open information
andComputationalNaturalLanguageLearning.
extraction from the web. Communications of the ACM,
[Larochelleetal.2008] Hugo Larochelle, Dumitru Erhan, and
51(12):68–74.
YoshuaBengio. 2008. Zero-datalearningofnewtasks. In
[FaruquiandKumar2015] ManaalFaruquiandShankarKumar.
NationalConferenceonArtificialIntelligence.
2015. Multilingual open relation extraction using cross-
[Lietal.2015] JiweiLi,DanJurafsky,andEudardHovy. 2015.
lingualprojection. arXivpreprintarXiv:1503.06450.
Whenaretreestructuresnecessaryfordeeplearningofrep-
[Faruquietal.2014] Manaal Faruqui, Jesse Dodge, Sujay K
resentations? arXivpreprintarXiv:1503.00185.
Jauhar, Chris Dyer, Eduard Hovy, and Noah A Smith.
[Linetal.2014] Hailun Lin, Zeya Zhao, Yantao Jia, Yuanzhuo
2014. Retrofittingwordvectorstosemanticlexicons. arXiv
Wang, Jinhua Xiong, and Xiaojing Li. 2014. OpenKN at
preprintarXiv:1411.4166.
TACKBP2014.
[Garc´ıa-Dura´netal.2015] Alberto Garc´ıa-Dura´n, Antoine Bor- [Linetal.2015] YankaiLin, ZhiyuanLiu, MaosongSun, Yang
des,NicolasUsunier,andYvesGrandvalet. 2015. Combin- Liu,andXuanZhu. 2015. Learningentityandrelationem-
ing two and three-way embeddings models for link predic- beddingsforknowledgegraphcompletion. InProceedings
tioninknowledgebases. CoRR,abs/1506.00999. ofAAAI.
[Gardneretal.2014] MattGardner,ParthaTalukdar,JayantKr- [Luongetal.2015] Thang Luong, Hieu Pham, and Christo-
ishnamurthy,andTomMitchell. 2014. Incorporatingvector pherDManning. 2015. Bilingualwordrepresentationswith
space similarity in random walk inference over knowledge monolingualqualityinmind. InProceedingsofthe1stWork-
bases. InEmpiricalMethodsinNaturalLanguageProcess- shoponVectorSpaceModelingforNaturalLanguagePro-
ing. cessing,pages151–159.
[Gouwsetal.2015] Stephan Gouws, Yoshua Bengio, and Greg [McCallumetal.2009] Andrew McCallum, Karl Schultz, and
Corrado. 2015. B IL BOWA : Fast Bilingual Distributed Sameer Singh. 2009. FACTORIE: Probabilistic program-
RepresentationswithoutWord Alignments. Icml, pages1– mingviaimperativelydefinedfactorgraphs. InNeuralIn-
10. formationProcessingSystems(NIPS).
[Guetal.2015] KelvinGu,JohnMiller,andPercyLiang. 2015. [Mikolovetal.2013] Tomas Mikolov, Quoc V Le, and Ilya
Traversingknowledgegraphsinvectorspace. arXivpreprint Sutskever. 2013. Exploiting Similarities among Lan-
arXiv:1506.01094. guages for Machine Translation. In arXiv preprint
[HermannandBlunsom2014] Karl Moritz Hermann and Phil arXiv:1309.4168v1,pages1–10.
Blunsom. 2014. Multilingualmodelsforcompositionaldis- [Minetal.2013] Bonan Min, Ralph Grishman, Li Wan, Chang
tributedsemantics. arXivpreprintarXiv:1404.4641. Wang, and David Gondek. 2013. Distant supervision for
895
relation extraction with an incomplete knowledge base. In knowledgebasepopulationevaluation. Proc.TextAnalysis
HLT-NAACL,pages777–782. Conference(TAC2014).
[Mintzetal.2009] Mike Mintz, Steven Bills, Rion Snow, and [Surdeanuetal.2012] MihaiSurdeanu,JulieTibshirani,Ramesh
DanJurafsky. 2009. Distantsupervisionforrelationextrac- Nallapati, and Christopher D Manning. 2012. Multi-
tionwithoutlabeleddata. InAssociationforComputational instancemulti-labellearningforrelationextraction. InPro-
Linguistics and International Joint Conference on Natural ceedingsofthe2012JointConferenceonEmpiricalMethods
LanguageProcessing. inNaturalLanguageProcessingandComputationalNatural
[Neelakantanetal.2015] Arvind Neelakantan, Benjamin Roth, Language Learning, pages 455–465. Association for Com-
andAndrewMcCallum. 2015. Compositionalvectorspace putationalLinguistics.
modelsforknowledgebasecompletion. Proceedingsofthe [Sutskeveretal.2014] Ilya Sutskever, Oriol Vinyals, and Quoc
53rdAnnualMeetingoftheAssociationforComputational V. V Le. 2014. Sequence to sequence learning with neu-
Linguistics. ralnetworks. InAdvancesinNeuralInformationProcessing
[Nickeletal.2011] MaximilianNickel,VolkerTresp,andHans- Systems.
PeterKriegel. 2011. Athree-waymodelforcollectivelearn- [Toutanovaetal.2015] KristinaToutanova,DanqiChen,Patrick
ingonmulti-relationaldata. InInternationalConferenceon Pantel,HoifungPoon,PallaviChoudhury,andMichaelGa-
MachineLearning. mon. 2015. Representing text for joint embedding of text
[Nickeletal.2015] Maximilian Nickel, Kevin Murphy, Volker andknowledgebases. InEmpiricalMethodsinNaturalLan-
Tresp, and Evgeniy Gabrilovich. 2015. A review of rela- guageProcessing(EMNLP).
tionalmachinelearningforknowledgegraphs: Frommulti- [Vinyalsetal.2014] Oriol Vinyals, Lukasz Kaiser, Terry Koo,
relationallinkpredictiontoautomatedknowledgegraphcon- Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. 2014.
struction. arXivpreprintarXiv:1503.00759. Grammarasaforeignlanguage. InCoRR.
[Rendleetal.2009] Steffen Rendle, Christoph Freudenthaler, [Wangetal.2014] Zhen Wang, Jianwen Zhang, Jianlin Feng,
Zeno Gantner, and Lars Schmidt-Thieme. 2009. Bpr: and Zheng Chen. 2014. Knowledge graph embedding by
Bayesian personalized ranking from implicit feedback. In translating on hyperplanes. In Proceedings of the Twenty-
ProceedingsoftheTwenty-FifthConferenceonUncertainty Eighth AAAI Conference on Artificial Intelligence, pages
inArtificialIntelligence,pages452–461.AUAIPress. 1112–1119.Citeseer.
[Riedeletal.2010] Sebastian Riedel, Limin Yao, and Andrew [Xuetal.2015] YanXu,LiliMou,GeLi,YunchuanChen,Hao
McCallum. 2010. Modeling relations and their mentions Peng,andZhiJin. 2015. Classifyingrelationsvialongshort
withoutlabeledtext. InMachineLearningandKnowledge termmemorynetworksalongshortestdependencypaths. In
DiscoveryinDatabases,pages148–163.Springer. ProceedingsofConferenceonEmpiricalMethodsinNatural
[Riedeletal.2013] Sebastian Riedel, Limin Yao, Andrew Mc- LanguageProcessing(toappear).
Callum,andBenjaminM.Marlin. 2013. Relationextraction [Yangetal.2015] Bishan Yang, Wen-tau Yih, Xiaodong He,
with matrix factorization and universal schemas. In HLT- JianfengGao,andLiDeng. 2015. Embeddingentitiesand
NAACL. relationsforlearningandinferenceinknowledgebases. In-
[Rocktascheletal.2015] Tim Rocktaschel, Sameer Singh, and ternationalConferenceonLearningRepresentations2014.
Sebastian Riedel. 2015. Injecting logical background [Yaoetal.2010] LiminYao,SebastianRiedel,andAndrewMc-
knowledge into embeddings for relation extraction. In An- Callum. 2010. Collective cross-document relation extrac-
nualConferenceoftheNorthAmericanChapteroftheAsso- tionwithoutlabelleddata. InProceedingsofthe2010Con-
ciationforComputationalLinguistics(NAACL). ferenceonEmpiricalMethodsinNaturalLanguageProcess-
[Rothetal.2014] Benjamin Roth, Tassilo Barth, Grzegorz ing, pages 1013–1023. Association for Computational Lin-
Chrupała,MartinGropp,andDietrichKlakow. 2014. Rela- guistics.
tionfactory:Afast,modularandeffectivesystemforknowl- [Yaoetal.2013] LiminYao,SebastianRiedel,andAndrewMc-
edgebasepopulation. EACL2014,page89. Callum. 2013. Universalschemaforentitytypeprediction.
[Scheinetal.2002] Andrew I Schein, Alexandrin Popescul, InProceedingsofthe2013workshoponAutomatedknowl-
LyleHUngar,andDavidMPennock. 2002. Methodsand edgebaseconstruction,pages79–84.ACM.
metrics for cold-start recommendations. In Proceedings of [YatesandEtzioni2007] Alexander Yates and Oren Etzioni.
the25thannualinternationalACMSIGIRconferenceonRe- 2007. Unsupervised resolution of objects and relations on
searchanddevelopmentininformationretrieval,pages253– theweb. InNorthAmericanChapteroftheAssociationfor
260.ACM. ComputationalLinguistics.
[Socheretal.2013] RichardSocher,DanqiChen,ChristopherD [Zengetal.2015] DaojianZeng,KangLiu,YuboChen,andJun
Manning,andAndrewNg. 2013. Reasoningwithneuralten- Zhao. 2015. Distantsupervisionforrelationextractionvia
sornetworksforknowledgebasecompletion. InAdvancesin piecewiseconvolutionalneuralnetworks. EMNLP.
NeuralInformationProcessingSystems.
[Suchaneketal.2007] Fabian M. Suchanek, Gjergji Kasneci,
and Gerhard Weikum. 2007. Yago: A core of semantic
knowledge. In Proceedings of the 16th International Con-
ferenceonWorldWideWeb.
[SurdeanuandJi.2014] Mihai Surdeanu and Heng Ji. 2014.
Overview of the english slot filling track at the tac2014
896
