Dr.Quad at MEDIQA 2019: Towards Textual Inference
and Question Entailment using contextualized representations
VinayshekharBannihattiKumar∗ AshwinSrinivasan∗ AditiChaudhary∗
JamesRoute TerukoMitamura EricNyberg
{vbkumar,ashwinsr,aschaudh,jroute,teruko,ehn}@cs.cmu.edu
LanguageTechnologiesInstitute
CarnegieMellonUniversity
Abstract the efficacy of learning universal language repre-
sentations in providing a decent warm start to a
This paper presents the submissions by Team
task-specific model, by leveraging large amounts
Dr.QuadtotheACL-BioNLP2019sharedtask
ofunlabeleddata. MT-DNNusesBERTastheen-
onTextualInferenceandQuestionEntailment
coderandusesMTLtofine-tunethemultipletask-
in the Medical Domain. Our system is based
specific layers. This model has obtained state-
onthepriorworkLiuetal.(2019)whichuses
a multi-task objective function for textual en- of-the-art results on several natural language un-
tailment. In this work, we explore different derstanding tasks such as SNLI (Bowman et al.,
strategiesforgeneralizingstate-of-the-artlan- 2015),SciTail(Khotetal.,2018)andhenceforms
guageunderstandingmodelstothespecialized the basis of our approach. For the task 3, we use
medicaldomain.Ourresultsonthesharedtask
a simple model to combine the task 1 and task 2
demonstratethatincorporatingdomainknowl-
modelsasshownin§2.5.
edge through data augmentation is a power-
fulstrategyforaddressingchallengesposedby As discussed above, state-of-the-art models us-
specializeddomainssuchasmedicine.
ing deep neural networks have shown significant
performancegainsacrossvariousnaturallanguage
1 Introduction
processing (NLP) tasks. However, their general-
TheACL-BioNLP2019(BenAbachaetal.,2019) izationtospecializeddomainssuchasthemedical
shared task focuses on improving the following domain still remains a challenge. Romanov and
three tasks for medical domain: 1) Natural Lan- Shivade (2018) introduce a new dataset MedNLI,
guage Inference (NLI) 2) Recognizing Question a natural language inference dataset for the med-
Entailment(RQE)and3)Question-Answeringre- ical domain and show the importance of incor-
ranking system. Our team has made submissions porating domain-specific resources. Inspired by
toallthethreetasks. Wenotethatinthisworkwe their observations, we explore several techniques
focus more on the task 1 and task 2 as improve- of augmenting domain-specific features with the
mentsinthesetwotasksreflectdirectlyonthetask state-of-the-art methods. We hope that the deep
3. However, as per the shared task guidelines, we neural networks will help the model learn about
dosubmitonemodelforthetask3tocompleteour thetaskitselfandthedomain-specificfeatureswill
submission. assist the model in tacking the issues associated
Our approach for both task 1 and task 2 is with such specialized domains. For instance, the
based on the state-of-the-art natural language un- medicaldomainhasadistinctsublanguage(Fried-
derstanding model MT-DNN (Liu et al., 2019), man et al., 2002) and it presents challenges such
which combines the strength of multi-task learn- as abbreviations, inconsistent spellings, relation-
ing(MTL)andlanguagemodelpre-training. MTL shipbetweendrugs,diseases,symptoms.
in deep networks has shown performance gains
Our resulting models perform fairly on the un-
when related tasks are trained together resulting
seen test data of the ACL-MediQA shared task.
in better generalization to new domains (Ruder,
On Task 1, our best model achieves +14.1 gain
2017). RecentworkssuchasBERT(Devlinetal.,
abovethebaseline. OnTask2,ourfive-modelen-
2018), ELMO (Peters et al., 2018) have shown
semble achieved +12.6 gain over the baseline and
∗ equalcontribution forTask3ourmodelachievesaa+4.9gain.
2 Approach Train Validation Test
Entailment 3744 465 474
In this section, we first present our base model
Contradiction 3744 465 474
MT-DNN(Liuetal.,2019)whichweuseforboth
Neutral 3744 465 474
Task 1 and Task 2 followed by a discussion on
thedifferentapproachestakenfornaturallanguage
Table1: Thenumberoftrainandtestinstancesineach
inference (NLI) (§2.3), recognizing question en-
ofthecategoriesoftheNLIdataset.
tailment (RQE) (§2.4) and question answer (QA)
(§2.5).
Encoder: Following BERT (Devlin et al.,
Post-Process 2018), each sentence pair is separated by a [SEP]
token. Itisthenpassedthroughalexiconencoder
Dataset Prior Ensemble
which represents each token as a continuous rep-
resentation of the word, segment and positional
Pairwise Text NLI / RQE
Classification embeddings. A multi-layer bi-directional trans-
Model RQE only
former encoder (Vaswani et al., 2017) transforms
BERT Encoder NLI only
theinputtokenrepresentationsintothecontextual
embedding vectors. This encoder is then shared
acrossmultipletasks.
Data Pre-Processing Data Augmentation
Decoder: We use the Pairwise text classifica-
Pre-Process tion output layer (Liu et al., 2019) as our de-
Premise / CHQ Hypothesis / FAQ coder. Given a sentence pair (a,b), the above
encoder first encodes them into u and v respec-
Figure1: SystemoverviewforNLIandRQEtask
tively. Then a K-step reasoning is performed
.
on these representations to predict the final label.
(cid:80)
The initial state is given by s = α u where
j j j
2.1 Task1andTask2Formulation
exp(wTu )
α = j . Onsubsequentiterationsk ∈
Formally, we define the problem of textual j (cid:80) iexp(w1Tu i)
[1,K−1],thestateissk = GRU(sk−1,xk)where
entailment as a multi-class classification task.
x = (cid:80) β v and β = softmax(s w Tv).
Given two sentences a =a 1,a 2...,a n and b = k j j j j k−1 2
Then a single-layer classifier predicts the label at
b ,b ,...,b , the task is to predict the correct la-
1 2 m
eachiterationk:
bel. For NLI, a refers to the Premise and b refers
to the Hypothesis and the label set comprises of
Pk = softmax(w T[sk;xk;|sk −xk|;sk.xk])
entailment, neutral, contradiction. For RQE, a 3
referstotheCHQandbreferstotheFAQandthe
Finally, all the scores across the K iterations are
labelsetcomprisesofTrue,False.
averagedforthefinalprediction. Wenowdescribe
2.2 ModelArchitecture the modifications made to this model for each re-
spectivetask.
A brief depiction of our system is shown in Fig-
ure1. Werepresentcomponentswhichwereused
2.3 NaturalLanguageInference
for both NLI and RQE in Orange. An exam-
Thistaskconsistsofidentifyingthreeinferencere-
ple of this is the Data Pre-processing component.
lations between two sentences: Entailment, Neu-
The RQE only components are shown in yellow
tralandContradiction
(eg. DataAugmentation). Thecomponentswhich
wereusedonlyfortheNLImodulesareshownin
Data: ThedataisbasedofftheMedNLIdataset
Pink (eg. Dataset Prior). We base our model on
introduced by Romanov and Shivade (2018). The
thestate-of-the-artnaturallanguageunderstanding
statisticsofthedatasetcanbeseeninTable1.
model MT-DNN (Liu et al., 2019). MT-DNN is
a hierarchical neural network model which com- Data Pre-Processing: On manual inspection of
bines the advantages of both multi-task learning thedata,weobservethepresenceofabbreviations
and pre-trained language models. Below we de- inthepremiseandhypothesis. Sincelexicalover-
scribethedifferentcomponentsindetail. lapisastrongindicatorofentailmentbyvirtueof
pre-trainedembeddingsonlargecorpora,thepres- that local context should get preference while ex-
enceofabbreviationsmakesitchallenging. There- pandingtheabbreviation.
fore, we expand the abbreviations using the fol-
TrainingProcedure: FortrainingtheMT-DNN
lowingtwostrategies:
model, we use the same hyper-parameters pro-
vided by the authors (Liu et al., 2019). We train
1. Local Context: We observe that often an ab-
modelfor4epochsandearlystopwhenthemodel
breviation is composed of the first letters of
reachesthehighestvalidationaccuracy.
contiguous words. Therefore, we first con-
struct potential abbreviations by concatenat- Baselines: Weusethefollowingbaselinessimi-
ingfirstletterofallwordsinansequence,af- lartoRomanovandShivade(2018).
tertokenization. Forinstance,forthepremise
• CBOW:WeuseaContinuous-Bag-Of-Words
shown below we get {CXR, CXRS, XRS,
(CBOW)modelasourfirstbaseline. Wetake
CXRSI, XRSI, RSI, etc}. This is done for
boththepremiseandthehypothesisandsum
boththepremiseandthehypothesis. Wethen
the word embeddings of the respective state-
check if this n-gram exists in the hypothesis
ments to form the input layer to our CBOW
(or the premise). If yes, then we replace that
model. We used 2 hidden layers and used
abbreviation with all the words that make up
softmaxasthedecisionlayer.
the n-gram. Now the model has more scope
ofmatchingtwostringslexically. Wedemon-
• Infersent: Inferesent is a sentence encoding
strateanexamplebelow:
model which encodes a sentence by doing
Premise: Her CXR was clear and it did not a max-pool on all the hidden states of the
appearshehadaninfection. LSTM across time steps. We follow the au-
Hypothesis: Chest X-Ray showed infil- thorsofRomanovandShivade(2018)byus-
trates. ingsharedweightsLSTMcelltogetthesen-
tence representation of the premise(U) and
Premise Modified: Her Chest X-Ray was
the hypothesis(V). We feed these represen-
clear and it did not appear she had an infec-
tations U and V to an MLP to perform a
tion.
3 way prediction. For our experiments, we
use the pre-trained embeddings trained on
2. Gazetteer: If either the premise/hypothesis
theMIMICdatasetbyRomanovandShivade
does not contain the abbreviation expansion
(2018). Weusedthesamehyperparameters.
or contains only partial expansion, the Local
Context technique will fail to expand those • BERT: Since MT-DNN is based off of the
abbreviations. Hence, we use an external
BERT (Devlin et al., 2018) model as the en-
gazetteer extracted from CAMC1 to expand
coder, we also compare results using just
commonly occurring medical terms. There the pre-trained BERT. We used bert-base-
were 1373 entries in the gazetteer, cover- uncased model which was trained for 3
ingcommonmedicalandclinicalexpansions.
epochs with a learning rate of 2e-5 and a
Forinstance,
batch size of 16 with a maximum sequence
Premise: OnarrivaltotheMICU,patientis
length of 128. WE used the last 12 pre-
hemodynamicallystable.
trainedlayersofthemodel.
PremiseModified: OnarrivaltotheMedi-
2.3.1 ResultsandDiscussion
calIntensiveCareUnit,patientishemody-
namicallystable. In this section we discuss the results of all of our
experimentsontheNLItask.
We first performed the local context replace-
Ablation Study: First, we conduct an ablation
mentastheyaremorespecifictoagivenpremise-
study to study the effect of abbreviation expan-
hypothesis pair. If there was no local context
sion. Table 2 shows the results of the two ab-
match, then we did a gazetteer lookup. It is to be
breviation expansion techniques for the Infersent
noted that one abbreviation can have multiple ex-
model. We observe the best performance with
pansionsinthegazatteerandthuswehypothesized
the Gazetteer strategy. This is because most sen-
1https://www.camc.org/ tencesinthedatasetdidnothavetheabbreviation
ModelAblation Accuracy ModelAblation Accuracy
Infersent 78.8+/-0.06 CBOW 74.7
Infersent+Local-Context 78.8+/-0.02 Infersent 79.1
Infersent+Local-Context+Gazetteer 78.5+/-0.36 BERT 80.4
Infersent+Gazetteer 79.1+/0.14 Ours 82.1
(BenAbachaetal.,2019)(UnseenTest) 71.4
Table2: Theresultsreportedinthetableismeanand Ours(UnseenTest) 79.6
Ours(UnseenTest)+Prior 85.5
varianceofthemodelsaveragedon3runsusingdiffer-
entrandomseeds.
Table4: NLIresultsonthevalidationset.
matched through the local context match. Since
2.3.2 ErrorAnalysis
expanding abbreviations helped increase lexical
overlap, going forward we use the expanded ab- We perform qualitative analysis of our model and
breviationdataforallourexperimentshenceforth. buckettheerrorsintothefollowingcategories.
Table 3 shows the confusion matrix for the In-
1. Lexical Overlap: From Table 6, we see
fersentmodel. Therowsrepresentthegroundtruth
that there is a high lexical overlap between
andthecolumnsrepresentthepredictionsmadeby
the premise and hypothesis, prompting our
us. We can see that the model is most confused
modeltofalselypredictentailment.
abouttheentailmentandneutralclasses. 82times
the model predicts neutral for entailment and 85
2. Disease-Symptom relation: In the second
timesviceversa. Inordertoaddressthisissue,we
example, we can see that our model lacks
addaprioronthedatasetasapostprocessingstep.
sufficientdomainknowledgetorelatehyper-
glycemia(asymptom)todiabetes(adisease).
Contradiction Entailment Neutral
The model interprets these to be two unre-
Contradiction 396 43 26
latedentitiesandlabelsasneutral.
Entailment 30 353 82
Neutral 23 85 357
3. Drug-disease relation: In the final example
we see thatour modeldoesn’t detectthat the
Table3: ConfusionmatrixforNLIclassesforInfersent
model.Rowsdenotethetruelabelsandcolumnsdenote drugnamesinthepremiseactuallyentailthe
themodelpredictions. conditioninhypothesis.
These examples show that NLI in the medi-
cal domain is very challenging and requires in-
Prior on the dataset: Our dataset analysis on
tegration of domain knowledge with respect to
thevalidationsetrevealedthattherewerethreehy-
understandingcomplexdrug-diseaseorsymptom-
pothesis for a given premise with mutually exclu-
diseaserelations.
sivelabels. Sinceweknowthatforagivenpremise
therecanonlybeoneentailmentbecauseofthena-
2.4 RecognizingQuestionEntailment
tureofthedataset,wepost-processthemodelpre-
dictions to add this constraint. For each premise This task focuses on identifying entailment be-
we collect the prediction probability for each of tweentwoquestionsandisreferredasrecognizing
the hypothesis and pick the hypothesis having the questionentailment(RQE).Thetaskisdefinedas
highestprobabilityforentailment. Weperformthe : ”a question A entails a question B if every an-
same selectional preference procedure on the re- swer to B is also a complete or partial answer to
maining two classes. Such a post-processing en- A”. One of the questions is called CHQ and the
suresthateachpremisealwayshasthreehypothe- otherFAQ.
seswithmutuallyexclusivelabels.
Data: ThedataisbasedontheRQEdatasetcol-
Table 4 documents the results of the different
lected by Abacha and Dina (2016). The dataset
models on the validation set. We observe that
statisticscanbeseeninTable7.
ourmethodgivesthebestperformanceamongthe
three baselines. Based on these results, our final Pre-Processing: Similar to the NLI task, we
submission on the unseen data can be seen in the pre-process the data to expand any abbreviations
lastrow. intheCHQandFAQ.
Type CHQ FAQ Label
Train Whatisthetreatmentfor Whatisthetreatmentfor True
tri-iodothyroninethyrotoxicosis? T3(triiodothyronine)thyrotoxicosis?
DoCoumadinandAugmentininteract? Howdoyouinjectthebicipitaltendon? False
Validation sepsis.Cansepsisbeprevented. Whogetssepsis? True
Cansomeonegetthisfromahospital?
medicineandallied.ILIKETOKNOW WhatisanArrhythmia? False
RECENTTHERAPYONARRHYTHMIAOFHEART
Table5: Examplesofquestionentailmentfromtrainandvalidationset.
Premise Sheisonalowfatdiet
Hypothesis Shesaidtheyalsohaveheronalowsaltdiet.
LexicalOverlap
Groundtruth Neutral
Prediction Entailment
Premise Patienthasdiabetes
Hypothesis Thepatientpresentedwithachangeinmentalstatus
Disease-Symptomrelation andhyperglycemia.
Groundtruth Entailment
Prediction Neutral
Premise ShewastreatedwithMagnesiumSulfate,Labetalol,Hydralazine
andbedrestaswellasbetamethasone.
Drug-Diseaserelation Hypothesis Thepatientispregnant
Groundtruth Entailment
Prediction Neutral
Table6: Qualitativeanalysisoftheoutputsproducedbyourmodel. Wecategorizetheerrorsintodifferentbuckets
andprovidecherry-pickedexamplestodemonstrateeachcategory.
Label TrainSet Validationset tures and features from the Unified Medical
True 4655 129 Concepts (UMLS) repository. Due to access
False 3933 173 issues, we only use the i2b2 2 corpus for ex-
tractingtheNERfeatures.
Table7: Thenumberoftrainandvalidationinstances
• BERT: Like before, we compare our model
ineachofthecategoriesoftheRQEdataset.
with the pre-trained BERT model. For this
task, we used the bert-base-uncased model
Training Procedure: The multi-task MT-DNN andfine-tunedthelast12layersfor4epochs
modelgavethebestperformancefortheNLItask, with learning rate 2e-5. A batch size of 16
which motivated us to use it for the RQE task as wasused.
well. WeusethesamehyperparamtersasLiuetal.
2.4.1 DistributionMismatchChallenges
(2019)andtrainthemodelfor3epochs.
The RQE dataset posed many unique challenges,
Baselines: We compare our model with the fol-
the main challenge being that of distribution mis-
lowingbaselines:
match between the train and validation distribu-
tion. Table5showssomeexamplesfromthetrain-
• SVM:SimilartoAbachaandDina(2016),we
ing and validation set which illustrate these chal-
use a feature based model SVM and Logis-
lenges. We observe that in the training set, en-
tic Regression for the task of question en-
tailingexamplesalwayshavehighlexicaloverlap.
tailment. We extract the features presented
There were about 1543 datapoints in the training
in Abacha and Dina (2016) to the best of
set where the CHQ and FAQ were exact dupli-
our abilities. Their model uses lexical fea-
cates. The non-entailing examples in the training
tures such as word overlap, bigram propor-
tion, Named Entity Recognition (NER) fea- 2https://www.i2b2.org/NLP/DataSets/
set are completely un-related and hence the nega- 1. Orig: Usingonlytheprovidedtrainingdata.
tiveexamplesarenotstrongexamples. Whereasin
2. DataAug: Using the validation set aug-
the validation set thenegative examples also have
mentedwiththeUMLSfeaturesasdiscussed
lexical overlap. Furthermore, the nature of text
above. The provided training data was not
in the validation set is more informal with incon-
used in this setting because of distribution
sistent casing, punctuation and spellings whereas
mismatch. Despite the validation set being
the training set is more structured. Furthermore,
low-resources(300sentences),MT-DNNhas
the length of the CHQ in the validation set is
shown the capability of domain adaptation
much longer than those observed in the training
eveninlow-resourcesettings.
set. Therefore, we design our experimental set-
tingsbasedontheseobservations. 3. QQP: Quora Question pair 4(QQP) is a
dataset which was released to identify dupli-
2.4.2 DataAugmentation
cate questions on Quora. Questions are con-
Inordertoaddressthesechallenges,weattemptto
sidered duplicates if the answer to one ques-
createsyntheticdatawhichissimilartoourvalida-
tion can be be used as the answer to another
tionset. Anothermotivationfordataaugmentation
question. We hypothesized that jointly train-
was to increase the training size because neural
ingthemodelwiththeQuora-QuestionPairs
networks are data hungry. Since most deep neu-
datasetshouldhelpasitisclosesttoourRQE
ral models rely on lexical overlap as strong indi-
dataset in terms of online forum data. We
cator of entailment, we therefore use the UMLS
choose a subset of approx. 9k data points
features to augment our training set, but such that
from QQP as this dataset has 400k training
theyhelpdisambiguatethefalsepositives. Weuse
data points, inorder to matchthe data points
thefollowingprocedurefordataaugmentation:
from the RQE training data. Along with this
weusethevalidationsettotrainourmodel.
1. WeretrieveUMLSfeaturesforeachquestion
in the training, validation and test datasets, 4. Paraphrase: Generated paraphrases of the
usingtheMetaMap3 classifier. DataAug using an off-the-shelf tool 5. This
was inspired by the observation that valida-
2. We use the retrieved concept types and
tion set was in-domain but since it was low-
canonical names to create a new question-
resourced, this tool provides a cheap way of
pair with the same label as shown in Figure
creatingadditionalartificialdataset.
2, where the phrase primary ciliary dyskine-
sia has been replaced by its canonical name
2.4.3 ResultsandDiscussion
kartaganer syndrome and concept type Dis-
The results over the validation set are in Table 9.
ease or Syndrome. Since BERT and MT-
WeseethattheMT-DNNmodelperformsthebest
DNN have been trained on vast amount of
amongst all the other models. Addition of the
English data including Wikipedia, the mod-
QQPdatasetsdidnotaddextravalue. Wehypoth-
elsaresensitivetolanguagestructure. There-
esizethatthisisduetolackofin-domainmedical
fore,whileaugmentingdatawithUMLSfea-
dataintheQQPdataset.
tures, we attempt to maintain the language
TheresultsoftheMT-DNNmodelwiththedif-
structure,asdemonstratedinFigure2. Since
ferent training settings can be seen in Table 10.
UMLS provides the canonical features for
The test set comprises of 230 question pairs. We
each phrase in the sentence, we replace the
observe that the DataAug setting where the MT-
found phrase with the following template <
DNNmodelistrainedonin-domainvalidationset
UMLS Canonical name >, a <UMLS Con-
augmentedwithUMLSfeatures,performsthebest
ceptType>.
amongst all the strategies. Similar to the valida-
tion set, in this setting we also modify the test
Along with the synthetic data, we also exper-
set with the UMLS features by augmenting it us-
iment with another question entailment dataset
ing the procedure of data augmentation described
Quora-QuestionPairs(QQP).Wedescribethedif-
ferenttrainingdatausedinourexperiments: 4https://data.quora.com/First-Quora-Dataset-Release-
Question-Pairs
3https://metamap.nlm.nih.gov 5https://paraphrasing-tool.com
CHQ FAQ
I am suffering from Kartagener's syndrome What is primary ciliary
...wanted information ... for this syndrome. ... dyskinesia ?
UMLS FEATURE EXTRACTOR
DATA PROCESSING
I am suffering from Kartagener's syndrome,
a Disease or Syndrome, ...wanted what is kartagener syndrome,
information... for this syndrome, a Disease or a Disease or Syndrome, ?
Syndrome,. ...
Figure2: DataaugmentationusingdomainknowledgeforRQE.
CHQ PleaseiwanttoknowthecuretoAdenomyosis...Iwanttoseeaspecialistdoctortohelpmeout.
FAQ DoIneedtoseeadoctorforAdenomyosis?
LexicalOverlap
Groundtruth False
Prediction True
CHQ BipolarandGeneralizedAnxietyDisorderIreadaboutTranscranialmagneticstimulationTherapy.
Doyouknowanythingaboutit?Hasithadsuccess?AlsowonderingaboutECT?...
Isthattrueformixedbipolarandgeneralizedanxietydisorderalongwithmeds?
MultipleQuestions Haveyoueverheardofthis?
FAQ HoweffectiveisTranscranialmagneticstimulationforGAD?
Groundtruth True
Prediction False
CHQ spinabifida;vertbralfusion;syrinxtetheredcord.
canuhelpfortreatmentoftheseproblem.
Co-reference FAQ DoesSpinaBifidacausevertebralfusion?
Groundtruth True
Prediction True
Table8: QualitativeanalysisoftheoutputsproducedbyourRQEmodel. Wecategorizetheerrorsintodifferent
bucketsandprovidecherry-pickedexamplestoproveourclaim.
above. Therefore, the test set now comprises of
460 question pairs. We refer to the provided test Model Accuracy F1
setof230pairsasoriginalandtheaugmentedtest AbachaandDina(2016) - 75.0
SVM 71.9 70.0
set as UMLS. We submitted the outputs on both
theoriginaltestsetandtheUMLSaugmentedtest BERT 76.2 76.2
MT-DNN+Orig 78.1 77.4
set and observe that the latter gives +4.3 F1 gain
MT-DNN+QQP 80.8 77.2
over the original test set. We hypothesize that the
additionoftheUMLSaugmenteddatainthetrain- Table9: ResultsontheRQEvalidationset.
ingprocesshelpedthemodeltodisambiguatefalse
negatives.
Model F1
BenAbachaetal.(2019) 54.1
Despitetrainingdatabeingaboutmedicalques- MT-DNN +Orig 58.9
+Orig+DataAug+QQP 60.6
tions, it has a different data distribution and lan-
+DataAug(UMLS) 64.9
guage structure. Adding it actually harms the +DataAug(original) 61.5
model,asseenbythe +Orig+DataAug+QQP +DataAug+QQP(UMLS) 64.9
Ensemble 65.8
model. For our final submission, we took an en-
semble of all submissions using a majority vote
Table10: ResultsontheRQEtestset.
strategy. Theensemblemodelgaveusthebestper-
formance.
Questions Avganswercount Avganswerlength
Trainset1 104 8 434.8
Trainset2 104 8 432.5
Validationset 25 9 420.4
Testset 150 7 418.0
Table11: Datasetstatisticsforre-rankingtask.
2.4.4 ErrorAnalysis in terms of average number of answer candidates
Since we used the validation set for training the andaverageanswerlengthperquestiocanbeseen
model, we cannot directly perform a standard er- inTable11.
ror analysis. However, we manually analyze 100
2.5.1 OurMethod
question pairs from the test set and look at the
Weimplementthefollowingre-rankingmethods.
different model predictions. We categorize errors
intothefollowingcategories,asshowninTable8.
BM25: Thisisarankingalgorithmusedforrele-
vancebasedrankinggivenquery. Theformulation
1. Lexical Overlap: Most of the models we
isgivenbelow:
usedaboverelystronglyonlexicaloverlapof
tokens. Therefore, question-pairs with high
o thr eth To rg ur eap lah by elov de er nl oa tp inh ga ev ne taa ils mtr eo nn tg
.
prior for score(D,Q)=(cid:88) i=n
1IDF(qi)·
f(qi,Df )+(qi k, 1D ·) (cid:16)· 1( −k1 b+ +1 b)
· a| vD g| d(cid:17)
(1)
2. Multiple-Questions: Often CHQ questions
contained multiple sub-questions. We hy-
IDF(q
)=logN −n(q i)+0.5
(2)
i n(q )+0.5
pothesizethatmultiplequestionstendtocon- i
fusethemodel. Furthermore,asseeninTable Here D is the answer. Q is a list of all words in
8,theFAQentailsfromtwosub-questionsin the question. q refers to a single word. f(q ,D)
i i
theCHQ.Thisshowsthatthemodellacksthe isthetermfrequencyofq indocumentD.avgdis
i
abilitytoperformmulti-hopreasoning. the average answer length. The hyper-parameters
used for this experiment were b = 0.75 and k1=
3. Co-reference: The model is required to per-
1.2. Asshownintable12thisgaveanaccuracyof
form entity co-reference as part of the en-
66.6onthevalidationset.
tailment. In the example shown in Table 8,
majorityofourmodelsmarkedthisasentail- NLI-RQE based model: In our second ap-
mentpurelybecauseoflexicaloverlap. How- proach we leverage the pre-built NLI and RQE
ever, there was a need for the model to iden- models from Task 1 and 2 by including the NLI
tify co-reference between these problem and and RQE scores for each question-answer pair as
the problems mentioned in the previous sen- a feature. For instance, given a question, for each
tence. answer snippet we compute NLI scores for each
sentence in the answer with the question. Since
2.5 Question-Answering
theanswersnippetalsocontainssub-questions,we
In this section, we focus on building a re-ranker use the RQE scores to compute entailment with
for question-answering systems. In particular, we thequestion. Thisisillustratedbelow:
attempt to use the NLI and RQE models for this Question: ”about uveitis. IS THE UVEITIS, AN
task. IntheACLMediQAchallenge,thequestion- AUTOIMMUNEDISEASE”
answeringsystemCHiQA6providesapossibleset For the NLI scoring we would consider state-
ofanswersandthetaskistorankthemintheorder mentsfromtheanswerwhichmightpredictentail,
ofrelevance. contradictorneutralforthepair. SuchasUveitisis
causedbyinflammatoryresponsesinsidetheeye.
Data: Thetask-3datasetcomprisesof2training
Similarly we use the question phrases from the
sets and a validation set. The distribution of the
answer to give the particular answer a RQE score
dataacrosstrain,validationandtestwasconsistent
based on the number of entailments Facts About
6https://chiqa.nlm.nih.gov/ Uveitis(WhatCausesUveitis?)
Finally,weusetheBM25scoreforthegivenan- ceedings, volume2016, page310.AmericanMedi-
swer and concatenate with the above features and calInformaticsAssociation.
useSVMastheclassifier.
AsmaBenAbachaandDinaDemner-Fushman.2019.
Aquestion-entailmentapproachtoquestionanswer-
Model Accuracy%
ing. arXive-prints.
BM-25 66.6
RQE+NLI+Source 67.5 Asma Ben Abacha, Chaitanya Shivade, and Dina
Demner-Fushman. 2019. Overview of the mediqa
BenAbachaetal.(2019)(UnseenTest) 51.7
2019 shared task on textual inference, question en-
Ours 56.5
tailmentandquestionanswering. InProceedingsof
theBioNLP2019workshop,Florence,Italy,August
Table 12: Accuracy for task 3 on both validation set
1,2019.AssociationforComputationalLinguistics.
(top)andtestset(bottom).
Samuel R Bowman, Gabor Angeli, Christopher Potts,
and Christopher D Manning. 2015. A large anno-
tatedcorpusforlearningnaturallanguageinference.
2.5.2 Results
arXivpreprintarXiv:1508.05326.
Table12documentstheresultsofourexperiments.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
We observe that adding NLI and RQE as features
KristinaToutanova.2018. Bert:Pre-trainingofdeep
showsomeimprovementovertheBM25model. bidirectional transformers for language understand-
ing. arXivpreprintarXiv:1810.04805.
3 ConclusionandFutureWork
Carol Friedman, Pauline Kra, and Andrey Rzhetsky.
In this work, we present a multi-task learning ap- 2002. Twobiomedicalsublanguages: adescription
based on the theories of zellig harris. Journal of
proach for textual inference and question entail-
biomedicalinformatics,35(4):222–235.
menttailoredforthemedicaldomain. Weobserve
that incorporating domain knowledge for special- TusharKhot,AshishSabharwal,andPeterClark.2018.
Scitail: A textual entailment dataset from science
ized domains such as the medical domain is nec-
question answering. In Thirty-Second AAAI Con-
essary. ThisisbecausemodelssuchasBERTand
ferenceonArtificialIntelligence.
MT-DNNhavebeenpre-trainedonlargeamounts
of generic domains, leading to possible domain XiaodongLiu,PengchengHe,WeizhuChen,andJian-
feng Gao. 2019. Multi-task deep neural networks
mismatch. Inordertoachievedomainadaptation,
for natural language understanding. arXiv preprint
we explore techniques such as data augmentation arXiv:1901.11504.
usingUMLSfeatures,abbreviationexpansionand
MatthewEPeters, MarkNeumann, MohitIyyer, Matt
observe a gain of +10.8 F1 for RQE. There are
Gardner, Christopher Clark, Kenton Lee, and Luke
stillmanystandingchallengessuchasincorporat-
Zettlemoyer. 2018. Deep contextualized word rep-
ing common-sense knowledge apart from domain resentations. arXivpreprintarXiv:1802.05365.
knowledgeandmulti-hopreasoningwhichposean
Alexey Romanov and Chaitanya Shivade. 2018.
interestingfuturedirection.
Lessonsfromnaturallanguageinferenceintheclin-
In the future, we also plan to explore other icaldomain. arXivpreprintarXiv:1808.06752.
ranking methods based on relevancy feedback or
Sebastian Ruder. 2017. An overview of multi-task
priority ranking for task 3. We believe using
learning in deep neural networks. arXiv preprint
MedQuad (Ben Abacha and Demner-Fushman,
arXiv:1706.05098.
2019) as training set could further help improve
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
theperformance.
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
Acknowledgement
you need. In Advances in neural information pro-
cessingsystems,pages5998–6008.
We are thankful to the anonymous reviewers for
theirvaluablesuggestions.
References
Asma Ben Abacha and Demner-Fushman Dina. 2016.
Recognizing question entailment for medical ques-
tion answering. In AMIA Annual Symposium Pro-
