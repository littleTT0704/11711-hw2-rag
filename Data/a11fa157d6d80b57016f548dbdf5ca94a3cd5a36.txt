BertNet: Harvesting Knowledge Graphs with Arbitrary Relations
from Pretrained Language Models
ShiboHao1∗, BowenTan2∗, KaiwenTang1∗, BinNi1, XiyanShao1,
HengzheZhang1, EricP.Xing2,3, ZhitingHu1
1UCSanDiego, 2CarnegieMellonUniversity,
3MohamedbinZayedUniversityofArtificialIntelligence
{s5hao,zhh019}@ucsd.edu,{btan2}@cs.cmu.edu
Abstract Text Mining
Itiscrucialtoautomaticallyconstructknowl- Albert Einstein, a German Mechanical Pipelines
theoretical physicist, (Albert Einstein, publish, the
edgegraphs(KGs)ofdiversenewrelationsto publishedthe theory of NER, CR, RE... theory of relativity)
relativity in 1915.
supportknowledgediscoveryandbroadappli-
cations. Previous KG construction methods, KG Completion (COMET)
basedoneithercrowdsourcingortextmining,
Prompting Finetuned LMs
are often limited to a small predefined set of (bridge, UsedFor, cross water)
(bowl, UsedFor, holdingpopcorn)
relationsduetomanualcostorrestrictionsin (toothpaste, Usedfor,?) (freshen breath)
LMs trained with existing KG textcorpus. Recentresearchproposedtouse
pretrainedlanguagemodels(LMs)asimplicit BertNet(Ours)
knowledgebasesthatacceptknowledgequeries Automatic Harvesting Framework
with prompts. Yet, the implicit knowledge Prompt
A can doBbut not good at Creation (frog, A can do Bbut not good at,swim)
lacksmanydesirablepropertiesofafull-scale Aneeds B to doC (war, Aneeds B to doC, violence, end war)
… Entity …
symbolicKG,suchaseasyaccess,navigation, Other arbitrary relations Pair knowledge of arbitrary relations!
Search
editing, and quality assurance. In this paper,
Black-box Language Models
weproposeanewapproachofharvestingmas-
siveKGsofarbitraryrelationsfrompretrained Figure1:Differentexampleparadigmsofharvestingknowl-
edge. Textminingextractsknowledgeofrelationsexplicitly
LMs. Withminimalinputofarelationdefini-
mentionedinthetext. KGcompletionproducestailentities
tion(apromptandafewshotofexampleentity tocompleteknowledgeofpreexistingrelations.Ourmethod
pairs),theapproachefficientlysearchesinthe iscapableofharvestingknowledgeofarbitrarynewrelations
vastentitypairspacetoextractdiverseaccurate fromLMs.
knowledgeofthedesiredrelation. Wedevelop
aneffectivesearch-and-rescoremechanismfor
Ithasbeenalong-termdesiretoconstructKGs
improvedefficiencyandaccuracy. Wedeploy
ofdiverserelationstocomprehensivelycharacter-
theapproachtoharvestKGsofover400new
relationsfromdifferentLMs. Extensivehuman izethestructuresbetweenentities. Thetraditional
andautomaticevaluationsshowourapproach crowdsourcing-basedapproach(Speeretal.,2017;
managestoextractdiverseaccurateknowledge, Fellbaum, 2000; Sap et al., 2019) tends to cover
includingtuplesofcomplexrelations(e.g.,"A onlyarestrictedrelationset,suchasConceptNet
is capable of but not good at B"). The
(Speeretal.,2017)thatcontainsasmallsetof34
resultingKGsasasymbolicinterpretationof
relations. Thepopularmethodbasedontextmining
the source LMs also reveal new insights into
(Luanetal.,2019;ZhongandChen,2020;Wang
theLMs’knowledgecapacities.
et al., 2021b) has a similar limitation, as the text
1 Introduction
understandingmodelscanoftenrecognizeonlya
predefinedsetofrelationsincludedintrainingdata.
Symbolic knowledge graphs (KGs) are a power-
Someopen-schematextminingapproaches(e.g.,
fultoolforindexingrichknowledgeaboutentities
based on syntactic patterns) exist (Tandon et al.,
andtheirrelationships,andareusefulforinforma-
2014; Romero et al., 2019; Zhang et al., 2020b;
tionaccess(Google,2012),decisionmaking(Yang
Nguyenetal.,2021),yettheextractedrelationsare
et al., 2021; Santos et al., 2022), and improving
limitedtothoseexplicitlystatedinthetext,miss-
machinelearningingeneral(Lietal.,2019;Wang
ingallothersthatarenotmentionedordonothave
etal.,2019;Tanetal.,2020;Xiongetal.,2017).
exactmatchwiththetextinthecorpus. Similarly,
∗Equalcontribution.Codeavailableathttps://github.
KG completion approaches (Bordes et al., 2013;
com/tanyuqian/knowledge-harvest-from-lms. Demo
availableathttps://lmnet.io Bosselutetal.,2019;Yaoetal.,2019)isrestricted
3202
nuJ
2
]LC.sc[
3v86241.6022:viXra
Method Module(s) Outcome Arbitraryrelation
Textmining(Zhangetal.,2020a;Nguyenetal.,2021) NER,CR,RE,etc.1 KG ✗
LAMA(Petronietal.,2019),LPAQA(Jiangetal.,2020) LMs tailentity ✓
COMET(Bosselutetal.,2019) FinetunedGPT-2 tailentity ✗
SymbolicKnowledgeDistillation(Westetal.,2022) GPT-3 KG ✓2
BertNet(ours) LMs KG ✓
Table1:Categorizationofworksonautomaticknowledgeextraction.Comparedtoothercategoriesofapproaches,ourmethod
extractsfullexplicitKGsofarbitrarynewrelationsfromanyLMs.
tothepreexistingrelations(Figure1). 2020;Newmanetal.,2021)andenhancewithour
Ontheotherhand,largelanguagemodels(LMs) newrescorestrategyforpromptweighting,leading
pretrained on massive text corpus, such as BERT toconsistentandaccurateoutcomeknowledge.
(Devlin et al., 2019) and GPT-3 (Brown et al., We apply our approach on a range of LMs of
2020), have been found to encode a significant varyingcapacities,suchasROBERTA,BERT,and
amountofknowledgeimplicitlyintheirparameters. DISTILBERT. Inparticular,weharvestknoweldge
RecentresearchattemptedtouseLMsasflexible ofover400newrelations(anorderofmagnitude
knowledge bases by querying the LMs with arbi- more than ConceptNet relations) not available in
traryprompts(e.g.,"Obama was born in "for preexistingKGsandpreviousextractionmethods.
theanswer"Hawaii")(Petronietal.,2019). How- Extensivehumanandautomaticevaluationsshow
ever, such implicit query-based knowledge falls ourapproachsuccessfullyextractsdiverseaccurate
short of many desirable properties of a full-scale knowledge,includingtuplesforcomplexrelations
KGsuchasConceptNet(AlKhamissietal.,2022), suchas“A is capable of, but not good at,
including easy access, browsing, or even editing B” and 3-ary relations such as “A can do B at
(Zhu et al., 2020; Cao et al., 2021), as well as C”.Interestingly,theresultingKGsalsoserveasa
assuranceofknowledgequalitythankstothesym- symbolicinterpretationofthesourceLMs,reveal-
bolic nature (Anderson et al., 2020). Symbolic ingnewinsightsintotheirknowledgecapacitiesin
KnowledgeDistillation(SKD, Westetal.,2022) terms of varying factors such as model size, pre-
explicitlyextractsaknowledgebasefromGPT-3. trainingstrategies,anddistillation.
However, the approach exclusively relies on the
2 RelatedWork
strongin-contextlearningcapabilityofGPT-3and
thus is not applicable to other rich LMs such as Knowledgegraphconstruction Popularknowl-
BERT (Devlin et al., 2019) and ROBERTA (Liu edge bases or KGs are usually constructed with
et al., 2019). Moreover, its use of a quality dis- heavyhumanlabor. Forexample,WordNet(Fell-
criminator trained on existing KGs can limit its baum,2000)isalexicaldatabasethatlinkswords
generalizationtonewrelationsnotincludedinthe intosemanticrelations;ConceptNet(Speeretal.,
trainingdata. 2017) is a large commonsense knowledge graph
In this paper, we propose a new approach of presentedasasetofknowledgetriples;ATOMIC
harvestingmassiveKGsofarbitrarynewrelations (Sap et al., 2019) is a crowd-sourced social com-
fromanypretrainedLMs. Givenminimaluserin- monsenseKGofif-thenstatements. Recently,Au-
putofarelationdefinition,includingapromptand tomaticKnowledgeBaseConstruction(AKBC)as
a few shot of example entity pairs, our approach aresearchfocushasledtovariousapproaches(sum-
automaticallysearcheswithintheLMtoextractan marizedinTable1). Textmining-basedworksaim
extensivesetofhigh-qualityknowledgeaboutthe for knowledge extraction from text. A typical in-
desiredrelation. Toensuresearchefficiencyinthe formationextractionsystem(Angelietal.,2015)is
vast space of entity pairs, we devise an effective composedofseveralsub-taskslikecoreferenceres-
search-and-rescorestrategy. Wealsoadaptthepre- olution,namedentityrecognition,andrelationship
viouspromptparaphrasingmechanism(Jiangetal., extraction. Someworksoncommonsenseknowl-
edge extraction include WebChild (Tandon et al.,
1"NER","CR","RE"referto"namedentityrecognition",
2014), TransOMCS (Zhang et al., 2020a), DIS-
"coreferenceresolution","relationextraction",respectively.
COS(Fangetal.,2021),Quasimodo(Romeroetal.,
2SKDhasanoptionalfilterthatrequiresexistingKGto
finetune,whichdoesn’tworkforarbitraryrelations. 2019),ASCENT(Nguyenetal.,2021). Theseex-
traction pipelines are based on linguistic pattern, haveinvariantlyunderinputswithdifferentsurface
and involve complex engineering such as corpus forms but the same meaning. Elazar et al. 2021
selection,termaggregation,filtering,etc. Recent analyzed the consistency of pretrained LMs with
attempts also utilize LMs for AKBC. Wang et al. respecttofactualknowledge. Jiangetal.2020used
2021afinetunedLMsforlinkprediction. Feldman paraphrasingtoimprovefactualprobing. Newman
et al. 2019; Bouraoui et al. 2020 utilized LMs to etal.2021trainsanadditionallayerontopofword
score entity pairs collected from the Internet or embeddingtoimproveconsistency. Recently,con-
missingedgesinexistingKGs. COMET(Bosselut sistencyisalsoshownhelpfultoimprovetherea-
etal.,2019)isagenerativeLMtrainedtopredict soning ability of large LMs (Wang et al., 2022;
tailentitiesgivenheadentitiesandrelations. West Jungetal.,2022;Haoetal.,2023). Inourframe-
etal.2021distilltheknowledgeinGPT-3toagen- work, the extracted entity pairs for each relation
erative LM. By prompting GPT-3 (Brown et al., areenforcedtoconsistentlysatisfyadiversesetof
2020)withexamples,theyproducedATOMIC promptsandregularizedbyseveralscoringterms.
10x
to teach the student model. Yet, this method re-
quiresthestrongfew-shotlearningabilityofGPT-3 3 HarvestingKGsfromLMs
and is not generally applicable to most LMs. To
This section presents the proposed framework
the best of our knowledge, our framework is the
for extracting a relational KG from a given pre-
first to construct a KG by extracting purely from
trained LM, where the LM can be arbitrary fill-
an LM (with the minimal definition of relations
as input). The new paradigm can also be seen as
in-the-blank models such as BERT (Devlin et al.,
optimizingasymbolicKGwith(pretrained)neu-
2019),ROBERTA(Liuetal.,2019),BART(Lewis
etal.,2020),or GPT-3 (withappropriateinstruc-
ral models as supervision (Hu and Xing, 2022),
tions) (Brown et al., 2020). The KG consists of
which inverts the conventional problem of using
symbolicknowledgetolearnneuralnetworks(Hu
asetofknowledgetuplesintheform⟨HEAD EN-
etal.,2016). TITY (h), RELATION (r), TAIL ENTITY (t)⟩. Our
approach utilizes the LM to automatically har-
LMsasknowledgebases Anotherlineofworks vest a large number of appropriate entity pairs
attemptedtouseLMsasknowledgebases(LAMA, (h 1,t 1),(h 2,t 2),..., for every given relation r.
Petronietal.2019). Theseworksarealsoknownas Thispresentsamorechallengingproblemthantra-
factualprobingbecausetheymeasuredhowmuch ditionalLMprobingtasks,whichtypicallypredict
knowledgeisencodedinLMs. Thisisusuallyim- asingletailentityorasmallnumberofvalidtail
plementedbypromptingmethodsandleveraging entitiesgivenaheadentityandrelation.
the masked LM pretraining task. LPAQA (Jiang Our approach for extracting knowledge tu-
etal.,2020)proposestousetextminingandpara- ples of a specific relation of interest, such as
phrasing to find and select prompts to optimize "potential_risk" as depicted in Figure 2, only
thepredictionofasingleorafewcorrecttailenti- requiresminimalinputinformationthatdefinesthe
ties,insteadofextensivelypredictingallthevalid relation. This includes an initial prompt, such as
entity pairs like in our framework. AutoPrompt "The potential risk of A is B"andasmall
(Shinetal.,2020),QinandEisner,2021andOP- numberofexampleentitypairs,suchas⟨EATING
TIPrompt (Zhong et al., 2021) learn discrete or CANDY, TOOTH DECAY⟩. Thepromptprovidesthe
continuous prompts automatically with an addi- overallsemanticsoftherelation,whiletheexam-
tional training set. Though making prompts un- ple entity pairs clarify possible ambiguities. For
readable, these methods achieve higher accuracy new relations not included in existing KGs, it is
on the knowledge probing tasks. Our framework impractical to require a large set (e.g., hundreds)
differsfromtheseworksinthatweaimtoexplicitly ofexampleentitypairsasinpreviousknowledge
harvestknowledgegraphsinsteadofmeasuringthe probingorpromptoptimizationmethods(Petroni
knowledgeinasimplifiedsetting. et al., 2019; Jiang et al., 2020; Shi et al., 2019;
Zhongetal.,2021). Incontrast,ourapproachne-
ConsistencyofLMs Consistencyisasignificant cessitates only a small number of example entity
challengeforLMs,whichstressesthattheyshould pairs,forexample,asfewas2inourexperiments,
not produce conflicting predictions across infer- whichcaneasilybecollectedorwrittenbyusers.
ence sessions. For example, models should be- Inthefollowingsections,wedescribethecore
Input Entity Pair Search
BertNet!
Ranked Entity Pairs
Initial Prompt ExampleEntity Pairs
potential_risk
(eating candy, tooth decay)
The op fo t Ae n it si a Bl . risk (playing game, fail the exam) 0.85 (smoking, cancer)
... 0.43 (fishing, fish bite)
0.11 (speeding, crash)
Re-scoringw/LM
Prompt Creation Initialize
Candidate Entity Pairs
-Haircan potentially
T eh ae t ip no gt e cn at ni da yl i sri ts ok o to hf Sample Prompt Set (a(h lca oir h, oin l,f e suct icio idn e) ) c -a Tu hs ee p i on tf ee nc tt ii ao ln r. i sk of
decay. Paraphrase P o1 f: AT h ie s p Bo .tential risk (food, .o ..besity) a -Flc oo oh do mlis a ysu leic ai dde to.
Candy can potentially P2: A may lead to B. obesity
cause tooth decay. P3: If you A, you may
Extract be at risk for B. Search w/ LM
Add … Prompt
A can potentially weighting P1 P2 P3 P4 …
cause B. Weighted Prompt Set
Figure2:Anoverviewoftheknowledgeharvestingframework.Giventheminimaldefinitionoftherelationasinput(aninitial
promptandafewshotofexampleentitypairs),theapproachfirstautomaticallycreatesasetofpromptsexpressingtherelation
inadiverseways(§3.1).Thepromptsareweightedwithconfidencescores.WethenusetheLMtosearchalargecollectionof
candidateentitypairs,followedbyre-scoring/rankingthatyieldsthetopentitypairsastheoutputknowledge(§3.2).
components of our approach, namely the auto- conveytheintendedrelation. Tomitigatethis,we
maticcreationofdiversepromptswithconfidence proposeareweightingmethodthatutilizescompat-
weights(§3.1)andtheefficientsearchtodiscover ibilityscorestocalibratetheimpactofeachprompt
consistententitypairs(§3.2)thatcomposethede- inthesubsequentknowledgesearchstep. Specifi-
sired KGs. Figure 2 illustrate the overall frame- cally,weevaluatethecompatibilityofnewprompts
work. with example entity pairs by measuring the like-
lihood of the prompts under a LM, considering
3.1 CreatingDiverseWeightedPrompts
boththeindividualentitiesandtheentitypairasa
Ourautomatedapproachutilizesinputinformation, whole. Thisallowsustodeterminetheappropriate
specifically the initial prompt and several exam- weightsforeachpromptandimprovetheprecision
ple entity pairs, to generate a set of semantically of the knowledge search process. Formally, the
consistent but linguistically diverse prompts for compatibility score between an entity pair (h,t)
describingtherelationofinterest. Thegenerated andapromptpcanbewrittenas:
promptsareassignedconfidenceweightstoaccu-
f (⟨h,t⟩,p)=αlogP (h,t|p)
LM LM
rately measure consistency of knowledge in the
+(1−α)min{logP (h|p),logP (t|p,h)}
LM LM
subsequentstep(§3.2). (1)
To generate diverse prompts for a desired re- wherethefirsttermisthejointlog-likelihoodun-
lation, we begin by randomly selecting an entity der the LM distribution P , the second term is
LM
pair from a example set and inserting it into an the minimum individual log-likelihood given the
initial prompt to form a complete sentence. This prompt(andtheotherentity),andαisabalancing
sentence is then passed through an off-the-shelf factor (α = 2/3 in our experiments). We com-
text paraphrase model, which produces multiple pute the average compatibility score of each cre-
paraphrasedsentenceswiththesamemeaning. By atedpromptoverallexampleentitypairs,andthe
removingtheentitynames,eachparaphrasedsen- weightofthepromptisthendefinedasthesoftmax-
tence results in a new prompt that describes the normalizedscoreacrossallprompts.
desiredrelation. Toensureawiderangeofexpres-
3.2 EfficientSearchforConsistentKnowledge
sionsoftherelation,weretainonlythoseprompts
thataredistinctfromoneanotherintermsofedit With the set of prompts and corresponding confi-
distance. Thisprocessisrepeatedbycontinuously dence weights obtained in the steps described in
paraphrasingthenewlycreatedpromptsuntilamin- Section3.1,weproceedtosearchentitypairsthat
imum of 10 prompts for the relation have been consistently align with all prompts. To guide the
collected. searching process and evaluate the compatibility
Theautomaticgenerationofpromptscanbeim- ofsearched-outentitypairs(hnew,tnew),wereuse
precise,resultinginpromptsthatdonotaccurately thepreviouslydefinedprompt/entity-paircompati-
Relation Entities Relation Entities
prevent (humidity, excessive temperature) potential risk (viruses, virus transmission)
prevent (care, harm) potential risk (prolonged sleep, sleep disorders)
can help (localcouncil, village) potential risk (serious offence, conviction)
can help (therapist, client) ingredient for (electricity, electric lamp)
place for (lake, picnic tables) ingredient for (rice, soup)
place for (studios,live shows) ingredient for (milk, butter)
can but not good (appletree, wood) can but not good (locomotive, speed trains)
A can doB at C (people, communicate, web) A needs B to C (singers, vocal accompaniment, dance)
A can doB at C (adult couples, marry, marriage) A needs B to C (human lives, survival, flourish)
A can doB at C (skier, ski downhill, mountain) A needs B to C (actors, dialogue, portray characters)
Figure3:ExamplesofknowledgetuplesharvestedfromDISTILLBERT(randomlysampled).Thefirst7rowsshowsrelations
withtwoentities(headandtail),andlast3rowsshowsmorecomplexrelationswith3entities.
bilityfunction(Eq.1),andintuitivelydefineconsis- anced handling in the search procedure (e.g., the
tencyastheweightedaverageofitscompatibility processingofmulti-tokenentities,detailedpruning
withthevariousprompts,i.e., strategies)intheappendix.
new new (cid:88) new new
consistency((h ,t ))= w p·f LM((h ,t ),p) Generalizationtocomplexrelations Mostex-
p
(2) isting KGs or knowledge bases include relations
wherew isthepromptweightandthesumisover
p thatarepredicatesconnectingtwoentities,e.g.,"A
allautomaticallycreatedpromptsasabove,sothat
is capable of B". However,manyreal-liferela-
entitypairscompatiblewithallpromptsareconsid-
tionsaremorecomplex. Ourapproachisflexible
eredtobeconsistent.
and easily extensible to extract knowledge about
Basedontheconsistencycriterion,wedevelop
these complex relations. We demonstrate this in
an efficient search strategy to search for consis-
ourexperimentsbyexploringtwocases: (1)highly
tent entity pairs. A straightforward approach in-
customizedrelationsthathavespecificandsophis-
volves enumerating all possible pairs of entities,
ticated meanings, such as "A is capable of,
calculatingtheirrespectiveconsistencyscores,and
but not good at, B". This type of sophisti-
selecting the top-K entity pairs with the highest
cated knowledge is often difficult for humans to
scoresastheresultingknowledge. However, this
write down on a large scale. Our automatic ap-
approach can be computationally expensive due
proach naturally supports harvesting this kind of
tothelargevocabularysizeV (e.g.,V = 50,265
knowledgegivenonlyaninitialpromptandafew
for ROBERTA) and the high time complexity of
exampleentitiesthatcanbecollectedeasily,e.g.,
the enumeration process (i.e., O(V2) even when
⟨DOG, SWIM⟩, ⟨CHICKEN, FLY⟩, etc.; (2) N-ary
each entity consists of only one token). To over-
relationsinvolvingmorethantwoentities,suchas
comethislimitation,wehaveproposedanappro-
"A can do B at C". Ourapproachcanstraight-
priateapproximationthatleadstoamoreefficient
forwardly be extended to handle n-ary relations
searchandre-scoringmethod. Specifically,wefirst
bygeneralizingthecompatibilityscoreandsearch
use the minimum individual log-likelihoods (i.e.,
strategy accordingly to accommodate more than
the second term in the compatibility score Eq.1)
twoentities.
weightedaveragedacrossdifferentprompts(simi-
larasinEq.2),toproposealargesetofcandidate Symbolic interpretation of neural LMs The
entity pairs. The use of the minimum individual harvestedknowledgetuples,asconsistentlyrecog-
log-likelihoods allows us to apply pruning strate- nized across varying prompts by the LM, can be
gies, such as maintaining a heap and eliminating consideredastheunderlying"beliefs"oftheLM
entitiesrankedoutsidetop-Kineverysinglesearch- about the world (Stich, 1979; Hase et al., 2021).
ing step. Once we have collected a large number Thesefullysymbolicandinterpretabletuplespro-
ofproposals,were-rankthemusingthefullconsis- videameansforeasilybrowsingandanalyzingthe
tencyscoreinEq.2andselectthetop-Kinstances knowledgecapabilitiesoftheblack-boxLM.For
as the output knowledge. We describe more nu- example,viatheseoutcomeKGs,onecancompare
Paradigm Method(Size) RelationSet #Relations Accuracy(%) Novelty(%)
RobertaNet(122.2k) Auto 487 65.3 -
RobertaNet(2.2K) Human 12 81.8 -
RobertaNet(7.3K) Human 12 68.6 -
RobertaNet(23.6k) Human 12 58.6 -
Ours
RobertaNet(6.7K) ConceptNet 20 88.0 64.4
RobertaNet(24.3K) ConceptNet 20 81.6 68.8
RobertaNet(230K) ConceptNet 20 55.0 87.0
COMET(6.7K) ConceptNet 20 92.0 35.5
KGCompletion
COMET(230K) ConceptNet 20 66.6 72.4
WebChild(4.6M) - 20 82.0* -
TextMining ASCENT(8.6M) - - 79.2* -
TransOMCS(18.4M) ConceptNet 20 56.0* 98.3
Table2:StatisticsofKGsconstructedwithdifferentmethods.Differentparadigmsofworkscannotbedirectlycompared
duetotheirdifferentsettingsdiscussedinTable1. Weputtheresultstogetherforreferencepurpose. Noveltyreferstothe
proportionofentitiesthatdonotappearinConceptNet,soonlythemethodswithConceptNetrelationssethaveNoveltynumbers.
Theaccuracywith∗arefromtheoriginalpapersandsubjecttodifferentevaluationprotocol.Asafinetunedknowledgebase
completionmodel,COMET(Bosselutetal.,2019)canonlypredictthetailentitygivenasourceentityandarelation,wegenerate
KGswithCOMETbyfeedingittheheadentityproducedbyourROBERTANET. Thebottomblockofthetablesummarizes
theresultsfromsomemajortextminingmethodsdescribedinTable1,includingWebChild(Tandonetal.,2014),ASCENT
(Nguyenetal.,2021)andTransOMCS(Zhangetal.,2020a).
different LMs to understand the performance im- write12newrelationsofintereststhatcanhardlybe
pactofdiverseconfigurations,suchasmodelsizes foundinanyexistingKGs,andmanuallywritean
andpretrainingstrategies,asdemonstratedinour initialpromptand5exampleentitypairsforthem.
experiments. Theresultingrelationsincludecomplexrelations
asdescribedinSection3.2. (4)Auto: Besidesrela-
4 Experiments
tionsfromexistingKGsandhuman-writtenones,
weautomaticallyderivealargesetofrelationsfrom
Toevaluateourframework,weextractknowledge
E-KAR(Chenetal.,2022),adatasetforanalogical
of diverse new relations from various language
reasoning. Intheoriginaldataset,givenanentity
models, and conduct human evaluation. We then
pair,e.g. ⟨ID_CARD, IDENTITY⟩,thetaskistose-
makedeeperanalysisofpromptcreationandscor-
lectananalogoustuplefrommultiplechoices,e.g.
ingfunctioninourframework. Finally,byutilizing
⟨PRACTICE LICENSE, QUALIFICATION⟩. Toturna
ourframeworkasatooltointerprettheknowledge
sampleinE-KARintoarelation,weusethetuple
storedinlanguagemodels,wehavemadenotewor-
inthequestionandthecorrectchoicesas2exam-
thyobservationsregardingtheknowledgecapacity
pleentitypairs,andextracttheinitialpromptfrom
ofblack-boxmodels.
theexplanationprovidedinE-KAR(e.g. Proofof
4.1 Setup ArequiresB.),resultingin487relations. Someof
Relations Weevaluateourframeworkwithsev- therelationsarenotstraightforward, makingthis
eral relation sets: (1) ConceptNet (Speer et al., relationsetmoredifficultthanotherones. 3
2017): Following Li et al. 2016, we filter the
4.2 ExtractingKnowledgeofDiverseNew
KG and use a set of 20 common relations (e.g.
Relations
HAS_SUBEVENT, MOTIVATED_BY_GOAL). The
initialpromptsfortheserelationsarefromtheCon- Our framework is applied to extract knowledge
ceptNetrepository,andwerandomlysample5ex- graphs from LMs with relations of ConceptNet,
ample entity pairs from the ConceptNet KG for Auto, and Human. The accuracy of the ex-
each relation. (2) LAMA (Petroni et al., 2019): tracted knowledge is then evaluated with hu-
Followingpreviousworks,weusetheT-RExsplit man annotation using Amazon Mechanical Turk
(41 relations from WikiPedia, such as capital_of, (MTurk). Each extracted knowledge tuple is la-
member_of). Foreachrelation,thehuman-written beled for correctness by three annotators using a
prompt provided in Petroni et al. 2019 is used as True/False/Unjudgeablejudge. Atupleisconsid-
theinitialpromptandwerandomlysample5exam-
3For reference, finetuned ROBERTA-LARGE achieves
pleentitypairsforeachrelation. (3)Human: We about50%accuracyontheoriginaldataset.
Methods Acc Rej SourceLMs Acc Rej
AUTOPROMPT 0.33 0.47 DISTILBERT 0.67 0.24
HUMANPROMPT 0.60 0.27 BERT-BASE 0.63 0.26
TOP-1PROMPT(Ours) 0.69 0.23 BERT-LARGE 0.70 0.22
MULTIPROMPTS(Ours) 0.73 0.20 ROBERTA-BASE 0.70 0.22
ROBERTA-LARGE 0.73 0.20
Table3:Theportionsofacceptedandrejectedtuplesinhuman
evaluationacrosssettings,withtheROBERTA-LARGEasthe Table4:Theportionsofacceptedandrejectedtuplesinhuman
LM. evaluationacrossdifferentLMs,usingtheMULTI-PROMPTS
approach.
ered"accepted"ifatleasttwoannotatorsdeemit
tobetrueknowledge,and"rejected"ifatleasttwo severalsettingsontheHumanrelations: (1)Multi-
annotatorsrateitasfalse. Herewerefersportion Promptsreferstothethefullframeworkdescribed
ofacceptedtuplesasaccuracy. in§3whichusetheautomaticallycreateddiverse
The statistics of our resulting KGs are listed promptsinknowledgesearch. (2)Top-1Prompt:
in Table 2. Besides, we also put the results of Toablatetheeffectofensemblingmultipleprompts,
other paradigms of methods, including COMET weevaluatethevariantthatusesonlytheprompt
forKGcompletionandtext-miningbasedmethods withlargestweight(§3.1)forknowledgeextraction.
(Figure 1). Note that the results across different (3)HumanPrompt: Tofurtherunderstandtheef-
paradigms are generally not directly comparable fectiveness of the automatically created prompts,
duetovastlydifferentsettings. Yetwestillcollect weassessthevariantthatusestheinitialpromptof
the results together for reference purpose. From eachrelation. (4)AutoPrompt(Shinetal.,2020),
our RebertaNet with relation set "Auto", we are whichwasproposedtolearnpromptsbyoptimiz-
able to extract a reasonably large sets of knowl- ing the likelihood of tail entity prediction on the
edge (122K), by extracting knowledge with 487 trainingset. Tofitinoursetting,weadaptittoopti-
easy-to-collect "Auto" relations. The set of rela- mizethecompatibilityscore(Eq.1)ontheexample
tionisanorderofmagnitudelargerthantheprede- entity pairs. We omit other prompt tuning work
fined set of relations in both KG completion and (e.g.,Zhongetal.,2021;QinandEisner,2021)be-
textminingbasedonConceptNetasshowninthe causetheyeitheraredifficulttofitinourproblem
table. The accuracy of 65% is at a comparable orrequiremoretrainingdataandfailwithonlythe
levelwiththatofCOMET(230K)andTransOMCS fewshotofexampleentitypairsinoursetting.
(18.4M),whichisreasonableespeciallyconsider-
We harvest 1000 tuples for each Human rela-
ing our method solely uses an LM as the source
tion, and evaluate them with human annotation.
of knowledge without any external training data,
The annotation results are presented in Table 3
bringingflexibilitytodynamicallyincorporatenew
(We also list the detailed results per relation in
relations. Besides,forourRobertaNetonConcept-
Table5forreference)Our TOP-1 PROMPT signif-
Net relations, although the numbers listed in the
icantly improves the accuracy up to 9% over the
tablearenotsimplycomparable,wecanstillfind
HUMAN PROMPT,demonstratingtheeffectiveness
thatRobertaNetachievessimilaraccuracyandab-
of our prompt searching algorithm in generating
solutelyhighernoveltycomparingwiththeknowl-
high-quality prompts. MULTI-PROMPTS further
edge from COMET, which is already finetuned
improvestheaccuracybyanadditional4%,indicat-
usinglargenumberofknowledgetermsunderthe
ingthatthecombinationofdiversepromptsbetter
samesetofConceptNetrelations. Further,ourre-
capturesthesemanticsofarelation. However,the
sultsonthe"human"relationsetdemonstratethat
methodutilizingtheoptimizedpromptby AUTO-
ourRobertaNetkeepsworkingcomfortablyonour
PROMPTresultsinloweraccuracythantheuseof
highly realistic relations of user interests, includ-
humanorsearchedprompts. Thiscanbeattributed
ingthecomplexonesasdescribedinsection§3.2.
totheinsufficientnumberofexampleknowledge
Weshowcaseknowledgesamplesharvestedfrom
tuples used to learn effective prompts for the de-
DISTILLBERT inFigure3.
siredrelations.
Basedontheresultsabove,wemoveastepfor-
4.3 AnalyzingAutomaticPromptCreation
ward to see how the created prompts influence
To evaluate the effect of our automatic creation thesubsequentscoringmoduleintheframework.
ofprompts,wecomparethegeneratedKGsunder Specifically, we study both the precision and re-
0.9 AutoPrompt AutoPrompt
COMET 0.8 LPAQA
Human-written Prompt Human-written Prompt
Top-1 Prompt (ours) Top-1 Prompt (ours)
0.8
Multiple Prompts (ours) Multiple Prompts (ours)
0.7
0.7
0.6
0.6
0.5
0.5
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Recall Recall
Figure4:Precision-recallonConceptNetrelations. Figure5:Precision-recallcurveonLAMArelations.
callofourscoringfunctionparameterizedbythe prompts. The finding is consistent with previous
prompts,toseeiftheautomaticallycreatedprompts experiments,whichverifiedtheeffectivenessofour
(§3.1) bring the consistency scoring (§3.2) better scoringfunctiondesign. Ourframeworkalsoout-
balanceofknowledgeaccuracy(precision)andcov- performsotherbaselines,suchasCOMETonCon-
erage(recall). Tocomparewithotherscoringmeth- ceptNetand LPAQA onLAMA.Thoughtrained
odsthatarerestrictedtospecificsetsofrelations, withlabeleddata,thesemethodsareonlyoptimized
thisexperimentwasconductedusingexistingterms tocompletingatailentitygivenaquery,insteadof
fromboththeConceptNetandLAMAdatasets. scoringanentitypair,whichisessentialtoextract
Specifically,weusetheknowledgetuplesfrom KGsfromLMs.
ConceptNetandLAMAaspositivesamples(§4.1),
4.4 AnalysisofKnowledgeinDifferentLMs
andsynthesizethesameamountofnegativesam-
ples with the same strategy in Li et al. (2016) by AspreviouslymentionedinSection§3,theresult-
random replacing entities or relations in a true ing knowledge graphs can be viewed as a sym-
knowledgetuple. Eachscoringfunctionranksthe bolicinterpretationofLMs. Weextractknowledge
samplesbasedonthescoresfromhightolow. We graphsfrom5distinctlanguagemodelsandsubmit
canthencomputeboththeprecisionandrecallof themtohumanannotationevaluation. Thefindings
positive samples at different cut-off points along are presented in Table 4 (The detailed results per
theranking,andplottheprecision-recallcurvesfor relation is listed in Table 5), which sheds some
eachmethod. newlightonseveralknowledge-relatedquestions
Theautomaticevaluationsettingongivenknowl- regardingtheLMs’knowledgecapacity.
edgetermsenablesustoadaptexistingprevalent DoesalargerLMencodebetterknowledge?
works, e.g., KG completion and factual probing ThelargeversionofBERTandRoBERTahavethe
(Table 1), for comparison with our approach: (1) samepretrainingcorpusandtasksastheirbasever-
COMET(Bosselutetal.,2019)isatransformer- sions,buthavelargermodelarchitectureinterms
basedKGcompletionmodeltrainedtopredictthe oflayers(24v.s. 12),attentionheads(16v.s. 12),
tail entity t conditioning on the head entity and andthenumberofparameters(340Mv.s. 110M).
relation (h,r) on ConceptNet. We use its log- WecanseethattheaccuraciesofBertNet-largeand
likelihoodlogP(t|h,r)asthescoreforeachgiven RoBERTaNet-largearearound7%and3%higher
knowledgetuple. (2)LPAQA(Jiangetal.,2020) than their base version, separately, indicating the
collectsasetofpromptsonLAMAwithtextmin- larger models indeed encoded better knowledge
ingandparaphrasing,andoptimizetheirweights thanthebasemodels.
towards the objective of logP(t|h,r) on training Does better pretraining bring better knowl-
samples. edge? RoBERTa uses the same architecture as
Theresultingprecision-recallcurvesonConcept- BERTbutwithbetterpretrainingstrategies,likedy-
NetandLAMAknowledgeareshowninFigure4 namicmasking,largerbatchsize,etc. Intheircorre-
andFigure5,respectively. Scoringwithmultiple spondingKGsfromourframework,RoBERTaNet-
prompts always achieves best performance, fol- largeperformsbetterthanBertNet-large(0.73v.s.
lowedbyTop-1promptsandthenHuman-written 0.70), and RoBERTaNet-base is also better than
noisicerP noisicerP
BertNet-base(0.70v.s. 0.63),showingthatthebet- languagemodelsasknowledgebases. arXivpreprint
terpretraininginRoBERTaleadstobetterknowl- arXiv:2204.06031.
edgelearningandstorage.
GregAnderson,AbhinavVerma,IsilDillig,andSwarat
Is knowledge really kept in the knowledge
Chaudhuri. 2020. Neurosymbolic reinforcement
distillation process? DistilBERT is trained by learning with formally verified exploration. Ad-
distilling BERT-base, and it reduces 40% param- vances in neural information processing systems,
etersfromthelatter. Interestingly,theknowledge 33:6172–6183.
distillation process instead improves around 4%
Gabor Angeli, Melvin Johnson, and Christopher D.
of accuracy in the result knowledge graph. This
Manning.2015. Leveraginglinguisticstructurefor
shouldbeattributedtotheknowledgedistillation opendomaininformationextraction. InACL.
process which might eliminate some noisy infor-
mationfromtheteachermodel. Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
5 Conclusion 2013. Translatingembeddingsformodelingmulti-
relationaldata. Advancesinneuralinformationpro-
cessingsystems,26.
We have developed an automatic framework that
extracts a KG from a pretrained LM (e.g, BERT,
AntoineBosselut,HannahRashkin,MaartenSap,Chai-
ROBERTA),inanefficientandscalableway,result-
tanya Malaviya, Asli Çelikyilmaz, and Yejin Choi.
inginafamilyofnewKGs,whichwerefertoas 2019. Comet:Commonsensetransformersforknowl-
BERTNET,ROBERTANET,etc. Ourframeworkis edgegraphconstruction. TheAssociationforCom-
putationalLinguistics.
capableofextractingknowledgeofarbitrarynew
relationtypesandentities,withoutbeingrestricted
Zied Bouraoui, José Camacho-Collados, and Steven
bypre-existingknowledgeorcorpora. Theresult-
Schockaert. 2020. Inducing relational knowledge
ingKGsalsoserveasinterpretationofsourceLMs. frombert. InAAAI.
Limitations Ourcurrentdesignandexperimental
TomB.Brown,BenjaminMann,NickRyder,Melanie
studiesarelimitedonLMsinthegenericdomain, Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
and are not yet been studied in specific domains Neelakantan,PranavShyam,GirishSastry,Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
suchasextractinghealthcareknowledgefromrele-
Gretchen Krueger, T. J. Henighan, Rewon Child,
vantneuralmodels. Weleavetheexcitingworkof
AdityaRamesh,DanielM.Ziegler,JeffWu,Clemens
harvestingknowledgefromvariouskindsofneural Winter,ChristopherHesse,MarkChen,EricSigler,
networks across applications and domains in the MateuszLitwin,ScottGray,BenjaminChess,Jack
Clark, ChristopherBerner, SamMcCandlish, Alec
futurework.
Radford, Ilya Sutskever, and Dario Amodei. 2020.
Language models are few-shot learners. ArXiv,
Ethical considerations In this work, the har-
abs/2005.14165.
vested knowledge is automatically generated by
LMs. Wewouldliketonotethatthelanguagemod-
NicolaDeCao,WilkerAziz,andIvanTitov.2021. Edit-
els could possibly generate unethical knowledge ingfactualknowledgeinlanguagemodels.
tuples, same with the risks of other applications
using language models for generation. We hope JiangjieChen,RuiXu,ZiquanFu,WeiShi,Zhongqiao
Li, Xinbo Zhang, Changzhi Sun, Lei Li, Yanghua
that the knowledge extraction study could offer
Xiao,andHaoZhou.2022. E-kar: Abenchmarkfor
techniques to better interpret and understand the
rationalizingnaturallanguageanalogicalreasoning.
language models, and in turn foster the future re- arXivpreprintarXiv:2203.08480.
searchoflanguagemodelethics. Sincetheknowl-
edgegraphonlyconsistssimplephrases,wethink Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
KristinaToutanova.2019. Bert: Pre-trainingofdeep
filtering sensitive words would be effective. No
bidirectionaltransformersforlanguageunderstand-
foreseeablenegativesocietalimpactsarecausedby
ing. InNAACL-HLT(1).
themethoditself.
Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-
lashaRavichander, EduardHovy, HinrichSchütze,
References andYoavGoldberg.2021. Measuringandimproving
consistencyinpretrainedlanguagemodels. Transac-
BadrAlKhamissi,MillicentLi,AsliCelikyilmaz,Mona tionsoftheAssociationforComputationalLinguis-
Diab,andMarjanGhazvininejad.2022. Areviewon tics,9:1012–1031.
Tianqing Fang, Hongming Zhang, Weiqi Wang, YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
Yangqiu Song, and Bin He. 2021. Discos: Bridg- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
ingthegapbetweendiscourseknowledgeandcom- Luke Zettlemoyer, and Veselin Stoyanov. 2019.
monsense knowledge. In Proceedings of the Web Roberta: A robustly optimized bert pretraining ap-
Conference2021,pages2648–2659. proach. ArXiv,abs/1907.11692.
JoshuaFeldman,JoeDavison,andAlexanderM.Rush. YiLuan,DaveWadden,LuhengHe,AmyShah,Mari
2019. Commonsenseknowledgeminingfrompre- Ostendorf,andHannanehHajishirzi.2019. Ageneral
trainedmodels. InEMNLP. frameworkforinformationextractionusingdynamic
spangraphs. arXivpreprintarXiv:1904.03296.
ChristianeD.Fellbaum.2000. Wordnet: anelectronic
lexicaldatabase. Language,76:706. Benjamin Newman, Prafulla Kumar Choubey, and
NazneenRajani.2021. P-adapters: Robustlyextract-
Google.2012. Introducingtheknowledgegraph:things, ingfactualinformationfromlanguagemodelswith
notstrings. diverseprompts. ArXiv,abs/2110.07280.
Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Tuan-Phong Nguyen, Simon Razniewski, Julien
ZhenWang,DaisyZheWang,andZhitingHu.2023. Romero,andGerhardWeikum.2021. Refinedcom-
Reasoning with language model is planning with monsenseknowledgefromlarge-scalewebcontents.
worldmodel. arXivpreprintarXiv:2112.04596.
Fabio Petroni, Tim Rocktäschel, Patrick Lewis, An-
PeterHase,MonaT.Diab,AsliÇelikyilmaz,XianLi,
tonBakhtin,YuxiangWu,AlexanderH.Miller,and
ZornitsaKozareva,VeselinStoyanov,MohitBansal,
SebastianRiedel.2019. Languagemodelsasknowl-
andSriniIyer.2021. Dolanguagemodelshavebe-
edgebases? EMNLP.
liefs? methodsfordetecting,updating,andvisualiz-
ingmodelbeliefs. ArXiv,abs/2111.13654.
GuanghuiQinandJas’Eisner.2021. Learninghowto
ask: Queryinglmswithmixturesofsoftprompts. In
Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard H
NAACL.
Hovy,andEricPXing.2016. Harnessingdeepneural
networkswithlogicrules. InACL(1).
JulienRomero,SimonRazniewski,KoninikaPal,Jeff
Z.Pan,ArchitSakhadeo,andGerhardWeikum.2019.
Zhiting Hu and Eric P. Xing. 2022. Toward
Commonsensepropertiesfromquerylogsandques-
a ’Standard Model’ of Machine Learn-
tionansweringforums. InProceedingsofthe28th
ing. Harvard Data Science Review, 4(4).
ACMInternationalConferenceonInformationand
Https://hdsr.mitpress.mit.edu/pub/zkib7xth.
KnowledgeManagement,pages1411–1420.
Zhengbao Jiang, Frank F. Xu, J. Araki, and Graham
AlbertoSantos, AnaRColaço, AnnelauraBNielsen,
Neubig. 2020. How can we know what language
Lili Niu, Maximilian Strauss, Philipp E Geyer,
modelsknow? TACL.
FabianCoscia,NicolaiJWewerAlbrechtsen,Filip
Mundt,LarsJuhlJensen,etal.2022. Aknowledge
JaehunJung,LianhuiQin,SeanWelleck,FaezeBrah-
graphtointerpretclinicalproteomicsdata. Nature
man, Chandra Bhagavatula, Ronan Le Bras, and
Biotechnology,40(5):692–702.
Yejin Choi. 2022. Maieutic prompting: Logically
consistent reasoning with recursive explanations.
Maarten Sap, Ronan Le Bras, Emily Allaway, Chan-
arXivpreprintarXiv:2205.11822.
draBhagavatula,NicholasLourie,HannahRashkin,
BrendanRoof,NoahA.Smith,andYejinChoi.2019.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Atomic: An atlas of machine commonsense for if-
Ghazvininejad,AbdelrahmanMohamed,OmerLevy,
thenreasoning. ArXiv,abs/1811.00146.
VeselinStoyanov,andLukeZettlemoyer.2020. Bart:
Denoisingsequence-to-sequencepre-trainingfornat- Shaoyun Shi, Hanxiong Chen, Min Zhang, and
ural language generation, translation, and compre- Yongfeng Zhang. 2019. Neural logic networks.
hension. InACL. ArXiv,abs/1910.08629.
ChristyY.Li,XiaodanLiang,ZhitingHu,andEricP. TaylorShin,YasamanRazeghi,RobertLLoganIV,Eric
Xing. 2019. Knowledge-driven encode, retrieve, Wallace,andSameerSingh.2020. Elicitingknowl-
paraphraseformedicalimagereportgeneration. In edgefromlanguagemodelsusingautomaticallygen-
AAAI. eratedprompts. EMNLP.
Xiang Li, Aynaz Taheri, Lifu Tu, and Kevin Gimpel. RobynSpeer,JoshuaChin,andCatherineHavasi.2017.
2016. Commonsense knowledge base completion. Conceptnet5.5: Anopenmultilingualgraphofgen-
In Proceedings of the 54th Annual Meeting of the eralknowledge. InAAAI.
AssociationforComputationalLinguistics(Volume
1: LongPapers),pages1445–1455,Berlin,Germany. StephenPStich.1979. Doanimalshavebeliefs? Aus-
AssociationforComputationalLinguistics. tralasianJournalofPhilosophy,57(1):15–28.
Bowen Tan, Lianhui Qin, Eric Xing, and Zhiting Yunrong Yang, Zhidong Cao, Pengfei Zhao, Da-
Hu. 2020. Summarizing text on any aspects: A jun Daniel Zeng, Qingpeng Zhang, and Yin Luo.
knowledge-informed weakly-supervised approach. 2021. Constructing public health evidence knowl-
InProceedingsofthe2020ConferenceonEmpirical edge graph for decision-making support from
MethodsinNaturalLanguageProcessing(EMNLP), COVID-19 literature of modelling study. Journal
pages6301–6309. ofSafetyScienceandResilience,2(3):146–156.
NiketTandon,GerardDeMelo,FabianSuchanek,and LiangYao,ChengshengMao,andYuanLuo.2019. Kg-
GerhardWeikum.2014. Webchild: Harvestingand bert: Bertforknowledgegraphcompletion. ArXiv,
organizingcommonsenseknowledgefromtheweb. abs/1909.03193.
InProceedingsofthe7thACMinternationalconfer-
HongmingZhang,DanielKhashabi,YangqiuSong,and
enceonWebsearchanddatamining,pages523–532.
DanRoth.2020a. Transomcs:Fromlinguisticgraphs
tocommonsenseknowledge. InIJCAI.
BoWang,TaoShen,GuodongLong,TianyiZhou,and
YiChang.2021a. Structure-augmentedtextrepresen-
HongmingZhang,XinLiu,HaojiePan,YangqiuSong,
tationlearningforefficientknowledgegraphcomple-
and Cane Wing-Ki Leung. 2020b. Aser: A large-
tion. ProceedingsoftheWebConference2021.
scaleeventualityknowledgegraph. InProceedings
ofthewebconference2020,pages201–211.
HongweiWang,FuzhengZhang,MiaoZhao,WenjieLi,
XingXie,andMinyiGuo.2019. Multi-taskfeature
Zexuan Zhong and Danqi Chen. 2020. A frustrat-
learningforknowledgegraphenhancedrecommen-
inglyeasyapproachforentityandrelationextraction.
dation. TheWorldWideWebConference.
arXivpreprintarXiv:2010.12812.
LimingWang,SiyuanFeng,MarkHasegawa-Johnson, ZexuanZhong,DanFriedman,andDanqiChen.2021.
and Chang Yoo. 2022. Self-supervised semantic- Factualprobingis[mask]: Learningvs.learningto
drivenphonemediscoveryforzero-resourcespeech recall. NAACL.
recognition. InProceedingsofthe60thAnnualMeet-
ingoftheAssociationforComputationalLinguistics ChenZhu,AnkitSinghRawat,ManzilZaheer,Srinadh
(Volume1: LongPapers),pages8027–8047,Dublin, Bhojanapalli, Daliang Li, Felix X. Yu, and Sanjiv
Ireland.AssociationforComputationalLinguistics. Kumar.2020. Modifyingmemoriesintransformer
models. ArXiv,abs/2012.00363.
Qingyun Wang, Manling Li, Xuan Wang, Niko-
laus Nova Parulian, Guangxing Han, Jiawei Ma,
Jingxuan Tu, Ying Lin, H. Zhang, Weili Liu, Aab-
hasChauhan,YingjunGuan,BangzhengLi,Ruisong
Li,XiangchenSong,HengJi,JiaweiHan,Shih-Fu
Chang,JamesPustejovsky,DavidLiem,AhmedEl-
sayed,MarthaPalmer,JasmineRah,CynthiaSchnei-
der,andBoyanA.Onyshkevych.2021b. Covid-19
literatureknowledgegraphconstructionanddrugre-
purposingreportgeneration. InNAACL.
Peter West, Chandra Bhagavatula, Jack Hessel, Jena
Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Sean Welleck, and Yejin Choi. 2022. Symbolic
knowledgedistillation: fromgenerallanguagemod-
elstocommonsensemodels. InProceedingsofthe
2022ConferenceoftheNorthAmericanChapterof
theAssociationforComputationalLinguistics: Hu-
manLanguageTechnologies,pages4602–4625,Seat-
tle, United States. Association for Computational
Linguistics.
PeterWest,ChandraBhagavatula,JackHessel,JenaD
Hwang, Liwei Jiang, Ronan Le Bras, Ximing
Lu, Sean Welleck, and Yejin Choi. 2021. Sym-
bolicknowledgedistillation: fromgenerallanguage
models to commonsense models. arXiv preprint
arXiv:2110.07178.
ChenyanXiong,RussellPower,andJamieCallan.2017.
Explicit semantic ranking for academic search via
knowledge graph embedding. Proceedings of the
26thInternationalConferenceonWorldWideWeb.
A DetailedResultsofHarvested Algorithm1EfficientEntityTupleSearch
Knowledge Input: LM:Alanguagemodel;n : Theentitynumberfor
r
atupleofrelationr;N: maximumnumberofcandidate
tuples;P :Thesetofpromptsdescribingrelationr
r
In Table 3 and Table 4, we show the human- Output: tuple_list:AlistofN entitytuples
annotated results of harvested knowledge in dif- heap←MinHeap()
functionDFS(cur_tuple,cur_MTL)
ferentsettings. Herewelistthedetailedresultsper
idx←Count(cur_tuple)
relationinTable5. ifidx=n then
r
heap.push((cur_tuple,cur_MTL))
iflen(heap)>Nthen
B PreprocessingofConceptNet heap.pop()
endif
endif
We filter out some linguistic relations (e.g. forv∈Vocab(LM)do
cur_L←logp (v|cur_tuple,P )
etymologically derived from) and some triv- LM r
cur_MTL=min(cur_L,cur_MTL)
ialrelations(e.g. related to). Weonlyconsider ifCount(cur_tuple>0)andcur_MTL<heap.top()
thenreturn ▷Pruning
thetupleswithconfidencehigherthan1,andfilter
endif
outrelationscomprisinglessthan1000eligibletu-
cur_tuple.append(v)
ples. We don’t directly take the test set from (Li DFS(cur_tuple,cur_MTL)
endfor
etal.,2016)becausetheyreservealotoftuplesfor
endfunction
training, resulting in a small and unbalanced test DFS(EmptyList(),0)
set. tuple_list←list(heap)
C Efficientknowledgetuplesearch D DetailedExperimentsetting
We use GPT-3 with the instruction "para-
In the candidate entity pairs proposal step, we
phrase:sentence" with a few examples as the off-
usetheminimumtokenlog-likelihoods(shortedas
the-shelfparaphraser. Inentitypairsearching,we
MTL)insteadofthefullEquation2,whichallows
restricteveryentitytoappearnomorethan10times
ustoapplyapruningstrategy. Thepseudo-codeis
to improve the diversity of generated knowledge
showninAlgorithm1. Forsimplicityofthepseudo-
andsearchoutatmost50,000entitytuplesforeach
code, weonlyincludethecasewhereeachentity
relation. We finally use various score thresholds
iscomposedofasingletoken. Appendix??illus-
togettheoutcomeKGsindifferentscales,includ-
trates the processing of multi-token entities. It’s
ing(1)50%: takinghalfofallsearched-outentity
worthnotingthatouralgorithmisanexactsearch
pairswithhigherconsistencyforeachrelation(2)
algorithminsteadofapproximatedalgorithmslike
base-k: Naturally, there are different numbers of
beamsearch,whichpreventstheresultsfrombias-
validtuplesfordifferentrelations(e.g. tuplesof⟨
ingtowardsmoreprobableheadentities.
..., CAPITAL_OF, ...⟩shouldnotexceed200as
As a running example, when we are searching thatisthenumberofallthecountriesintheworld).
for100entitytuples,wemaintainaminimumheap Wedesignarelation-specificthresholdingmethod,
tokeeptrackoftheMTLoftheentitytuples. The that is to set 10% of the k-th consistency as the
maximum size of this heap is 100, and the heap threshold(i.e.,0.1×consistency ),andretainall
k
top can be used as a threshold for future search tuples with consistency above the threshold. We
becauseit’sthe100-thlargestMTL:Whenweare name the settings base-10 and base-100 when k
searchingforanewentitytuple,oncewefindthe is10and100,respectively. Welistthetruncation
log-likelihood at any time step is lower than the methodappliedtoeachvariantof ROBERTANET
threshold,wecanprunethecontinuoussearching listedinTable2:
immediately,becausethismeanstheMTLofthis
tuplewillneversurpassanyexistingtuplesinthe • RobertaNet(122.2k)-Auto: base-10
heap. Ifanewentitytupleissearchedoutwithout
• RobertaNet(6.7K)-ConceptNet: base-10
being pruned, we will pop the heap and push the
MTLofthenewtuple. Intuitively,thepruningpro-
• RobertaNet(24.3K)ConceptNet: base-100
cessmakessurethatthegeneratedpartofthetuple
insearchingisreasonableforthegivenprompt. • RobertaNet(230K)ConceptNet: 50%
Table5:Detailedresultofhumanevaluation.Thenumbersindicatetheportionsofacceptedandrejectedtuples.Ro-l,DB,B-b,
B-l,Ro-bareshortforRoberta-large,DistilBert,Bert-large,Bert-base,Roberta-base.Human,Auto,Top-1,andMultistandfor
methodsthatuseHumanPrompt,Autoprompt,Top-1Prompt(Ours),andMultiPrompts(Ours).
Model Ro-l Ro-l Ro-l Ro-l DB B-b B-l Ro-b
Prompt Human Auto Top-1 Multi Multi Multi Multi Multi
BUSINESS 0.60/0.32 0.76/0.13 0.75/0.16 0.88/0.07 0.54/0.27 0.64/0.23 0.76/0.13 0.74/0.19
HELP 0.77/0.12 0.52/0.34 0.92/0.03 0.87/0.05 0.91/0.04 0.81/0.04 0.88/0.06 0.88/0.06
INGREDIENTFOR 0.59/0.33 0.33/0.59 0.73/0.20 0.71/0.24 0.70/0.26 0.55/0.40 0.72/0.23 0.51/0.40
PLACEFOR 0.76/0.10 0.41/0.36 0.63/0.32 0.89/0.07 0.84/0.14 0.78/0.18 0.87/0.11 0.88/0.09
PREVENT 0.42/0.42 0.18/0.67 0.60/0.25 0.40/0.45 0.60/0.32 0.44/0.39 0.62/0.25 0.68/0.25
SOURCEOF 0.76/0.17 0.21/0.67 0.52/0.44 0.60/0.33 0.63/0.36 0.65/0.32 0.75/0.24 0.55/0.37
SEPARATEDBYTHEOCEAN 0.48/0.38 0.16/0.48 0.56/0.35 0.55/0.40 0.51/0.24 0.57/0.26 0.44/0.46 0.44/0.49
ANTONYM 0.50/0.41 0.10/0.83 0.50/0.48 0.55/0.44 0.38/0.56 0.41/0.56 0.52/0.42 0.75/0.22
FEATUREDTHING 0.85/0.12 0.38/0.40 0.88/0.06 0.89/0.10 0.37/0.44 0.44/0.40 0.46/0.44 0.65/0.20
NEEDATODOB 0.71/0.18 0.62/0.21 0.66/0.22 0.79/0.10 0.83/0.12 0.62/0.25 0.65/0.18 0.72/0.17
CANBUTNOTGOODAT 0.52/0.34 0.29/0.42 0.61/0.19 0.44/0.21 0.51/0.31 0.60/0.21 0.64/0.22 0.39/0.35
WORTHCELEBRATING 0.47/0.29 0.23/0.51 0.81/0.05 0.85/0.08 0.79/0.12 0.74/0.14 0.84/0.10 0.83/0.10
POTENTIALRISK 0.40/0.23 0.31/0.45 0.70/0.21 0.76/0.19 0.87/0.05 0.66/0.22 0.72/0.16 0.79/0.08
ADOBAT 0.56/0.33 0.14/0.55 0.79/0.14 0.97/0.03 0.93/0.07 0.93/0.05 0.94/0.06 0.94/0.06
AVERAGE 0.60/0.27 0.33/0.47 0.69/0.22 0.73/0.20 0.67/0.24 0.63/0.26 0.70/0.22 0.70/0.22
𝑃𝑃𝐿𝐿𝐿𝐿(ℎ|𝑝𝑝) 𝑃𝑃𝐿𝐿𝐿𝐿(ℎ1|𝑝𝑝)
(Multiple tokens)
BERT BERT
=
𝑃𝑃𝐿𝐿𝐿𝐿(ℎ|𝑝𝑝) 𝑃𝑃𝐿𝐿𝐿𝐿ℎ1𝑝𝑝 ∗𝑃𝑃𝐿𝐿𝐿𝐿(ℎ2|𝑝𝑝,ℎ1)
[MASK] is the place for [MASK] [MASK] [MASK] is the place for [MASK]
𝑃𝑃𝐿𝐿𝐿𝐿(𝑡𝑡|𝑝𝑝,ℎ) 𝑃𝑃𝐿𝐿𝐿𝐿(ℎ2|𝑝𝑝,ℎ1)
BERT BERT
Library is the place for [MASK] Study [MASK] is the place for [MASK]
Figure6:Wedemonstratethecalculationwithanexamplewherep="AISTHEPLACEFORB".Thelefttwofiguresshowshow
wecalculateP (h|p)andP (t|p,h). Inthisexample,h="library"whenwesetbothheadandtailentitiestohaveone
LM LM
singletoken.Therightblockshowshowwecalculatetheconditionalprobabilityofmultiple-tokenentitiesbydecomposingit
intotwosteps.Inthisexample,thefirsttokenoftheheadentityh ="study".
1
• RobertaNet(2.2K)Human: base-10 G Thelicenseoftheassets
• RobertaNet(7.3K)Human: base-100 All the data we used in this paper, including
datasets,relationdefinitions,seedentitypairs,etc.,
• RobertaNet(23.6k)Human: 50%
areofficiallypublicresources.
E Humanevaluation H PotentialRisks
WepresentthescreenshotoftheinstructioninFig- Weidentifythatoursystemisminimalinrisks. Our
ure7andquestioninFigure8. Theinter-annotator proposedsystemproduceresultsonlybasedonthe
agreement(Krippendorff’sAlpha)is0.27,showing source language models like BERT. The risks of
fairagreement. language models are well studied and our meth-
ods do not perpetuate or add to the known risks.
F Computeresource However, weacknowledgethemethodscouldbe
appliedtomaliciouslytrainedlanguagemodelsand
All of our experiments are running on a single
discouragesuchuses.
Nvidia GTX1080Ti GPU. Harvesting a knowl-
edgegraphofonerelationwithRoberta-largetakes
aboutonehour.
Figure7:Theinstructiontoannotators
Figure8:Thequestionstoannotators
