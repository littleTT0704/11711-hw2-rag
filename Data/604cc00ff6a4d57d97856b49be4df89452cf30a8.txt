Findings of the Second WMT Shared Task on Sign Language Translation
(WMT-SLT23)
MathiasMüller MaliheAlikhani EleftheriosAvramidis RichardBowden
UniversityofZurich NortheasternUniversity DFKIBerlin UniversityofSurrey
AnneliesBraffort NecatiCihanCamgöz SarahEbling CristinaEspaña-Bonet
UniversityofParis-Saclay MetaRealityLabs UniversityofZurich DFKISaarbrücken
AnneGöhring RomanGrundkiewicz MertInan ZifanJiang
UniversityofZurich Microsoft NortheasternUniversity UniversityofZurich
OscarKoller AmitMoryossef AnnetteRios DimitarShterionov
Microsoft Bar-IlanUniversity UniversityofZurich TilburgUniversity
SandraSidler-Miserez KatjaTissi DavyVanLanduyt
HfHZurich HfHZurich EuropeanUnionoftheDeaf
Abstract (WMT-SLT23). Thissharedtaskfocusesonauto-
matictranslationbetweensignedandspokenlan-
ThispaperpresentstheresultsoftheSecond guages. Ourmaingoalisworkingtowardsinclud-
WMT Shared Task on Sign Language Trans-
ingsignedlanguagesinNLPresearch(Yinetal.,
lation (WMT-SLT23)1. This shared task is
2021).
concernedwithautomatictranslationbetween
Signlanguagetranslationrequiresprocessingvi-
signedandspoken2languages. Thetaskisun-
usual in the sense that it requires processing sualinformation(suchasvideoframesorhuman
visualinformation(suchasvideoframesorhu- poseestimation)beyondthewell-knownparadigm
manposeestimation)beyondthewell-known oftext-to-textmachinetranslation(MT).Asacon-
paradigm of text-to-text machine translation sequence,viablesolutionsneedtoconsideracom-
(MT). The task offers four tracks involving
bination of Natural Language Processing (NLP),
thefollowinglanguages: SwissGermanSign
computervision(CV),computergraphicsandani-
Language(DSGS),FrenchSignLanguageof
mationtechniques.
Switzerland(LSF-CH),ItalianSignLanguage
We build on and extend the work done for
ofSwitzerland(LIS-CH),German,Frenchand
Italian.Fourteams(includingoneworkingona the first shared task on sign language translation
baselinesubmission)participatedinthissecond (WMT-SLT22;Mülleretal.,2022). Comparedto
editionofthetask,allsubmittingtotheDSGS- thefirstedition,we
to-Germantrack. Besidesasystemrankingand
systempapersdescribingstate-of-the-arttech- • extendedourcompetitiontomorelanguages
niques, this shared task makes the following
(threelanguagepairsinsteadofone),
scientificcontributions: novelcorporaandre-
produciblebaselinesystems. Finally,thetask • providedmuchmoretrainingdataforSwiss
alsoresultedinpubliclyavailablesetsofsys-
GermanSignlanguagecomparedtolastyear
temoutputsandmorehumanevaluationscores
(437hoursinsteadof16),
forsignlanguagetranslation.
• emphasizedsignlanguagesasthetargetlan-
1 Introduction
guageinsteadofthesource, forinstance,by
offeringofficialbaselinesystemsforspoken-
This paper presents the outcome of the Second
to-signedtranslation(notofferedlastyear).
WMTSharedTaskonSignLanguageTranslation
1https://www.wmt-slt.com/ In this second edition of the shared task, we
2Inthispaperweusetheword“spoken”torefertoany consideredthefollowinglanguages: SwissGerman
languagethatisnotsigned,nomatterwhetheritisrepresented
Sign Language (DSGS), French Sign Language
astextoraudio,andnomatterwhetherthediscourseisformal
(e.g.writing)orinformal(e.g.dialogue). ofSwitzerland(LSF-CH),ItalianSignLanguage
of Switzerland (LIS-CH), German, French, and overview of SLP in general (§2.3) and of SLT in
Italian. Weofferedfourtracks: DSGS-to-German particular (§2.4) For a general motivation for a
translation,German-to-DSGStranslation,French- shared task involving sign languages see Müller
to-LSFtranslation,andItalian-to-LIStranslation. etal.(2022).
Four teams participated in the task, which we
2.1 Signlanguages
consider a success. All teams submitted to the
DSGS-to-Germantrack,whiletherewerenosub- Sign languages are natural languages with their
missionstoanyofthetrackswhereasignlanguage owngrammaticalstructuresandlexicons,primarily
isthetargetlanguage. usedbythedeafandhard-of-hearingcommunities.
Theremainderofthispaperisorganizedasfol- Contrary to the popular belief that sign language
lows: isuniversal, hundredsofdifferentSLshavebeen
documentedsofar.
• Wegivesomebackgroundonsignlanguages
Nature of sign languages Sign languages are
andsignlanguageprocessingin§2.
visuo-gesturallanguages. Asignerconveysanut-
• We describe the shared task tracks and sub- teranceusingtheirbody: throughtheexpressionof
missionprocedurein§3. manualfeatures(handconfiguration,location,and
orientation) and non-manual features (including
• We report on the corpora we built and dis- facialexpressions,mouthingandmouthgestures,
tributed specifically for this task in §4 and gaze and torso direction). The linguistic system
§5. of SLs makes use of these specific channels. In-
formationisexpressedsimultaneously(asopposed
• Wedescribeallsubmittedsystems,including
to the sequential nature of spoken language), or-
ourbaselinesin§6.
ganizedinthree-dimensionalspace,andiconicity
playsacentralrole(Woll,2013;Pernissetal.,2015;
• Weranbothanautomaticandahumanevalu-
Slonimskaetal.,2021).
ation. Weexplainourevaluationin§7.
Writing systems To date, SLs have no univer-
• Wesharethemainoutcomesin§8anddiscuss
sally accepted written form or graphical system
in§9.
for transcription (Pizzuto and Pietrandrea, 2001;
Filhol, 2020). Several notation systems, such as
2 Background
HamNoSys (Hanke, 2004) or SignWriting (Sut-
Inrecentyears,SignLanguageProcessing(SLP) ton,1990;BianchiniandBorgia,2012), areused
has emerged as a sub-area of Natural Language inresearchorteachingbutarerarelyadoptedasa
Processing(NLP).Withinthisfield,automaticsign writingsystemineverydaylife,limitingthestan-
language translation (SLT; or sign language ma- dardisation of data collection and processing. In
chine translation, SLMT) represents a more spe- SLresearch,acommonpracticeisthereforetouse
cializeddiscipline,aimingtodeveloptechnology glosses–text-based,semanticlabelsforsigns,typ-
thatfacilitatestranslationbetweensignlanguages ically borrowed from the corresponding regional
andspokenorwrittenlanguages,butalsobetween spokenlanguage.
signandsignlanguages. However,thechallenges A common misconception among MT re-
relatedtoSLPandSLTdifferfromthoseofNLP searchers is that transcribed glosses are a full-
and MT for spoken languages in both range and fledged writing system for sign languages. In re-
complexity. Duetothedifferentmodality,lackof ality, glossing can only be seen a linguistic tool,
structured,high-quality,high-quantitydata,andthe usefulforannotatingcorporaforlinguisticstudies
lack of NLP tools, joint efforts from the fields of (Johnston,2010). Glossesdonotadequatelyrepre-
signlinguisticsandcomputationallinguistics,com- sentthemeaningofanSLutteranceand,moreim-
puterscience,machinelearning,computervision, portantly,“deafpeopledonotreadorwriteglosses”
3D animation and others are needed in order to ineverydaylife(Mülleretal.,2023).
advancethisfield.
2.2 Relevanceofsignlanguageprocessing
In this section we give an introduction to sign
languages(§2.1)anddescribethesocietalandaca- SLPisaresearchareawithhighpotentialsocietal
demic relevance of SLP (§2.2). Then we give an andacademicimpact.
Societal impact The overall aim of SLP is to 2.3 Signlanguageprocessing
provide language technology for sign languages,
Sign language processing is an interdisciplinary
which currently are somewhat overlooked, since
field,bringingtogetherresearchonNLPandcom-
thevastmajorityofNLPsystemsaredesignedonly
putervision,amongotherdisciplines(Braggetal.,
for spoken languages. This means that more re-
2019). For a general overview in the context of
searchinSLPcouldresultinmoreequalaccessto
NLP see Yin et al. (2021); Moryossef and Gold-
languagetechnology.
berg(2021).
The more specific goal of SLT is to facili-
tate communication between the deaf and hard- Tasks SLPinvolvesavarietyof(sub)taskswith
of-hearing communities on the one side and the individualchallenges. Widelyknowntasksaresign
hearing community on the other side. There is language recognition, sign language translation,
a need for this because speakers of spoken lan- andsignlanguageproduction(orsynthesis). Sign
guages and signers of sign languages experience languagerecognitionusuallyreferstoidentifying
communication difficulties (the same kind of dif- individualsignsfromvideos;seeKoller(2020)for
ficultiesencounteredbyspeakersofdifferentspo- anoverview. Signlanguagetranslationreferstothe
kenlanguages). Weemphasizethatthesetechnolo- taskoftransformingsignlanguagedatatoasecond
gies should be developed in such a way, so that language,nomatterwhethersignedorspoken;see
deaf/hard-of-hearingandhearingpeoplecanbene- DeCosteretal.(2022)foracomprehensivesurvey.
fitfromtheminanequalmeasure.3 Finally,signlanguageproductionreferstorender-
ingsignlanguageasavideo,usingmethodssuch
Besides aiding direct communication, SLT
as avatar animation (Wolfe et al., 2022) or video
would improve accessibility to spoken language
generation.
content, given that spoken languages are often a
SLPresearchischallengingforanumberofdif-
second language for deaf people, where they ex-
ferentreasons. Theoneswechosetohighlighthere
hibitvaryingproficiency. Thereversedirectionis
are linguistic properties, availability of data, and
alsocrucial,forexampletoautomaticallysubtitle
availabilityofbasicNLPtools.
signedcontenttomakeitaccessibletopeoplewho
donotknowsignlanguages(Braggetal.,2019).
Linguistic challenges SLP is challenging be-
causethecharacteristicsofsignlanguages(§2.1)
Academicrelevance InthefieldofNLP,work- cannotbefullyhandledwithexistingmethods,for
ing on sign languages is highly innovative and instance,themultilinearity,theuseofthesigning
timely. Recently,acallformoreinclusionofsigned space,andtheiconicity. Asexplainedearlier,SLP
languages in NLP (Yin et al., 2021) was widely needstotakeintoaccountmanualandnon-manual
publicized,andanACLinitiativeforDiversityand cuesinordertocaptureacompletelinguisticpic-
Inclusion4 targetsSLprocessingaswell. tureofanSLutterance(Crasborn,2006). Informa-
tionisspatio-temporalinnatureandthedataissi-
Andeventhoughsignlanguagesarestillaniche
multaneouslyconveyedbyanumberofarticulators.
topicinthegeneralfieldofNLP(thevastmajority
Signingmakesfrequentuseofindexingstrategies
ofNLPsystemsaredesignedforspokenlanguages,
forexampletoidentifyreferentsintroducedearlier
not for signed languages), the advancement and
in the discourse or timelines (Engberg-Pedersen,
spread of SLP tools, calls, initiatives and events
1993). Inotherwords,asignlanguageutteranceis
leadtoknowledgetransfernotonlywithintheaca-
notasimplesequenceoflexicalunits.
demicspheres,orbetweenresearchers,developers
Signlanguageshaveanestablishedvocabulary
andusers,butalso,moreimportantly,betweendeaf,
but are also lexically productive to allow for the
hard-of-hearingandhearingindividualsinvolved
definitionofnewsignsorconstructionstobeused
intheprocess.
todepictentitiesorsituations(Johnston,2011).
Availabilityofdata Giventhecurrentresearch
3Wedistanceourselvesfromtheaudisticviewthatonly
deaf people are in need (of access to spoken language dis- landscape in NLP, sign languages are under-
course). Languagebarriersareinherentlytwo-way,andad- resourced. AnanalysisbyJoshietal.(2020)places
dressingtheminvolvesbothparties.
all sign languages considered in this study in the
4https://www.2022.aclweb.org/
dispecialinitiative category“leftbehind”(togetherwithmanyspoken
languages). Existingresourcesaresmallandhet- atevideosofrealisticsigners(e.g. Saundersetal.
erogeneous. They are created under a variety of 2022).
circumstancesandvaryinquality(e.g. videores-
olution),signerdemographics(e.g. deafvs. hear- Paralleldatasets Intermsofdatasets,pastwork
ing signers), richness of annotation (e.g. glosses, in SLT can be characterized as focusing very
sentencesegmentation,translationtoaspokenlan- much on a narrow linguistic domain, most of
guage), and linguistic domain (e.g. only weather the work was done on one single data set called
reports,henceaverylimiteddomain). RWTH-PHOENIX Weather 2014T (Forster et al.,
Also,notallcorporaareeasilyaccessibleonline 2014). PHOENIXhasasizeof8ksentencepairs
and some have restrictive licenses that disallow and contains only weather reports. The biggest
NLPresearch. AsurveyofSLcorporaavailablein parallel corpus for a European sign language to
EuropecanbefoundinKopfetal.(2021). Foran date,thePublicDGSCorpus(Hankeetal.,2020),
account of further challenges relating to data see containsroughly70ksentencepairs.
DeSistoetal.(2022). Thus,thereisaclearshortageofusableparallel
corpora, and existing ones are orders of magni-
Lack of basic linguistic tools SLP currently
tudesmallerthanwhatisconsideredanacceptable
lacksfundamentalNLPtoolsthatarereadilyavail-
sizeforspokenlanguageMT(asaruleofthumb,
ableforspokenlanguages. Suchtoolsincludeau-
at least hundreds of thousands of sentence pairs).
tomatic language identification (Monteiro et al.,
Nevertheless,thereareplentyofspokenlanguages
2016), sign segmentation (De Sisto et al., 2021),
thatalsohavelittleparalleldataandMTmethods
sentencesegmentation(OrmelandCrasborn,2012;
havebeendevelopedspecificallyforlow-resource
Bulletal.,2020b)andsentencealignment(Varol
MT(SennrichandZhang,2019).
etal.,2021). Althoughthereareexperimentalsolu-
tions,theyarenotyetviableinpractice. Evaluation ForspokenlanguageMTavarietyof
Toolslikethesewouldbecrucialtocreatebetter automaticmetricsexist. Theseincludemorecon-
corporabyconstructingthemautomatically,asis ventional,string-basedmetricssuchasBLEU(Pap-
routinelydoneforspokenlanguages(Bañónetal., inenietal.,2002)orchrF(Popovic´,2015),aswell
2020),anddevelopbetterhigh-levelNLPsolutions. as recent, learned metrics based on embeddings
like COMET (Rei et al., 2020). In the context of
2.4 Signlanguagetranslation
SLT,noautomaticmetricsarevalidatedempirically,
In recent years, different methods to tackle SLT butifthetargetlanguageisspoken,manyexisting
have been proposed, most of them suggesting a metricsarereasonabletouse. However,ifsignlan-
cascadedsystemwhereasignedvideoisfirstcon- guageisthetargetlanguage,noautomaticmetric
vertedtoanintermediaterepresentationandthen isknownatthetimeofwriting,andtheonlyviable
tospokentext(similarlyfortext-to-videotransla- evaluationmethodishumanevaluation. Apartfrom
tion). Intermediaterepresentations(withindividual lastyear’ssharedtask,ahumanevaluationofSLT
strengthsandweaknesses)includeposeestimation systemshasneverbeenconductedonalargescale
(§5.3), glosses or writing systems such as Ham- before,andthereareopenquestionsregardingthe
NoSys(§2.1,writingsystems). exactevaluationmethodologyandwhattheideal
There isexisting work ongloss-to-text transla- profile(e.g. hearingstatus,languageproficiency)
tion(e.g. Camgözetal.2018;YinandRead2020) forevaluatorsshouldbe.
andviceversa(e.g.Stolletal.,2020),pose-to-text
translation and vice versa (e.g. Ko et al. 2019; 3 Tracksandsubmissionprocedure
Saundersetal.2020a,b,c;Inanetal.2022;Viegas
etal.2023)andsystemsinvolvingHamNoSys(e.g. We offered four translation directions (“tracks”):
Morrissey 2011; Walsh et al. 2022), or AZee ex- translationfromDSGStoGermanandviceversa,
pressions, designed to be used as input to avatar FrenchtoLSF-CH,andItaliantoLIS-CH.
synthesissystems(Bertin-Leméeetal.,2023). Re- ForDSGStoGerman,submittedsystemswere
cently,directvideo-to-texttranslationwasalsopro- rankedonaleaderboard. Forallotherdirections,
posedbyCamgözetal.(2020a,b). Forrendering noautomaticrankingwasshownsinceautomatic
signlanguageoutput,avatarsarecommonlyused metricsoftranslationqualitydonotexistforsign
(Wolfe et al., 2022), as well as methods to gener- languagesasthetargetlanguage.
Weprovidedbaselinesystemsforbothtransla- Additionally, Signsuisse contains sentence-level
tion scenarios (translating from or to a sign lan- parallel data as well, since there is one example
guage). Wewerepreparedtoprovidehumaneval- sentencetoshowtheuseofthesignincontextfor
uationforallsubmittedsystems,regardlessofthe each lexical item. SRF23 contains parallel data
translationdirectionorlanguagepair. betweenDSGSandGerman,anditslinguisticdo-
Wedeliberatelydidnotlimitthesharedtaskto mainisgeneralnews. Bothdatasetsaredistributed
anyparticularkindofSLrepresentationasinputor throughSwissUbase6,whereindividualresearchers
output of an MT system. For DSGS-to-German hadtoagreewiththeusagetermsandapplyforac-
translation, participants were free to use video cessbeforedownloading.
frames, pose estimation, or something else. For
Trainingcorpus1: SignsuisseLexicon Wecol-
German-to-DSGSparticipantswerefreetosubmit
lected 18,221 lexical items from the Signsuisse
avideoshowingposeestimationoutput,anavatar,
website,17,221ofwhicharereleasedastraining
oraphoto-realisticsigner.
dataand1,000arereservedfortestingandthere-
Participantshadtosubmittheirtranslationout-
putsontheOCELoTplatform5 whichdisplayedan forenotincludedinthetrainingdatarelease. The
lexiconcontainsthreelanguages: (i)DSGS(9044
unofficial public leaderboard based on automatic
items,500reserved),(ii)LSF-CH(6423items,250
metrics. Participantswereallowedtomakeupto
reserved), and (iii) LIS-CH (2754 items, 250 re-
sevensubmissionsandwereaskedtomarkoneof
served).
themastheirprimarysubmission.
Thelexicalitemsarerepresentedasvideosand
Mainoutcome Fourteams(includingonefrom glosses,whichenablesign-by-signtranslationfrom
NortheasternUniversitywhosesubmissionwecon- spoken to signed languages. The videos were
sider a baseline) participated in our task. All recordedwithdifferentframerates,either24,25,or
ofthemsubmittedtotheDSGS-to-Germantrack, 30fps,andthevideoresolutionis640x480.
whiletherewerenosubmissionsforothertransla-
tiondirections. Trainingcorpus2: SRF23 Thesearedailyna-
tional news and weather forecast episodes broad-
4 Data cast by the Swiss National TV (Schweizerisches
RadioundFernsehen,SRF)7.Theepisodesarenar-
Forthistaskweprovidedseparatetraining,devel-
ratedinStandardGermanofSwitzerland(different
opmentandtestdata. Whilethetrainingdatawas
fromStandardGermanofGermany,anddifferent
availablefromthebeginning,thetestdatahasbeen
fromSwissGermandialects)andinterpretedinto
releasedintwostages,startingwithareleaseofthe
Swiss German Sign Language (DSGS). The in-
testsourcesonly.
terpreters are hearing individuals, some of them
Table1givesahigh-leveloverviewofourtrain-
childrenofDeafadults(CODAs).
ing,developmentandtestdata.
Thesubtitlesarepartlypreproduced,andpartly
created live via respeaking to automatic speech
4.1 Licensingandattribution
recognition. Whileboththesubtitlesandthesign-
Bothdatasets(SRF23andSignsuisse)canbeused
ing are based on the original speech (audio), due
fornon-commercialresearch. Pleasenotethatdis-
tothelivesubtitlingandliveinterpretingscenario,
tributingthedatasetsormakingthemaccessibleto
a temporal offset between audio and subtitles as
thirdpartiesisnotpermitted,eitherintheiroriginal
well as audio and signing is inevitable (Müller
or edited form. In addition, this overview paper
et al., 2022). It should also be pointed out that
shouldbecitedifthecorporaareused.
therearedifferencesbetweeninterpretedandnon-
interpretedlanguage(Dayter,2019)duetosource
4.2 TrainingData
languageinterferenceandtimeconstraints. SLdur-
The training data comprises two corpora called
ingreal-timeinterpretationtendstocloselyfollow
Signsuisse(Jiangetal.,2023a)andSRF23(Jiang
thegrammaticalstructureofthespokenlanguage
etal.,2023b). Signsuisseisamultilingualdictio-
(Leeson,2005).
nary containing lexical items in DSGS, LSF-CH
and LIS-CH, represented as videos and glosses. 6https://www.swissubase.ch/en/catalogue/
studies/20452/19280/overview
5https://ocelot-wmt23.mteval.org/ 7https://www.srf.ch
SRF23 Signsuisse Total
direction episodes segments segments lexicalitems segments lexicalitems
DSGS↔DE 771 231834 9044 9044 240878 9044
training FR→LSF-CH - - 6423 6423 6423 6423
IT→LIS-CH - - 2754 2754 2754 2754
development DSGS↔DE 3 712 - - 712 -
DSGS→DE 1 246 250 250 496 250
DE→DSGS 1 258 250 250 508 250
test
FR→LSF-CH - - 250 250 250 250
IT→LIS-CH - - 250 250 250 250
Table1: Overviewoftraining,developmentandtestdata. SRF23andSignsuissearetwodifferenttrainingcorpora
(§4.2). Segmentcountforthetrainingcorporaisafterautomaticsentencesegmentation. Thetrainingdataand
developmentdataforDSGS→DEandDE→DSGSareidentical, whilethetestdataisdifferent. Therewasno
designateddevelopmentdataforLSF-CHandLIS-CH.
Differentfromthefirsteditionofthesharedtask part one episode was manually aligned using the
(WMT-SLT22),theoffsetbetweenthesigningand iLexeditor(HankeandStorz,2008),andthesigner
the subtitles was not manually corrected for the isa“known”personthatappearedinthetraining
training data of the current edition. On the other set. Wedidnotintendtotestgeneralizationtoun-
hand, the size of the training data is much larger known signers during the shared task evaluation
thanlastyear,presentingadifferenttrade-off. See campaign. For the Signsuisse part we do not use
Table2foracomparisonbetweenthisyear’sand theisolatedlexicalentriesthemselvesfortesting,
lastyear’sSRFresources. Whilelastyearourfo- but the example sentences associated with each
cuswasprovidingtrainingdataofthehighestqual- lexicalitem.
ity,thisyearourfocuswasofferingalarge,noisy
DE→DSGS SameprocedureasDSGS→DE,ex-
datasetthatlendsitselftodatacleaningorfiltering
cept that a different SRF23 episode and different
experimentssuchasautomaticalignment.
sentences from Signsuisse are reserved for this
Additional resources We encouraged partici- translationdirection.
pantstoconsidertheMEDIAPI-SKELcorpuswith
FR→LSF-CH 250undisclosedsentencesfrom
parallelexamplesbetweenFrenchSignLanguage
Signsuisse.
andFrench(Bulletal.,2020a)asafurtherresource.
Besides,wesuggestedthatparticipantsre-usethe
IT→LIS-CH 250 undisclosed sentences from
trainingcorporareleasedforlastyear’ssharedtask
Signsuisse.
(Mülleretal.,2022).
5 Datapreprocessing
4.3 Developmentdata
For each data set described in §4 we provided
Wedidnotprovideanydedicateddevelopmentdata
videosandcorrespondingtextinaspokenlanguage.
forthiseditionofthesharedtask. Asiscustomary
Inaddition,weincludedposeestimates(location
forWMTsharedtasks,weencouragedparticipants
ofbodykeypointsineachframe)asaconvenience.
touselastyear’sdevelopmentandtestdataasde-
velopmentdataforthecurrentyear.
5.1 Videoprocessing(onlySRF23)
4.4 Testdata Videosarere-encodedwithlosslessH264anduse
an mp4 container. The framerate of videos is un-
Wedistributeseparatetestdataforourfourtransla-
changed,meaningeither25,30or50. Wearenot
tiondirections. SeeTable1foranoverview.
distributing the original videos but ones that are
DSGS→DE Thetestdataconsistsofsegments preprocessedinaparticularwaysothattheyonly
takenfromundisclosedSRF23andSignsuissema- show the part of each frame where the signer is
terial(see§4.2forageneraldescription). Thefinal located(cropping)andthebackgroundisreplaced
testsetisbalanced,containingroughly50%Sign- with a monochrome color (signer masking), see
suisseand50%SRF23examples. FortheSRF23 Figure1forexamples.
SRF22 SRF23
Numberofepisodes 29 771
Timespanofepisodes March2020toMarch2021 July2014toMay2021
Totaldurationvideos 16hours 437hours
Totalnumberofsubtitles(before/aftersentencesegmentation) 14265/7071 354901/231834
Numberofsigners 3 4
Subtitlesegmentation manual automatic
Subtitlealignment manual audio
Table2: ComparisonbetweenSRFtrainingdataofthe2022and2023editionoftheWMT-SLTsharedtask. Subtitle
segmentation=ensuringthateachsubtitleunitisoneentiresentence. Subtitlealignment=Subtitletimesareeither
manuallycorrectedtomatchthesigninginthevideo(manual)orarematchedwiththeaudiotrack(audio).
Figure1: Illustrationofvideopreprocessingsteps(cropping,instancesegmentationandmasking). Fromleftto
right: originalframe,croppedframe,maskedframe. TakenfromMülleretal.(2022).
Cropping We manually annotate a rectangle anewendtimewillbecomputed. Theendtimeis
(boundingbox)aroundwherethesignerislocated proportionaltothelocationofthelastcharacterof
foreachvideo. Wethencropthevideotoonlykeep thesentence,relativetotheentirelengthofthesub-
thisregionusingtheFFMPEGlibrary. title. SeeExample2inTable3foranillustration
ofthiscase.
Signer segmentation and masking To the
croppedvideoweapplyaninstancesegmentation 5.3 Poseprocessing(bothcorpora)
model,SoloV2(Wangetal.,2020),toseparatethe
“Poses” are an estimate of the location of body
backgroundfromthesigner. Thisproducesamask
keypoints in video frames. The exact set of key-
thatcanbesuperimposedonthecroppedvideoto
pointsdependsontheposeestimationsystem,well-
replace each background pixel in a frame with a
knownonesareOpenPose(Caoetal.,2019)9 and
greycolor([127,127,127]inRGB).
MediaPipeHolistic(Lugaresietal.,2019)10. Usu-
Thevideoprocessingstepsdescribedaboveare
allysuchasystemprovides2Dor3Dcoordinates
onlynecessaryfortheSRF23data,sinceSignsuisse
ofkeypointsineachframe,plusaconfidencevalue
footage is recorded against a neutral background
foreachkeypoint.
andshowingonlyonesignerinthecenterofeach
Theinputforposeprocessingarecroppedand
frame.
maskedvideos(§5.1). SeeFigure2forexamples
5.2 Subtitleprocessing(onlySRF23) ofposeestimationonourdata.
Since SRF23 subtitles are not manually aligned,
OpenPose We use the Openpose 137 model
automatic sentence segmentation8 is used to re-
(which is the default) for the Signsuisse data and
distributetextacrosssubtitlesegments,seeTable3
theOpenpose135modelfortheSRFdata. Thetwo
forexamples. Thisprocessalsoadjuststimecodes
models are both widely used and the 137 model
inaheuristicmannerifneeded. Forinstance,ifau-
hastwoadditionalkeypointsbecauseitrepresents
tomaticsentencesegmentationdetectsthatawell-
formedsentencestopsinthemiddleofasubtitle, 9https://github.com/CMU-Perceptual-Computing-Lab/
openpose
8https://github.com/bricksdont/srt/tree/ 10https://ai.googleblog.com/2020/12/
sentence_segmentation mediapipe-holistic-simultaneous-face.html
Example1
Originalsubtitle Afterautomaticsegmentation
81 48
00:05:22,607 –> 00:05:24,687 00:05:22,607 –> 00:05:28,127
Die Jury war beeindruckt Die Jury war beeindruckt und begeistert von
dieser gehörlosen Frau.
82
00:05:24,687 –> 00:05:28,127
und begeistert von dieser gehörlosen Frau.
Example2
Originalsubtitle Afterautomaticsegmentation
7 4
00:00:24,708 –> 00:00:27,268 00:00:24,708 –> 00:00:31,720
Die Invalidenversicherung Region Bern startete Die Invalidenversicherung Region Bern startete
dieses Pilotprojekt und will herausfinden, ob
8 man es zukünftig umsetzen kann.
00:00:27,268 –> 00:00:29,860
dieses Pilotprojekt und will herausfinden, ob
man es
9
00:00:29,860 –> 00:00:33,460
zukünftig umsetzen kann. Es geht um die
Umsetzung
Table3: ExamplesofautomaticsentencesegmentationforGermansubtitles. ThesubtitlesareformattedasSRT,a
commonsubtitleformat. TakenfromMülleretal.(2022).
Figure2:Examplesoftheoutputofposeestimationsystemsoverlaidovertheoriginalvideoframes.Left:OpenPose,
right: MediaPipeHolistic. TakenfromMülleretal.(2022).
the wrists twice. OpenPose often detects several 6.1 BaselinebyNortheasternUniversity
peopleinourvideos,eventhoughthereisonlyone (DSGS→DE)
single person present. We distribute the original
Basedonthemodelsofthepreviouschallenge,we
predictionswhichcontainallpeoplethatOpenPose
pre-trainthebaselinesigned-to-spokensystemus-
detected.
ingaTransformerarchitecture. Weusethefairseq
seq2seq translation library (Ott et al., 2019), and
MediaPipeHolistic Asanalternative,wealsoes- theopen-sourceimplementationofthearchitecture
timatesigners’poseswiththeMediaPipeHolistic by Tarrés et al. (2023). We first train a Sentence-
system developed by Google. Unlike our Open- piecetokenizationmodelontheGermantextofthe
Pose model, which only provides 2D joint loca- examplesentencesoftheSignsuissedataset. Then,
tions, MediaPipe produces both 2D and 3D joint wetrainthemodelontheMediapipeHolisticposes
locationcoordinates. FortheSRFdata,valuesfrom on the Signsuisse example sentences. We, then,
Holisticarenormalizedbetween0and1, instead validate and test the model on the extracted Me-
ofreferringtoactualvideocoordinates. diapipeHolisticposesofboththeSignsuisseand
SRFDSGS-to-Germandatasets. Thefinaloutput
Unlike the first edition of the task, where the
isdetokenizedtoresultinspokenGermantext.
keypointswerestoredinaJSONformat,todeliver
theposedataformorecompactstorageandfaster
6.2 BaselinebyUZH(DE→DSGS,
I/O, in WMT-SLT 23 the binary .pose format of
FR→LSF-CH,IT→LIS-CH)
MoryossefandMüller(2021)wasused.
Asanaivesolution,wechooseasign-by-signtrans-
lationbaseline(Moryossefetal.,2023). Thesys-
6 Baselinesandsubmittedsystems tem gets German text as input, performs text-to-
gloss translation, then for each gloss looks up a
signintheSignsuisselexicon. Theestimatedposes
Inthissectionwedescribethesubmissionstoour
fromeachsignarethenconcatenatedandsmoothed
sharedtask. Incasetherearesubstantialdifferences
out,tocreateasingleposevideowiththetransla-
betweentheprimaryandsecondarysubmissionsof
tionintoasignlanguage.
ateamweoptedtodescribetheprimarysubmission
Sincetherewerenosubmissionsbyparticipants
here. At the time of writing this overview paper
tothesetracks,thisbaselinewasnotusedforany
threeoutoffourteamshavegivenusdetailedinfor-
subsequentevaluation.
mationabouttheirsubmissions. Thesubmissions
aresummarizedinTable4.
6.3 SubmissionbyKNOWCOMP(Xuetal.,
Overall,theparticipatingteamshavediverseaca- 2023)
demicbackgrounds,buttheirexpertiseisleaning
Theteamproposedaframeworkwhichcombines
towardsNLPmorethancomputervision. Allsub-
a pre-trained visual model to extract visual em-
mittedsystemsaresequence-to-sequencemodels
beddings with a GPT2-based language model to
basedonTransformers(Vaswanietal.,2017). Par-
translateintotext.
ticipantsmostlychosetorepresentsignlanguage
TheframeworkfirstutilisesanI3Dmodel(Varol
dataasvideoframes(usingavisualfeatureextrac-
etal.,2022)pre-trainedontheBSL-1Kcorpus(Al-
torontheencoderside). Onlythebaselinesystem
banie et al., 2020) to extract 1024-dimensional
optedforMediapipeposefeaturesinstead.
tensors for a 64-frame video input. The video
Twosystems,byKNOWCOMPandTTIC,are
extractor, i.e. the I3D model, generates a 1024-
unconstrainedbecausetheirvisualorspokentext
dimensional tensors as the visual representation
componentsarepretrainedonotherdatasets. Their
of the input video (64 frames). For decoding, a
approaches are best summarized as a combina-
German-GPT2 (Radford et al., 2019) large lan-
tionofvisualembeddingsandpre-trainedlanguage
guage model (LLM) is used to generate the final
models. TTICusedadditionalmonolingualvideo
translations. To establish an alignment between
datafromOpenASLforpretraining,andnosubmis-
thevisualandthetextualembeddingsfromthetwo
sionusedmonolingualtextinaspokenlanguage.
models, the team trains an embedding alignment
Two teams have published their code, with an- block to project the obtained visual embeddings
otherteamplanningtodosointhefuture. intotextualembeddings.
BASELINE KNOWCOMP TTIC CASIA
Constrained ✔ - - ?
Multilingual - - - ?
Document-level - - - ?
Modelensemble - - - ?
Pretrainedcomponents - ✔ ✔ ?
Monolingualdata - ✔ ✔ ?
Syntheticdata - - - ?
Signedlanguagerepresentation Mediapipe I3Dfeatures Videoframes ?
Spokenlanguagerepresentation SP BPE SP ?
Open-sourcecode ✔ (✔) ✔ ?
Table4: Overviewofcharacteristicsofsubmittedsystems. CASIAdidnotdiscloseanyinformation. Inthecode
row,checkmarksareclickablelinks. BPE=BytePairEncoding,SP=Sentencepiece,(✔)=authorsplantopublishthe
code.
Thisisimplementedbystacking6Transformer 6.4 SubmissionbyTTIC
encoderlayerstogether. Twofullyconnectedneu- (Sandoval-Castanedaetal.,2023)
ralnetworksareplacedbeforeandafterthealign-
ThesystembytheTTICteamusesasvisualback-
mentblocktoextendthevisualembeddingsintoa
bonetheVideoSwinTransformer(Liuetal.,2022)
sequentialformatandtodensifythealignedembed-
andtheT5modelbyRaffeletal.(2020)fortrans-
dings into prefix embeddings for German-GPT2,
lation into text. The VideoSwin model was pre-
respectively.
trainedonthevisual(video)sideofOpenASL(Shi
BeforetrainingtheirmodelKnowCompfirstem- et al., 2022, thus excluding the English transla-
ploysadatapreprocessingstepwheretherawdata tions) using the codebook from a discrete varia-
isdividedintosmallervideosegmentswhichare tionalauto-encoder(dVAE,Rameshetal.,2021)to
thenmatchedwiththecorrespondinggroundtruth producethelabelsintheself-supervisionobjective.
Germantranslations. Toensurethattheinputob- Next,themodelwasfine-tunedforthetaskofiso-
servesthevisualmodelrequirements,i.e. inputof latedsignlanguagerecognitiononthegloss-based
64 frames, they downsample the video segments version (Dafnis et al., 2022) of the WLASL2000
takingthefirstofeachthreeframes. Incaseswhere dataset(Lietal.,2020).
thevideosegmentissmallerthan64frames,pure The input data was segmented into non-
blackframesareappended. Next,thevideoframes overlapping,paddedchunksof16framesinorder
areresizedto224x224. tomeettheinputrequirementsofVideoSwin. The
outputswereconcatenatedtogether.
Attrainingtime,toenhancetrainingefficiency,
FollowingthefindingsofUthusetal.(2023)that
the parameters of the visual and the translation
Englishpre-trainedT5andfine-tunedforASLto
modelsarefirstfrozen;later,atacertainiteration,
Englishtranslationproducesstate-of-the-artresults,
theparametersofGPT2areunfrozen. Thisstrategy
theTTICteamusedaT5modelpre-trainedonthe
ensuresthattherandomlyinitializedTransformer
GermanColossalCleanedCommonCrawl(GC4)
encoderdoesnotcompromisetheLLM.Thehyper-
corpus.11 Theyusedpre-trainedcheckpointsfrom
parameterstheyusedare: batchsizeof4,learning
HuggingFace(Wolfetal.,2019). Totokenizethe
optimizer Adam (Kingma and Ba, 2015) with a
targetside,SentencePiece(KudoandRichardson,
learningrateof5e−6,andunfreezingthetraining
2018)trainedonthesamedatawasusedtoproduce
parametersatiteration66000. Theinputandout-
avocabularyof32,128tokens.
put lengths of GPT2 were set to 20. The number
Theirsystememploysaconvolutionallayerthat
of heads in the multi-head attention was set to 8;
istrainedtoprojectthesequenceofvisualfeatures
theprefixlengthforGPT2to4. Beforethevisual
intoasinglevectorpertimestep. TheT5embed-
embeddingswerefedtothealignmentblock, the
dingslayerisreplacedbythisconvolutionallayer.
sequencelengthwasadjustedto2×4,where4is
Thecross-entropylosswasusedfortheBEVTpre-
theGPT2’sprefixnumber. Theyrantheirexperi-
mentsonanNVIDIAGeForceGTX1080Tiwith
11https://german-nlp-group.github.io/projects/
11GVRAM. gc4-corpus.html
training,theISLRfine-tuning,thetext-to-textpre- Afterrankingthesystemsbasedontheiraverage
trainingaswellasforthetranslation. Atinference scores,theyaregroupedintosignificanceclusters,
time,thediversebeamsearchalgorithm(Vijayaku- followingtheWilcoxonrank-sumtest. Rankranges
mar et al., 2016) with 5 beams, 5 beam groups give an indication of the translation quality of a
andadiversitypenaltyof1wasused. Incontrast systemwithinaclusterandarebasedonthesame
toKNOWCOMP,theTTICteamused8GPUsto head-to-headstatisticalsignificancetests.
traintheirsystem. Inter- and intra-annotator agreement was mea-
suredwithFleissκ(Fleiss,1971). Thisshouldbe
6.5 SubmissionbyCASIA
consideredanapproximation,notingtheconcerns
Finally,wereceivedseveralsubmissionsfromthe ofMaetal.(2017)thatkappacoefficientsarenot
NationalLaboratoryofPatternRecognitionatthe suitableforcontinuousscales. Inordertocalculate
InstituteofAutomation,ChineseAcademyofSci- thecoefficient,thevalueshavebeendiscretizedin
ences(submissionID:CASIA).Nosystempaper seven bins in the scale 0-6, since those were the
wassubmittedandtheauthorsdidnotprovidefur- scores marked on the continuous evaluation bar
therinformation. thatwasgiventotheannotators.
7 EvaluationProtocols Settings of evaluation campaign We used the
Appraise evaluation framework12 (Federmann,
We performed both a human (§7.1) and an auto-
2018)forcollectingsegment-leveljudgments. As
matic(§7.2)evaluationoftranslationquality. Our
there were submissions in the DSGS-to-German
finalsystemrankingisbasedonthehumanevalua-
direction only (§6), we only set up a sign-to-text
tiononly.
humanevaluationcampaign. Annotatorswerepre-
sentedwithvideofragmentsassourcecontextand
7.1 Humanevaluation
translationoutputsofarandomdocumentfragment
Our human evaluation follows the setting we es-
fromanMTsystem. Thereferencetranslationand
tablishedlastyearforSLThumanevaluationwith
the official baseline were included as additional
customguidelines(Mülleretal.,2022),whichwas
systemoutputs. Documentfragmentswerecreated
originally adapted from the evaluation protocol
from (up to) twelve consecutive segments. The
usedattherecentWMTconferences(Kocmietal.,
SRF23partofthetestsetwasevaluatedwithinthe
2022).
documentcontext. BecausetheSignsuissepartisa
collectionofutteranceswithoutdocumentbound-
Scoringmethod Weemployedthesource-based
aries,wepresenteduptotwelverandomsegments
directassessment(DA;Grahametal.,2013;Cet-
atoncebutemphasizedintheguidelinesthatthose
toloetal.,2017)methodologywithdocumentcon-
areunrelatedandshouldbeassessedindependently.
text, extended with Scalar Quality Metric (SQM;
A screenshot of an example annotation in Ap-
Freitagetal.,2021). Assessmentswereperformed
praiseispresentedinFigure3. Thefullinstructions
onacontinuousscalebetween0and100asintra-
toevaluatorsinEnglishandGermanarelistedin
ditionalDAbutwith0-6markingsontheanalogue
AppendixB.
sliderandcustomannotatorguidelinesspecifically
Data and scripts used for generating tasks and
designedforourtask.
computing the final system rankings are publicly
Asaresultofthehumanevaluation,thesystems
availableinaGithubrepository.13
arerankedfrombesttoworst,afteraveragingthe
WehiredthreeevaluatorswhoarenativeGerman
segment-levelDAscoresgivenbythehumananno-
speakers and trained DSGS interpreters. All of
tators. Incontrasttopreviousevaluationcampaigns
themhadpriorexperiencewithevaluationofMT
(Akhbardehetal.,2021)whichcalculatetherank-
output. Each evaluator was assigned an identical
ings based on standardized scores (z-scores), we
setofannotationtaskscomprisingtheentiretestset
decidedtonotdoso,becausethelargenumberof
andallparticipatingsystems,includingthebaseline
zero-scoreditemsledtoaratherskewedstandard-
systemandthereferencetranslation. Aslastyear,
izationscalewhichaffectedthecalculationofthe
wedidnotincludeanyqualitycontrolitemsinthe
clusters. Wedidnotmakeanydistinctionbetween
annotation tasks as we had multiple independent
segment-levelanddocument-levelscores,simply
includingthelatterasadditionaldataforcomputing 12https://github.com/AppraiseDev/Appraise
theaveragescores. 13https://github.com/WMT-SLT/wmt-slt23
Figure3:Ascreenshotofanexamplesign-to-textannotationtaskinAppraisefeaturingdocument-levelsource-based
directassessment(DA)withscalarqualitymetrics(SQM)andcustomannotatorguidelinesinGerman. Takenfrom
Mülleretal.(2022).
annotations of the entire test set and because of
BASELINE
theverylowqualityoftranslations,whichwould
KNOWCOMP
makethemindistinguishablefromsegmentswith CASIA
TTIC
randomlyreplacedwordsorphrasesusedasquality 15
controlitems.
Feedbackfromevaluators Aftercompletingthe 10
evaluation all three evaluators filled out the feed-
backformweusedlastyearregardingtheevalua-
5
tion procedure and the Appraise platform, where
theygaveusadditionalinformalfeedback.
0
7.2 Automaticevaluation 0 5 101520253035404550556065707580859095100
Asinthepreviousedition,tocomplementourhu- Figure4: Histogramwiththedistributionofthesystem
outputsattheDAscorescale(xaxis)withoverlapping
manevaluation(whichprovidesthemainranking)
semi-transparent bars, discretized into 20 bins. For
wealsoprovideanautomaticevaluation. Weevalu-
everysegmentweincludeonlytheaverageofallratings.
atethesubmissionsfromDSGSintoGermanusing
Bin0,wheremostratingsbelong(upto496),iscropped
three automatic metrics: BLEU (Papineni et al.,
to20tomakethehistogramvisible.
2002),chrF(Popovic´,2015)andBLEURT(Sellam
etal.,2020). Wenotethatlearned,semanticmet-
ricscorrelatebetterwithhumanjudgement(Kocmi human translations. The score of TTIC is signif-
et al., 2021), but if they consider the source text icantly better than the other systems in the table.
as an input (e.g. COMET; Rei et al., 2020), they Allothersystemsendedupinthesameclusterwith
cannotbeusedinourcontextbecauseoursourceis overalllowertranslationquality.
videoandnottext. Thereisnoknownlearnedmet-
ricwhichsupportssignlanguagevideos. Weuse Distributionofscores Inordertomakethedis-
sacreBLEU (Post, 2018) for BLEU14 and chrF15 tributionofDAscoresmoreinterpretable,itisvi-
andthePythonlibraryforBLEURT.16 Inallcases, sualizedinFigure4. TTIChadonesegmentwitha
weestimate95%confidenceintervalsviabootstrap scoreof99outof100,onewith83,oneforeach
resampling(Koehn,2004)with1000samples. ofthescores22,18and15,then4segmentswitha
scoreofabout10,and16segmentswithascoreof
8 Results about5. CASIAhadtwosegmentswithascoreof
about5. Therestofthesegments,includingallthe
8.1 Humanevaluation
outputs from the KNOWCOMP and BASELINE
Assessment scores All three evaluators com- systems,havebeengivenascoreverycloseto0.
pletedalltasks,whichgaveusthreeindependent
Some example outputs of the highest-scoring
judgementsforeachsegmentfromtheofficialtest
translationsarelistedinTable6. Onecanseethat
set. Intotal,fortheoutputoffivesystems,wecol-
TTICcameclosetocorrectlytranslatingthegen-
lected7,800segment-leveland792document-level
eralintroductorygreetingsofthenews,butforthe
assessmentscores,whichaveragesto1,718scores
restoftheMTouputs,ratedlessthan20outof100,
persystem.
onlyafewwordsmatchthereference.
Systemranking Theofficialsystemrankingis
Annotatoragreement InTable7wearereport-
presented in Table 5. The significance clusters
ing intra-annotator agreement for every annota-
are indicated with horizontal lines. According to
tor, measured with Fleiss κ (Fleiss, 1971) over
ourhumanevaluation(Table5),thesubmissionby
134 segments which were evaluated twice. (Lan-
TTIChasachievedanaveragescoreof0.7onthe
dis and Koch, 1977; Agresti, 1996). The inter-
scaleof0to100,comparedtoascoreof83.8for
annotator agreement is κ = 0.80 ± 0.01. One
14BLEU|nrefs:1|bs:1000|seed:12345|case: canobservethattheintra-annotatoragreementand
mixed|eff:no|tok:13a|smooth:exp|version: 2.2.0
all 3 intra-annotator agreements are substantial
15chrF2|nrefs:1|bs:1000|seed:12345|case:
(0.61 < κ ≤ 0.80) based on Landis and Koch,
mixed|eff:yes|nc:6|nw:0|space:no|version: 2.2.0
16BLEURTv0.0.2usingcheckpointBLEURT-20. 1977).
tnuoC
bothdomains SRF Signsuisse
Rank Ave. System Rank Ave. System Rank Ave. System
1 83.829 HUMAN 1 68.809 HUMAN 1 98.630 HUMAN
2 0.669 TTIC 2 1.192 TTIC 2 0.154 TTIC
3-5 0.024 CASIA 3-4 0.046 CASIA 3-5 0.008 BASELINE
3-5 0.008 BASELINE 3-5 0.009 BASELINE 3-5 0.007 KNOWCOMP
3-5 0.005 KNOWCOMP 4-5 0.002 KNOWCOMP 3-5 0.003 CASIA
Table5: OfficialresultsoftheWMT23SignLanguageTranslationtaskfortranslationfromSwissGermanSign
LanguagetoGerman. Systemsareorderedbyaveraged(non-standardized)humanscoreinthepercentagescale.
LinesindicateclustersaccordingtoaWilcoxonrank-sumtestp<0.05.
score system testset doc seg text
99.3 TTIC SRF 0 0 hyp: GutenAbend,meineDamenundHerren,willkommenzur"Tagesschau".
ref: GutenAbend,meineDamenundHerren,willkommenzur"Tagesschau".
83.3 TTIC SRF 0 1 hyp: HeutemitdiesenThemen:
ref: DasmachtheuteMontagSchlagzeilen:
18.7 TTIC SRF 23 9 hyp: DerUS-PräsidentistheutezuGastbei"10vor10".
ref: Wesentlichesgibtesauchheutebei"10vor10".
16.3 TTIC SRF 18 0 hyp: UndauchfürEU-Bürger,dieindieSchweizeinreisenwollen,sollesver-
schärfteEinreiseregelngeben.
ref: AuchdieEUwillnunihreBürgervomKreuzfahrtschiffzurückholen,denn
manmisstrautJapansKrisenmanagement.
12.0 TTIC SRF 14 2 hyp: Die Leute müssen sich Gedanken machen, wie sie die Zukunft meistern
können.
ref: Dasmusssichändern,sindsichdieEU-Aussenministereinig.
11.0 TTIC SS 18 5 hyp: DerFilmkannaufYouTubeangeschautwerden.
ref: DieserFilmistspannendundinteressant.
8.3 TTIC SRF 15 4 hyp: TausendeMenschensindseitherohneHilfevonaussenausgewandert.
ref: Über70’000MenschenhabensichbisheutemitdemneuenCoronavirus
infiziert.
5.0 CASIA SRF 1 1 hyp: DieTemperaturensteigeninderSchweiz.
ref: UndmorgengibtessonnigePhasenbeiTemperaturenum9°C.
Table6:Examplesofsomeofthehighest-scoringtranslationsinthetestset.hyp=MToutputs,ref=humantranslation
annotator kappa ConcerningAppraisedevelopment,nobodyex-
periencedtechnicalproblems,whichisanimprove-
A 0.80±0.05
B 0.80±0.06 mentoverlastyear,whentwopeopleexperienced
C 0.79±0.06
majortechnicalissues. Evaluatorssuggestedthat
theuserinterfacecouldbeimprovedinsomeplaces.
Table7: Intra-annotatoragreementbasedontheFleiss
For instance, automatically playing videos could
κcoefficientforreliabilityofagreement(withscores
makeevaluationsmoreefficient,thevideosshould
discretizedinthescale0-6).
be bigger by default, there should be more key-
30 boardshortcutsandthereshouldbeaquickwayto
givealowscoretoanentiredocument.
25 As explained in more detail below (§9.3), and
similar to last year, evaluators told us that some
20 videosdonothaveidealcuts,inthesensethatthe
beginning or end are slightly cut off. This is per-
15 hapsinevitableincontinuoussigning,oraproblem
inourmanualalignmentprocess.
10 Full responses to the feedback form submitted
byevaluatorsarelistedinAppendixC.
5
8.2 Automaticevaluation
0 Table 8 summarises the results of the automatic
0 0 0 0 0 0 +
0-1 0-2 0-3 0-4 0-5 0-6 60
evaluation. Ingeneral,thetranslationoftheSign-
1 2 3 4 5
suisse subset (SS) and the SRF23 subset seem to
Figure5: Numberoftaskcompletiontimes(ataskcon- haveasimilarcomplexity,especiallyaccordingto
sistsof100segments)groupedinto10-minutebuckets, chrF and BLEURT evaluation scores. BLEU, on
afterremovingtopandbottom5-percentiles. the other hand, shows higher translation quality
forSRFinselectedsystemsby CASIAand TTIC.
Bothteamsareabletosignificantlyoutperformthe
Evaluationspeed Asingletaskrequiringprovid-
baselinesystemaccordingtothethreeevaluation
ing100segment-levelandabout12document-level
metrics. TTIC achievesthebestscoreswiththeir
scores took on average 29 minutes to complete,
primary submission TTIC.423. Although chrF
afterexcluding5%ofslowestandfastesttaskan-
pointsoutanotheroftheirsubmissionsasthebest
notations. The majority of tasks were finished in
system,thedifferencewithrespecttotheprimary
between10and30minutesasshowninFigure5.
submissionisnotstatisticallysignificant.
This is substantially faster than last year, which
averagedaround45minutespertask.
9 Discussion
Feedbackfromevaluators Aftercompletingthe
9.1 Generaltranslationquality
evaluationallthreeevaluatorsfilledinaformmeant
for feedback regarding the evaluation procedure Overall,allsystemsperformpoorlyinourshared
andtheAppraiseplatform. Allevaluatorsgaveus task, as there is an extreme difference in average
additionalinformalfeedback. score between all systems and the human refer-
In general, evaluators reported that their expe- encetranslation. Thesystemsexhibitwell-known
rience with Appraise was positive (two of them problems of natural language generation such as
had used Appraise before), and that our instruc- overfittingtofewhigh-probabilityhypothesesand
tionswereclear. Allofthemwouldbewillingto hallucination(Leeetal.,2018;Raunaketal.,2021).
dosimilarworkinthefuture. Theyfoundsource The best submitted system in the best case
videos understandable and the documents or seg- achieves an average score of about 1 out of 100
ments given were neither too long nor too short. (where the human translation achieved 69 out of
Thegeneralmethodofassessingtranslations(DA 100),whichindicatesthatcurrentautomatictrans-
withSQM)wasnotfounddifficultnorstressful,but lations are not usable in practice, unlike spoken
onthecontraryannotatorsthoughtitwasefficient, language MT where in specific scenarios experi-
simple,fastandpractical. mentshaveshownsystemstobeonparwithhuman
sksatnoitatonnaforebmuN
BLEU chrF BLEURT
Submission all SS SRF23 all SS SRF23 all SS SRF23
BASELINE 0.09±0.03 0.15±0.06 0.10±0.05 12.4±0.4 12.2±0.5 12.5±0.5 0.072±0.003 0.083±0.005 0.060±0.005
CASIA.426 0.38±0.20 0.16±0.04 0.52±0.28 14.6±0.4 14.2±0.5 14.8±0.7 0.148±0.006 0.143±0.008 0.152±0.007
CASIA.427 0.39±0.20 0.13±0.05 0.52±0.28 14.2±0.5 13.4±0.5 14.8±0.7 0.162±0.006 0.171±0.009 0.152±0.007
CASIA.428 0.16±0.07 0.16±0.04 0.20±0.10 13.5±0.4 14.2±0.5 13.0±0.5 0.156±0.005 0.143±0.008 0.168±0.007
CASIA.429 0.38±0.20 0.15±0.06 0.52±0.28 14.3±0.4 13.5±0.5 14.8±0.7 0.175±0.006 0.197±0.008 0.152±0.007
CASIA.430 0.33±0.16 0.15±0.10 0.52±0.28 14.7±0.4 14.6±0.5 14.8±0.7 0.166±0.006 0.179±0.008 0.152±0.007
CASIA.431 0.13±0.06 0.15±0.10 0.14±0.03 14.5±0.4 14.6±0.5 14.4±0.6 0.169±0.006 0.179±0.008 0.159±0.008
CASIA.432 0.37±0.19 0.11±0.05 0.52±0.28 14.4±0.4 13.7±0.5 14.8±0.7 0.172±0.006 0.190±0.008 0.152±0.007
KNOWCOMP.418 0.06±0.03 0.07±0.03 0.09±0.04 6.2±0.3 6.9±0.5 5.7±0.5 0.077±0.005 0.080±0.007 0.073±0.007
KNOWCOMP.419 0.07±0.05 0.06±0.02 0.11±0.09 7.6±0.3 8.2±0.4 7.2±0.4 0.083±0.005 0.084±0.007 0.081±0.007
TTIC.417 0.56±0.46 0.30±0.14 0.29±0.13 15.9±0.5 16.6±0.8 15.3±0.6 0.222±0.010 0.231±0.011 0.210±0.015
TTIC.420 0.78±0.83 0.21±0.04 0.17±0.02 16.0±0.5 16.2±0.6 15.5±0.6 0.224±0.010 0.228±0.011 0.216±0.015
TTIC.421 0.21±0.09 0.13±0.06 0.29±0.13 13.2±0.4 13.3±0.5 13.2±0.6 0.087±0.006 0.078±0.006 0.095±0.010
TTIC.422 0.77±0.74 0.22±0.13 0.29±0.12 17.3±0.5 16.7±0.6 17.4±0.6 0.239±0.010 0.230±0.011 0.245±0.015
TTIC.423 1.03±0.87 0.21±0.03 0.69±0.46 17.0±0.6 16.2±0.7 17.2±0.7 0.243±0.010 0.236±0.011 0.246±0.013
TTIC.424 0.79±0.74 0.24±0.12 0.33±0.14 17.2±0.5 16.6±0.7 17.5±0.7 0.236±0.009 0.228±0.011 0.241±0.015
TTIC.425 0.74±0.79 0.14±0.06 0.23±0.10 16.3±0.6 16.0±0.7 16.3±0.7 0.205±0.009 0.194±0.010 0.214±0.014
Table8: AutomaticevaluationofallthesubmissionforthefullWMT-SLTtestset(all),theSignsuissesubset(SS)
andtheSRF23subset. Meanand95%confidenceintervalsobtainedviabootstrapresamplingareshown. Primary
submissionsmanuallyevaluatedareboldfaced.
translation(Hassanetal.,2018;Popeletal.,2020). 9.3 Lowscoresofhumantranslations
This assessment of general translation quality is
When looking at the domain-specific results (Ta-
unchangedfromlastyear,seeMülleretal.(2022)
ble5bandc),weobservethatthehumantranslation
forpotentialreasonsthatstillapplytothecurrent
inSRFwasrankedconsiderablylowerthanSignsu-
sharedtask.
isse(69%against98%). Thisdifferencewarrants
further investigation, as does the fact that a per-
9.2 Nosubmissionsforspoken-to-signed centageof69%isbyitselfratherlow. Weexplain
translationdirections potentialreasonsforthisbelow,attributingthedif-
ferencetothewaythecorporaweregenerated.
Noteamsparticipatedinatrackwhereasignlan-
Interpretationvs. translation SRFispartially
guageisthetargetlanguage(§3). Webelievethis
generatedasliveinterpretationofthespokenTV
could be due to the fact that generating sign lan-
shows(spoken-to-sign),whereinterpretersareun-
guage may appear considerably harder to partici-
dertimepressure. Duetospecificefficiencystrate-
pants. Theproblemofsigned-to-spokentranslation
giestheyoccasionallyomitcontenttokeepupwith
fits well into existing translation paradigms and
the spoken audio. Therefore, since here we are
toolkits, because using arbitrary features on the
evaluating the performance of the systems in the
sourcesideiseasierthangeneratingarbitrarynu-
oppositedirection(sign-to-spoken)itmayaswell
merical data (such as a video). Decoding text on
veryoftenbethatthecontentoftheinterpretation
thetargetsideisconsiderablyeasierandmorewell-
does not match the one of the written or spoken
defined in NLP than decoding a video or similar
sentence. However,asexplainedinSection4,the
datastructure.
Signsuisse part of the testset derives from a lexi-
Wethoughtthatprovidingabaselinesystemfor
con,containingsentencesrecordedasexamplesof
spoken-to-signedtranslation(§6.2)mayhelplower
particular lexicon entries. Since these have been
thebarrierstoentrybutclearly,moremeasuresare
generatedforthepurposeofbeingincludedinthe
needed. A different hypothesis is that our shared
lexicon,theaccuracyofthetranslationisexpected
taskinitscurrentformdoesnotappealtoscientists
tobemuchhigherthantheoneachievedwithinlive
workinginthefieldofsignlanguagegenerationor
interpretation.
avatartechnology. Theymayhavefeltalienatedby
aspectsofthesharedtaskwhicharefamiliartoMT Videoeditingissues Themeasuredbadhuman
researchers, but would need more explanation or performanceonSRFmayalsobeexplainedbythe
introductionforpeoplefromneighboringfields. fact that the video cuts are sometimes not ideal,
i.e. thebeginningorendofanSLutteranceiscut wellinouronlinedocumentation. Onereasonfor
off, as noted by our evaluators. This may have thismaybethatwedidnotmakeitclearenoughto
occurredbecausesegmentingcontinuoussigning participantsthatoneofourtrainingcorporaisef-
is difficult and there is no ideal way to separate fectivelyun-aligned. Butessentially,itmeansthere
seamlesstransitions. isunexploredpotentialinimprovingorfilteringthe
In the future these problems could perhaps be trainingdatainsteadoftrainingontherawcorpora.
mitigatedbyincludingmoreframesfromtheleft
9.5 Limitationsofsharedtasksetup
andrightborderofavideoclip,orsimplydiscard-
ingsentenceswithunclearboundaries. The limitations we identified in last year’s find-
ingspaperstillapply. Briefly,thelimitationscon-
Role of discourse context A third reason may
cernthelackofgeneralizationacrosssigners,the
bethatSLsareprobablymoredependentoncon-
favourable recording conditions of our sign lan-
textthanspokenlanguages,e.g. becauseofindex
guagedataandinterpretationvs. translationsetups.
signs. ThismeansthatevaluatinganisolatedSLut-
SeeMülleretal.(2022)foramorecomprehensive
terance(theequivalentofonesentenceinaspoken
description.
language) may lead to low scores. This is a phe-
nomenonthatwouldmorelikelyoccurinanews 10 Conclusionandfuturedirections
reportofSRF,ascomparedtotheisolatedexample
InthispaperwepresentthesecondWMTShared
sentencesofSignsuisse.
TaskonSignLanguageTranslation(WMT-SLT23).
Contrarytowhatwasobservedfortheevaluation
We consider automatic sign language translation,
of the human translation, the two submitted MT
andsignlanguageprocessingingeneral,tobeof
systems TTIC and CASIA perform significantly
wide public interest and to have a high potential
better on SRF than on Signsuisse. Here we may
impactinasocietalandacademicsense(§2).
provide the assumption, that since the amount of
Compared to last year we ran our shared task
trainingsentencesfromSRFisbiggerthantheones
for three language pairs instead of one, we dis-
fromSignsuisse,thesystemsareoptimizedbetter
tributed considerably more training data (albeit
forthatdomain. Additionally,ithasbeennotedthat
with a higher amount of noise) and we put more
ininterpretationsettingssimilartotheonesofSRF,
emphasis on scenarios where sign languages are
thelinguisticcharacteristicsofthesigningmaybe
thetargetlanguage.
morecloselyrelatedtoGermanthaninanoffline
Four teams participated in the second edition
translationsetting,suchastheoneinSignsuisse.
ofthesharedtask. Overall,weobservedlowsys-
9.4 Qualityoftrainingdataandunexplored temperformancewithanaveragehumanevaluation
potential scoreofabout1outof100(forthebest-performing
system),whichisnotusableinpractice. Themain
Compared to last year we offered considerably
reasonsforthisoutcomearealackofusabletrain-
more training data (hundreds of hours worth of
ing data, a modality gap (considering that most
video compared to dozens last year; §4.2). How-
existingworkinMTisbasedontext)andalackof
ever, while last year all training data was manu-
basicNLPtoolsspecificallyforsignlanguages.
allycorrected, thisyearweofferedthedataas-is.
The SRF23 training data is best understood as a Futureofthesharedtask Aftertwosuccessful
comparablecorpus,orweb-crawledparallelcorpus iterationsthesharedtaskisnowwellestablished,
including various types of noise (Khayrallah and in the sense that suitable protocols are in place
Koehn,2018). Forinstance,thetimestampsofthe for human and automatic evaluation, reasonable
Germansubtitlesaremorealignedwiththeaudio baselinesystemsexist,aswellasseveraltraining
signalpresentinthebroadcastanddonotaccount corporaandofficialWMTtestsets.
forthedelayoflive-interpretedsigning. Anynaive So far our shared tasks have certainly helped
extractionofparallelexamplesfromSRF23with- topaintamorerealisticpictureofthetranslation
out any alignment tools or shifting subtitle times quality of state-of-the-art systems, but they have
willresultinnoisytrainingdata. notledtoanymajortechnicalinnovation. Thismay
As far as we know no participant investigated be because technologies more fundamental than
ways to improve the alignments automatically, machinetranslationdonotexistforsignlanguages,
which is perhaps because we did not explain this orarenotreliableenough. Forthisreasonwewill
considerrunningsharedtasksonmorefundamental Swiss Innovation Agency (Innosuisse) flagship
problemsinSLPsuchasalignment,segmentation, IICT(PFFS-21-47)andtheGermanMinistryofEd-
orautomaticfilteringofparallelcorpora. ucationandResearch(BMBF)throughtheproject
Inthefuturewecouldalsotrytoshiftthefocus SocialWear(01IW20002).
awayfrominterpretednewsbroadcastmaterialas Finally,wewouldliketoextendheartfeltthanks
thebasisfortrainingandtestdata. Amajorchal- totheDSGSinterpreterswhoperformedourhuman
lenge to overcome is that interpreted material is evaluation: HeidiStocker,JanineCriblezandTanja
availableinlargeramounts,whilesigningproduced Joseph.
by conventional, off-line translation or produced
bynativesignersishardertocomeby. Neverthe-
References
less,usingnon-interpretedmateriallargelyavoids
alignment shifts in the training data and leads to
AlanAgresti.1996. Anintroductiontocategoricaldata
higherscoresforthehumantranslationsofthetest analysis,volume135. WileyNewYork.
data,amongotheradvantages.
Farhad Akhbardeh, Arkady Arkhangorodsky, Mag-
dalena Biesialska, Ondˇrej Bojar, Rajen Chatter-
11 Ethicalstatement
jee, Vishrav Chaudhary, Marta R. Costa-jussa,
Cristina España-Bonet, Angela Fan, Christian Fe-
Withinthissharedtask,twomainethicalconsider-
dermann, Markus Freitag, Yvette Graham, Ro-
ationsemerge: thepotentialimpactofSLtechnol-
man Grundkiewicz, Barry Haddow, Leonie Harter,
ogyontargetusersandprivacyconsiderations. Kenneth Heafield, Christopher Homan, Matthias
Researchinsignlanguageprocessing,ifnotex- Huck,KwabenaAmponsah-Kaakyire,JungoKasai,
DanielKhashabi,KevinKnight,TomKocmi,Philipp
ecutedcarefully,mayinadvertentlycauseharmto
Koehn, Nicholas Lourie, Christof Monz, Makoto
end users, especially members of deaf communi-
Morishita,MasaakiNagata,AjayNagesh,Toshiaki
ties. Hearing scientists should refrain from pre- Nakazawa,MatteoNegri,SantanuPal,AllahseraAu-
scribingwhatsortoflanguagetechnologyshould gusteTapo,MarcoTurchi,ValentinVydrin,andMar-
be accepted by deaf or hard-of-hearing individu- cos Zampieri. 2021. Findings of the 2021 Confer-
enceonMachineTranslation(WMT21). InProceed-
alsandshouldavoidclaimingthattheirapproach
ingsoftheSixthConferenceonMachineTranslation,
“solves”anyparticularproblem. Ideally,researchof pages1–88,Online.AssociationforComputational
thisnatureshouldincludedeafandhard-of-hearing Linguistics.
people,notonlyatevaluationtimebutintheentire
SamuelAlbanie,GülVarol,LilianeMomeni,Triantafyl-
developmentcycle(Foxetal.,2023).
losAfouras,JoonSonChung,NeilFox,andAndrew
Secondly,thereisaconcernfortheprivacyofin-
Zisserman.2020. Bsl-1k: Scalingupco-articulated
dividualsdepictedinSLPdatasets. Forthespecific signlanguagerecognitionusingmouthingcues. In
usecaseofsignlanguagedata,properanonymisa- ComputerVision–ECCV2020: 16thEuropeanCon-
ference,Glasgow,UK,August23–28,2020,Proceed-
tion is impossible, since identifying details such
ings,PartXI16,pages35–53.Springer.
asfacialexpressionsarecrucialforsignlanguage
communication. We have obtained written per- MartaBañón,PinzhenChen,BarryHaddow,Kenneth
mission of all individuals shown in our datasets. Heafield,HieuHoang,MiquelEsplà-Gomis,MikelL.
Forcada, Amir Kamran, Faheem Kirefu, Philipp
Storing and processing pose estimation features
Koehn,SergioOrtizRojas,LeopoldoPlaSempere,
instead of raw videos may be an alternative that
GemaRamírez-Sánchez,ElsaSarrías,MarekStrelec,
providesanonymity(andhasothergeneralization BrianThompson,WilliamWaites,DionWiggins,and
effectssuchasignoringdifferencesinrace,gender, JaumeZaragoza.2020. ParaCrawl: Web-ScaleAc-
quisitionofParallelCorpora. InProceedingsofthe
clothing,background,etc.). However,inourshared
58thAnnualMeetingoftheAssociationforCompu-
taskandrelatedliterature,(Moryossefetal.,2021;
tationalLinguistics,pages4555–4567,Online.Asso-
Tarrésetal.,2023)videofeaturesoutperformpose ciationforComputationalLinguistics.
features.
EliseBertin-Lemée, AnneliesBraffort,CamilleChal-
Acknowledgements lant, Claire Danet, and Michael Filhol. 2023.
Example-basedmachinetranslationfromtexttoahi-
The organizing committee acknowledges fund- erarchicalrepresentationofsignlanguage. InPro-
ceedings of the 24th Annual Conference of the Eu-
ing from the following projects: the EU Hori-
ropeanAssociationforMachineTranslation,pages
zon2020projectsEASIER(grantagreementnum-
21–30,Tampere,Finland.EuropeanAssociationfor
ber 101016982) and SignON (101017255), the MachineTranslation.
ClaudiaBianchiniandFabrizioBorgia.2012. Writing KonstantinosMDafnis,EvgeniaChroni,CarolNeidle,
signlanguages: analysisoftheevolutionofthesign- andDimitriMetaxas.2022. Bidirectionalskeleton-
writing system from 1995 to 2010, and proposals basedisolatedsignrecognitionusinggraphconvolu-
forfuturedevelopments. InProceedingsoftheIntl tional networks. In Proceedings of the Thirteenth
JubileeCongressoftheTechnicalUniversityofVarna, Language Resources and Evaluation Conference,
pages118–123. pages7328–7338.
Danielle Bragg, Oscar Koller, Mary Bellard, Larwan DariaDayter.2019. Collocationsinnon-interpretedand
Berke,PatrickBoudreault,AnneliesBraffort,Naomi simultaneouslyinterpretedenglish: acorpusstudy.
Caselli, Matt Huenerfauth, Hernisa Kacorri, Tessa In New empirical perspectives on translation and
Verhoef,ChristianVogler,andMeredithRingelMor- interpreting,pages67–91.Routledge.
ris.2019. SignLanguageRecognition,Generation,
andTranslation: AnInterdisciplinaryPerspective. In MathieuDeCoster,DimitarShterionov,MiekeVanHer-
The21stInternationalACMSIGACCESSConference reweghe,andJoniDambre.2022. Machinetransla-
onComputersandAccessibility,ASSETS’19,pages tionfromsignedtospokenlanguages:Stateoftheart
16–31,NewYork,NY,USA.AssociationforCom- andchallenges. arXivpreprintarXiv:2202.03086.
putingMachinery.
Mirella De Sisto, Dimitar Shterionov, Irene Murtagh,
HannahBull,AnneliesBraffort,andMichèleGouiffès. MyriamVermeerbergen,andLorraineLeeson.2021.
2020a. Mediapi-skel-a2d-skeletonvideodatabase DefiningMeaningfulUnits.ChallengesinSignSeg-
offrenchsignlanguagewithalignedfrenchsubtitles. mentationandSegment-MeaningMapping(shortpa-
InProceedingsofthe12thConferenceonLanguage per). InProceedingsofthe1stInternationalWork-
ResourcesandEvaluation(LREC2020),pages6063– shoponAutomaticTranslationforSignedandSpoken
6068. Languages(AT4SSL),pages98–103,Virtual.Associ-
ationforMachineTranslationintheAmericas.
HannahBull,MichèleGouiffès,andAnneliesBraffort.
2020b. Automatic segmentation of sign language
Mirella De Sisto, Vincent Vandeghinste, Santiago
intosubtitle-units. InEuropeanConferenceonCom-
Egea Gómez, Mathieu De Coster, Dimitar Shteri-
puterVision,pages186–198.Springer.
onov,andHoracioSaggion.2022. Challengeswith
signlanguagedatasetsforsignlanguagerecognition
NecatiCihanCamgöz,SimonHadfield,OscarKoller,
andtranslation. InProceedingsoftheThirteenthLan-
HermannNey,andRichardBowden.2018. Neural
guageResourcesandEvaluationConference,pages
SignLanguageTranslation. In2018IEEE/CVFCon-
2478–2487,Marseille,France.EuropeanLanguage
ferenceonComputerVisionandPatternRecognition,
ResourcesAssociation.
pages7784–7793.
Elisabeth Engberg-Pedersen. 1993. Space in Danish
NecatiCihanCamgöz,OscarKoller,SimonHadfield,
SignLanguage: TheSemanticsandMorphosyntaxof
and Richard Bowden. 2020a. Multi-channel trans-
theUseofSpaceinaVisualLanguage. SIGNUM-
formersformulti-articulatorysignlanguagetransla-
Press.
tion. InEuropeanConferenceonComputerVision,
pages301–319.
Christian Federmann. 2018. Appraise Evaluation
FrameworkforMachineTranslation. InProceedings
NecatiCihanCamgöz,OscarKoller,SimonHadfield,
of the 27th International Conference on Computa-
andRichardBowden.2020b. Signlanguagetrans-
tional Linguistics: System Demonstrations, pages
formers: Jointend-to-endsignlanguagerecognition
86–88,SantaFe,NewMexico.AssociationforCom-
and translation. In Proceedings of the IEEE/CVF
putationalLinguistics.
ConferenceonComputerVisionandPatternRecog-
nition,pages10023–10033.
MichaelFilhol.2020. ElicitationandCorpusofSponta-
Z.Cao,G.HidalgoMartinez,T.Simon,S.Wei,andY.A. neousSignLanguageDiscourseRepresentationDi-
Sheikh.2019. OpenPose: RealtimeMulti-Person2D agrams. InProceedingsofthe9thWorkshoponthe
Pose Estimation using Part Affinity Fields. IEEE Representation and Processing of Sign Languages
TransactionsonPatternAnalysisandMachineIntel- atLanguageResourcesandEvaluationConference,
ligence. pages53–60.EuropeanLanguageResourcesAssoci-
ation(ELRA).
Mauro Cettolo, Marcello Federico, Luisa Bentivogli,
Niehues Jan, Stüker Sebastian, Sudoh Katsuitho, Joseph L. Fleiss. 1971. Measuring Nominal Scale
YoshinoKoichiro, andFedermannChristian.2017. AgreementAmongManyRaters. Psychologicalbul-
OverviewoftheIWSLT2017evaluationcampaign. letin,76(5):378.
In International Workshop on Spoken Language
Translation,pages2–14. Jens Forster, Christoph Schmidt, Oscar Koller, Mar-
tinBellgardt,andHermannNey.2014. Extensions
Onno Crasborn. 2006. Nonmanual structures in sign oftheSignLanguageRecognitionandTranslation
language. EncyclopediaofLanguageandLinguistics, CorpusRWTH-PHOENIX-Weather. InProceedings
8:668–672. oftheNinthInternationalConferenceonLanguage
ResourcesandEvaluation(LREC’14),pages1911– TrevorJohnston.2010. Fromarchivetocorpus: Tran-
1916, Reykjavik, Iceland. European Language Re- scription and annotation in the creation of signed
sourcesAssociation(ELRA). languagecorpora. InternationalJournalofCorpus
Linguistics,15(1):106–131.
NeilFox,BencieWoll,andKearsyCormier.2023. Best
practicesforsignlanguagetechnologyresearch. Uni- TrevorJohnston.2011. LexicalFrequencyinSignLan-
versalAccessintheInformationSociety,pages1–9. guages. TheJournalofDeafStudiesandDeafEdu-
cation,17(2):163–193.
MarkusFreitag,GeorgeFoster,DavidGrangier,Viresh
Ratnakar,QijunTan,andWolfgangMacherey.2021. PratikJoshi, SebastinSanty, AmarBudhiraja, Kalika
Experts,Errors,andContext:ALarge-ScaleStudyof Bali,andMonojitChoudhury.2020. Thestateand
HumanEvaluationforMachineTranslation. Trans- fateoflinguisticdiversityandinclusionintheNLP
actionsoftheAssociationforComputationalLinguis- world. InProceedingsofthe58thAnnualMeetingof
tics,9:1460–1474. theAssociationforComputationalLinguistics,pages
6282–6293,Online.AssociationforComputational
YvetteGraham,TimothyBaldwin,AlistairMoffat,and Linguistics.
JustinZobel.2013. ContinuousMeasurementScales
inHumanEvaluationofMachineTranslation. InPro- Huda Khayrallah and Philipp Koehn. 2018. On the
ceedingsofthe7thLinguisticAnnotationWorkshop impactofvarioustypesofnoiseonneuralmachine
and Interoperability with Discourse, pages 33–41, translation. InProceedingsofthe2ndWorkshopon
Sofia,Bulgaria.AssociationforComputationalLin- NeuralMachineTranslationandGeneration,pages
guistics. 74–83,Melbourne,Australia.AssociationforCom-
putationalLinguistics.
Thomas Hanke.2004. Hamnosys- representingsign
language data in language resources and language Diederik P. Kingma and Jimmy Ba. 2015. Adam: A
processingcontexts. InLREC2004,Workshoppro- method for stochastic optimization. In 3rd Inter-
ceedings : Representation and processing of sign national Conference on Learning Representations,
languages,pages1–6.Paris: ELRA. ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
ConferenceTrackProceedings.
Thomas Hanke, Susanne König, Reiner Konrad,
Gabriele Langer, Patricia Barbeito Rey-Geißler, Sang-Ki Ko, Chang Jo Kim, Hyedong Jung, and
DollyBlanck,StefanGoldschmidt,IlonaHofmann, ChoongsangCho.2019. Neuralsignlanguagetrans-
Sung-EunHong,OlgaJeziorski,ThimoKleyboldt, lationbasedonhumankeypointestimation. Applied
Lutz König, Silke Matthes, Rie Nishio, Christian Sciences,9(13):2683.
Rathmann, Uta Salden, Sven Wagner, and Satu
Worseck.2020. MEINEDGS.ÖffentlichesKorpus Tom Kocmi, Rachel Bawden, Ondˇrej Bojar, Anton
derDeutschenGebärdensprache,3.Release. Dvorkovich, Christian Federmann, Mark Fishel,
Thamme Gowda, Yvette Graham, Roman Grund-
ThomasHankeandJakobStorz.2008. ilex–adatabase kiewicz,BarryHaddow,RebeccaKnowles,Philipp
tool for integrating sign language corpus linguis- Koehn,ChristofMonz,MakotoMorishita,Masaaki
ticsandsignlanguagelexicography. Insign-lang@ Nagata,ToshiakiNakazawa,MichalNovák,Martin
LREC2008,pages64–67.EuropeanLanguageRe- Popel,andMajaPopovic´.2022. Findingsofthe2022
sourcesAssociation(ELRA). conference on machine translation (WMT22). In
ProceedingsoftheSeventhConferenceonMachine
Hany Hassan, Anthony Aue, Chang Chen, Vishal Translation(WMT),pages1–45,AbuDhabi,United
Chowdhary, Jonathan Clark, Christian Federmann, ArabEmirates(Hybrid).AssociationforComputa-
XuedongHuang,MarcinJunczys-Dowmunt,William tionalLinguistics.
Lewis, Mu Li, et al. 2018. Achieving human par-
ityonautomaticchinesetoenglishnewstranslation. Tom Kocmi, Christian Federmann, Roman Grund-
arXivpreprintarXiv:1803.05567. kiewicz,MarcinJunczys-Dowmunt,HitokazuMat-
sushita,andArulMenezes.2021. ToShiporNotto
MertInan,YangZhong,SabitHassan,LornaQuandt, Ship: AnExtensiveEvaluationofAutomaticMetrics
and Malihe Alikhani. 2022. Modeling intensifica- forMachineTranslation. InProceedingsoftheSixth
tionforsignlanguagegeneration: Acomputational ConferenceonMachineTranslation,pages478–494,
approach. InFindingsoftheAssociationforCom- Online.AssociationforComputationalLinguistics.
putationalLinguistics: ACL2022,pages2897–2911,
Dublin,Ireland.AssociationforComputationalLin- PhilippKoehn.2004. StatisticalSignificanceTestsfor
guistics. MachineTranslationEvaluation. InProceedingsof
the2004ConferenceonEmpiricalMethodsinNatu-
Zifan Jiang, Amit Moryossef, Mathias Müller, and ralLanguageProcessing,pages388–395,Barcelona,
SarahEbling.2023a. Signsuissedsgs/lsf/lislexicon. Spain.AssociationforComputationalLinguistics.
Zifan Jiang, Amit Moryossef, Mathias Müller, and OscarKoller.2020. Quantitativesurveyofthestateof
SarahEbling.2023b. Srfdsgsdailynewsbroadcast: theartinsignlanguagerecognition. arXivpreprint
videoandoriginalsubtitledata. arXiv:2008.09918.
MariaKopf,MarcSchulder,andThomasHanke.2021. Amit Moryossef and Yoav Goldberg. 2021.
OverviewofDatasetsfortheSignLanguagesofEu- Sign Language Processing. https:
rope. //sign-language-processing.github.io/.
TakuKudoandJohnRichardson.2018. SentencePiece: Amit Moryossef and Mathias Müller. 2021. pose-
A simple and language independent subword tok- format: Libraryforviewing,augmenting,andhan-
enizer and detokenizer for Neural Text Processing. dling .pose files. https://github.com/AmitMY/
InProceedingsofthe2018ConferenceonEmpirical pose-format.
Methods in Natural Language Processing: System
Amit Moryossef, Mathias Müller, Anne Göhring, Zi-
Demonstrations, pages 66–71, Brussels, Belgium.
fanJiang,YoavGoldberg,andSarahEbling.2023.
AssociationforComputationalLinguistics.
Anopen-sourcegloss-basedbaselineforspokento
signed language translation. In 2nd International
JRLandisandGGKoch.1977. TheMeasurementof
WorkshoponAutomaticTranslationforSignedand
ObserverAgreementforCategoricalData. Biomet-
SpokenLanguages(AT4SSL). Availableat: https:
rics,33(1):159–174.
//arxiv.org/abs/2305.17714.
KatherineLee,OrhanFirat,AshishAgarwal,ClaraFan-
Amit Moryossef, Ioannis Tsochantaridis, Joe Dinn,
njiang,andDavidSussillo.2018. Hallucinationsin
NecatiCihanCamgöz,RichardBowden,TaoJiang,
NeuralMachineTranslation.
Annette Rios, Mathias Müller, and Sarah Ebling.
2021. Evaluating the immediate applicability of
LorraineLeeson.2005. Makingtheeffortinsimultane-
pose estimation for sign language recognition. In
ousinterpreting. TopicsinSignedLanguageInter-
IEEE/CVF Conference on Computer Vision and
preting: TheoryandPractice,ed.byTerryJanzen.–
Pattern Recognition Workshops, 10166v1. 2021
Amsterdam.
ChaLearnLookingatPeopleSignLanguageRecog-
DongxuLi,CristianRodriguez,XinYu,andHongdong nitionintheWildWorkshopatCVPR.
Li.2020. Word-leveldeepsignlanguagerecognition
MathiasMüller, SarahEbling, EleftheriosAvramidis,
fromvideo: Anewlarge-scaledatasetandmethods
Alessia Battisti, Michèle Berger, Richard Bowden,
comparison. InProceedingsoftheIEEE/CVFwinter
Annelies Braffort, Necati Cihan Camgöz, Cristina
conferenceonapplicationsofcomputervision,pages
España-bonet, Roman Grundkiewicz, Zifan Jiang,
1459–1469.
Oscar Koller, Amit Moryossef, Regula Perrollaz,
SabineReinhard,AnnetteRios,DimitarShterionov,
ZeLiu,JiaNing,YueCao,YixuanWei,ZhengZhang,
SandraSidler-miserez,andKatjaTissi.2022. Find-
StephenLin,andHanHu.2022. Videoswintrans-
ingsofthefirstWMTsharedtaskonsignlanguage
former. InProceedingsoftheIEEE/CVFconference
translation (WMT-SLT22). In Proceedings of the
oncomputervisionandpatternrecognition, pages
SeventhConferenceonMachineTranslation(WMT),
3202–3211.
pages744–772,AbuDhabi,UnitedArabEmirates
(Hybrid).AssociationforComputationalLinguistics.
CamilloLugaresi, JiuqiangTang, HadonNash, Chris
McClanahan, Esha Uboweja, Michael Hays, Fan
MathiasMüller,ZifanJiang,AmitMoryossef,Annette
Zhang, Chuo-Ling Chang, Ming Guang Yong,
Rios, and Sarah Ebling. 2023. Considerations for
Juhyun Lee, Wan-Teh Chang, Wei Hua, Manfred
meaningfulsignlanguagemachinetranslationbased
Georg,andMatthiasGrundmann.2019. MediaPipe:
onglosses. InProceedingsofthe61stAnnualMeet-
A Framework for Building Perception Pipelines.
ingoftheAssociationforComputationalLinguistics
CoRR,abs/1906.08172.
(Volume2: ShortPapers),pages682–693,Toronto,
Canada.AssociationforComputationalLinguistics.
QingsongMa,YvetteGraham,TimothyBaldwin,and
QunLiu.2017. Furtherinvestigationintoreference
EllenOrmelandOnnoCrasborn.2012. Prosodiccorre-
bias in monolingual evaluation of machine transla-
latesofsentencesinsignedlanguages: Aliterature
tion. InProceedingsofthe2017ConferenceonEm-
reviewandsuggestionsfornewtypesofstudies. Sign
pirical Methods in Natural Language Processing,
LanguageStudies,12(2):279–315.
pages2466–2475,Copenhagen,Denmark.Associa-
tionforComputationalLinguistics. MyleOtt,SergeyEdunov,AlexeiBaevski,AngelaFan,
SamGross,NathanNg,DavidGrangier,andMichael
Caio DD Monteiro, Christy Maria Mathew, Ricardo Auli. 2019. fairseq: A fast, extensible toolkit for
Gutierrez-Osuna,andFrankShipman.2016. Detect- sequencemodeling. InProceedingsofNAACL-HLT
ing and identifying sign languages through visual 2019: Demonstrations.
features. In2016IEEEInternationalSymposiumon
Multimedia(ISM),pages287–290.IEEE. KishorePapineni,SalimRoukos,ToddWard,andWei-
Jing Zhu. 2002. BLEU: a Method for Automatic
SaraMorrissey.2011. Assessingthreerepresentation EvaluationofMachineTranslation. InProceedings
methodsforsignlanguagemachinetranslationand of the 40th Annual Meeting of the Association for
evaluation. InProceedingsofthe15thannualmeet- ComputationalLinguistics,pages311–318,Philadel-
ingoftheEuropeanAssociationforMachineTransla- phia,Pennsylvania,USA.AssociationforComputa-
tion(EAMT2011),Leuven,Belgium,pages137–144. tionalLinguistics.
PamelaPerniss,AsliÖzyürek,andGaryMorgan.2015. Shakhnarovich.2023. TTIC’sSubmissiontoWMT-
The influence of the visual modality on language SLT23. InProceedingsoftheEighthConferenceon
structure and conventionalization: Insights from MachineTranslation(WMT),Singapore,Singapore
signlanguageandgesture. TopicsinCognitiveSci- (Hybrid).AssociationforComputationalLinguistics.
ence,7(1):2–11.
BenSaunders,NecatiCihanCamgöz,andRichardBow-
ElenaPizzutoandPaolaPietrandrea.2001. TheNota- den.2020a. Adversarialtrainingformulti-channel
tionofSignedTexts:OpenQuestionsandIndications sign language production. In The 31st British Ma-
forFurtherResearch. SignLanguage&Linguistics, chineVisionVirtualConference.BritishMachineVi-
4:29–45. sionAssociation.
MartinPopel,MarketaTomkova,JakubTomek,Łukasz BenSaunders,NecatiCihanCamgöz,andRichardBow-
Kaiser,JakobUszkoreit,OndˇrejBojar,andZdeneˇk den.2020b. Everybodysignnow: Translatingspo-
Žabokrtsky`.2020. TransformingMachineTransla- kenlanguagetophotorealisticsignlanguagevideo.
tion: aDeepLearningSystemReachesNewsTrans- arXivpreprintarXiv:2011.09846.
lationQualityComparabletoHumanProfessionals.
Naturecommunications,11(1):1–15. BenSaunders,NecatiCihanCamgöz,andRichardBow-
den.2020c. Progressivetransformersforend-to-end
Maja Popovic´. 2015. chrF: character n-gram F-score signlanguageproduction. InEuropeanConference
forautomaticMTevaluation. InProceedingsofthe onComputerVision,pages687–705.
TenthWorkshoponStatisticalMachineTranslation,
pages 392–395, Lisbon, Portugal. Association for Ben Saunders, Necati Cihan Camgoz, and Richard
ComputationalLinguistics. Bowden. 2022. Signing at Scale: Learning to Co-
ArticulateSignsforLarge-ScalePhoto-RealisticSign
MattPost.2018. ACallforClarityinReportingBLEU
LanguageProduction. InProceedingsoftheIEEE
Scores. InProceedingsoftheThirdConferenceon
ConferenceonComputerVisionandPatternRecog-
MachineTranslation: ResearchPapers,pages186–
nition(CVPR).
191, Belgium, Brussels. Association for Computa-
tionalLinguistics.
ThibaultSellam,DipanjanDas,andAnkurParikh.2020.
BLEURT:LearningRobustMetricsforTextGenera-
AlecRadford,JeffreyWu,RewonChild,DavidLuan,
tion. InProceedingsofthe58thAnnualMeetingof
DarioAmodei,IlyaSutskever,etal.2019. Language
theAssociationforComputationalLinguistics,pages
modelsareunsupervisedmultitasklearners. OpenAI
7881–7892,Online.AssociationforComputational
blog,1(8):9.
Linguistics.
ColinRaffel,NoamShazeer,AdamRoberts,Katherine
RicoSennrichandBiaoZhang.2019. RevisitingLow-
Lee,SharanNarang,MichaelMatena,YanqiZhou,
ResourceNeuralMachineTranslation:ACaseStudy.
WeiLi,andPeterJLiu.2020. Exploringthelimits
InProceedingsofthe57thAnnualMeetingoftheAs-
oftransferlearningwithaunifiedtext-to-texttrans-
sociationforComputationalLinguistics,pages211–
former. TheJournalofMachineLearningResearch,
221,Florence,Italy.AssociationforComputational
21(1):5485–5551.
Linguistics.
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott
Bowen Shi, Diane Brentari, Gregory Shakhnarovich,
Gray,ChelseaVoss,AlecRadford,MarkChen,and
and Karen Livescu. 2022. Open-domain sign lan-
IlyaSutskever.2021. Zero-shottext-to-imagegen-
guagetranslationlearnedfromonlinevideo. InPro-
eration. In International Conference on Machine
ceedingsofthe2022ConferenceonEmpiricalMeth-
Learning,pages8821–8831.PMLR.
ods in Natural Language Processing, pages 6365–
Vikas Raunak, Arul Menezes, and Marcin Junczys- 6379,AbuDhabi,UnitedArabEmirates.Association
Dowmunt.2021. TheCuriousCaseofHallucinations forComputationalLinguistics.
in Neural Machine Translation. In Proceedings of
the2021ConferenceoftheNorthAmericanChap- AnitaSlonimska,AsliÖzyürek,andOlgaCapirci.2021.
teroftheAssociationforComputationalLinguistics: UsingDepictionforEfficientCommunicationinLIS
HumanLanguageTechnologies,pages1172–1183, (ItalianSignLanguage). LanguageandCognition,
Online.AssociationforComputationalLinguistics. 13(3):367–396.
RicardoRei,CraigStewart,AnaCFarinha,andAlon StephanieStoll,NecatiCihanCamgöz,SimonHadfield,
Lavie.2020. COMET:ANeuralFrameworkforMT and Richard Bowden. 2020. Text2Sign: Towards
Evaluation. InProceedingsofthe2020Conference Sign Language Production Using Neural Machine
onEmpiricalMethodsinNaturalLanguageProcess- TranslationandGenerativeAdversarialNetworks. In-
ing(EMNLP),pages2685–2702,Online.Association ternationalJournalofComputerVision,128(4):891–
forComputationalLinguistics. 908.
Marcelo Sandoval-Castaneda, Yanhong Li, Bowen Valerie Sutton. 1990. Lessons in sign writing. Sign-
Shi, Diane Brentari, Karen Livescu, and Gregory Writing.
LaiaTarrés,GerardI.Gállego,AmandaDuarte,Jordi BencieWoll.2013. 9091TheHistoryofSignLanguage
Torres,andXavierGiróiNieto.2023. Signlanguage Linguistics. InTheOxfordHandbookoftheHistory
translationfrominstructionalvideos. InProceedings ofLinguistics.OxfordUniversityPress.
of the IEEE/CVF Conference on Computer Vision
andPatternRecognition(CVPR):Workshops. BaixuanXu,HaochenShi,TianshiZheng,QingZong,
Weiqi Wang, Zhaowei Wang, and Yangqiu Song.
DavidUthus,GarrettTanzer,andManfredGeorg.2023. 2023. KnowComp Submission for WMT23 Sign
Youtube-asl: Alarge-scale,open-domainamerican Language Translation Task. In Proceedings of the
signlanguage-englishparallelcorpus. EighthConferenceonMachineTranslation(WMT),
Singapore,Singapore(Hybrid).AssociationforCom-
GülVarol,LilianeMomeni,SamuelAlbanie,Triantafyl- putationalLinguistics.
los Afouras, and Andrew Zisserman. 2021. Read
Kayo Yin, Amit Moryossef, Julie Hochgesang, Yoav
andattend: Temporallocalisationinsignlanguage
Goldberg, and Malihe Alikhani. 2021. Including
videos. InCVPR.
SignedLanguagesinNaturalLanguageProcessing.
In Proceedings of the 59th Annual Meeting of the
GülVarol,LilianeMomeni,SamuelAlbanie,Triantafyl-
Association for Computational Linguistics and the
los Afouras, and Andrew Zisserman. 2022. Scal-
11thInternationalJointConferenceonNaturalLan-
ing up sign spotting through sign language dictio-
guageProcessing(Volume1: LongPapers),pages
naries. International Journal of Computer Vision,
7347–7360,Online.AssociationforComputational
130(6):1416–1439.
Linguistics.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
KayoYinandJesseRead.2020. Bettersignlanguage
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
translationwithstmc-transformer. InProceedingsof
Kaiser,andIlliaPolosukhin.2017. Attentionisall
the28thInternationalConferenceonComputational
youneed. InAdvancesinNeuralInformationPro-
Linguistics,pages5975–5989.
cessingSystems,volume30.CurranAssociates,Inc.
Carla Viegas, Mert Inan, Lorna Quandt, and Malihe
Alikhani.2023. Includingfacialexpressionsincon-
textualembeddingsforsignlanguagegeneration. In
Proceedingsofthe12thJointConferenceonLexical
andComputationalSemantics(*SEM2023),pages1–
10,Toronto,Canada.AssociationforComputational
Linguistics.
Ashwin K. Vijayakumar, Michael Cogswell, Ram-
prasaathR.Selvaraju,QingSun,StefanLee,DavidJ.
Crandall, and Dhruv Batra. 2016. Diverse beam
search: Decodingdiversesolutionsfromneuralse-
quencemodels. CoRR,abs/1610.02424.
HarryWalsh,BenSaunders,andRichardBowden.2022.
Changing the representation: Examining language
representationforneuralsignlanguageproduction.
InLREC2022.
XinlongWang,RufengZhang,TaoKong,LeiLi,and
ChunhuaShen.2020. SOLOv2: DynamicandFast
InstanceSegmentation. InAdvancesinNeuralInfor-
mationProcessingSystems,volume33,pages17721–
17732.CurranAssociates,Inc.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond,ClementDelangue,AnthonyMoi,Pier-
ricCistac,TimRault,RémiLouf,MorganFuntowicz,
andJamieBrew.2019. Huggingface’stransformers:
State-of-the-artnaturallanguageprocessing. CoRR,
abs/1910.03771.
Rosalee Wolfe, John C. McDonald, Thomas Hanke,
Sarah Ebling, Davy Van Landuyt, Frankie Picron,
VerenaKrausneker,EleniEfthimiou,EvitaFotinea,
andAnneliesBraffort.2022. Signlanguageavatars:
Aquestionofrepresentation. Information,13(4):206.
A Detailsonsharedtaskdataandsubmission
A.1 Dataresources
Direct download links: https://www.swissubase.ch/en/catalogue/studies/20452/19173/
datasets/2327/2705/overview
Signsuisse lexicon (release 2.0): https://www.swissubase.ch/en/catalogue/studies/20452/
19280/datasets/2350/2715/overview
SRFcorpusposesandsegmentedsubtitles(release1.0): https://www.swissubase.ch/en/catalogue/
studies/20452/19280/datasets/2343/2721/overview
Test sources as a tar ball (release 2.0): https://files.ifi.uzh.ch/cl/archiv/2023/easier/
wmtslt/test_sources.v2.0.tar.gz
TestsourcesinWMTXMLformatforsubmissions: https://files.ifi.uzh.ch/cl/archiv/2023/
easier/wmtslt/xml/
A.2 XMLsubmissionschema
<?xml version= ' 1.0 ' encoding= ' utf −8 '?>
<dataset id=" slttest2022 .de−dsgs">
<doc origlang="de" id=" srf .0">
<src lang="de">
<p>
<seg id="0">Guten Abend meine Damen und Herren - willkommen zur
"Tagesschau".</ seg>
</p>
</ src>
<hyp system="YOURSYSTEMNAME" language="dsgs">
<p>
<seg id="0"> https://www.your_hosting.com/your_url_for_this_segment
</ seg>
</p>
</hyp>
</doc>
</ dataset>
B Appraiseinstructionstohumanevaluators
B.1 Sign-to-textdirection
B.1.1 English
Below you see a document with 10 sentences in Swiss-German Sign Language (Deutschschweizer
Gebärdensprache (DSGS)) (left columns) and their corresponding candidate translations in German
(Deutsch)(rightcolumns). Scoreeachcandidatesentencetranslationinthedocumentcontext. Youmay
revisitalreadyscoredsentencesandupdatetheirscoresatanytimebyclickingonasourcevideo.
Assessthetranslationqualityonacontinuousscaleusingthequalitylevelsdescribedasfollows:
• 0: Nonsense/Nomeaningpreserved: Nearlyallinformationislostbetweenthetranslationandsource.
Grammarisirrelevant.
• 2: SomeMeaningPreserved: Thetranslationpreservessomeofthemeaningofthesourcebutmisses
significantparts. Thenarrativeishardtofollowduetofundamentalerrors. Grammarmaybepoor.
• 4: MostMeaningPreservedandFewGrammarMistakes: Thetranslationretainsmostofthemeaning
ofthesource. Itmayhavesomegrammarmistakesorminorcontextualinconsistencies.
• 6: PerfectMeaningandGrammar: Themeaningofthetranslationiscompletelyconsistentwiththe
sourceandthesurroundingcontext. Thegrammarisalsocorrect.
Pleasescoretheoveralldocumenttranslationquality(youcanscorethewholedocumentonlyafterscoring
allindividualsentencesfirst). Assessthetranslationqualityonacontinuousscaleusingthequalitylevels
describedasfollows:
• 0: Nonsense/Nomeaningpreserved: Nearlyallinformationislostbetweenthetranslationandsource.
Grammarisirrelevant.
• 2: SomeMeaningPreserved: Thetranslationpreservessomeofthemeaningofthesourcebutmisses
significantparts. Thenarrativeishardtofollowduetofundamentalerrors. Grammarmaybepoor.
• 4: MostMeaningPreservedandFewGrammarMistakes: Thetranslationretainsmostofthemeaning
ofthesource. Itmayhavesomegrammarmistakesorminorcontextualinconsistencies.
• 6: PerfectMeaningandGrammar: Themeaningofthetranslationiscompletelyconsistentwiththe
sourceandthesurroundingcontext. Thegrammarisalsocorrect.
B.1.2 German
Unten sehen Sie ein Dokument mit 10 Sätzen in Deutschschweizer Gebärdensprache (DSGS) (linke
Spalten)unddieentsprechendenmöglichenÜbersetzungenaufDeutsch(rechteSpalten). BewertenSie
jedemöglicheÜbersetzungdesSatzesimKontextdesDokuments. SiekönnenbereitsbewerteteSätze
jederzeitdurchAnklickeneinesEingabevideoserneutaufrufenunddieBewertungaktualisieren.
Bewerten Sie die Übersetzungsqualität auf einer kontinuierlichen Skala mit Hilfe der nachfolgend
beschriebenenQualitätsstufen:
• 0: Unsinn/Bedeutungnichterhalten: FastalleInformationenzwischenÜbersetzungundEingabev-
ideosindverlorengegangen. DieGrammatikistirrelevant.
• 2: EinTeilderBedeutungisterhalten: DieÜbersetzungbehälteinenTeilderBedeutungderQuelle
bei,lässtaberwichtigeTeileaus. DieErzählungistaufgrundvongrundlegendenFehlernschwerzu
verstehen. DieGrammatikkannmangelhaftsein.
• 4: Der grösste Teil der Bedeutung ist erhalten und es gibt nur wenige Grammatikfehler: Die
ÜbersetzungbehältdengrösstenTeilderBedeutungderQuellebei. SiekanneinigeGrammatikfehler
oderkleinerekontextuelleUnstimmigkeitenaufweisen.
• 6: PerfekteBedeutungundGrammatik: DieBedeutungderÜbersetzungstimmtvollständigmitder
QuelleunddemumgebendenKontext(fallszutreffend)überein. AuchdieGrammatikistkorrekt.
BittebewertenSiedieÜbersetzungsqualitätdesgesamtenDokuments. (SiekönnendasDokumenterst
bewerten,nachdemSiezuvoralleSätzeeinzelnbewertethaben.) BewertenSiedieÜbersetzungsqualität
aufeinerkontinuierlichenSkalamitHilfedernachfolgendbeschriebenenQualitätsstufen:
• 0: Unsinn/Bedeutungnichterhalten: FastalleInformationenzwischenÜbersetzungundEingabev-
ideosindverlorengegangen. DieGrammatikistirrelevant.
• 2: EinTeilderBedeutungisterhalten: DieÜbersetzungbehälteinenTeilderBedeutungderQuelle
bei,lässtaberwichtigeTeileaus. DieErzählungistaufgrundvongrundlegendenFehlernschwerzu
verstehen. DieGrammatikkannmangelhaftsein.
• 4: Der grösste Teil der Bedeutung ist erhalten und es gibt nur wenige Grammatikfehler: Die
ÜbersetzungbehältdengrösstenTeilderBedeutungderQuellebei. SiekanneinigeGrammatikfehler
oderkleinerekontextuelleUnstimmigkeitenaufweisen.
• 6: PerfekteBedeutungundGrammatik: DieBedeutungderÜbersetzungstimmtvollständigmitder
QuelleunddemumgebendenKontext(fallszutreffend)überein. AuchdieGrammatikistkorrekt.
C Feedbackfromevaluators
Tables 9 and 10 detail for each evaluator the feedback answers and comments regarding the human
evaluationprocedureandtheAppraisesystem. Allthreeevaluatorssubmittedaresponse.
Answer1 Answer2 Answer3
Whatisyourexperienceinassessingmachinetranslationoutputs?
Low:Ihavedoneitonceoralong Moderate:Ihavedoneitafewtimes Low: Ihavedoneitonceortwice
timeago before,oralongtimeago
Pleasespecifyhowmuchyouagreeordisagreewiththefollowingstatements.
Generally,myexperiencewiththe Agree Agree Agree
toolwaspositive
Instructionswereclear Neutral Stronglyagree Stronglyagree
Qualitylevels0-6werehelpfulto Neutral Neutral Agree
me
Sourcevideoswereunderstandable Stronglyagree Agree StronglyAgree
Therewastoomuchrepetitiveness Stronglyagree Neutral Stronglyagree
Documentsweretoolong Disagree Disagree Neutral
Segmentsweretooshort Disagree Disagree Disagree
Insomecases,thecontextwasinsuf- Neutral Neutral Disagree
ficient
Iexperiencedtechnicalissues Neutral Neutral Disagree
I would be willing to do similar Agree Agree Agree
workinthefuture
ThisevaluationcampaignfeaturedtheDirectAssessmentwithScalarQualityMetricsmethod.
Whatdoyouthinkaboutthismethod?Onascalebetween-3(negative)and3(positive)itwas...
difficult/easy +1 +3 +3
stressful/relaxed 0 +3 +2
laborious/effortless +2 +2 -2
slow/fast +2 +2 0
inefficient/efficient +2 +2 +2
boring/exciting -1 +2 0
complicated/simple +1 +2 +3
annoying/enjoyable -1 +2 0
limiting/creative -1 0 0
impractical/practical 0 +2 +3
Table9: FeedbackfromevaluatorsaboutthehumanevaluationsetupandtheAppraiseplatform.
Answer1 Answer2 Answer3
Pleaseprovidemoredetailsrelatedtothestatementsabovethatyouthinkcanbeusefultous.
Whatwasmosttroublesome?Whatcouldweimprove?
(original in German) - Ich hätte (translatedintoEnglish)-Iwould Someofthefilmclipswerepoorly Thelargeamountofnonsensetrans-
ein grösseres Video geschätzt have appreciated a larger video editedandthereforedidnotmatch lationscouldleadtothefactthat
(ohne dass ich das jedes Mal (withouthavingtoactivelyclickthat the translated text. Certain writ- onedoesnotworkconcentratedany
aktiv anklicken muss) > Z.B. bei everytime)>E.g. whenclicking tenformulationsarenotcommonin more.
Klicken auf Play, automatische play,automaticenlargementandat Switzerland. Therearesomevery
Vergrösserung und bei Ende der theendofplaybackautomatically Germanformulations.TheGerman
Wiedergabe automatisch zurück backtothescale.-Thevideocuts textwastakenover,therewasno
aufdieSkala. -DieVideoschnitte were-especiallywithonemodel realtranslation.
waren - v.a. bei einem Modell (longlag!) -verybad. Videoand
(langer Lag!) - sehr schlecht. textthereforeoftendidnotmatch.
VideoundTextstimmtendeshalb Difficultfortheevaluation!-Itof-
oft nicht überein. Schwierig für tenhappenedthatwholedocuments
die Beurteilung! - Es kam oft appearedataglanceas"completely
vor,dassganzeDokumenteschon wrong"(textscompletelyincompre-
auf einen Blick als "komplett hensible).Thereitwouldbehelpful
falsch" ersichtlich waren (Texte ifonecouldjudgeawholedocument
komplettunverständlich).Dawäre as"RED"withoutjudgingeverysin-
eshilfreich,wennmaneingesamtes glevideo.
Dokument als "ROT" beurteilen
könnte,ohnejedeseinzelneVideo
zubeurteilen.
Whatwerethemainormostcommonissueswiththeautomatictranslations?
(originalinGerman)Esgabwenig (translatedintoEnglish)Therewere Someofthefilmclipswerepoorly Thelargeamountofnonsensetrans-
ProblemetechnischerArt. Nur1x fewproblemsofatechnicalnature. editedandthereforedidnotmatch lations.
keinZugangzumDokument. Ab Only1xnoaccesstothedocument. thetranslatedtext.
undzu(aberselten!)eineMeldung, Nowandthen(butrarely!) ames-
dassdie"Resultate"nichtangenom- sagethatthe"results"couldnotbe
men/gespeichertwerdenkonnten. accepted/saved.
Table10: FeedbackcommentsfromevaluatorsaboutthehumanevaluationsetupandtheAppraiseplatform.
