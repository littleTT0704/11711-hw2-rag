ALERT: Adapting Language Models to Reasoning Tasks
PingYu♠ TianluWang♠ OlgaGolovneva♠ BadrAlKhamissi△
SiddharthVerma△ ZhijingJin‡△ GargiGhosh♠ MonaDiab♠ AsliCelikyilmaz♠
♠MetaAI △WorkdoneatMetaAI
‡MaxPlanckInstitute&ETH
{pingyu,aslic}@meta.com
Abstract Thecafeteriahad23apples. Iftheyused20tomakelunchand
bought6more,howmanyapplesdotheyhave?
Theansweris 29apples.
Recentadvancementsinlargelanguagemodels
have enabled them to perform well on com- Selectthebesttranslationintopredicatelogic.DavidteachesChris.
(c:Chris;d:David;Txy:xteachesy)(A)Tdc;(B)Tcd;(C)Tcc;
plextasksthatrequirestep-by-stepreasoning
(D)dTc.Theansweris (B)Tcd.
withfew-shotlearning. However,itisunclear
Isabella entered the hall. Olivia entered the hall. The ap-
whetherthesemodelsareapplyingreasoning
ple is in the blue_treasure_chest. Olivia exited the hall. Is-
skillstheyhavelearnedduringpre-training,or
abellamovedtheappletothegreen_basket. Question: Where
if they are simply memorizing their training does Isabella think that Olivia searches for the apple? The
corpusatfinergranularityandhavelearnedto answeris IsabellathinksthatOliviasearchesfortheappleinthe
betterunderstandtheircontext. Toaddressthis green_basket.
question, we introduce ALERT, a benchmark
and suite of analyses for evaluating reason- Table1:Examplesfromtasksthatrequirereasoningskillsand
generatedoutputsfromGPT-3seriestext-davinci-003engine.
ingskillsoflanguagemodels. ALERTenables
The failed outputs are highlighted in red. Predictions by
comparingpre-trainedandfinetunedmodelson
ChatGPTareshowninTable9inAppendix.
complextasksthatrequirereasoningskillsto
solvethem. Ourbenchmarkprovidesatestbed
toassessanylanguagemodelonfine-grained
thepowerfulLLMs(suchastext-davinci-0031 and
reasoningskills,whichspansover20datasets
ChatGPT2)failtomakecorrectpredictions.
and covers 10 different reasoning skills. To
provetheefficacyofALERTweinvestigatethe ToimprovelargeLLMs’performanceontasks
roleoffinetuning.Ourextensiveempiricalanal- that require multiple steps of reasoning, recent
ysis shows that language models acquire rea- workuseddifferentpromptingmethodswhichin-
soningskillssuchastextualentailment,abduc- cludedarationalewiththefinalanswerintheform
tive reasoning, and analogical reasoning dur-
of: scratchpad for arithmetic and logical reason-
ingthefinetuningstagecomparedtopretrain-
ing(Nyeetal.,2021),chain-of-thought(CoT)(Wei
ing stage. Another finding is when language
etal.,2022)forpracticallyanytasks,oraddinglet’s
modelsarefinetunedtheytendtooverfittothe
prompttemplate,whichhurtstherobustnessof thinkstep-by-step (Kojimaetal.,2022)toprompt
modelsresultingingeneralizationproblems. modelstogenerateexplanations. Otherworkssuch
asChungetal.(2022)integratedstep-by-stepexpla-
1 Introduction nationsintothefinetuningstage(CoT-finetuning).
Whilethesetechniquesmayimprovetheaccuracy
Large language models (LLMs) (e.g., GPT-
andinterpretability,itisnotwellunderstoodwhich
3(Brownetal.,2020a),PALM(Chowdheryetal.,
reasoningskillstheyrelyonortowhatdegreethey
2022), OPT (Zhang et al., 2022)) have shown in-
requirehigher-orderreasoning. Itisalsouncertain
creasingin-contextlearningcapabilitieswithscal-
howfrequentlythestatedreasoningstepsactually
ing up the model and data sizes. Despite this
contributetothefinaltaskpredictions. Forinstance,
progress, even the largest of these models still
tocorrectlyanswerthequestionsinTable1acom-
struggle with tasks such as commonsense rea-
binationoflogical,commonsense,mathandspatial
soning (West et al., 2022), and math word prob-
reasoningskillsarerequired.
lems(Hendrycksetal.,2021b)whichrequirearith-
Inthiswork,togainadeeperunderstandingof
meticreasoningorsymbolicmanipulation(Rytting
and Wingate, 2021). Table 1 presents some ex- 1https://beta.openai.com/docs/models/gpt-3.
amplesthatrequirecertainreasoningskills. Even 2https://chat.openai.com/chat.
3202
luJ
7
]LC.sc[
2v68280.2122:viXra
LLMs reasoning abilities in in-context learning ReasoningSkills Datasets
settings, we introduce ALERT, a new pipeline to Logical bigbenchrepeatcopylogic,mmmluan-
benchmark different LLMs on various reasoning swergeneration
Causal plausableresultgeneration,anlir2entail-
skillsandprovideanalysistoassessreasoningabil-
ment,anlir3entailment,cbentailment
ities. Unlikeexistingcommonlyusedbenchmarks Commonsense piqaanswergeneration,commongensen-
(e.g.,Mishraetal.(2022);Wangetal.(2022c);Sri- tencegeneration,sciqanswergeneration,
openbookqaquestionanswering
vastava et al. (2022)), ALERT can evaluate LLMs’
Entailment nlir2entailment,anlir3entailment,cb
fine-grained reasoning skills. It spans over 20 entailment,lueentailmentclassification
datasets and covers 10 different reasoning skills Mathematics semevalclosedvocabularymath,semeval
geometricmath,mmmluformallogic
includinglogical,causal,commonsense,abductive,
Abductive tellmewhy
spatial,analogical,argumentanddeductivereason- Spatial babit1singlesupportingfact,piqaanswer
ingaswellastextualentailment,andmathematics generation,toqafindlocationeasyclean
Analogical commongen sentence generation, bard
(see Figure 6). ALERT enables easy benchmark-
analogicalreasoningcausation
ing of any LM (e.g., pre-trained, finetuned, CoT- Argument argumentstanceclassification,argument
finetuned)onarichsetofnewinferencemethods consequenceclassification
Deductive rocstoriescorrectanswergeneration
includingzero-shot,few-shotandCoT.
Using ALERT, we further investigate whether
Table2: ALERTbenchmarkconsistsof20datasetscovering
finetuning can improve LMs’ performance on 10differentreasoningskills. Thefulllistofthereasoning
downstreamreasoningtasks. Specifically,weare skillsanddatasetsisinTable4inAppendixA.1.
interested in diagnosing what actually improved
when we observe a performance increase on rea-
datasets. Tothisend,weusevocabularyoverlapto
soningtasks. Isitbecausemodelshaveseensimilar
measuretheextenttowhichtheevaluationdatais
datainthefinetuningstage? Orisitbecausemod-
differentfromthefinetuningdata,i.e. Weinvesti-
els have seen prompts in a specific template and
gatewhethertheimprovementismoresignificant
memorize thetemplate duringfinetuning such as
whenevaluationdataandfinetuningdataaremore
definitionsprovidedintheNIV2benchmark(Wang
similar.
etal.,2022c)? OrdoestheLLMactuallyacquired
(2) Reasoning skills transfer: We investigate if
therequiredreasoningskill? Weinvestigatethese
certain reasoning skills can be more successfully
threepossibilities.
permeated in LLMs than other reasoning skills.
Tostudytheabovequestions,wecomparethree
To verify this, we carefully divide the evaluation
differentmodeltypes(asshowninFigure2): apre-
datasetsintogroupswhichrequiredifferentreason-
trainedmodelandtwotypesoffinetunedmodels.
ingskills. Wecompileheld-outdatasetsasshown
Specifically:
inFigure6whichrequireskillsheld-outfromany
of the training datasets. This way, we expect to
• OPT(Zhangetal.,2022): AbaselineLLMa
seelargerimprovementsonin-domainskillscom-
pre-trainedmodelwithnofinetuning(figure
pared to held-out skills if reasoning skills can be
(A)inFigure2);
transferredduringfinetuningstages.
• OPT-FT: Meta-finetuned OPT on reference (3) Prompt template memorization: Our third
answers without explanations, illustrated in hypothesis is that LLMs can overfit to data for-
(figure(B)inFigure2); matusedinthefinetuningdatasetssuchastraining
dataformatusedinFigure2. Inotherwords, the
• OPT-CoT:Meta-finetunedOPTondatawith consistencyindataformathelpsLLMsbetterun-
rationales(explanations)(Chungetal.,2022; derstand the instruction which then yields better
AlKhamissi et al., 2023) (figure (C) in Fig- performanceafterfinetuning. Totestthis,weeval-
ure2). uatefinetunedLLMsondatasetswith5different
prompttemplates.
Usingthesethreetypesofmodels,weinvestigate
theroleoffinetuningonthreedimensions: Summary of findings: (i) Different from Gu-
(1)Datamemorization: Weinvestigatewhether rurangan et al. (2020), our experiments indicate
theperformanceimprovementsobtainedafterfine- that there is no strong correlation between high
tuningcanbeattributedtousingsimilarorsome- vocabularyoverlap(betweenfinetuningandevalu-
times the exact same data as in the evaluation ationdatasets)andperformancegainonreasoning
DatasetsConstruction. Toconstructthedatasets
Definition: Inthistask,weaskyoutowriteanimplausible
answertoaquestionthatinvolveseventduration,basedonagiven ofALERT,weselectdatasetsfromNIV2benchmark
sentence.Here,eventdurationisdefinedastheunderstandingof (Wang et al., 2022c) and perform the following
howlongeventstypicallylast.Forexample,“brushingteeth”,
operations:
usuallytakesafewminutes.Eventhoughthereexistmultiple
(1) Omit extremely hard tasks. We design
wronganswers,weonlyneedasinglewronganswer.
Example1- ALERT so that it can be used to benchmark a
input:Sentence:Jackplayedbasketballafterschool,after variety of LLMs, from pre-trained, finetuned to
whichhewasverytired.
instruction-tuned models. To select such tasks,
Question:HowlongdidJackplaybasketball?
we apply several heuristics: firstly, we manually
output: 22hours.
explanation: Typicallyweplaybasketballforacoupleof omittasksthatheavilyrelyoninstructions. Some
hours.Soanyanswerbeyondthatrangeisunlikely. tasks are hard to solve when only in-context ex-
amples(demonstrations)areprovided(e.g.,theex-
Figure1: AnexamplefromNIV2(Wangetal.,2022c)that
ample in Figure 1). Secondly, we selected only
requiresadeepunderstandingofthelongtaskinstructionand
canbeverychallengingevenforhumans. those tasks that achieved a reasonable level of
performance (empirically use ROUGE-L > 5.0)
evaluationdatasets. ThismeansthatLLMsarenot whenevaluatedwithapre-trainedmodel(weuse
simplymemorizingthetrainingdataduringthefine- the OPT-13B model). Thirdly, we omit tasks on
tuningstage;(ii)Finetuninghelpsimprovecertain whichhumansfailtogetdecentperformancegiven
reasoning capabilities of LLMs (e.g. analogical the ground truth labels from NIV2. For exam-
andabductive)butnotallofthem(e.g. common-
ple,task963_librispeech_asr_next_word_predic-
sensereasoning); (iii)Finetuningcancauseover- tion(Weiretal.,2020)providesaprompt“Joey’s
fittingtowardsdataformat,whichmakesitharder favouritefoodis___”,withthegroundtruthanswer
forLLMstogeneralizetootherprompttemplates, “sandwiches”. Withoutanycontextorbackground
whileCoT-finetuninghelpstomitigatethisissueas information,theanswercanbeanyfoodthusitis
itincorporatesavarietyofexplanations. extremely hard for humans to accurately predict
“sandwiches”.
Thoughmanyoftheaspectsthatwestudyhave
(2)Removetaskswithlonginputcontext. The
beendiscussedinprioranalysesofLLMs(Chung
input sentence length of some tasks can be very
etal.,2022;Weietal.,2021a,2022;Kojimaetal.,
long, and currently most LLMs are not designed
2022;Cobbeetal.,2021;Sanhetal.,2021),prior
forsolvinglongtextproblems. Weomittaskswith
workhasnotevaluatedLLMsondifferentreason-
demonstrationlengthlongerthan2048tokens.
ing skills and how these skills can be improved.
(3) Fix ground truth labels. For each
Overall,byevaluatingreasoningskillswithALERT,
reasoning task, NIV2 provides the reason-
wegainnewinsightsonhowmodelshaveorhave
ing skills required to solve the task, e.g.
notsucceededingeneralizingbeyondtheirtraining
task102_commongen_data_to_text requires rela-
experience.
tional, analogical and commonsense reasoning.
To summarize our contributions, this paper
However,wefoundthatsometaskshavebeenla-
presents a meticulously designed benchmark for
beled with incorrect reasoning skills. For exam-
assessingreasoningabilities. Furthermore,athor-
ple,task393_plausible_result_generationprovides
oughinvestigationoftheroleoffinetuninginthe
a sentence and asks LLMs to complete the sen-
contextofreasoningabilities,datamemorization,
tence. ThelabelsgivenbyNIV2arecausalreason-
anddataformatisconducted.
ingandtextualentailment,butinfactthistaskcan
hardly examine an entailment skill. Accordingly,
2 MotivationandOurBenchmark
wemanuallyfixreasoningskilllabels. Inaddition,
weonlykeepthepredominantskill. Forexample,
Motivation. TheanalysesinALERTareinspired
manytasksneedmoreorlesscommonsenseknowl-
byascientificquestion: TowhatextentdoLLMs
edge,thereforeweselecttherelatedtasksthatonly
learngeneralizablereasoningabilities? Thisques-
heavilyrelyoncommonsenseknowledgetoassess
tionmotivatesourfocusonmeasuringLLMs’per-
commonsensereasoning.
formance on tasks that require contextual under-
standingandperformmulti-stepoperations,which Benchmark. After the above steps, we select
arecrucialtoperformwellondownstreamtasks. tasks that represent a variety of reasoning skills
(A) pretrained language models (e.g. GPT-3, OPT)
0. Forall1.3Bmodels, weusebatchsizeof128,
Pretrained Inference on
LM task A, B, C,... andfor13Bmodels,weusebatchsizeof256.
(B) meta-finetuned language models (e.g. FLAN, OPT-FT) 3.2 FinetuningData
Pretrained finetune on Inference on Ourfinetuningcorpusiscomprisedof10datasets:
LM task D, E, F, … task A, B, C,...
Q: If X and Y are digits and 8XY is a 3-digit number ProofWriter (Tafjord et al., 2020), StrategyQA
that is divisible by 2, which of the following is a
possible product of X and Y? A)15 B)31 C)12 D)27 (Gevaetal.,2021),ECQA(Aggarwaletal.,2021),
E)91; A: The answer is C.
CoQA(Reddyetal.,2019),GSM8K(Cobbeetal.,
(C) CoT finetuned language models (e.g. OPT-CoT)
2021), AQUA-RAT (Ling et al., 2017), ESNLI
finetune on
Pretrained task D, E, F, … Inference on (Camburuetal.,2018),MATH(Hendrycksetal.,
LM task A, B, C,...
with explanations
2021c), CoS-E (Rajani et al., 2019), WinoWhy
Q: If X and Y are digits and 8XY is a 3-digit number that is
divisible by 2, which of the following is a possible product of X (Zhangetal.,2020). These10finetuningdatasets
and Y? A)15 B)31 C)12 D)27 E)91; A: The answer is C. because
Key to this question is to remember the fact that a number
collectively contain 6 different reasoning skills:
divisible by 2 must end with even OR 0 (i.e Y). If Y had to be 0,
product should also be 0 regardless of X. Otherwise, product is a
multiple of 2. Only one answer choice meets the requirement logicalreasoning,causalreasoning,commensense
reasoning,textualentailment,mathematics,abduc-
Figure2: Wecomparethreetypesofmodels: (A)directly tive reasoning. In addition, these 10 datasets all
applypretrainedLLMsonreasoningtasks;(B)finetuneLLMs
come with instructions, demonstration examples
onasetoftasks;(C)finetuneLLMsontaskswithexplana-
tions(CoT-finetuning).Finetuningdatacontains source and and explanations. This enables fair comparison
target parts,andthelanguagemodelinglossonlyappliedto of OPT-FT and OPT-CoT models. More details
the target part. aboutfinetuningcorpuscanbefoundinTable5in
SectionA.2. Moredetailsaboutdevelopmentdata
andconstructALERTreasoningbenchmark,where selectioncanbefoundintheAppendix.A.3.
Table2showsdetailsaboutourbenchmark.
3.3 Evaluation
3 ExperimentSetup
Templates Following(Weietal.,2021b),tocon-
3.1 Models trolfortheeffectofvariableprompttemplates,we
adoptdifferenttemplates(T)duringinferencestage
Toperformacontrolledcomparisonacrosstraining
inourexperiments:
andpromptingmethods,wefocusonthreedifferent
T1: instruction + demonstration examples with
models: pre-trained,meta-finetuned,andrationale-
explanations+"let’sthinkstepbystep";
basedmeta-finetuned(CoT-finetuned)models. For
T2: instruction+"Pleasegiveashortexplanation
pre-trained models, we use OPT (Zhang et al.,
aftertheanswer"+demonstrationexampleswith
2022), a suite of decoder-only pre-trained trans-
explanations+"let’sthinkstepbystep"
formers which are reported to yield comparable
T3: instruction+"Pleasegiveashortexplanation
performancetoGPT-3(Brownetal.,2020b). We
aftertheanswer"+demonstrationexampleswith
benchmarkwithOPTmodelsoftwoscales: 1.3B
explanations
and13B.Forfinetunedmodels(OPT-FT),wefine-
T4: "Please give a short explanation after the an-
tuneOPTmodelsondatasetswithoutexplanations.
swer"+demonstrationexampleswithexplanations
ForCoT-finetunedmodels(OPT-CoT),wefinetune
+"Let’sthinkstepbystep"
OPTmodelsondatawithrationales(explanations).
T5: instructions+demonstrations
We train all models in Pytorch (Paszke et al.,
Foreachdataset,wereporttheaverageandmax
2017)usingOPT-IML(Iyeretal.,2022)codebase3.
scoreamongthesefivetemplates. Thefinalaggre-
We initialize model hyper-parameters for each
gatedresults(includingaggregatedaveragescore
model scale following OPT (Zhang et al., 2022).
andaggregatedmaxscore)arereportedbyfurther
Wepackourtrainingexamplesintosequencesof
averagingacrossalldatasets. Unlessspecifiedoth-
length2048,left-truncatingexamplesthatoverflow.
erwise, the default score refers to the aggregated
We use AdamW (Loshchilov and Hutter, 2017)
maxscoreamongfivetemplates.
with 32-bit state with (β ,β ) = (0.9,0.95), lin-
1 2
earlywarmingupthelearningratefor6%stepsto Evaluationmetrics. Sinceourbenchmarkcon-
themaximum,followedbylinearlydecayingitto tains both classification and generation tasks, we
cannot use classification accuracy to evaluate all
3https://github.com/facebookresearch/metaseq/tree/main/pr
ojects/OPT-IML thetasks. FollowingFLAN(Weietal.,2021b),we
appendclassificationchoicesattheendofprompts To confirm that the improvement in finetuning
and ask models to generate answers. Thus, clas- performanceisduetotheincreasedamountofdata
sificationtaskscanbetreatedasaspecialcaseof seen during the finetuning stage, we measure the
generationtasks. Accordingly,weuseROUGE-L dissimilaritybetweenthetrainingdatausedinfine-
(Lin, 2004) to measure the performance of both tuningandevaluation,respectively. Ifhighersimi-
classification and generation tasks and report the larityleadstobetterperformance,itmayindicate
aggregated score. Similar to Chung et al. (2022), thattheimprovementsoffinetunedLLMsaredue
wealsouseexact-matchscorewhichismoresuit- to seeing more similar data during the finetuning
ablefortaskswithshortanswers. Additionally,we stage. Following (Gururangan et al., 2020), we
compute relaxed-match score which is a relaxed use unigram vocabulary overlap to measure the
version of exact-match. Specifically, we normal- data similarity. More specifically, we divide our
ize ground truth answers and predictions to have tasksintothreecategories: Thefirstcategoryhas
alltextinlowercaseandremovepunctuationand 10 datasets which consists of up to 10% overlap
extrawhitespaces. between the finetuning data and evaluation data.
Thesecondcategorycomprises3datasetswithan
4 Analysis overlapbetween10%and30%. Thethirdcategory
has7 datasetswithanoverlapover30%. Details
4.1 Doesfinetuninghelp?
canbefoundinTable7inappendixA.5.
Figure 3 demonstrates the performance averaged Wemeasuretheperformanceimprovementsof
across all evaluation tasks in our benchmark. OPT-FTandOPT-CoTcomparedagainstthepre-
Rationale-based finetuning (OPT-CoT) has been trained OPT model. We present both ROUGE-
shown to improve the performance of the 1.3B L score (top) and relaxed-match score (down) in
model by 3.89% in terms of the aggregated max Figure 5. The results indicate that there is no
ROUGE-Lscoreand3.83%intermsoftheaggre- strongcorrelationbetweenthevocabularyoverlap
gatedmaxexact-matchscore. Asfor13Bmodel, betweenfineuningandevaluationdatasetsandthe
OPT-CoTgainstheimprovementby15.22%inre- performanceofthemodel(neitherahighernora
gardofaggregatedmaxROUGE-Lscore,12.64% lowervocabularyoverlapalwaystranslatetoaper-
in regard of aggregated max exact-match score. formance improvement). OPT-CoT achieves the
However, finetuning (OPT-FT) sometimes yields bestROUGE-Landrelaxed-matchscoresbothin
worseresultsthanthevanillapre-trainedmodel. settingswhenthereisamedium(10%-30%)level
ofvocabularyoverlap. Wedon’tobserveaconsis-
4.2 WhatdoesLLMslearnduringfinetuning?
tentpatternonOPT-FTmodelseither. Overall,for
WefindthatCoT-finetuningimprovesperformance thesechallengingtasks,seeingsimilardataduring
onreasoningtasksingeneral. However,whatex- finetuning stage does not guarantee performance
actly does the LLMs learn during the finetuning improvement.
stage is still under explored. Thus, we study the
4.2.2 ReasoningSkillTransfer
role of finetuning from three perspectives: data
memorization,reasoningskilltransfer,andprompt Table 6 illustrates the reasoning skills present in
templatememorization. each stage. 7 skills can be learned from pretrain-
ingdata. Appendix.A.4showsmoredetailsabout
4.2.1 DataMemorization
pretrainingdata. 6skillscanbelearnedfromfine-
Gururanganetal.(2020)findsthattheperformance tuningdata(Table5). UsingALERT wemeasurea
gainislargerwhenthefinetuningdatasetismore totalof10reasoningskillsinmodelevaluation.
dissimilar to the pre-training dataset. However, The average ROUGE-L scores are calculated
their conclusion is made by a single-task finetun- for each reasoning skill on 6 models (1.3B OPT,
ing. Theyevaluatetheirmodelonthesamedataset 1.3BOPT-FT,1.3BOPT-CoT,13BOPT,13BOPT-
thatwasusedforfinetuning. Amorethorougheval- FT,13BOPT-CoT).Figure7showsthedifference
uation dictates that finetuned models (Wei et al., betweenOPT-FTandOPT,andthedifferencebe-
2021b; Chung et al., 2022) be evaluated on held- tween OPT-CoT and OPT models’ performance.
outdatasets. Assuch,inFigure2inblocks(B)and For example, OPT-FT 1.3B model yields on av-
(C)weshowtwopotentialwaysoffinetuningand erage 3.5 less ROUGE-L points than OPT 1.3B
inferenceasillustratedhereinourpaper. modelonthetasksoflogicalreasoning.
OPT OPT-FT OPT-CoT
100 12
80 10
8
60
6
40
4
20 2
0 0
1.3B 13B 1.3B 13B
Parameters Parameters
Figure4: Analyzingtherobustness
Figure3: Performanceofpre-trainedLM(OPT),finetunedLM(OPT-FT)andCoT- ofmodelsinfollowingthetemplates.
finetunedLM(OPT-CoT)onALERTreasoningbenchmark.Leftchartsshowaggregated Left:templatefollowingpercentage
maxscoreswhilerightareaveragescoresacross5templates. Scoresareaveraged byeachmodel;Right:standarddevi-
across20tasks. ationoftemplatefollowingpercent-
age.
soning or spatial reasoning can be gained during
thepretrainingstage,whilethebenefitsoffurther
finetuning are not as pronounced. Additionally,
Gururanganetal.(2020)concludedthatthemore
dissimilarthedomainbetweenpretrainingandfine-
tuningare, thehigherthepotentialforfinetuning
to yield gains. We see the same trend but the do-
Performance Changes (%) compared to OPT
maininGururanganetal.(2020)isdefinedbythe
Figure5: Correlationbetweenvocabularyoverlapandper-
vocabularyoverlaps,whilewedefinethedomains
formanceimprovementusing13Bparametermodels. The
leftchartshowsROUGE-Lwhiletherightshowsrelaxed- by reasoning skills. From figure (iii) we can see
matchscore.
that the reasoning skills gained during the meta-
finetuningstagemaynotnecessarilytransfertothe
Figure7contains4sub-figures,showingreason- improvementofthesameskillsontheevaluation
ing skills transfer results: (i) The upper left sub- datasets.
figure shows 7 skills that are acquired during the WealsoobservethatfinetuningwithOPT-CoT
pretrainingstage(OPTpretrainingdata),andhow enablesthemodeltoacquireawiderrangeofrea-
muchimprovementcanbeobtainedthroughmeta- soningskills,resultinginstrongerperformanceon
finetuning (OPT-FT and OPT-CoT); (ii) The bot- logical and causal reasoning tasks, in addition to
tomleftsub-figureillustratesthatthese3skillsare skillsthatconsistentlyimproveacrossallfinetuned
hardertoacquireduringthepre-trainingstage,and models.
the amount of improvement that can be obtained
4.2.3 DataFormatMemorization
throughmeta-finetuning;(iii)Theupperrightsub-
Weinvestigatewhetherfinetuningcansimplymem-
figureillustratesthatsuch7skillsareacquireddur-
orize the template representation of the training
ing the meta-finetuning stage through finetuning
data, and the effect of data format on the robust-
datasets(Table5). Dotheseskillsshowimprove-
nessofthemodels.
mentmeasuredbyevaluationbenchmark? (iv)The
bottomrightsub-figurestudiesthereasoningskills
Evaluationwithrelaxed-matchscore. Wecom-
that were not learned in the finetuning stage, can
paretwometrics: exact-matchandrelaxed-match.
theseskillsbeimprovedthroughmeta-finetuning?
FromFigure3,weobservethatOPT-FTisworse
Westudytheanswerstothesequestionsbelow.
thanOPTwhenexact-matchisusedasthemetric.
Fromfigure(ii)Weobservethatallfourofthe However, when relaxed-match is used, OPT-FT
LLMs demonstrate enhanced reasoning capabili- outperformsOPTasshowninFigure8. Relaxed-
tiesontextualentailment,abductivereasoning,and match score ignores punctuation, articles and ex-
analogicalreasoningtasks. Theseabilitiesarenot trawhitespace. Thissuggeststhatifwedecouple
readily acquired during the pretraining stage, as performancefromformatadherence,OPT-FTper-
thepretrainingdataconsistsonlyofplaintext. On formsbetterthanOPT.Inotherwords,finetuning
the other hand, skills such as commonsense rea- is helpful but it can make the output more noisy.
spalrevO
yralubacoV
egatnecrep
gniwollof
etalpmeT
noitaived
dradnatS
Skills in Pretraining Data Skills in Meta-finetuning Data
Pretraining Reasoning Skills Skills in Pretraining Data Skills in Meta-finetuning Data
Pretraining Reasoning Skills
Logical, CLaougsiacla, lC, Comaumsoanl,s Cenosmem, onsense,
Math, SpaMtiaatl,h A, Srgpuamtieanl,t ,A Drgeudmucetnivte, Deductive
* OPT pretr*a OinPinTg pdraettaraining data
Meta-finMeteutnai-nfign Reteuansionngi nRge Saksiollnsing Skills
Logical, CLaougsiacla, lC, Comaumsoanl,s Cenosmem, onsense,
EntailmenEt,n Mtaailtmh,e Anbt,d Mucattihve, Abductive
* Finetunin*g Fdianteat uinn iSnegc d. a3.t2a in Sec. 3.2 Held-out SHkiellsld f-rooumt SPkreiltlrsa finroinmg PDraettaraining HDealtda-out SkilHlse flrdo-mou Mt Setkail-lfisn ferotumn iMnge Dtaa-tfianetuning Data
EvaluatioEnv aRlueaastioonni nRge Saksoillnsing Skills
Logical, CLaougsiacla, lC, Comaumsoanl,s Cenosmem, onsense,
EntailmenEt,n Mtaailmth,e Antb, dMucattihv,e A, Sbpdautciatilv, e, Spatial,
AnalogicaAl,n Aarlgougmiceanl,t ,A Drgeudmucetnivte, Deductive
* ALERT be*n AcLhEmRaTrk benchmark
Figure 6: Reasoning skills
learned during pretraining and Figure7: TheROUGE-LscoresillustratingthedifferencebetweenOPT-FTandOPT,
meta-finetuningstages,aswellas aswellasOPT-CoTandOPTmodelswithineachreasoningskill. Left:skillssplitby
testedthroughALERT. pretrainingdata;Right:skillssplitbymeta-finetuningdata.
OPT OPT-FT OPT-CoT onrationales,theOPT-CoTmodelperformswell
whenevaluatedusingnon-CoTtemplates.
25
30
20 Robustness To assess the robustness of each
20 15 modeltovarioustemplates,wecomputethestan-
darddeviationofROUGE-Lscoresforeachmodel 10
10 acrossfivedifferenttemplates. Aswecanseefrom
5
Figure 4 (right), OPT is robust to different tem-
0 0
1.3B 13B 1.3B 13B plates, while OPT-FT has difficulties adapting to
Model scale Model scale
Figure8: Comparingpretrainingandfinetuningmodelswith changing templates. In general, finetuning (both
relaxedmatchscore.Left:aggregatedbest(max)performance OPT-FT and OPT-CoT) adversely affects the ro-
across5Templates;Right:aggregatedaverageperformance
bustnessofthemodelandmakesthemodelbiased
across5Templates.
towardsaspecificdataformat,however,OPT-CoT
isbetterthangeneralfinetuning(OPT-FT).
Thisexplainsthereasonfortheperformancedrop
whenexact-matchisusedasthemetric.
Reasoningchainquality. Following(Golovneva
Template following percentage. We check etal.,2022)weevaluatereasoningabilitiesofthe
whetherthemodelcanfollowthetemplateofthe modelsusingROSCOEscoringsuite(Table3). Look-
demonstrations. For example, if a demonstration ingateachscoreindetail(AppendixC),wefound
uses "the answer is xxx because yyy", then we thatoverallacrosstemplatesOPT-FTmodelspro-
checkwhatpercentageofinstancescanfollowthe duce shorter, less informative chains, while OPT
exactsametemplateasthedemonstration. Figure4 baseline models produce long chains with high
(left)showstheaveragetemplatefollowingpercent- amountofself-repetitions. 13BOPT-CoTchains
ageforeachmodel. BothOPTandOPT-CoTcon- showedbestqualitydespitesomeself-consistency
sistentlyshowthattheycanfollowdemonstrations’ andgrammarissues. Whencomparingprompttem-
eventhoughOPTisnotpre-trainedonrationales. plates,modelspromptedwithTemplate5produce
Comparedto1.3Bmodels,largermodelsdemon- short chains, often without reasoning at all, even
strateagreateroverallabilitytofollowthetemplate iftheywerefine-tunedonreasoningchains(OPT-
ofthedemonstrations. ComparedtoOPTandOPT- CoT),suggestingoverfittingtotheprompttemplate.
CoT, OPT-FT lacks the ability to follow diverse
templates. This is because the OPT-FT training In summary, models learn the data format rep-
processdoesnotcontainanyrationaledata. Fine- resentationandtemplatesduringfinetuningstage.
tuning causes the model to become more biased However, finetuned models contain bias towards
towardsaparticulartemplaterepresentation,while the data formats and template it has seen, which
itsabilitytoadapttoothertemplatesbecomesim- potentiallyreducestherobustnessofthemodelto
paired. Itisworthnotingthatdespitebeingtrained more generalized settings. When comparing ro-
hctam-dexaleR
xaM
hctam-dexaleR
egarevA
1.3B 13B task393_plausible_result_generationgivestextual
Metrics OPT OPT-FT OPT-CoT OPT OPT-FT OPT-CoT entailmentlabelbutthistaskcanhardlyexamine
ROSCOE-SA 0.936 0.921 0.938 0.936 0.923 0.940
ROSCOE-SS 0.925 0.923 0.920 0.926 0.916 0.925 theentailmentskill.
ROSCOE-LI 0.848 0.953 0.875 0.863 0.944 0.890 The Curriculum benchmark (Chen and Gao,
ROSCOE-LS 0.725 0.744 0.666 0.688 0.705 0.640
2022) is designed for probing LLMs’ reasoning
Table3: SummaryoftheROSCOEevaluationresultsaveraged abilities and covers 8 different reasoning skills.
acrosstemplates.Eachmetricisboundedwithin[0,1],where
However,thisworkonlyfocusesonclassification
1indicatestheperfectscoreand0correspondstofailure.In
eachrow,valuescorrespondingtothebest-performingmodel tasks and it converts all examples into the Natu-
arebolded,secondbestareunderscored. ral Language Inference (NLI) format to fit into a
unifiedframework. Wearguethattheforcedcon-
bustness,OPT-CoTisbetterthanOPT-FT,butitis
versionofalldatasetsintotheNLIformatdoesnot
stillnotasrobustasthepre-trainedmodel.
alignwithhumannaturalconversationalstyle. We
observedthatevendavinci-003failsatsomesimple
5 RelatedWork
tasksduetotheirforcedconversion,e.g. examples
LLMsthatReason. ToimproveLLMs’reason- inTable1. Morediscussionandresultsareshown
ingabilities,Kojimaetal.(2022)showsthatLLMs intheAppendixB.
can be decent zero-shot reasoners by simply ap-
Finetuning LLMs. LLMs meta-finetuned on a
pending “Let’s think step by step” to the prompt.
range of NLP tasks have shown improved per-
Weietal.(2022)addsaseriesofintermediaterea-
formance on held-out downstream tasks such as
soningstepstoimproveLLMs’reasoningabilities.
FLAN(Weietal.,2021b),T0(Sanhetal.,2021),
Wang et al. (2022a) further proposes to expand
Tk-Instruct(Wangetal.,2022c)andInstruct-GPT
promptstoincluderationalesineachfew-shotex-
(Ouyang et al., 2022). Following this approach,
ample. Fu et al. (2022) discovers that prompting
we finetune OPT models and name this type of
withhigherreasoningcomplexityachievessubstan-
modelsasOPT-FT((B)inFigure2). Chungetal.
tialgainsonmathwordtasks. Totackleproblems
(2022) further adds chain-of-thought data at fine-
harder than demonstration examples, Zhou et al.
tuningstageandshowssignificantimprovements.
(2022)firstreducesacomplexproblemintoalistof
Wealsostudythistypeofmodelsandnamethem
subproblemsandsolvesubproblemssequentially.
as OPT-CoT ((C) in Figure 2). However, from
Another line of research is to improve the naive
previousresearchitstillremainsunclearwhether
decodingstrategy,Wangetal.(2022b)introduces
theimprovementcomesfromsimplyaddingmore
aself-consistencystrategywhichselectsthemost
training data or finetuning on rationales actually
consistentansweramongasetofreasoningpaths.
helps. Weconductrigorousevaluationstoaddress
thisquestion.
ExistingReasoningBenchmarks. Manybench-
marks are used for evaluating language models’
6 Conclusion
performance,suchasBIG-Bench(Srivastavaetal.,
2022),NaturalInstructionV2(NIV2)(Wangetal., WeintroduceALERT,acarefullycuratedbenchmark
2022c),MMLU(Hendrycksetal.,2020). Although forevaluatingreasoningabilitiesofLLMs. Itcom-
they contain some reasoning tasks, none of them prisesover20datasetsandcovers10differentrea-
arespecificallydesignedtotestmodels’reasoning soning skills. Using this benchmark, we further
skills. For example, NIV2 contains 172 datasets investigatetheimpactoffinetuningonthesecom-
andatotalof1554tasks,includingsomereasoning plextasks. OurexperimentsrevealthatLLMsdo
tasks. It has several issues which make it inap- notsimplymemorizetrainingdata,butarecapable
propriatetobedirectlyusedasareasoningbench- oflearningvariousreasoningskills,suchastextual
mark: (1)itisdesignedforinstruction-tunedmod- entailment,abductivereasoningandanalogicalrea-
elsandsometasksmightbeunsuitableforevaluat- soning. Whilewefoundthatfinetuninggenerally
ingpretrainedmodelsornon-instructionfinetuned leadstoimprovedperformance,wealsodiscovered
models,asshowninFigure1;(2)reasoningskills some negative effects. LLMs tend to memorize
have been divided into 27 categories while some thedatatemplaterepresentationandtemplatesseen
ofthemhavelargeoverlaps,e.g. numericalreason- duringfinetuning,thusreducingtherobustnessof
ing,quantitativereasoning,reasoningonnumbers; themodeltogeneralizedsettings. CoT-finetuning
(3)somereasoninglabelsarewronglylabeled,e.g. (OPT-CoT)canalleviatethisissuetosomeextent,
but it is still less robust compared to the vanilla BadrAlKhamissi,SiddharthVerma,PingYu,Zhijing
pre-trainedmodel. Jin, Asli Celikyilmaz, and Mona Diab. 2023. Opt-
r: Exploring the role of explanations in finetuning
andpromptingforreasoningskillsoflargelanguage
Limitations
models. arXivpreprintarXiv:2305.12001.
ALERT aims to encompass a wide range of rea- Mikel Artetxe, Shruti Bhosale, Naman Goyal, Todor
soning skills, but some reasoning skills are miss- Mihaylov,MyleOtt,SamShleifer,XiVictoriaLin,
ing, specifically in regards to symbolic reason- Jingfei Du, Srinivasan Iyer, Ramakanth Pasunuru,
et al. 2021. Efficient large scale language mod-
ing (last letter concatenation task and coin flip
eling with mixtures of experts. arXiv preprint
(Wei et al., 2022)) and compositionality reason-
arXiv:2112.10684.
ing(SCAN(LakeandBaroni,2018),COGS(Kim
andLinzen,2020)andCFQ(Keysersetal.,2019)). JasonBaumgartner,SavvasZannettou,BrianKeegan,
Megan Squire, and Jeremy Blackburn. 2020. The
Thesereasoningskillsshouldbeincludedinfuture
pushshift reddit dataset. In Proceedings of the
work. international AAAI conference on web and social
In terms of computing power, we have experi- media,volume14,pages830–839.
mentedwithmodelsthatwereaccessibletous. We
Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jian-
acknowledgethattherearelargermodelsthatwe
feng Gao, and Yejin Choi. 2020. Piqa: Reasoning
werenotabletotrainduetothelimitationsofour about physical commonsense in natural language.
computationalbudget. In Thirty-Fourth AAAI Conference on Artificial
Intelligence.
During our analysis, we discovered that some
datasetscontainnoise,whereevenhumanexperts Tom Brown, Benjamin Mann, Nick Ryder, Melanie
areunabletoprovideaccurateanswersforcertain Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
instances. While it is important to address this Neelakantan,PranavShyam,GirishSastry,Amanda
Askell,etal.2020a. Languagemodelsarefew-shot
issue, it is a time-consuming process to carefully
learners. Advancesinneuralinformationprocessing
reviewandcleaneachinstanceinthedataset. We
systems,33:1877–1901.
plantoaddressthisinfuturework.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
EthicsStatement
Neelakantan,PranavShyam,GirishSastry,Amanda
Askell,etal.2020b. Languagemodelsarefew-shot
Large language models (LLMs), due to potential
learners. Advancesinneuralinformationprocessing
bias in the training data, can be prone to gener-
systems,33:1877–1901.
atetoxic andunwantedcontent (Weidinger etal.,
Oana-Maria Camburu, Tim Rocktäschel, Thomas
2021). However,inthispaper,wearefocusedon
Lukasiewicz,andPhilBlunsom.2018. e-snli: Natu-
reasoning tasks where the model is prompted to
rallanguageinferencewithnaturallanguageexplana-
explainitsdecisions,becauseofwhichourmodel tions. Advances in Neural Information Processing
falls under contained generation. By providing Systems,31.
clearpromptsandconstraints,webelievethatthis
Zeming Chen and Qiyue Gao. 2022. Curriculum: A
mighthelpguidethemodel’soutputtowardsspe-
broad-coveragebenchmarkforlinguisticphenomena
cific,desiredoutcomesandreducethelikelihood in natural language understanding. arXiv preprint
ofgeneratingunwantedorharmfulcontent,asop- arXiv:2204.06283.
posedtoopenendedtextgenerationtasks.
AakankshaChowdhery,SharanNarang,JacobDevlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
References Sebastian Gehrmann, et al. 2022. Palm: Scaling
language modeling with pathways. arXiv preprint
Shourya Aggarwal, Divyanshu Mandowara, Vishwa- arXiv:2204.02311.
jeet Agrawal, Dinesh Khandelwal, Parag Singla,
and Dinesh Garg. 2021. Explanations for Com- Hyung Won Chung, Le Hou, Shayne Longpre, Bar-
monsenseQA: New Dataset and Models. In ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
Proceedings of the 59th Annual Meeting of the Wang,MostafaDehghani,SiddharthaBrahma,etal.
Association for Computational Linguistics and the 2022. Scalinginstruction-finetunedlanguagemodels.
11th International Joint Conference on Natural arXivpreprintarXiv:2210.11416.
Language Processing (Volume 1: Long Papers),
pages3050–3065,Online.AssociationforComputa- Karl Cobbe, Vineet Kosaraju, Mohammad Bavar-
tionalLinguistics. ian, Jacob Hilton, Reiichiro Nakano, Christopher
Hesse, and John Schulman. 2021. Training veri- SrinivasanIyer,XiVictoriaLin,RamakanthPasunuru,
fiers to solve math word problems. arXiv preprint TodorMihaylov,DánielSimig,PingYu,KurtShus-
arXiv:2110.14168. ter,TianluWang,QingLiu,PunitSinghKoura,etal.
2022. Opt-iml: Scaling language model instruc-
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark,
tionmetalearningthroughthelensofgeneralization.
andTusharKhot.2022. Complexity-basedprompt-
arXivpreprintarXiv:2212.12017.
ing for multi-step reasoning. arXiv preprint
arXiv:2210.00720. Daniel Keysers, Nathanael Schärli, Nathan Scales,
Hylke Buisman, Daniel Furrer, Sergii Kashubin,
Nancy Fulda, Nathan Tibbetts, Zachary Brown, and
Nikola Momchev, Danila Sinopalnikov, Lukasz
David Wingate. 2017. Harvesting common-sense
Stafiniak,TiborTihon,etal.2019. Measuringcom-
navigationalknowledgeforroboticsfromuncurated
positionalgeneralization: Acomprehensivemethod
text corpora. In Conference on Robot Learning,
onrealisticdata. arXivpreprintarXiv:1912.09713.
pages525–534.PMLR.
NajoungKimandTalLinzen.2020. Cogs: Acompo-
LeoGao,StellaBiderman,SidBlack,LaurenceGold-
sitionalgeneralizationchallengebasedonsemantic
ing,TravisHoppe,CharlesFoster,JasonPhang,Ho-
interpretation. arXivpreprintarXiv:2010.05465.
raceHe, AnishThite, NoaNabeshima, etal.2020.
The pile: An 800gb dataset of diverse text for lan-
Diederik P Kingma and Jimmy Ba. 2014. Adam: A
guagemodeling. arXivpreprintarXiv:2101.00027.
methodforstochasticoptimization. arXivpreprint
MorGeva,DanielKhashabi,EladSegal,TusharKhot, arXiv:1412.6980.
DanRoth,andJonathanBerant.2021. Didaristotle
Jonathan Kobbe, Ioana Hulpus, and Heiner Stucken-
usealaptop? aquestionansweringbenchmarkwith ,
schmidt.2020. Unsupervisedstancedetectionforar-
implicit reasoning strategies. Transactions of the
gumentsfromconsequences. InProceedingsofthe
Association for Computational Linguistics, 9:346–
2020 Conference on Empirical Methods in Natural
361.
LanguageProcessing(EMNLP),pages50–60.
Olga Golovneva, Moya Chen, Spencer Poff, Martin
Corredor,LukeZettlemoyer,MaryamFazel-Zarandi, TakeshiKojima,ShixiangShaneGu,MachelReid,Yu-
and Asli Celikyilmaz. 2022. Roscoe: A suite of takaMatsuo,andYusukeIwasawa.2022. Largelan-
metricsforscoringstep-by-stepreasoning. guagemodelsarezero-shotreasoners. arXivpreprint
arXiv:2205.11916.
Suchin Gururangan, Ana Marasovic´, Swabha
Swayamdipta,KyleLo,IzBeltagy,DougDowney, Brenden Lake and Marco Baroni. 2018. Generaliza-
and Noah A Smith. 2020. Don’t stop pretraining: tion without systematicity: On the compositional
adaptlanguagemodelstodomainsandtasks. arXiv skillsofsequence-to-sequencerecurrentnetworks. In
preprintarXiv:2004.10964. Internationalconferenceonmachinelearning,pages
2873–2882.PMLR.
DanHendrycks,CollinBurns,StevenBasart,AndyZou,
MantasMazeika,DawnSong,andJacobSteinhardt. Yash Kumar Lal, Nathanael Chambers, Raymond
2020. Measuringmassivemultitasklanguageunder- Mooney, and Niranjan Balasubramanian. 2021.
standing. arXivpreprintarXiv:2009.03300. TellMeWhy: Adatasetforansweringwhy-questions
in narratives. In Findings of the Association
Dan Hendrycks, Collin Burns, Steven Basart, Andy
forComputationalLinguistics: ACL-IJCNLP2021,
Zou,MantasMazeika,DawnSong,andJacobStein-
pages 596–610, Online. Association for Computa-
hardt.2021a. Measuringmassivemultitasklanguage
tionalLinguistics.
understanding. Proceedings of the International
ConferenceonLearningRepresentations(ICLR).
Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen,
Pei Zhou, Chandra Bhagavatula, Yejin Choi, and
DanHendrycks,CollinBurns,SauravKadavath,Akul
Xiang Ren. 2020. CommonGen: A constrained
Arora, Steven Basart, Eric Tang, Dawn Song, and
text generation challenge for generative common-
JacobSteinhardt.2021b. Measuringmathematical
sense reasoning. In Findings of the Association
problemsolvingwiththemathdataset. NeurIPS.
forComputationalLinguistics:EMNLP2020,pages
DanHendrycks,CollinBurns,SauravKadavath,Akul 1823–1840,Online.AssociationforComputational
Arora, Steven Basart, Eric Tang, Dawn Song, and Linguistics.
Jacob Steinhardt. 2021c. Measuring mathemati-
cal problem solving with the math dataset. arXiv Chin-YewLin.2004. Rouge: Apackageforautomatic
preprintarXiv:2103.03874. evaluation of summaries. In Text summarization
branchesout,pages74–81.
Mark Hopkins, Ronan Le Bras, Cristian Petrescu-
Prahova, Gabriel Stanovsky, Hannaneh Hajishirzi, WangLing,DaniYogatama,ChrisDyer,andPhilBlun-
and Rik Koncel-Kedziorski. 2019. Semeval-2019 som. 2017. Program induction by rationale gen-
task 10: math question answering. In Proceedings eration: Learning to solve and explain algebraic
of the 13th International Workshop on Semantic wordproblems. InProceedingsofthe55thAnnual
Evaluation,pages893–899. Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 158– Stephen Roller, Emily Dinan, Naman Goyal, Da Ju,
167, Vancouver, Canada. Association for Compu- Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott,
tationalLinguistics. Kurt Shuster, Eric M Smith, et al. 2020. Recipes
forbuildinganopen-domainchatbot. arXivpreprint
YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
arXiv:2004.13637.
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019. ChristopherRyttingandDavidWingate.2021. Lever-
Roberta: A robustly optimized bert pretraining ap- aging the inductive bias of large language models
proach. arXivpreprintarXiv:1907.11692. for abstract textual reasoning. Advances in Neural
InformationProcessingSystems,34:17111–17122.
Ilya Loshchilov and Frank Hutter. 2017. Fixing
weight decay regularization in adam. CoRR, VictorSanh,AlbertWebson,ColinRaffel,StephenH
abs/1711.05101. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Chaffin, Arnaud Stiegler, Teven Le Scao, Arun
TodorMihaylov,PeterClark,TusharKhot,andAshish
Raja, et al. 2021. Multitask prompted training en-
Sabharwal.2018. Canasuitofarmorconductelec-
ables zero-shot task generalization. arXiv preprint
tricity? anewdatasetforopenbookquestionanswer-
arXiv:2110.08207.
ing. arXivpreprintarXiv:1809.02789.
Mohammad Shoeybi, Mostofa Patwary, Raul Puri,
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and
PatrickLeGresley, JaredCasper, andBryanCatan-
Hannaneh Hajishirzi. 2022. Cross-task generaliza-
zaro. 2019. Megatron-lm: Training multi-billion
tionvianaturallanguagecrowdsourcinginstructions.
parameterlanguagemodelsusingmodelparallelism.
InACL.
arXivpreprintarXiv:1909.08053.
NasrinMostafazadeh,NathanaelChambers,Xiaodong
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
He,DeviParikh,DhruvBatra,LucyVanderwende,
AbuAwalMdShoeb,AbubakarAbid,AdamFisch,
PushmeetKohli,andJamesAllen.2016. Acorpus
Adam R Brown, Adam Santoro, Aditya Gupta,
and cloze evaluation for deeper understanding of
Adrià Garriga-Alonso, et al. 2022. Beyond the
commonsense stories. In Proceedings of the 2016
imitation game: Quantifying and extrapolating the
Conference of the North American Chapter of the
capabilities of language models. arXiv preprint
AssociationforComputationalLinguistics: Human
arXiv:2206.04615.
LanguageTechnologies,pages839–849.
Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin
Aida Nematzadeh, Kaylee Burns, Erin Grant, Alison
Choi, and Claire Cardie. 2019. DREAM: A chal-
Gopnik,andThomasLGriffiths.2018. Evaluating
lengedatasetandmodelsfordialogue-basedreading
theoryofmindinquestionanswering. arXivpreprint
comprehension. TransactionsoftheAssociationfor
arXiv:1808.09352.
ComputationalLinguistics.
MaxwellNye,AndersJohanAndreassen,GuyGur-Ari,
Oyvind Tafjord, Bhavana Dalvi Mishra, and Peter
Henryk Michalewski, Jacob Austin, David Bieber,
Clark.2020. Proofwriter: Generatingimplications,
David Dohan, Aitor Lewkowycz, Maarten Bosma,
proofs, and abductive statements over natural lan-
DavidLuan,etal.2021. Showyourwork: Scratch-
guage. arXivpreprintarXiv:2012.13048.
pads for intermediate computation with language
models. arXivpreprintarXiv:2112.00114.
Trieu H Trinh and Quoc V Le. 2018. A simple
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car- methodforcommonsensereasoning. arXivpreprint
rollLWainwright,PamelaMishkin,ChongZhang, arXiv:1806.02847.
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
AlexWang,YadaPruksachatkun,NikitaNangia,Aman-
2022. Training language models to follow in-
preetSingh,JulianMichael,FelixHill,OmerLevy,
structions with human feedback. arXiv preprint
andSamuelRBowman.2019. Superglue: Astickier
arXiv:2203.02155.
benchmarkforgeneral-purposelanguageunderstand-
AdamPaszke,SamGross,SoumithChintala,Gregory ingsystems. arXivpreprintarXiv:1905.00537.
Chanan,EdwardYang,ZacharyDeVito,ZemingLin,
Alex Wang, Amanpreet Singh, Julian Michael, Felix
Alban Desmaison, Luca Antiga, and Adam Lerer.
Hill,OmerLevy,andSamuelBowman.2018. GLUE:
2017. Automaticdifferentiationinpytorch. InNIPS
Amulti-taskbenchmarkandanalysisplatformfornat-
2017WorkshoponAutodiff.
urallanguageunderstanding. InProceedingsofthe
Nazneen Fatema Rajani, Bryan McCann, Caiming 2018EMNLPWorkshopBlackboxNLP:Analyzing
Xiong, and Richard Socher. 2019. Explain your- and Interpreting Neural Networks for NLP, pages
self! leveraginglanguagemodelsforcommonsense 353–355,Brussels,Belgium.AssociationforCom-
reasoning. arXivpreprintarXiv:1906.02361. putationalLinguistics.
SivaReddy,DanqiChen,andChristopherD.Manning. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc
2019. CoQA: A conversational question answer- Le, Ed Chi, and Denny Zhou. 2022a. Rationale-
ing challenge. Transactions of the Association for augmented ensembles in language models. arXiv
ComputationalLinguistics,7:249–266. preprintarXiv:2207.00747.
XuezhiWang,JasonWei,DaleSchuurmans,QuocLe, Hongming Zhang, Xinran Zhao, and Yangqiu Song.
EdChi,andDennyZhou.2022b. Self-consistency 2020. WinoWhy: A deep diagnosis of es-
improves chain of thought reasoning in language sential commonsense knowledge for answering
models. arXivpreprintarXiv:2203.11171. Winograd schema challenge. In Proceedings of
the 58th Annual Meeting of the Association for
Yizhong Wang, Swaroop Mishra, Pegah Alipoor- Computational Linguistics, pages 5736–5745, On-
molabashi, Yeganeh Kordi, Amirreza Mirzaei, line.AssociationforComputationalLinguistics.
Anjana Arunkumar, Arjun Ashok, Arut Selvan
Dhanasekaran, Atharva Naik, David Stap, et al. Susan Zhang, Stephen Roller, Naman Goyal, Mikel
2022c. Super-naturalinstructions:generalizationvia Artetxe,MoyaChen,ShuohuiChen,ChristopherDe-
declarativeinstructionson1600+tasks. InEMNLP. wan,MonaDiab,XianLi,XiVictoriaLin,etal.2022.
Opt: Openpre-trainedtransformerlanguagemodels.
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin arXivpreprintarXiv:2205.01068.
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drewMDai,andQuocVLe.2021a. Finetunedlan- Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,
guagemodelsarezero-shotlearners. arXivpreprint Nathan Scales, Xuezhi Wang, Dale Schuurmans,
arXiv:2109.01652. Olivier Bousquet, Quoc Le, and Ed Chi. 2022.
Least-to-most prompting enables complex reason-
Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin ing in large language models. arXiv preprint
Guu, Adams Wei Yu, Brian Lester, Nan Du, An- arXiv:2205.10625.
drewMDai,andQuocVLe.2021b. Finetunedlan-
guagemodelsarezero-shotlearners. arXivpreprint YukunZhu,RyanKiros,RichZemel,RuslanSalakhut-
arXiv:2109.01652. dinov,RaquelUrtasun,AntonioTorralba,andSanja
Fidler.2015. Aligningbooksandmovies: Towards
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
story-like visual explanations by watching movies
Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.
and reading books. In Proceedings of the IEEE
Chainofthoughtpromptingelicitsreasoninginlarge
international conference on computer vision, pages
languagemodels. arXivpreprintarXiv:2201.11903.
19–27.
LauraWeidinger,JohnMellor,MaribethRauh,Conor
Griffin, Jonathan Uesato, Po-Sen Huang, Myra
Cheng,MiaGlaese,BorjaBalle,AtoosaKasirzadeh,
et al. 2021. Ethical and social risks of harm from
languagemodels. arXivpreprintarXiv:2112.04359.
NathanielWeir,JoãoSedoc,andBenjaminVanDurme.
2020. Cod3s: Diverse generation with discrete se-
manticsignatures. arXivpreprintarXiv:2010.02882.
JohannesWelbl,NelsonFLiu,andMattGardner.2017.
Crowdsourcing multiple choice science questions.
arXivpreprintarXiv:1707.06209.
Peter West, Chandra Bhagavatula, Jack Hessel, Jena
Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Sean Welleck, and Yejin Choi. 2022. Symbolic
knowledgedistillation: fromgenerallanguagemod-
elstocommonsensemodels. InProceedingsofthe
2022 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies, pages 4602–4625,
Seattle,UnitedStates.AssociationforComputational
Linguistics.
JasonWeston,AntoineBordes,SumitChopra,Alexan-
derMRush,BartVanMerriënboer,ArmandJoulin,
and Tomas Mikolov. 2015. Towards ai-complete
questionanswering: Asetofprerequisitetoytasks.
arXivpreprintarXiv:1502.05698.
Adina Williams, Tristan Thrush, and Douwe Kiela.
2022. Anlizing the adversarial natural language
inference dataset. In Proceedings of the 5th
Annual Meeting of the Society for Computation in
Linguistics,pages23–54.AssociationforComputa-
tionalLinguistics.
A MoreDetailsaboutDataUsage RoBERTa ThreedatasetsinRoBERTa(Liuetal.,
2019)areusedaspretrainingcorpus: BookCorpus
A.1 ReasoningBenchmark
(Zhu et al., 2015), Stories (Trinh and Le, 2018),
andCCNews(Liuetal.,2019). Deductivereason-
Table4showsdetailedreasoningbenchmark.
ingskillandspatialreasoningskillcanbelearned
fromstoriesdataset. Logicalreasoningskillcanbe
A.2 TrainingCorpus(cont. from§3.2)
learnedfromthesethreedatasets.
Weused10datasetsforfinetuning,whichcontain
6differentreasoningskills. Pile A subset of the Pile (Gao et al., 2020) are
used as pre-training corpus, including Common-
A.3 DevelopmentDataDetails Crawl,DMMathematics,ProjectGutenberg,Hack-
erNews,OpenSubtitles,OpenWebText2,USPTO,
Our finetuning models are tuned on pretrained
andWikipedia. Mathematicsreasoningskillcanbe
LLMs on the finetuning corpus with the goal of
learnedfromDMMathematicsdataset. CausalRea-
improving the performance of unseen tasks. For
soningcanbelearnedwidelyfromOpenWebText2.
example,blocks(B)and(C)inFigure2areshow-
Commensensereasoningskillcanbelearnedfrom
ingmodelsthatarefinetunedontasksB,C,Dand
Wikipedia.
thegoalistoachievegoodresultsontaskA.
Checkpointselectioncandeterminethefinalper- PushShift.io Reddit The longest chain of
formanceoftheLLMstoaverylargeextent. There comments in each thread are extracted from
are several ways to select checkpoints: (i) select PushShift.ioReddit(Baumgartneretal.,2020). Ar-
checkpoint of the last iteration; (ii) select check- gument reasoning skill can be learned from this
point based on perplexity or loss from validation dataset.
datasets of finetuning corpus (validation datasets
A.5 VocabularyOverlaps(Cont. from§4.2.1)
of task B, C, D); (iii) select checkpoint based on
perplexityorlossfromvalidationdatasetsofevalu- Wemeasureunigramvocabularyoverlapsbetween
ationcorpus(validationdatasetsoftaskA); our finetuning corpus and the evaluation corpus
(reasoningbenchmark).
Inordertoachieveabetterperformanceonevalu-
ationcorpus,acommonapproachistousemethods
B CurriculumBenchmarkResults(Cont.
like(iii)toselectacheckpoint. However,wewould
from§5)
liketopreventLLMsoverfitingtothedistribution
of our final evaluation corpus. We initially used We randomly selected one dataset from each rea-
the method (ii) but found that it did’t work well. soning skill and reported the results of GPT-3
However,thisresultedinadistributionmismatch (Brownetal.,2020b)(text-davinciengine). Since
issue. Wespeculatethistothefactthatsometasks allofthedatahasbeenconvertedtoNLIformat,we
in our finetuning corpus do not have a validation measure classification accuracy of GPT-3 model.
set. Wethusselect3tasksfromNIV2benchmark FromTable8,wecanseethatevenGPT-3achieves
andcompileadevelopmentsetthatdoesnothave aprettyrandomresultsonthesedatasets. Through
anyoverlapswithourfinetuningdataorevaluation ouranalysis,wefoundthatitisnotbecausethose
data. There are 3 datasets used as our develop- tasks are too difficult for GPT-3, it is because
mentsetforcheckpointselection: task247dream curriculum benchmark forcing all the data to be
answergeneration(Sunetal.,2019),task118se- NLIformat,resultinginunnaturaldataexpression,
mevalandtask10openvocabularymathematical whichmadeGPT-3failonit. Weconcludethatthe
answergeneration(Hopkinsetal.,2019)andanli curriculumbenchmarkmaybesuitableforclassi-
r1entailment(Williamsetal.,2022) ficationfinetunedmodels,butitisnotsuitablefor
languagemodelsforin-contextlearning.
A.4 PretrainingDataAnalysis
C Evaluatingreasoningchains(Cont.
Thepre-trainingcorpusofOPTmodel(Zhangetal.,
from§5)
2022)containsaconcatenationofdatasetsusedin
RoBERTa (Liu et al., 2019), the Pile (Gao et al., Following (Golovneva et al., 2022) we evaluate
2020),andPushShift.ioReddit(Baumgartneretal., reasoning abilities of the models using ROSCOE
2020;Rolleretal.,2020). scoring suite (Table 10). Chains are evaluated
Reasoning
TaskID Datasets
Skills
Logical 62 bigbenchrepeatcopylogic(Srivastavaetal.,2022)
Reasoning 697 mmmluanswergenerationformallogic(Hendrycksetal.,2021a)
393 plausibleresultgeneration(Weiretal.,2020)
Causal 1386 anlir2entailment(Williamsetal.,2022)
Reasoning 1387 anlir3entailment(Williamsetal.,2022)
1388 cbentailment(Wangetal.,2019)
80 piqaanswergeneration(Bisketal.,2020)
Commonsense 102 commongensentencegeneration(Linetal.,2020)
Reasoning 591 sciqanswergeneration(Welbletal.,2017)
1286 openbookqaquestionanswering(Mihaylovetal.,2018)
1386 anlir2entailment(Williamsetal.,2022)
Texual 1387 anlir3entailment(Williamsetal.,2022)
Entailment 1388 cbentailment(Wangetal.,2019)
1344 glueentailmentclassification(Wangetal.,2018)
104 semevalclosedvocabularymathanswergeneration(Hopkinsetal.,2019)
Mathematics 119 semevalgeometricmathanswergeneration(Hopkinsetal.,2019)
697 mmmluanswergenerationformallogic(Hendrycksetal.,2021a)
Abductive
332 tellmewhyanswergeneration(Laletal.,2021)
Reasoning
83 babit1singlesupportingfactanswergeneration(Westonetal.,2015)
Spatial
80 piqaanswergeneration(Bisketal.,2020)
Reasoning
151 tomqafindlocationeasyclean(Nematzadehetal.,2018)
Analogical 102 commongensentencegeneration(Linetal.,2020)
Reasoning 1152 bardanalogicalreasoningcausation(Fuldaetal.,2017)
Argument 513 argumentstanceclassification(Kobbeetal.,2020)
Reasoning 514 argumentconsequenceclassification(Kobbeetal.,2020)
Deductive
216 rocstoriescorrectanswergeneration(Mostafazadehetal.,2016)
Reasoning
Table4: DetailsaboutALERT benchmark.
Datasets TrainSize ValSize TestSize ReasoningSkills
ProofWriter 69,810 10,190 20,030 LogicalReasoning,CausalReasoning
StrategyQA 2,290 - 490 CommonsenseReasoning
ECQA 7,598 1,090 2,194 CommonsenseReasoning
CoQA 10,8647 7,983 - TextualEntailment
GSM8K 7,473 - 1,319 Mathematics
AQUA-RAT 97,467 254 254 Mathematics
ESNLI 549,367 9,842 9,824 CommonsenseReasoning,LogicalReasoning,TextualEntailment
MATH 7,500 - 5,000 Mathematics
CoS-E 9,741 1,221 - CommonsenseReasoning
WinoWhy 273 - - AbductiveReasoning,CommonsenseReasoning
Table5: Trainingcorpusformeta-finetuningOPT-FTandOPT-CoT.(Cont.from§3.2)
TaskID Datasets ReasoningSkills
LogicalReasoning
247 dreamanswergeneration(Sunetal.,2019)
CommonsenseReasoning
semevalopenvocabularymathematical CommonsenseReasoning
118
answergeneration(Hopkinsetal.,2019) Mathematics
TextualEntailment
1385 anlir1entailment(Williamsetal.,2022) CommonsenseReasoning
CausalReasoning
Table6: Devsetforcheckpointselection
usingfacebook/roscoe-512-roberta-basesentence Repetition-Tokenscorevariationsexhibitdiffer-
embeddingmodel. Evaluationresultsaredetailed ent behavior. Half of the tasks have higher num-
inTable10. Wefoundthatthechainqualityvaries berofrepetitionsbetweenreasoningstepsforpre-
betweenmodels,inparticularsomereasoningas- trainedmodels,withOPT-FTmodelsgenerallyout-
pectscorrelatewithchainlengthasseeninTable11. performingothers(allperformanceimprovements
Similarto(Chungetal.,2022),wenoticedthatnon- are significant). Generations produced by these
finetuned models (i.e. OPT-1.3B and OPT-13B) modelstendtobeshorterintermsofthenumber
tend to produce long chains of reasoning, often ofsteps(Figure9),sotheycontainlessrepetitions,
repeating themselves, which significantly affects butalsolesssemanticoverlapwiththecontext,thus
thequalityofthechainsandfinalscores(Figure9). ingeneralhavinglowerfaithfulnessandinforma-
Belowweexplorethedifferencesbetweenmodels’ tiveness. Some examples reflecting this behavior
outputs under four perspectives: semantic align- areprovidedinTable12.
ment, semantic similarity, logical inference and ScoresaremostlyalignedacrossTemplates(Fig-
languagecoherence. ure11),exceptTemplate5,thatstandsoutinhav-
inglessalignedscoreswithrespecttothecontext,
C.1 SemanticAlignment butalsomoreself-consistentacrossthetask. This
is the only template that did not have any expla-
Despite the fact that model 13B OPT-CoT on
nation inits prompt. Manual reviewshowed that
average outperforms other models in almost
despiteCoT-finetuning,OPT-COTmodelstendto
all semantic alignment scores (Faithfulness-Step,
produce1-stepanswer-onlygenerations(seeexam-
Faithfulness-Token, and Info-Step, see Table 10),
pleintheTable12,andFigure9forchains’length
thereisnocommonpatternacrosstasks(Fig10).
distribution),thusoverfittingtothetemplaterather
Theperformancechangebetweenfinetunedmod-
thanlearningfromfinetuning.
els and corresponding pretrained version are sig-
In summary, ROSCOE-SA is able to identify
nificant4 on half of the tasks (11 tasks out of 20
alignedinformation,butitdoesnotguaranteehigh-
forFaithfulness-*scores,and9outof20forInfo-
quality output. It will favor model with short ex-
Step).
planationsandhighsemanticoverlapwiththeref-
erence. We found that often OPT-FT-1.3B sim-
4Significance is determined using T-test comparison,
wherep-valueisbelow0.05. ply repeats one sentence from the input, instead
Category Datasets VocabularyOverlaps
bigbenchrepeatcopylogic(Srivastavaetal.,2022) 1.59%
babit1singlesupportingfactanswergeneration(Westonetal.,2015) 0.38%
semevalclosedvocabularymathanswergeneration(Hopkinsetal.,2019) 7.90%
semevalgeometricmathanswergeneration(Hopkinsetal.,2019) 5.84%
tomqafindlocationeasyclean(Nematzadehetal.,2018) 0.94%
0%to10%
plausibleresultgeneration(Weiretal.,2020) 3.72%
argumentstanceclassification(Kobbeetal.,2020) 6.04%
argumentconsequenceclassification(Kobbeetal.,2020) 6.11%
mmmluanswergenerationformallogic(Hendrycksetal.,2021a) 5.35%
bardanalogicalreasoningcausation(Fuldaetal.,2017) 0.45%
commongensentencegeneration(Linetal.,2020) 29.31%
10%to30% tellmewhyanswergeneration(Laletal.,2021) 28.05%
cbentailment(Wangetal.,2019) 20.97%
piqaanswergeneration(Bisketal.,2020) 42.51%
rocstoriescorrectanswergeneration(Mostafazadehetal.,2016) 57.45%
sciqanswergeneration(Welbletal.,2017) 32.54%
over30% openbookqaquestionanswering(Mihaylovetal.,2018) 48.2%
glueentailmentclassification(Wangetal.,2018) 55.19%
anlir2entailment(Williamsetal.,2022) 43.37%
anlir3entailment(Williamsetal.,2022) 53.13%
Table 7: Vocabularyoverlap. Dissimilarityhasbeenmeasuredbetweentrainingdata(inTable4)andevaluationdata(in
Table5).
Datasets Randomscore GPT-3Davinciscore
Boolean 34.50% 31.80%
Physical 49.08% 50.00%
EntailmentTree 50.88% 54.41%
EventSemantic 54.08% 55.89%
Spatial 49.80% 49.30%
Table8: ClassificationaccuracybyGPT-3davinci-engineontheCurriculumbenchmark.
of producing reasoning, and thus will get high- answer given s given single supporting fact, po-
estROSCOE-SAscoresonthesechains,whileother tentially amongst a set of other irrelevant facts.
modelsthatproducesomesortofreasoningwillbe Manual review showed that although in this task
punished. finetunedmodelstendtoproduceanswersthatare
more consistent, they often fail to select the fact
C.2 SemanticSimilarity thatisrelevanttothequestionasked(see"Spatial
Semanticsimilarityscoressupportpreviousconclu- Reasoning"exampleinTable12.
sions: models,finetunedonfinalanswers(OPT-FT)
C.4 LanguageCoherence
exhibit lower similarity with respect to the base-
lineandCoT-finetunedmodels,whilehavingless Despite the variations in the values, Perplexity-*
repetitions(Figure12). Again,weattributethatto scorechangesbetweenmodelsaremostlyinsignif-
thefactthatthesemodelsproduceshortchainsthat icant (15 out of 20 tasks, see Figure 14). Man-
lackdetailedreasoningsteps. ualreviewshowedthatallmodelsproducemostly
grammaticallycorrectcontent.
C.3 LogicalInference
D Licenses
In general, finetuned models are more self- and
source-consistent than respective baselines (Fig- D.1 DatainALERT
ure 13, significantly outperforming nonfinetuned
• task62: Apache2.0
models on 14 out of 20 tasks. We further looked
into the task 083, which is a task to find a right • task697: MIT
Thecafeteriahad23apples.Iftheyused20tomakelunchandbought6more,howmanyapplesdotheyhave?
Theansweris 29apples.Thecafeteriastartedwith23applesandbought6more,foratotalof23+6=«23+6=29»29apples.
Select the best translation into predicate logic. David teaches Chris. (c: Chris; d: David; Txy: x teaches y)
(A)Tdc;(B)Tcd;(C)Tcc;(D)dTc.
Theansweris (B)Tcd.Inpredicatelogic,thepredicate(inthiscase,"T")iswrittenbeforethesubjectandobjectofthesentence.
SinceDavid(d)istheteacherandChris(c)isthestudent,thecorrecttranslationisTcd,whichreadsas"DavidteachesChris."
Isabellaenteredthehall. Oliviaenteredthehall. Theappleisintheblue_treasure_chest. Oliviaexitedthehall. Isabella
movedtheappletothegreen_basket. Question: WheredoesIsabellathinkthatOliviasearchesfortheapple? Theanswer
is ItisimpossibleformetoanswerthisquestionasIhavenoinformationaboutthethoughtsoractionsofIsabellaorOlivia.
Additionally,Idonothaveaccesstobrowseanyinformationbeyondmytrainingdata,whichendsin2021.
Table 9: Examples from tasks that require reasoning skills and generated outputs from ChatGPT. The faild outputs are
highlightedinred.
OPT1.3B OPT-FT1.3B OPT-CoT1.3B OPT13B OPT-FT13B OPT-CoT13B
ROSCOE-SA
Faithfulness-Step 0.863 0.841 0.862 0.863 0.858 0.870
Faithfulness-Token 0.936 0.921 0.938 0.936 0.923 0.940
Info-Step 0.857 0.829 0.854 0.858 0.846 0.861
Repetition-Token 0.618 0.920 0.683 0.582 0.857 0.701
ROSCOE-SS
Info-Chain 0.925 0.909 0.920 0.926 0.916 0.925
Repetition-Step 0.627 0.923 0.692 0.591 0.859 0.708
ROSCOE-LI
SourceConsistency 0.550 0.604 0.573 0.584 0.617 0.598
Self-Consistency 0.848 0.953 0.875 0.863 0.944 0.890
ROSCOE-LS
Perplexity-Step 0.016 0.006 0.015 0.010 0.006 0.009
Perplexity-Chain 0.022 0.006 0.020 0.016 0.006 0.013
Grammar 0.725 0.744 0.666 0.688 0.705 0.640
Table10: ROSCOEevaluationresultsaveragedacrosstemplates. Eachmetricisboundedwithin[0,1],where1indicatesthe
perfectscoreand0correspondstofailure. Valuescorrespondingtothebestperformingmodelarebolded,secondbestare
underscored.
• task393: MIT • task332: Pleasereferto: https://github.c
om/StonyBrookNLP/tellmewhy
• task1386: CCBY-NC4.0
• task083: CCBY3.0
• task1387: CCBY-NC4.0
• task151: Pleasereferto: https://github.c
• task1388: CCBY-SA3.0 om/kayburns/tom-qa-dataset
• task080: AFL3.0 • task1152: Apache2.0
• task513: Pleasereferto: https://github.c
• task102: MIT
om/dwslab/StArCon
• task591: CCBY-NC-3.0
• task514: Pleasereferto: https://github.c
• task1286: Apache2.0 om/dwslab/StArCon
• task216: Pleasereferto: https://www.micr
• task1344: CCBY4.0
osoft.com/en-us/research/publicati
• task104: Pleasereferto: https://github.c on/a-corpus-and-cloze-evaluation-f
om/allenai/semeval-2019-task-10#te or-deeper-understanding-of-commons
rms-and-conditions ense-stories/
D.2 DatainDevset
• task119: Pleasereferto: https://github.c
om/allenai/semeval-2019-task-10#te • task247: Dream dataset is intended for non-
rms-and-conditions commercial research purpose only. https:
Kendall’sτ score Kendall’sτ p-value
Faithfulness-Step -0.101 0.000
Faithfulness-Token 0.039 0.000
Info-Step 0.054 0.000
Repetition-Token -0.869 0.000
Info-Chain 0.009 0.000
Repetition-Step -0.867 0.000
SourceConsistency -0.119 0.000
Self-Consistency -0.553 0.000
Perplexity-Step 0.000 0.960
Perplexity-Chain 0.369 0.000
Grammar 0.013 0.000
Table11: Kendallcorrelationbetweenevaluationperspectiveandnumberofstepsinchainacrossallgeneratedreasoningchains.
Strongcorrelations(|τ|>0.4)arebolded.
.com/proofwriter/proofwriter-datas
et-V2020.12.3.zip
• StrategyQA:MIT.Downloadedfromhttps:
//storage.googleapis.com/ai2i/strate
gyqa/data/strategyqa_dataset.zip.
• ECQA:LiteratureandWikipediapassagesare
shared under CC BY-SA 4.0 license. Mid-
dle/Highschoolexampassagesarecollected
fromRACEwhichcomeswithitsownlicense.
• GSM8K:MIT.Downloadedfromhttps://
raw.githubusercontent.com/openai/gra
de-school-math/master/grade_school_
math/data/train.jsonl.
• AQUA-RAT: Apache License, Version 2.0.
Downloaded from: https://raw.github
usercontent.com/deepmind/AQuA/master
/train.json
• ESNLI: please refer to https://github.c
om/OanaMariaCamburu/e-SNLI/commit/b
Figure9: Distributionofthesteps’numberacrossalltasks
and templates varying between models (top) and between ab0fa0212be9e5c6737da70c639a596f882e
templatesforOPT-CoT13Bmodel. 931. Downloadedfrom: https://raw.gith
ubusercontent.com/OanaMariaCamburu/e
//github.com/nlpdata/dream. -SNLI/master/dataset/esnli_train_1.c
sv
• task118: Pleasereferto: https://github.c
om/allenai/semeval-2019-task-10#te • MATH: MIT. Downloaded from: https://
rms-and-conditions people.eecs.berkeley.edu/~hendrycks
/MATH.tar
• task1385: CCBY-NC4.0
• CoS-E:BSD-3-Clauselicense. Downloaded
D.3 DatainTrainingset
from: https://raw.githubusercontent.
• ProofWriter: CCBY.Downloadedfromhttp com/salesforce/cos-e/master/data/v1.
s://aristo-data-public.s3.amazonaws 11/cose_train_v1.11_processed.jsonl
• WinoWhy: MIT. Downloadedfrom: https:
//raw.githubusercontent.com/HKUST-K
nowComp/WinoWhy/master/winowhy.json
E MoreDetailsaboutModelTraining
We finetune our 1.3B models on 32 V100s with
batchsize8oneachGPUwithtotally38hoursand
21 minutes. We finetune our 13B models on 128
V100swithbatchsize4oneachGPUwithtotally
13hoursand26minutes.
Following OPT-IML (Iyer et al., 2022), we
use Fully Sharded Data Parallel (Artetxe et al.,
2021) and the Megatron-LM Tensor Parallelism
(Shoeybi et al., 2019). We inherit most model
hyper-parametersforeachmodelscalefollowing
OPT-IML.Wepackourtrainingexamplesintose-
quencesoflength2048, left-truncatingexamples
that overflow. We use Adam (Kingma and Ba,
2014)with32-bitstatewith(β ,β ) = (0.9,0.95),
1 2
linearlywarmingupthelearningratefor60steps
tothemaximum,followedbylinearlydecayingit
to0.
Figure10: NormalizedROSCOE-SAscorespertask,averagedacrosstemplates. Scoresarenormalisedbytheirmeanvalue
acrossOPT1.3Bmodel’sgenerations.
Figure11: SelectedscorespertaskforOPT-CoT13Bmodel.ScoresarenormalisedbytheirmeanvalueacrossTemplate1
generations.
Figure12: NormalizedROSCOE-SSscorespertask,averagedacrosstemplates. Scoresarenormalisedbytheirmeanvalue
acrossOPT1.3Bmodel’sgenerations.
Figure13: NormalizedROSCOE-LIscorespertask,averagedacrosstemplates. Scoresarenormalisedbytheirmeanvalue
acrossOPT1.3Bmodel’sgenerations.
Figure14: NormalizedROSCOE-LCscorespertask,averagedacrosstemplates. Scoresarenormalisedbytheirmeanvalue
acrossOPT1.3Bmodel’sgenerations.
REASONINGSKILL:LogisticReasoning,Mathematics
PROMPT:Pleasegiveashortexplanationaftertheanswer. Input: Identifytheconclusionofthefollowingargument. Itis
hardnottoverifyinourpeersthesameweakenedintelligenceduetoemotionsthatweobserveinoureverydaypatients.
Thearroganceofourconsciousness,whichingeneral,belongstothestrongestdefensemechanisms,blockstheunconscious
complexes.Becauseofthis,itisdifficulttoconvincepeopleoftheunconscious,andinturntoteachthemwhattheirconscious
knowledgecontradicts.(SigmundFreud,TheOriginandDevelopmentofPsychoanalysis)(A)Itishardnottoverifyinour
peersthesameweakenedintelligenceduetoemotionsthatweobserveinoureverydaypatients. (B)Thearroganceofour
consciousness,whichingeneral,belongstothestrongestdefensemechanisms,blockstheunconsciouscomplexes.(C)Because
ofthis,itisdifficulttoconvincepeopleoftheunconscious,andinturntoteachthemwhattheirconsciousknowledgecontradicts.
(D)Itisdifficulttoconvincepeopleoftheunconscious,andinturntoteachthemwhattheirconsciousknowledgecontradicts.
Let’sthinkstepbystep.Output:TheanswerisDbecauseBecauseofthereasonsspecifiedintheargument,itisdifficultto
convincepeopleoftheunconscious,andinturntoteachthemwhattheirconsciousknowledgecontradicts.Input:Selectthe
besttranslationintopredicatelogic:NopeopledriveonMars. (Dx:xdrivesonMars)(A)∼Pd(B)(∀x)(Px∨∼Dx)(C)
(∀x)(Px⊃∼Dx)(D)∼DpLet’sthinkstepbystep.Output:TheanswerisCbecauseAnswerCmeansforeverything,ifthat
thingisaperson,itdoesn’tdriveonMars.Sothat’sthecorrecttranslation.Input:Selectthebesttranslationintopredicatelogic.
DavidteachesChris.(c:Chris;d:David;Txy:xteachesy)(A)Tdc(B)Tcd(C)Tcc(D)dTcLet’sthinkstepbystep.Output:The
answerisAbecauseDavidteachesChris,sointherelationTxyxshouldbe’d’fordavisandyshouldbe’c’forChris.Input:
WhichofthegivenformulasofPListhebestsymbolizationofthefollowingsentence?EitherEngland’simportingbeefisnota
necessaryconditionforFrance’ssubsidizingagriculture,orChinapromoteshumanrightsifSouthAfricasuppliesdiamonds.
(A)(∼F ⊃E)∨(C ≡∼S)(B)(∼E ⊃F)∨(C ⊃S)(C)(∼F ⊃E)∨(C ≡S)(D)∼(F ⊃E)∨(S ⊃C)Let’sthink
stepbystep.Output:TheanswerisDbecauseWhennotdefinedinthequestion,entities,relationshipsorstatementsareshown
withtheirfirstletter.Inthisexample’Francesubsidizingagriculture’isshownwithFforsimplicity.ThecorrectanswerisD,
becauseitusesthe’or’operatorbetweenthetwo’if’clauses.Input:Selectthebesttranslationintopredicatelogic.Kevinis
introducedtoJosébyWilma.(j:José;k:Kevin;w:Wilma;Ixyz:xintroducesytoz)(A)Iwjk(B)Ijkw(C)Ikjw(D)IwkjLet’s
thinkstepbystep.Output:
REFERENCE:D
OPT1.3B:TheanswerisAbecauseallstatementsneedtobepresentedwithanargument.
OPT-FT1.3B:TheanswerisB
OPT-CoT1.3B:TheanswerisAbecauseUsingthe’or’operatorbetweenthestatements,wehave:KevinisintroducedtoJosé,
becauseofits’e’factorintheequation.WilmaisintroducedtoKevinbecauseofits’j’factorintheequation.Joséisintroduced
toWilmabecauseofits’y’factorintheequation.Inbothcases,Wilmaaccepts’x’and’y’.
OPT13B:TheanswerisAbecauseintroducingapersontoanotherpersonistheactionofintroducing.ItispossiblethatKevin
hasbeenintroducedtoWilmabutnotJose.
OPT-FT13B:TheanswerisAbecausewhenwisintroduced,itsays’WilmaintroducedKevintoJosé’
OPT-CoT13B:TheanswerisDbecausethecorrecttermis’introduces’,therelationis’j:kevinandw:wilmatok:x’,itisan
’and’relation.Usingtheoperator’and’allowsustochoosethegreatestofthe5possibilities.
REASONINGSKILL:CommonsenseReasoning
PROMPT:Pleasegiveashortexplanationaftertheanswer.Input:Desertsareinextremelydryenvironments,soliquidswill
naturallybe(A)rainbow(B)plentiful(C)meager(D)talentedLet’sthinkstepbystep.Output:TheanswerisCbecauseThisis
agoodexampleandtheoutputcorrectlyanswersthequestion.Input:Dairyhasthingsinitthatwouldmakehumanssick,soin
orderfordairytobeedible,thisprocesshastotakeplace(A)mixing(B)boiling(C)freezing(D)pasteurizedLet’sthinkstep
bystep.Output:TheanswerisDbecauseinorderfordairytobeedible,thisprocesshastotakeplacepasteurized.So,the
correctansweris"D".Input:Digestioniswhenstomachacidbreaksdown(A)apizza(B)ahouse(C)arock(D)acarLet’s
thinkstepbystep.Output:TheanswerisAbecauseDigestioniswhenstomachacidbreaksdownafoodandonlyoptionAisa
food.So,thisexampleiscorrect.Input:WitharulerIcanmeasure(A)feelings(B)love(C)air(D)aphoneLet’sthinkstepby
step.Output:
REFERENCE:D
OPT1.3B:Aisafeeling,andallfeelingscomefromfeelings(A).Therefore,feelingsareproductsofemotions(A).Therefore,
emotionsarecreatedbyemotions(A).Therefore,feelingsandemotionsaredirectlyrelated(A).Therefore,emotionsarecreated
byemotions(A)...[repeats249times]
OPT-FT1.3B:Abecausefeelingsandlovearemeasurementsandairisaphone
OPT-CoT1.3B:TheanswerisDbecauseWitharulerIcanmeasureanobjectorrangeofobjectsandoptionsarealltodowith
measuring.So,thisexampleiscorrect.
OPT13B:TheanswerisBbecauseWitharulerIcanmeasurealengthandonlyoptionsBandDareinfrontofme.So,the
answerisB.
OPT-FT13B:TheanswerisDbecauseaphoneisanobject
OPT-CoT13B:TheanswerisAbecauseAnswer:MeasurefeelingsWitharulerIcanmeasure.
REASONINGSKILL:CasualReasoning,Textualentailment
PROMPT:Pleasegiveashortexplanationaftertheanswer.Input:Premise:Ifyoucandreamit,youcanachieveit—unless
you’reagoosetryingtoplayaveryhumangameofrugby.Inthevideoabove,oneboldbirdtookachancewhenitranontoa
rugbyfieldmid-play.Thingsgotdiceywhenitgotintoatusslewithanotherplayer,butitshookitoffandkeptrightonrunning.
Aftertheplayended,theplayersescortedthefeistygooseoffthepitch.Itwasariskymove,butthecrowdchantingitsname
waswellworthit.Videocredit:Storyful/NathanSwarbrick@swazza1990<sep>Hypothesis:Thecrowdbelievedtheyknew
thenameofthegooserunningonthefield.Let’sthinkstepbystep.Output:TheanswerisEntailmentbecauseThisisagood
example,thehypothesissentenceentailsthegivenpremise.Becausethecrowdwaschantingitsname,thecrowdmusthave
believedtheyknewthegoose’sname.Input:Premise:Notleyhopefulattacksonwomenpoliticianswillfadeincomingyear
Afterapoliticallynastyyearthatsawwomenpoliticiansfaceabarrageofattacksonsocialmediaandangrydemonstrators
shoutingtohavethemputbehindbars,PremierRachelNotleyisoptimistictherewillbeareturntocivildiscourse.Inayear-end
interviewwithCBCNews,Notleyreflectedon2016,ayearthatsawhatefulsocial-mediaattacksagainstMLASandraJansen,
andchantsof“Lockherup”directedatthepremieratananti-carbontaxrallyinEdmonton.<sep>Hypothesis:Notleyreflected
onthechantsof"lockherup"fromprevioustotheyear2016.Let’sthinkstepbystep.Output:TheanswerisContradiction
becauseThePremisestatesNotleyreflectedonthechantsfrom2016,notbefore2016.Inthisexamplehypothesissentence
contradictsthegivenpremise. Input: Premise: MazdaSales(Thailand),aunitofJapanesecarmakerMazdaMotorCorp,
remainsbullishaboutitssalesprospectsthisyeardespitefallingfiguresinthefirstsixmonths,theBangkokPostreported,citing
itsPresidentHidesukeTakesue. (bit.ly/1gr7HMd)—-NOTE:Reutershasnotverifiedthisstoryanddoesnotvouchforits
accuracy.(BangkokNewsroom;EditingbyPrateekChatterjee)<sep>Hypothesis:MazdaSaleswillbefirednextweekLet’s
thinkstepbystep.Output:TheanswerisNeutralbecauseInthisexamplethehypothesiscan’tbeprovenonewayortheother
basedonthecontext.It’ssetinthefutureandnooneknowsthefuture.So,hypothesissentenceisneutralwithrespecttoa
givenpremise. Input:Premise:Howtoclearnasalcongestionquickly<br>Gentlyblowyournose. Perhapstheeasiestand
quickestwaytoreducenasalcongestionistosimplyblowyournoseintoasofttissue.Unfortunately,it’snotalwayspossibleto
completelyrelievecongestionbymerelyblowing,butit’salwaysagoodstartingpoint.<sep>Hypothesis:strikeaposetofix
yournoseLet’sthinkstepbystep.Output:
REFERENCE:Contradiction
OPT1.3B:TheanswerisModifiedContradictionbecauseInthisexamplethehypothesissentencesuggeststhemethodis"Do
nothityourhead."Infact,that’sthephraseapersonwhoisrollingaroundontheground,orwhohashadtheirheadhitahard
surfacewhiletryingtogetagoodsleeperonthesheetsshouldtry. Whyisthis? Ahead-oncollisionwill... [continuesto
hallucinatefor23steps]
OPT-FT1.3B:Answer:Blowyournoseintoasofttissue.
OPT-CoT1.3B:TheanswerisContradictionbecauseThehypothesisstatesthatNastaiwillsolvehisandnasalcongestiononly
byblowingintohisnose,butthat’snotnecessarilytrue,becausehecouldhaveblownintohisnoseandcausedirritationaswell.
OPT13B:TheanswerisYesbecauseTheanswerisYes.Alltheaboveinformationaboutclearingthenoseisprovenbythe
givenpremise,butifyoustilldon’tknowtheanswer,thenwesuggestyougohereandclickon"Howtoclearyournose
naturally"page.
OPT-FT13B:Theanswer:contradiction
OPT-CoT13B:TheansweriscontradictionbecauseOnecannotblowtheirnoseiftheyhavestruckapose.
REASONINGSKILL:AnalogicalReasoning
PROMPT:Pleasegiveashortexplanationaftertheanswer.Input:throw:fly.aspire:?Let’sthinkstepbystep.Output:The
answerisattainbecauseFlyisacausationofthrow. Hence,theinferredanalogybeingcausation,attainisthecausationof
aspire.Input:listen:hear.drop:?Let’sthinkstepbystep.Output:TheanswerisfallbecauseHearisacausationoflisten.
Hence,theinferredanalogybeingcausation,thecausationofdropisfall.Input:hit:shatter.nourish:?Let’sthinkstepbystep.
Output:TheanswerisgrowbecauseShatterisacausationofhit.Hence,theinferredanalogybeingcausation,thecausationof
nourishisgrow.Input:throw:fly.ignite:?Let’sthinkstepbystep.Output:
REFERENCE:burn
OPT1.3B:Theanswerismovebecauseflyisacausationofignite.Hence,theinferredanalogybeingcausation,thecausation
ofmoveisfly.
OPT-FT1.3B:Theansweristhrow
OPT-CoT1.3B:TheanswerisignitebecauseFireisacausationofthrow.Hence,theinferredanalogybeingcausation,the
causationofigniteisfly.
OPT13B:TheanswerisevaporatebecauseFlyisacausationofthrow. Hence,theinferredanalogybeingcausation,the
causationofevaporateisignite.
OPT-FT13B:TheanswerisflybecauseIgniteisacausationofthrow
OPT-CoT13B:TheanswerisgrowbecauseThrowisacausationofgrow.
REASONINGSKILL:Commonsensereasoning,SpatialReasoning
PROMPT:Pleasegiveashortexplanationaftertheanswer.Input:Howdoyouremovekeysfromacomputerkeyboardfor
cleaning?Let’sthinkstepbystep.Output:TheanswerisPlacethetipofaknifeunderthecornerofakeyandgentlytwistto
popitoff.becauseTheprocessofremovingkeysfromakeyboardforcleaningisdescriptiveandlogical.Input:Howcanyou
drywetreplacementcomputerkeyboardkeys?Let’sthinkstepbystep.Output:Theanswerisbyarrangingpapertowelsonthe
counterandevenlyspacingouteachkeytodry,facesideup,ontopofthem.becauseThestepsinvolvedintheprocessofdrying
wetreplacementkeyboardkeysarelogical.Input:TocoatsmallplasticobjectslikereplacementkeyboardkeyswithsoapLet’s
thinkstepbystep.Output:Theanswerisplacethem,waterandliquiddishsoapinasealedcontainer.Shakevigorouslyuntilthe
containeriscompletelyfulloffoam.becauseTheprocessofcoatingsmallplasticobjectslikereplacementkeysisdescriptive
andlogical.Input:Howdoyoucutgnocchiwithoutaknife?Let’sthinkstepbystep.Output:TheanswerisPresstheedgeofa
spoondownintothedoughtocutit.becauseTheanswerisquitedetailedaboutthemethodtocutgnocchiwhenknifeisnot
available.Input:Howdoyoutastesomething?Let’sthinkstepbystep.Output:TheanswerisPlaceitinyourmouthtotaste.
becauseTotastesomethingonehastokeepitincontactwiththetongue.Henceitislogicaltoputitinthemouthtotaste.Input:
Howdoyouwearabracelet?Let’sthinkstepbystep.Output:TheanswerisPutitonaroundyourwrist.becauseBraceletis
wornaroundwrists.Henceitiscorrectanswer.Input:Tofindaneasywaytocompletelevelsonavideogame,Let’sthinkstep
bystep.Output:
REFERENCE:lookupcheatcodestomaketherulesofthegamedifferentornull.
OPT1.3B:TheanswerisEnterkeywithoutpressing.becauseHowtofindtheperfectwaytocompletelevelsonavideogame
islogicalanddescriptive.
OPT-FT1.3B:Ittellsyoutheeasiestwaytogetallthecoinsandmedalsandthefastestwaytogetthroughthelevel.
OPT-CoT1.3B:Theanswerisplaythegame.becauseIfyouplayagametofinishthelevelsthenyoucancallitagame.
OPT13B:TheanswerisCompletethelevelasfastaspossibletogetahighscore,byjumpingthroughthestageasquicklyas
possible.becauseTheanswerisexplicitandveryclearthathowausercancompletelevelsonavideogamewithjustahint.
OPT-FT13B:Theansweristryharderoruseaguide,becauseTheprocessoffindinganeasywaytocompletelevelsonavideo
gameisdescriptiveandlogical.
OPT-CoT13B:TheanswerisYouTubetofindouthowtogetpastalevel.becauseYouTubeisusedtofindoutwaystocomplete
agameeasily.
REASONINGSKILL:SpatialReasoning
PROMPT:Instructions:Youwillbegivenapassageconsistingofsetoffactsandaquestionasinput.Thetaskistoanswera
questionofform’Whereis<person_name>?’usingoneofthegivenfactstodeterminethelatestlocationoftheperson.Answer
shouldbeaword/phrasedescribingthelocationfromthesupportingfact. Avoidanswersthatareincompleteorincorrect.
PositiveExamples:Input:Passage:Marymovedtothebathroom.Johnwenttothehallway.Question:WhereisMary?Output:
bathroomInput:Passage:Marymovedtothebathroom.Johnwenttothehallway.Danielwentbacktothehallway.Sandra
movedtothegarden.Question:WhereisDaniel?Output:hallwayInput:Passage:Marymovedtothebathroom.Johnwentto
thehallway. Danielwentbacktothehallway. Sandramovedtothegarden. Johnmovedtotheoffice. Sandrajourneyedto
thebathroom.Question:WhereisDaniel?Output:hallwayInput:Passage:Johnmovedtothehallway.Marytravelledtothe
hallway.Sandrawenttothebedroom.Sandrawentbacktothehallway.Question:WhereisMary?Output:
REFERENCE:hallway
OPT1.3B:bathroom
OPT-FT1.3B:hallway
OPT-CoT1.3B:hallway
OPT13B:bathroom
OPT-FT13B:bathroom
OPT-CoT13B:hallway
Table12: Examplesfromtasksthatrequiredifferentreasoningskillsandgeneratedoutputs.Thefailedoutputsarehighlighted
inred.Outputsthataredifferentfromthereference,butcanbevalidbecausethequestionisambiguousarehighlightedinblue.
AllexcepttheoneareexamplesgeneratedusingpromptTemplate4,lastexampleusedTemplate5.
