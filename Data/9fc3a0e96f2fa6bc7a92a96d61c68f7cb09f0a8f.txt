Augmenting Pre-trained Language Models with
QA-Memory for Open-Domain Question Answering
WenhuChen,PatVerga,MichieldeJong†,JohnWieting,WilliamW.Cohen
GoogleResearch,UniversityofSouthernCalifornia†
{wenhuchen,patverga,jwieting,wcohen}@google.com, msdejong@usc.edu
Abstract (Xiaoetal.,2021;Lewisetal.,2021). Notably,the
RePAQsystemfrom(Lewisetal.,2021)wonthe
Existing state-of-the-art methods for open- 2020EfficientQAcompetition(Minetal.,2021),
domain question-answering (ODQA) use an
outperformingclosed-bookQA(CBQA)modelsby
open book approach in which information is asignificantmarginandmatchingthepriorSoTA
first retrieved from a large text corpus or
performanceonNQ(Kwiatkowskietal.,2019).
knowledge base (KB) and then reasoned over
to produce an answer. A recent alternative AcollectionofQApairsisappealingforseveral
is to retrieve from a collection of previously- reasons. Asopposedtotextpassagesandmuchlike
generated question-answer pairs; this has sev- a KB triple, QA pairs are often concise, tending
eralpracticaladvantagesincludingbeingmore
to express a single relationship. However, unlike
memory and compute-efficient. Question-
KBtriples,QAcollectionshavegoodcoverageof
answer pairs are also appealing in that they
actuallyaskedquestionslikethoseinstandardopen
canbeviewedasanintermediatebetweentext
QAdatasets. RePAQdemonstratedseveraladvan-
andKBtriples:likeKBtriples,theyoftencon-
cisely express a single relationship, but like tageouspropertiessuchasmemoryandcomputa-
text, have much higher coverage than tradi- tionalefficiency,strongselectiveQAperformance
tional KBs. In this work, we describe a new (i.e. selectivelyabstainingfromanswering),andef-
QAsystemthataugmentsatext-to-textmodel fectiveensemblingwithtext-retrievalQAsystems.
withalargememoryofquestion-answerpairs,
However, question-retrieval QA systems have
and anew pre-trainingtask forthe latentstep
severallimitationsaswell. First,thereisnolarge-
of question retrieval. The pre-training task
scale supervised data for question-question re-
substantially simplifies training and greatly
improves performance on smaller QA bench- trieval. This contrasts with the step of retriev-
marks. Unlike prior systems of this sort, our ing text given a question, where supervised data
QA system can also answer multi-hop ques- is used to build retrievers like DPR (Karpukhin
tions that do not explicitly appear in the col-
etal.,2020). Toaddressthis,RePAQusesalatent-
lectionofstoredquestion-answerpairs.
retrievaltrainingprocess(similartoREALM(Lee
et al., 2019)), in which the retriever is trained us-
1 Introduction
ing the downstream end loss from the QA task.
Open-domain question answering (ODQA) is a This requires asynchronously updating the index
well-studied knowledge-intensive task. State-of- astrainingproceeds,aprocessthatiscomplexand
the-artmethodsrequireretrievingrelevantknowl- computationallyexpensive. Thisisalsoaproblem
edge from a large corpus or datastore before rea- fordomainswithlimitedQAdata: aswewillshow,
soningoverthisretrievedevidence. Mostexisting RePAQ’sperformanceisdisappointingonsmaller
methods retrieve documents (Chen et al., 2017a; datasets like WebQuestions (Berant et al., 2013),
Leeetal.,2019;Karpukhinetal.,2020)orstruc- containingonly3Ktraininginstances. Toaddress
tured KB triples (Verga et al., 2021). Recently, a this problem, we introduce a novel pre-training
fewworkshaveproposedretrievingfromacollec- taskforquestionretrieval,whichcanbeappliedto
tionofquestion-answer(QA)pairs—anapproach anytext-QAdataset,whichgreatimprovesperfor-
made feasible by advances in scalable automatic manceonsmallerdatasets.
question generation. In this setting, a new ques- A second problem is that RePAQ is limited to
tionisansweredbyretrievingparaphrasesfroma answeringquestionsexplicitlystoredintheindex,
questionindex,andreturningtheassociatedanswer or paraphrases of such questions. This contrasts
3202
naJ
32
]LC.sc[
3v18540.4022:viXra
Figure1: Duringpre-training,theencoderfirstencodestextualinputandusespecialtokenrepresentationtoquery
theQA-memory. TheretrievedQA-pairsareintegratedtothedecodertogenerateoutputs.
withQAsystemsthatretrievefromKBs,whichcan thatwecanavoidtheexpensivelatenttrainingpro-
typically generate complex queries that combine cedureusedbyRePAQ,andinsteaduseanefficient
the atomic triples in the KB.To address this, we two-stage training pipeline. In the first stage, we
presentanextendedmodelthatanswersmulti-hop use a small local in-batch memory of QA pairs
questionsbyiterativelyretrievingfromaquestion- to optimize the QA pair encoder. We then freeze
answer corpus, the first question-retrieval-based theencoderandconstructtheindexfortheglobal
QAsystemthataddressesthistask. memory. Inthesecondstage,weretrievefromthis
Inmoredetail,weproposeanewQA-Memory- fixedglobalmemoryandcontinuetooptimizethe
Augmented Transformer (QAMAT) with better remainingparameters—includingtheparameters
compositionality paired with a lower complex- usedtoconstructqueriestotheglobalmemory—
ity training strategy. QAMAT is based on a forbetterperformance.
T5 encoder-decoder (Raffel et al., 2020) paired Lastly,weextendQAMATtobuildQAMAT+,
withanintegratedkey-valuememory(Khandelwal whichiterativelyretrievesfromthememorytogen-
etal.,2019;Borgeaudetal.,2021)populatedwith erateoutputs. WedemonstratethatQAMAT+ef-
question-answer pairs (See Figure 1). Given an fectivelychainsmultipleQA-pairstogethertoan-
input,theencodergeneratesaqueryrepresentation swermulti-hopquestionsinHotpotQA(Yangetal.,
scored against the QA memory and retrieves the 2018) and Musique (Trivedi et al., 2021). Such
top-KrelevantQApairs. Theencoderthenrepro- compositionalreasoningcapabilityisnonexistent
cessestheinputalongwiththeretrievalsforminga inRePAQ(Lewisetal.,2021).
QA-injectedrepresentationwhichispassedtothe Insummary,wedevelopanewQAaugmented
decodertoattendtoandgenerate. architecture which extends the lines of research
consideringQApairsasarepresentationofknowl-
Toreducethetraining(fine-tuning)samplecom-
edgeaswellasthoseonmemory-augmentedlan-
plexity,weproposetofirstpre-trainQAMATona
guagemodels. Whenpairedwithourproposedpre-
large-scalecorpustoteachthemodeltoretrieveand
trainingstrategy(section4),weaddressmanyof
interpretQApairs. Weconstructthepre-training
theshortcomingsofpreviousQA-indexing-based
corpus by leveraging existing methods for ques-
approaches leading to lower sample complexity
tion generation, producing a very large set of po-
trainingandtheabilitytoperformcompositional
tentially interesting questions from text passages
reasoning(subsection3.5).
(Zhouetal.,2017;Albertietal.,2019;Lewisetal.,
2021). For each QA pair and the passage it was
2 RelatedWork
generatedfrom,wemasktheanswerandtrainthe
model to fill the mask by retrieving and using an 2.1 Retriever-ReaderModels
appropriate QA pair. We show that pre-training Retrieve-and-readmodelshavebeenwidelystudied
greatlybooststhemodel’sperformanceandhelps toaddressknowledge-intensivetasksandachieve
the model generalize to different domains. For state-of-the-art performance on most QA tasks.
example,thepre-trainedmodelcanachieveazero- These methods use two models, one to retrieve
shotperformanceof40%EMonNQandTriviaQA fromapassageindexbasedonBM25(Robertson
withoutanyfine-tuning.
andZaragoza,2009),andonetoperformreading
Theeffectivenessofthispre-trainingtaskmeans comprehension on the returned passages (Chen
etal.,2017b). Morerecently,deepretrievalmodels 2022) or knowledge triples (Verga et al., 2021).
havegainedmorepopularitytoreplacetraditional Memoryattentionlayersarethenusedtoinfluence
string-similarityretriever. thecomputationoftransformerlayers. Theseenti-
DPR (Karpukhin et al., 2020) is a widely tiesandfact-centricmemoriesarenaturallyatomic
usedsupervisedapproachtoachievebetterresults and interpretable, and models employing them
than BM25 on a large collection of text retrieval have shown competitive performance on entity-
tasks (Thakur et al., 2021). Contrastive learning focused QA datasets like Web-Question-SP (Yih
isusedtotrainthedeepretrievermodeltodistin- etal.,2016)andComplexWebQuestions(Talmor
guishbetweenannotatedpositiveandminednega- andBerant,2018). However,thesemodelsarelim-
tivecandidates. Morerecently,ColBERT(Khattab ited to integrating entity-centric knowledge and
andZaharia,2020)hasbeenproposedtointegrate classifying the answer w.r.t a pre-defined entity
more fine-grained late fusion between query and list. For example, these models cannot handle
contexttoimproveDPR. questions with non-entity answers, e.g. number,
RetrievalAugmentedGeneration(RAG)(Lewis date, noun phrases, etc, which are ubiquitous in
etal.,2020),Fusion-in-Decoder(FiD)(Izacardand variousQAdatasetslikeNQ(Kwiatkowskietal.,
Grave, 2021) and End-to-end training of Multi- 2019), SQuAD (Rajpurkar et al., 2016), or Hot-
Document Reader and Retriever (EmDR) (Singh potQA(Yangetal.,2018).
etal.,2021)areproposedtoreadretrievalstoex-
tractorgenerateanswers. Thesemodelsrequirea 3 OurModel: QAMAT
trained retriever/reranker to obtain top-K results,
3.1 ProblemDefinition
whicharefedtothereadertogeneratetheanswer.
Asdiscussedinsection1,ourmodelprovidesbetter The input to our model is a piece of text X =
interpretabilityduetoatomicknowledgerepresen- x 1,··· ,x n, where X is either a question dur-
tation. Insubsection5.4,wealsodemonstratethat ing fine-tuning or a paragraph in pre-training.
ourmodel’sinferencespeedis5xfaster. Pre-training is formulated as a span corruption
task(Raffeletal.,2019): givenanexampleinthe
2.2 QuestionGeneration pre-training corpus as (X,{Qk,Ak}m ), where
k=1
The problem of question generation (Zhou et al., A1,··· ,Am correspond to spans in the input
2017)hasattractedattentionfromthecommunity X. We sample k spans from X as a cloze an-
inrecentyears. Ithasbeenusedfordataaugmen- swer and replace all tokens within a span with
tation(Albertietal.,2019)toimprovecurrentQA a [MASK] token, and the model needs to re-
systemsortoimproveretrievalsystems(Nogueira coveralltheanswers. Duringfine-tuning,weadd
etal.,2019). Panetal.(2021)alsodemonstrated an artificial [MASK] in the question front, and
thatbyconnectinggeneratedsingle-hopquestions, let the model recover this as the answer. The
wecantrainzero-shotmulti-hopquestionanswer- pre-training/fine-tuning objective function is to
ingsystems. BesidesQA,ithasalsobeenwidely maximizethemaskedlanguagemodelobjectives
(cid:80)
usedinotherdomainslikeevaluatingfactualcon- p(Y|X) =
mi∈M
p(Y|X,m i)p(m i|X), which
sistencyofsummarization(Eyaletal.,2019;Wang marginalizesovertheentirememoryM. However,
etal.,2020)orenhancingcontextualizedrepresen- duetoitsintractabilityinalarge-scalememory,we
tation(Jiaetal.,2021). Mostrelatedtoourwork adoptanapproximationtoonlysumoverthetop-K
isPAQ(Lewisetal.,2021),whichaimstogener- memoryentriesTop K(M).
ateanduseQApairsasretrievalunitsforquestion We define the encoder function as f θ, which
answering. The efficacy of this data was further takes an input sequence X as input to generate a
verified when it was used to train DPR, yielding sequenceofvectorF θ(X) ∈ Rn×d,wherenisthe
betterdomaingeneralization(Og˘uzetal.,2021). input length and d is the hidden size. The desig-
natedpositionofF (X)willbeusedasthequery
θ
2.3 Memory-AugmentedLanguageModels
and memory representation, which are denoted
End-to-endmemory-augmentedlanguagemodels as f (X;[MASK]) ∈ Rd (at [MASK] position)
θ
aim to train a model to explicitly access external andmemorykey/valueasf (mk;[CLS]) ∈ Rd (at
θ i
memory. The current work is focused on storing [CLS]position). Forbrevity,weleaveout[MASK]
entities(Févryetal.,2020),entitymentions(Dhin- and[CLS]andsimplyusef (·).
θ
gra et al., 2019; Sun et al., 2021; de Jong et al., We also define a broadcast operator Bn(x) to
k
Figure2: Architecture: upperfigureshowstheretrievalprocesswithsharedencoder, thelowerfigureshowsthe
decoderprocesstoleverageneuralanddiscreterepresentationofmemoryretrieval.
broadcast a vector into a matrix by assigning the jectivecanbewrittenasfollows:
vectorxtok-throwwhilefillingtherestwithzero,
i.e. Bn(x) = [0,...xT,...,0]. p(Y|X)=g θ(Y|H(X,Top K(M),p(m|X))) (1)
k
3.2 DenseRetriever AsshownintheupperpartofFigure2,wefirst
useweighted-sumovertheneuralrepresentationof
The memory M contains separate key and value
retrievedmemoryentriesf (mv)andthensimply
components, where the key mk contains a ques- θ i
i addittotheencoderrepresentationtoinfusethere-
tion,andthecorrespondingvaluemv containsthe
i trievedQA-pairinformation. Thesetwooperations
question-answerconcatenation. Toretrievethetop-
arebothdifferentiable,whichmakestheitpossible
kQA-pairsfromthememory,weuseourencoder
totrainretrieverlatently. Inessence,theretriever
f to encode X and m separately and select the
θ i willincreasingweightsp(m |X)onmorerelevant
top-KentriesTop (M)basedontheirinnerprod- i
K
memoryitemsinsteadofirrelevantones.
uct,i.e. TopK f (X)·f (mk).
mi∈M θ θ i
3.4 Neural+DiscreteMemoryIntegration
3.3 NeuralMemoryIntegration
A disadvantage of adopting weighted-sum
After the model retrieves the Top-K candidates, (cid:80) p(m |X)f (mv) ∈ Rd is that all the infor-
their corresponding memory values mv needs be i i θ i
i mation from all of the top-K documents are
leveragedintotheencodertoinfluencethedecoder
overly compressed into a d-dimension vector,
outputs in a differentiable fashion. We write our
whereasthetokenretrievalrepresentationcontains
objectivep(Y|X)as:
more information. Therefore, we propose to
add a fine-grained token-wise representation
(cid:88)
p(Y|X,m i)p(m i|X) Hˆ(X,Top (M)) to help the model access the
K
mi∈TopK(M)
retrieveddiscretevaluesm directly. Therepresen-
= (cid:88) p(m |X)g (Y|F (X)+Bn[f (mv)]) i
i θ θ k θ i tation is obtained by encoding the concatenation
mi∈TopK(M)
of the input X and retrieved discrete tokens
≈g θ(Y| (cid:88) p(m i|X)(F θ(X)+B kn[f θ(mv i)])) Xˆ = Concat[m ;··· ;m ;X] ∈ R(n+k|m|)×d.
k 1
mi∈TopK(M)
=g (Y|F (X)+Bn[ (cid:88) p(m |X)f (mv)]) Such discrete memory integration greatly en-
θ θ k i θ i richestherepresentationform andenablescross-
i
mi∈TopK(M)
attentionbetweenthequeryandretrieval,address-
efθ(X)·fθ(mk i)
p(m |X)= ing the bottleneck problem. However, such dis-
i (cid:80)
mi∈TopKM
efθ(X)·fθ(mk i)
crete representation cannot propagate gradients
backtotheretriever. Finally,weproposetocom-
The probability p(Y|X,m ) is parmeterized by a
i
binetheneuralmemoryH(X,·)anddiscretemem-
decoderfunctiong ,whichtakesamemory-infused
θ oryHˆ(X,·)integrationtocombinetheirmerits.
encoder representation F (X) + Bn[f (mv)] as
θ k θ i
input. We approximate this marginal probabil-
p(Y|X)
ity by pulling weighted summation inside the de-
=g (Y|H(cid:48)(X,Top (M),p(m|X))+λHˆ(X,Top (M)))
θ K K
coderfunctiong toderiveanaggregatedmemory-
θ (2)
infusedencoderrepresentationsF (X)+Bn[···].
θ k
The retrieval weight p(m|X) is calculated as the where the λ is the balancing factor to weight the
softmaxovertheretrievalscoreovertop-Kitems. tworepresentations. WeuseH(cid:48)(...) = [0;H(...)]
Forsimplicity,H(X,Top (M),p(m|X))isused torepresenttheconcatenationofzero-matrix0 ∈
K
todenotethisencoderrepresentation,thustheob- Rk|m|×d,whichhasconsistentdimensionwithHˆ.
AfterleveragingHˆ,ourmodeldemonstratessignif-
icantimprovementsonthedownstreamtaskswith
14%onTriviaQAand10%onHotpotQA.
H(X,Top (M),p(m|X)) is only used to la-
K
tentlytraintheretriever,aftertraining,wecandrop
it and only use the concatenated representation
Hˆ(X,Top (M)) as the encoder representation.
K
The decoder g will attend to Hˆ and perform a
θ
Figure4: Twostagetrainingprocedure: in-batchtrain-
greedysearchovervocabularytogenerateoutput.
ingwithabatch-specificmemoryandend-to-endgradi-
3.5 Multi-hopExtension entupdates,globaltrainingwithafixedglobalmemory
andpartialgradientupdates.
To further extend QAMAT’s capability to per-
form compositional reasoning, we propose a cas- describedintheAppendix. Thefinalstatisticsof
caded architecture (depicted in Figure 3) known ourQA-memoryisdescribedinTable1,wherethe
asQAMAT+, wherethemodellearnstoperform totalsizeiscomparabletoRePAQ.
multiple rounds of retrieval before feeding the
augmented inputs to the decoder. Specifically Memory Size #Passages TrainingData
for two-hop reasoning, we use X as the query
Dedup-PAQ 30M 10M NaturalQuestions
to retrieve a first-round of top-K memory val- Additional 30M 10M SQuAD2.0
uesTop (M;1)withourlearnedretrieverf de-
K θ Combined 60M 20M -
scribed in subsection 3.2. Next, we augment the
query by concatenating the retrieved values as Table1: ThebreakdownstatisticsofourQAcorpus.
X1 = [Top (M;1);X]. This new query X1 is
K WedenotetheentirememoryasM andformu-
usedtoperformasecondroundofretrievaltoob- latethepre-trainingcorpusas{X,{Qk,Ak}m },
k=1
tainadditionaltop-Kmemoryvalues,Top (M;2).
K whereX isthepassagealignedwithmultipleQA-
Based on Top K(M;2), we compute the hybrid pairs{Qk,Ak}m generatedfromit.
encoderrepresentationH(X1,Top (M;2))and k=1
K
Hˆ(X1,Top (M;2))tocomputep(Y|X1;θ). 4.2 End-to-EndTraining
K
Duringtraining,theretrievalprocessisintegrated
into the model’s training loop. The most widely
adopted approach to accomplish this is approxi-
matenearest neighborsearch (ANNS)efficiently
implementedbyseverallibrarieslikeScaNN(Guo
et al., 2020), FAISS (Johnson et al., 2019), etc.
Figure 3: QAMAT+ architecture: Multi-Hop frame- These libraries require a fixed set of dense vec-
workforquestion-answermemoryintegration. torstoconstructtheindexandperformaNearest-
Neighbor search using approximate algorithms.
4 Training
However,ourmemoryencoderf iscontinuously
θ
updated,whichposesgreatchallengesforANNS
4.1 Pre-trainingCorpus
index building. REALM (Guu et al., 2020) and
OurQA-pairsareconstructedbycombining30M
RePAQ(Lewisetal.,2021)useanasynchronousin-
deduplicated QA-pairs from PAQ (Lewis et al.,
dexbuildingsub-processtorefreshtheindexevery
2021)(originally 65M, we delete paraphrases to
Ksteps,whichisknowntobeextremelycomputa-
keepasubset)and30MadditionalQA-pairsgen-
tionallyexpensive,especiallywithalargememory.
eratedfromourownpipeline. TheadditionalQA-
Toavoidsuchexpensivecomputationoverhead,we
pairsarepopulatedfromnon-overlappingpassage
are inspired by TOME (de Jong et al., 2022) to
blocks to increase the knowledge coverage over
adoptatwo-stagetrainingasshowninFigure4.
Wikipedia. Our QA generation pipeline is simi-
lar to (Lewis et al., 2021) but trained solely on In-Batch Pre-training In the first stage, in-
SQuAD 2.0 (Rajpurkar et al., 2018) and filtered stead of using the whole memory, we propose
withacheapreadingcomprehensionmodelrather a batch-specific memory that concatenates the
thanFiD(IzacardandGrave,2021),thedetailsare positive, random negative, and hard negative en-
tries from each instance in the batch. Assuming 5 QAExperiments
we have a batch size of B containing examples
5.1 ImplementationDetails
{X ,{Qk,Ak}K }B . For each example there
i i i k=1 i=1
existK positiveQA-pairsgeneratedfromthegiven OurmodelisbasedontheT5-baseorlargearchi-
context X . Additionally, we mine K hard nega- tecture implemented in JAX2 and pre-trained on
i
tive QA-pairs {Q¯ k,A¯ k}K for each input X to 32TPUsonGoogleCloud3. Duringin-batchtrain-
i i k=1 i
increaseretrievaldifficulty. Thishardnegativemin- ing, our query and index encoder f θ are shared
ingisdonewithBM25(RobertsonandZaragoza, andinitializedfromtheT5encoder(duringglobal
2009)similartoDPR(Karpukhinetal.,2020). We training the index encoder is fixed and the query
constructthein-batchmemorybyaggregatingthe encodercontinuestobeupdated). Ourdecoderg θ
K×B positiveQA-pairsandK×B hardnegative issimilarlyinitializedfromtheT5decoder. Into-
memory entries, so the in-batch memory Mˆ con- tal,weconstruct∼60Mquestion-answerpairsas
tains a total of 2K ×B QA-pairs (roughly a few theglobalmemory. Thememorykeyistheques-
thousand). Due to the small size of the memory, tiontokenizedbyT5sentencepiecemodelinto32
wecanconstructthememoryindexveryefficiently. tokens, and the memory value is the answer con-
Thus,itenablesustocontinuouslyupdatethemem- catenatedwithitsquestiontokenizedinto40tokens.
ory encoder parameters f to achieve strong QA- Thememoryisindexedbyapre-computedmatrix
θ
pairretrievalperformance. Mk ∈ R|M|×d computedbasedonitskeys(ques-
tions). The corresponding top-K memory values
(question+answer)willbefetched.
Global Pre-training and Fine-Tuning In this During in-batch pre-training, we use a large
stage, we first freeze the memory encoder f to batch size of 512 and a learning rate of 1e-3,
θ
generate memory-key embedding for the entire whereeachexamplecontainsapositiveQ-Apair
memorytobuilditsindex. Wethenincorporatethe and 7 hard negative QA-pairs mined through
on-device approximate search algorithm1 to per- BM25 (Robertson and Zaragoza, 2009). The in-
formthenearest-neighborsearchoverthememory batchmemorycontainsatotalof4096entries,we
indextoretrievethetop-KQA-pairs. Formally,we setTop-kof4andupdateoverallthemodules. Af-
proposetomaximizethesameobjectiveasEqua- ter100Kstepsofin-batchpre-training,weswitch
tion 2 but with stop-gradient applied to p(m|X) toglobalpre-trainingwithglobalmemoryretrieval.
term. Inthisstep,themodelwillonlyupdatethe Wedecreasethebatchsizeto32andenlargeTop-K
querymodelf andthedecodermodelg . During to16forlargermemory. Weupdateonlythequery
θ θ
fine-tuning,wefollowthesamerecipeastheglobal encoder and decoder for another 100K steps. Fi-
pre-training. Insteadoffeedingmaskedpassages nally, we set K to 32 to fine-tune on downstream
asinputs,weusequestionswithpseudo[MASK] datasetswithadecreasedlearningrateof5e-4.
tokeninthefrontastheinput.
5.2 Datasets
We evaluate our framework on the three most
4.3 MultihopExtension widely used single-hop open-domain question-
answeringdatasetsandtwomulti-hopopen-domain
For our extension model QAMAT+, since the re- question-answeringdatasets
trievalaugmentationprocesscannotbelearnedla- NQ-Open The NaturalQuestions (Kwiatkowski
tently, i.e. the gradient propagation is blocked in etal.,2019)datasetconsistsofnaturallyoccurring
theconcatenationstep,weaddadditionalsupervi- Googlequeriesandtheiranswers. WefollowLee
siontomaximizethegroundtruthretrievalproba- et al. (2019) to keep questions that have a "short
bilityp(m 1|X)forthefirst-roundretrievalm 1. We answertype". Itconsistsof79168trainingexam-
addsuchretrievalsupervisionobjectivetotheorig- ples,8757devexamples,and3610testexamples.
inalobjectivep(Y|X1),whereX1 istheretrieval-
TriviaQATheTriviaQAdatasetisacollectionof
augmentedinputsasdescribedinsubsection3.5.
triviaquestion-answerpairsthatwerescrapedfrom
theweb(Joshietal.,2017). Weusetheirunfiltered
1https://github.com/google-research/language/ 2https://github.com/google-research/t5x
tree/master/language/mentionmemory 3https://cloud.google.com/tpu/
versiontoevaluateourmodelconsistingof78785 proach"RePAQw/rerank(XXLALBERT)". This
training,8837dev,and113313testexamples. modelhasasimilarnumberofparameterstoQA-
MAT(Large). Withoutusinganexplicitre-ranking
WebQuestionsTheWebQuestiondatasetcontains
procedure,ourmodelperformsslightlyworseon
questionsthatweresampledfromGoogleSuggest
NQbutobtainssignificantgainsonTriviaQAand
API (Berant et al., 2013). The answers are anno-
WebQuestion. EspeciallyonWebQuestion,which
tatedfromFreeBase,thetrainingsetcontains3417
only contains 3K training examples, RePAQ per-
examples,thedevsetcontains361examples,and
formssignificantlyworsethantheotherdatasetsbe-
thetestsetcontains2032examples.
causeitrequiresahighvolumeofexamplestoup-
HotpotQATheHotpotQAdatasetcontainsques-
datetheretrieverfromscratch. Withourproposed
tionsgeneratedbyhumanworkersbyreadingtwo
pre-trainingstrategy,QAMATcaninitializefroma
passages (Yang et al., 2018). The questions are
muchbettercheckpointtodecreasethesamplecom-
designedtorequiremultiplehopsandincludeboth
plexity,yieldinganabsolute6%EMimprovement.
bridge questions and comparison questions. The
Additionally,withoutanyfine-tuning,wedemon-
trainingsetcontainsatotalof90564examples,the
strate that our model already achieves promising
dev-setcontains7405examplesforevaluation.
resultsacrossthesedatasets, nearlymatchingthe
MusiqueTheMusiquedatasetcontainsquestions performanceof"RePAQw/orerank"4.
createdbycomposingmultiplequestionsfromex-
Comparison with retrieve-and-read models In
istingsingle-hopquestionsandwasconstructedto
comparisontothisclassofmodel,QAMATroughly
containlessbiasandartifacts(Trivedietal.,2021).
matches the performance of RAG, though it still
In our experiments, we consider only the subset
lags behind the SoTA model FiD. However, FiD
of 2-hop questions, resulting in a training set of
requires reading 100 passages, i.e. 20K tokens
14376 examples and a dev set of 1252 examples
while our best model works more efficiently by
for evaluation. While the dataset was originally
only reading top-32 QA-pairs, i.e. 1.2K tokens.
designed as a distractor setting (given a question
Toinvestigatethespeeddifferencebetweenthese
andasmallnumberofpassages,returntheanswer),
approaches, we compared their inference speeds
weinsteadconsideranopen-domainsetting.
using the same hardware (32 Google Cloud v3
TPUs). We found that QAMAT can answer 240
5.3 Baselines
Qs/sec, while FiD only answers 50 Qs/sec, a 5x
Wecompareourmodelwithbaselinesfromthefol- inferencetimespeedupoverFiD.
lowingcategories. 1)CBQAlargelanguagemodels
(T5XXL),whichdirectlyoutputsananswerwith- 5.5 Multi-hopResults
out retrieval. 2) Entity/KG memory-augmented
SincethedocumentcorporasourceofHotpotQA
models that use memory attention to incorporate
and Musique are different from single-hop QA
entity-levelfeaturesintolanguagemodels(Entities-
datasets, we adopt question generation model
as-Experts(EaE)(Févryetal.,2020),Fact-Injected
trainedonSQuAD2.0(Rajpurkaretal.,2018)to
LanguageModel(FilM)(Vergaetal.,2021),Men-
generatequestionsforthesetwodatasets. Tocreate
tionMemory (TOME) (de Jong et al., 2022)). 3)
the document corpora, we gather all of the pro-
Retrieve-and-readmodel,whichretrievespassages
videdpositiveandnegativedocuments,obtaining
topasstoareadermodelwhichpredictstheanswer.
500K passages for HotpotQA and 85K passages
4)QA-retrievalmodels,whichtrainaretrieverto
for Musique. We then use the trained generation
collectQA-pairsfromalargedatastore,andthen
models to populate 3M QA pairs for HotpotQA
rerank these QA-pairs (top 50-100) with original
and500KQApairsforMusique. TheseQApairs
querywithcross-attention. Thehighest-rankedan-
arethenusedasthememorysourceforQAMAT+,
swerisreturnedasthefinalanswer.
simulatinga(slightlysmaller)open-domainsetup.
WhentrainingQAMAT+onMusique,weinitialize
5.4 Single-HopResults
fromHotpotQA’sin-Batchpre-trainedcheckpoint,
Our results are summarized in Table 2 which re- whichcanbring5-7%F1improvement.
portsexact-match(EM)score.
4It’sworthnotingthatthequestiongenerationmodelsare
ComparisonwithRePAQOurmaincomparison
trainedusingsomeofthesedatasets’trainingdatasothisis
is with the previous best QA-retrieval-based ap- nottruly“zero-shot”performance.
Model(TestSet) NQ TQA WQ Top-K 1 10 20 30
T5-3B(Robertsetal.,2020) 30.4 35.1 33.6 NQ-Recall@K 0.41 0.58 0.62 0.64
T5-11B(Robertsetal.,2020) 32.6 42.3 37.2 TriviaQA-Recll@K 0.46 0.66 0.70 0.72
EaE(Févryetal.,2020) - 43.2 -
NQ-EM@K 0.39 0.42 0.44 0.44
FILM(Vergaetal.,2021) - 29.1 -
TriviaQA-EM@K 0.45 0.51 0.53 0.53
TOME-2(deJongetal.,2022) - 53.4 -
DensePhrases(Leeetal.,2021) 40.9 50.7 -
Table4: TheretrievalrecallandEMscoreofdifferent
REALM(Guuetal.,2020) 40.4 55.8 40.7
retrievalnumbersontestsets.
DPR(Karpukhinetal.,2020) 41.5 57.9 42.4
RAG-Seq(Lewisetal.,2020) 44.5 56.8 45.2
FiD(IzacardandGrave,2021) 48.2 65.0 -
Pre-trainingStages NQ TQA WQ
RePAQ(Lewisetal.,2021) 41.2 38.8 29.4†
OnlyIn-Batch 42.1 48.2 39.7
RePAQ+Rerank(Lewisetal.,2021) 47.6 50.7 37.6†
OnlyGlobal 26.0 28.9 26.1
QAMATZero-Shot(Base) 37.9 34.1 25.9 In-Batch→Global 44.5 53.2 43.0
QAMATZero-Shot(Large) 39.8 40.0 25.1
QAMATFine-tuned(Base) 44.5 53.2 43.0
Table5:DownstreamEMperformanceofmodelswhen
QAMATFine-tuned(Large) 45.5 54.8 43.6
pre-trainedusingin-batch,global,orbothstages.
Table 2: The main experimental results on single-hop
lecttherecallandfinalQAperformance. There-
question answering datasets (NQ=NaturalQuestions,
sultsareshowninTable4. Weobservethateven
TQA=TriviaQA, WQ=WebQuestions), † means Best-
effortreplicationusingourownimplementation. thoughretrievalrecallcontinuestoincreasebeyond
K > 20,theEMscoresaturatesmuchearlier. Fu-
ture research could improve performance further
Model(DevSetF1Score) HPQ MusQ
bydevelopingdecoderstomoreaccuratelyexploit
T5-3B(Robertsetal.,2020) 27.8 7.5
T5-11B(Robertsetal.,2020) 30.2 9.0 theselargerretrievalssets.
MDR+T5-Decoder(Xiongetal.,2020) 62.6 26.8 ImportanceofTwo-StagePre-trainingWenext
RePAQ(Lewisetal.,2021)† 47.8 18.6
analyze the importance of the two-stage pre-
QAMAT 42.0 16.7 trainingfromsection4byremovingeitherthein-
QAMAT+ 57.6 29.8
batchorglobalstage. FromourresultsshowninTa-
ble5, wecanseethatusingin-batchpre-training
Table 3: The main experimental results on MultiHop
QA datasets with QAMAT and QAMAT+, † means aloneleadstoadegradationinperformancewhen
Best-effortreplicationusingourownimplementation. comparedtothetwo-stageapproach. Thisislikely
becausethemodelisneverexposedtothefullset
ofhardnegativeswhichwillbeencounteredwhen
In Table 3, we show that QAMAT+ achieves
performingretrievalovertheglobalmemory. On
promisingresultsonbothmulti-hopdatasets,out-
theotherhand,ifwedirectlypre-traintheglobal-
performingT5-CBQAandRePAQbyalargemar-
memorymodelwithoutanyin-batchinitialization,
gin. Additionally, QAMAT+ performs consider-
theretrieverperformanceisnearlyrandomandthe
ably better than the single-hop QAMAT, demon-
decoderconsequentlylearnstoignoretheretrieval
strating the effectiveness of performing multi-
andsimplymemorizequestion-answerpairs.
roundretrieval. ThoughQAMAT+stilllagsbehind
thedocument-basedmodel(MDR+T5Decoder)on
6 Conclusion
HotpotQA,itsurpassesitonthemorechallenging
Musique dataset. These encouraging results sug- Inthispaper,weproposeamoreaccurateandeffi-
gestthepotentialforQAMAT+toperformcompo- cientarchitecturetoutilizeQA-pairsasrepresen-
sitionalreasoningovermultipleQA-pairs,which tation units of knowledge. Our proposed model
greatlyincreasesthecoverageofQAdatastoreto QAMAToutperformsRePAQsignificantly,while
covermorecompositefactualinformation. leveraging our less expensive training procedure.
Furthermore, we show how a QA-backed model
5.6 AblationStudies
canperformcompositionalreasoningandaddress
Number of Retrievals To understand the proper- morecomplexqueries. Inthefuture,wehopetofur-
tiesofourmodelbetter,wefirstinvestigatetheim- therclosethegapwithstate-of-the-artdocument-
pactofthenumberofretrievals,K,onthemodel’s basedretrieve-and-readmodelsandextendthisap-
performance. WegraduallyincreasetheK tocol- proachtoabroadersetoftasks.
Limitations George van den Driessche, Jean-Baptiste Lespiau,
Bogdan Damoc, Aidan Clark, et al. 2021. Improv-
Our approach has several limitations: 1) we use ing language models by retrieving from trillions of
generated question-answer pairs as a knowledge tokens. arXivpreprintarXiv:2112.04426.
base, which are extracted from web documents.
DanqiChen, AdamFisch, JasonWeston, andAntoine
Inordertomaintainhighqualityandfaithfulness,
Bordes. 2017a. Reading wikipedia to answer open-
thequestiongenerationpipelineneedstobewell
domain questions. In Proceedings of the 55th An-
trainedwithasufficientamountofcleandata. Such nual Meeting of the Association for Computational
conditionsmightnotholdforotherdomainsoutside Linguistics (Volume 1: Long Papers), pages 1870–
1879.
ofWikipedialikebiomedicaltext,thusthegeneral
QA-as-Knowledge-Baseconceptcouldrequiread-
DanqiChen, AdamFisch, JasonWeston, andAntoine
ditionalinnovationstoextendtootherareas. 2)Our Bordes.2017b. ReadingWikipediatoansweropen-
latentretrievallearningrequiresquasipaireddata domain questions. In Proceedings of the 55th An-
nual Meeting of the Association for Computational
tolearnthealignmentbetweenthequeryandmem-
Linguistics (Volume 1: Long Papers), pages 1870–
ory. Thisishardtosatisfyinsomedomainswith
1879,Vancouver,Canada.AssociationforComputa-
noisierdataoronlyaveryweakalignmentbetween tionalLinguistics.
a query and the memory. 3) Our model requires
mined intermediate retrieval signals to train QA- MichieldeJong,YuryZemlyanskiy,NicholasFitzGer-
ald, Fei Sha, and William Cohen. 2022. Mention
MAT+, whichcurrentlyreliesonlexical-overlap-
memory:incorporatingtextualknowledgeintotrans-
basedheuristics. Inothercases,thismaynotbesuf-
formers through entity mention attention. Interna-
ficientandinsteadmightrequireamoreprincipled tionalConferenceonLearningRepresentations.
designtominebetterintermediatesupervision.
Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachan-
EthicalStatement dran, Graham Neubig, Ruslan Salakhutdinov, and
William W Cohen. 2019. Differentiable reasoning
Ourworkencouragesthemodeltogroundonthe overavirtualknowledgebase. InInternationalCon-
ferenceonLearningRepresentations.
existing knowledge populated from large textual
collections. Webelieveitisareasonabletowards
Matan Eyal, Tal Baumel, and Michael Elhadad. 2019.
building more trustworthy and more robust ma-
Questionansweringasanautomaticevaluationmet-
chinelearningmodels. Havingbetterattributions ric for news article summarization. In Proceedings
toknowledgesourcecouldhelphumansbetterun- ofNAACL-HLT,pages3938–3948.
derstandthemodel’srationalefordecisionmaking.
ThibaultFévry,LivioBaldiniSoares,NicholasFitzger-
However, we do admit that the question genera-
ald,EunsolChoi,andTomKwiatkowski.2020. En-
tion models used to populate the QA knowledge tities as experts: Sparse memory access with entity
basecouldpotentiallyexacerbatethebiasesalready supervision. InProceedingsofthe2020Conference
present in the original Wikipedia data. We will onEmpiricalMethodsinNaturalLanguageProcess-
ing(EMNLP),pages4937–4951.
keepworkingonthisdirectiontominimizeitspo-
tentialnegativeimpacts.
Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng,
DavidSimcha,FelixChern,andSanjivKumar.2020.
Accelerating large-scale inference with anisotropic
References vectorquantization. InInternationalConferenceon
MachineLearning,pages3887–3896.PMLR.
Chris Alberti, Daniel Andor, Emily Pitler, Jacob De-
vlin, and Michael Collins. 2019. Synthetic qa cor-
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pa-
poragenerationwithroundtripconsistency. InPro-
supat, and Mingwei Chang. 2020. Retrieval aug-
ceedings of the 57th Annual Meeting of the Asso-
mented language model pre-training. In Proceed-
ciation for Computational Linguistics, pages 6168–
ings of the 37th International Conference on Ma-
6173.
chine Learning, volume 119 of Proceedings of Ma-
chineLearningResearch,pages3929–3938.PMLR.
JonathanBerant,AndrewChou,RoyFrostig,andPercy
Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In Proceedings of the 2013 GautierIzacardandÉdouardGrave.2021. Leveraging
conference on empirical methods in natural lan- passage retrieval with generative models for open
guageprocessing,pages1533–1544. domain question answering. In Proceedings of the
16thConferenceoftheEuropeanChapteroftheAs-
Sebastian Borgeaud, Arthur Mensch, Jordan Hoff- sociation for Computational Linguistics: Main Vol-
mann,TrevorCai,ElizaRutherford,KatieMillican, ume,pages874–880.
Robin Jia, Mike Lewis, and Luke Zettlemoyer. 2021. Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale
Questionansweringinfusedpre-trainingofgeneral- Minervini,HeinrichKüttler,AleksandraPiktus,Pon-
purpose contextualized representations. arXiv tusStenetorp, andSebastianRiedel.2021. Paq: 65
preprintarXiv:2106.08190. millionprobably-askedquestionsandwhatyoucan
do with them. Transactions of the Association for
Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. ComputationalLinguistics,9:1098–1115.
Billion-scale similarity search with GPUs. IEEE
TransactionsonBigData,7(3):535–547. SewonMin,JordanBoyd-Graber,ChrisAlberti,Danqi
Chen, Eunsol Choi, Michael Collins, Kelvin Guu,
Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Hannaneh Hajishirzi, Kenton Lee, Jennimaria Palo-
Zettlemoyer.2017. Triviaqa: Alargescaledistantly maki, et al. 2021. Neurips 2020 efficientqa com-
supervisedchallengedatasetforreadingcomprehen- petition: Systems, analyses and lessons learned.
sion. InProceedingsofthe55thAnnualMeetingof In NeurIPS 2020 Competition and Demonstration
the Association for Computational Linguistics (Vol- Track,pages86–111.PMLR.
ume1: LongPapers),pages1601–1611.
Rodrigo Nogueira, Wei Yang, Jimmy Lin, and
VladimirKarpukhin,BarlasOguz,SewonMin,Patrick
Kyunghyun Cho. 2019. Document expansion by
Lewis,LedellWu,SergeyEdunov,DanqiChen,and
queryprediction. arXivpreprintarXiv:1904.08375.
Wen-tau Yih. 2020. Dense passage retrieval for
open-domainquestionanswering. InProceedingsof
Barlas Og˘uz, Kushal Lakhotia, Anchit Gupta, Patrick
the 2020 Conference on Empirical Methods in Nat-
Lewis, Vladimir Karpukhin, Aleksandra Piktus,
ural Language Processing (EMNLP), pages 6769–
Xilun Chen, Sebastian Riedel, Wen-tau Yih, Sonal
6781.
Gupta, et al. 2021. Domain-matched pre-
training tasks for dense retrieval. arXiv preprint
Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke
arXiv:2107.13602.
Zettlemoyer,andMikeLewis.2019. Generalization
through memorization: Nearest neighbor language
Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-
models. In International Conference on Learning
YenKan, andWilliamYangWang.2021. Unsuper-
Representations.
visedmulti-hopquestionansweringbyquestiongen-
eration. In Proceedings of the 2021 Conference of
Omar Khattab and Matei Zaharia. 2020. Colbert: Ef-
the North American Chapter of the Association for
ficient and effective passage search via contextual-
ComputationalLinguistics: HumanLanguageTech-
ized late interaction over bert. In Proceedings of
nologies,pages5866–5880.
the 43rd International ACM SIGIR conference on
research and development in Information Retrieval,
ColinRaffel,NoamShazeer,AdamRoberts,Katherine
pages39–48.
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
WeiLi, andPeterJLiu.2019. Exploringthelimits
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
of transfer learning with a unified text-to-text trans-
field, MichaelCollins, AnkurParikh, ChrisAlberti,
former. arXivpreprintarXiv:1910.10683.
Danielle Epstein, Illia Polosukhin, Jacob Devlin,
KentonLee,etal.2019. Naturalquestions: abench-
ColinRaffel,NoamShazeer,AdamRoberts,Katherine
markforquestionansweringresearch. Transactions
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
of the Association for Computational Linguistics,
Wei Li, and Peter J Liu. 2020. Exploring the lim-
7:453–466.
its of transfer learning with a unified text-to-text
Jinhyuk Lee, Mujeen Sung, Jaewoo Kang, and Danqi transformer. JournalofMachineLearningResearch,
Chen. 2021. Learning dense representations of 21:1–67.
phrasesatscale. InProceedingsofthe59thAnnual
Meeting of the Association for Computational Lin- Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
guisticsandthe11thInternationalJointConference Know what you don’t know: Unanswerable ques-
on Natural Language Processing (Volume 1: Long tions for squad. In Proceedings of the 56th Annual
Papers),pages6634–6647. Meeting of the Association for Computational Lin-
guistics(Volume2: ShortPapers),pages784–789.
KentonLee,Ming-WeiChang,andKristinaToutanova.
2019. Latent retrieval for weakly supervised open PranavRajpurkar,JianZhang,KonstantinLopyrev,and
domain question answering. In Proceedings of the Percy Liang. 2016. Squad: 100,000+ questions for
57thAnnualMeetingoftheAssociationforCompu- machine comprehension of text. In Proceedings of
tationalLinguistics,pages6086–6096. the2016ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing,pages2383–2392.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Hein- AdamRoberts,ColinRaffel,andNoamShazeer.2020.
rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock- Howmuchknowledgecanyoupackintotheparam-
täschel,etal.2020. Retrieval-augmentedgeneration eters of a language model? In Proceedings of the
forknowledge-intensivenlptasks. AdvancesinNeu- 2020 Conference on Empirical Methods in Natural
ralInformationProcessingSystems,33:9459–9474. LanguageProcessing(EMNLP),pages5418–5426.
Stephen Robertson and Hugo Zaragoza. 2009. The In Proceedings of the 2018 Conference on Empiri-
probabilistic relevance framework: BM25 and be- calMethodsinNaturalLanguageProcessing,pages
yond. NowPublishersInc. 2369–2380.
Devendra Singh, Siva Reddy, Will Hamilton, Chris Wen-tauYih,MatthewRichardson,ChristopherMeek,
Dyer, and Dani Yogatama. 2021. End-to-end train- Ming-WeiChang,andJinaSuh.2016. Thevalueof
ingofmulti-documentreaderandretrieverforopen- semanticparselabelingforknowledgebasequestion
domainquestionanswering. AdvancesinNeuralIn- answering. InProceedingsofthe54thAnnualMeet-
formationProcessingSystems,34. ingoftheAssociationforComputationalLinguistics
(Volume2: ShortPapers),pages201–206.
Haitian Sun, Pat Verga, Bhuwan Dhingra, Ruslan
Salakhutdinov, and William W Cohen. 2021. Rea- Qingyu Zhou, Nan Yang, Furu Wei, Chuanqi Tan,
soningovervirtualknowledgebaseswithopenpred- Hangbo Bao, and Ming Zhou. 2017. Neural ques-
icate relations. In International Conference on Ma- tion generation from text: A preliminary study. In
chineLearning,pages9966–9977.PMLR. National CCF Conference on Natural Language
ProcessingandChineseComputing,pages662–671.
Alon Talmor and Jonathan Berant. 2018. The web as Springer.
aknowledge-baseforansweringcomplexquestions.
InProceedingsofthe2018ConferenceoftheNorth
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Volume1(LongPapers),pages641–651.
Nandan Thakur, Nils Reimers, Andreas Rücklé, Ab-
hishek Srivastava, and Iryna Gurevych. 2021. Beir:
A heterogeneous benchmark for zero-shot evalua-
tion of information retrieval models. In Thirty-fifth
Conference on Neural Information Processing Sys-
temsDatasetsandBenchmarksTrack(Round2).
Harsh Trivedi, Niranjan Balasubramanian, Tushar
Khot,andAshishSabharwal.2021. Musique:Multi-
hop questions via single-hop question composition.
arXivpreprintarXiv:2108.00573.
Pat Verga, Haitian Sun, Livio Baldini Soares, and
WilliamWestonCohen.2021. Adaptableandinter-
pretable neural memory over symbolic knowledge.
InProceedingsofNAACL-HLT,pages3678–3691.
Alex Wang, Kyunghyun Cho, and Mike Lewis. 2020.
Askingandansweringquestionstoevaluatethefac-
tual consistency of summaries. In Proceedings of
the58thAnnualMeetingoftheAssociationforCom-
putationalLinguistics,pages5008–5020.
JinfengXiao,LidanWang,FranckDernoncourt,Trung
Bui,TongSun,andJiaweiHan.2021. Open-domain
question answering with pre-constructed question
spaces. In Proceedings of the 2021 Conference of
the North American Chapter of the Association for
ComputationalLinguistics: StudentResearchWork-
shop,pages61–67.
WenhanXiong,XiangLi,SriniIyer,JingfeiDu,Patrick
Lewis, William Yang Wang, Yashar Mehdad, Scott
Yih,SebastianRiedel,DouweKiela,etal.2020. An-
sweringcomplexopen-domainquestionswithmulti-
hopdenseretrieval. InInternationalConferenceon
LearningRepresentations.
ZhilinYang,PengQi,SaizhengZhang,YoshuaBengio,
WilliamCohen, RuslanSalakhutdinov, andChristo-
pher D Manning. 2018. Hotpotqa: A dataset for
diverse, explainable multi-hop question answering.
A QuestionAnswerPairsasKnowledge jpurkaretal.,2016)couldbecontextualizedoram-
Base biguous,whichcouldleadtoambiguityproblems
to hurt the retrieval performance. Therefore, we
WecanseeQA-pairsasavirtualknowledgegraph,
add question filtering to select the most accurate
where the question template defines the relation,
QApairs.
the topic entity in the question defines the head
entitynode,andtheanswerdenotesthetailentity. Question Filtering For the question filtering
AtypicalexampleisgiveninFigure5,suchcom- model,wetakethedocument+generatedquestion
positionalitymakestheQA-pairmorecontrollable togenerateananswer. Wecomparethepredicted
andeasytoreasonoverthandocuments. answervs. theoriginalanswertoseeiftheymatch
eachother. Ifnot,theQA-pairwillbefilteredbased
onsuchinconsistency. Weuseareadingcompre-
hensionmodeltrainedwithSQuADtopredictthe
answer. Thepredictedanswerbasedonthedocu-
mentwillmatchwiththeoriginalQA-pairtodecide
its consistency. Such an option runs much faster,
providingmuchhigherrecallbutlowerprecision
compared to the open-domain FiD filtering used
in(Lewisetal.,2021).
We visualize our question generation pipeline
mentionedaboveinFigure6.
Figure 5: QA pairs can be seen as virtual knowledge
base, where the question can represent complex rela-
tionsconnectingsubjectandanswer.
B QuestionGeneration
Here, we use existing SQuAD datasets’ <Q, A,
Document>triples(Rajpurkaretal.,2016)totrain
Figure 6: Question generation pipeline: Answers are
answerextraction,questiongenerationmodel.
extracted from passages and then questions are gener-
AnswerExtraction Specifically,ouranswerex- ated conditioned on that contextualized answer. This
tractionmodeltakesadocumentastheinputand procedure is used to generate both our model’s QA
memoryandourpre-trainingdata.
trainsanencoder-decodermodeltogenerateapo-
tentialanswer. Weusebeamsearchoverthetrained C AblationStudy
model to find the highest-likely answers in the
Weexperimentwithtwovariantsofmemorytosee
givendocument. Inourexperiment,theanswerex-
theirperformancedifference.
tractionmodelistrainedwiththeSQuADdataset,
wherethedocumentisgivenastheinput,andthe C.1 PAQmemory
answerspansarethepredictiontargets.
ThefirstversionisthestandardPAQcorpus(Lewis
Question Generation For the question genera- et al., 2021) containing 65M QA pairs, where
tion model, we take the SQuAD dataset and use theseQA-pairsaregeneratedbymodelstrainedon
document+extractedanswerastheinputtogen- NQ(Kwiatkowskietal.,2019)andfilteredthrough
eratequestionsastheoutputs. Thisstepisalsoac- FiDmodel(IzacardandGrave,2021)alsotrained
complishedbyanencoder-decodermodel. whichis onNQ(Kwiatkowskietal.,2019). Thismemory
mainlypurposedforreadingcomprehensionprob- is highly precise due to ODQA-filtering process,
lems,wheretheannotatedquestionsarehighlycor- however,itonlycoversinformationfrom9Moutof
relatedwiththedocumentcontainingveryfewhal- the20MpassageblocksusedinDPR(Karpukhin
lucinations. However,thequestionsinSQuAD(Ra- etal.,2020).
Our memory contains 30M PAQ corpus being
de-duplicated,i.e. onlyonequestioncorresponds
to an answer span. We generate 30M additional
QA-pairs based on the left-out 10M documents
fromPAQ(Lewisetal.,2021)andaddthesecom-
plementaryQA-pairstoformour60Mmemoryto
increasethecoverage. However,sinceourfiltering
procedureisbasedonreadingcomprehension,the
precision of QA-pairs is lower than the original
PAQmemory.
Figure 7: The impact of memory size on downstream
QAEMperformance.
Memory NQ TriviaQA WebQuestions
PAQ65M 44.7 48.0 39.4 SizeofMemory Finally,welookathowbigof
Ours60M 44.5 53.2 43.0
memoryweneedtoreachoptimaldownstreamac-
curacyandhowthemodelbehaveswithasmaller
Table 6: Impact of different memory over the down-
streamQAdatasetperformance. memory. AsisshowninFigure7,havingasmall
memoryoflessthan5Mentriesdoesnotimprove
As can be seen, from Table 6, using the over a model with no memory at all. Due to the
mostprecisebutlow-coveragePAQmemoryfrom lackofcoverage,themodeldoesnotreceiveause-
PAQ(Lewisetal.,2021)yieldstheworseresults ful signal from the retrieval and is subsequently
onTriviaQAandWebQuestions. Afteraddingan not incentivized to utilize those retrievals when
additional30MPAQstothememorygeneratedby making a prediction. However, once the size of
ourpipeline,weareabletoachieve4-5%improve- thememoryincreasesbeyond15Mweobservea
mentsonthesetwodatasetswhilestillmaintaining steepincreaseinthefinalperformance,indicating
NQ’sperformance. thatthemodelisgraduallylearningtoincorporate
retrievedinformationretrievalstoassistprediction.
C.2 SizeofPre-trainingCorpus
D MultiHopQATraining
Next, weinvestigatetheimpactofthesizeofthe
pre-training corpus. As a baseline, we repurpose
Inordertotrainthemulti-hopQAmodel,weneed
the aligned query-passage corpus used to train
tohaveintermediatesupervisionforthequeryaug-
DPR (Karpukhin et al., 2020) which we adapt to
mentation process. Here we use a string-based
oursettingbysimplyreversingthepairs(120Kpas-
matchtoderivewhatarethemostpossibleinterme-
sage->questionretrieval). Additionally,wevary
diatequestionsfromacollectionofpre-generated
thesizeofgeneratedpre-trainingcorpus(from1M
QA pairs. We depict the mining process as Fig-
to20Minstances)toseeitsimpactonthemodel’s
ure8.
finaldownstreamperformance. FromTable7,we
canseethatthesmaller-sizedpre-trainingcorpus
can drastically reduce the model’s performance,
withuptoa5%dropseenonTriviaQA.
Pre-trainExamples NQ TQA WQ
120K 42.5 48.2 39.7
1M 42.8 48.8 40.2
5M 43.8 51.5 41.7
10M 44.3 52.1 42.5
20M 44.5 53.2 43.0
Table 7: Impact of pre-training corpus size on final
downstream EM performance. The upper portion is
pre-trainedusingtheDPR-reversecorpusdescribedin
subsection5.6andthelowerportionusessubsetsofour
generatedpre-trainingcorpus(subsection4.1)
Figure 8: We first find the final question based on answer string matching with the pre-generated question, and
thenbaseonthattotracebacktheintermediatequestion.
