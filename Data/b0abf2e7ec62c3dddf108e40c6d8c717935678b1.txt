SpeechandLanguageTechnologyin
ISCAArchive Education(SLaTE2009)
WroxallAbbeyEstate,Warwickshire,UK
http://www.isca-speech.org/archive
September3-5,2009
Detecting Prosody Improvement in Oral Rereading
Minh Duong Jack Mostow
Project LISTEN, School of Computer Science
Carnegie Mellon University, Pittsburgh, PA, USA
mnduong@cs.cmu.edu mostow@cs.cmu.edu
narrations. The Reading Tutor displays text incrementally,
Abstract
adding a sentence at a time. It uses an automatic speech
A reading tutor that listens to children read aloud should be recognizer (ASR) [7] to listen to the child read the sentence
able to detect fluency growth – not only in oral reading rate, aloud, to track the child‟s position in the text to detect
but also in prosody. How sensitive can such detection be? deviations from it, and to identify the start and end points of
We present an approach to detecting improved oral reading each word and silence in the recorded oral reading [8]. It
prosody in rereading a given text. We evaluate our method on responds with spoken and graphical feedback to hesitations
data from 133 students ages 7-10 who used Project LISTEN‟s and miscues detected by the ASR, as well as the child‟s
Reading Tutor. We compare the sensitivity of our extracted requests for help by clicking on hard words. The spoken
features in detecting improvements. We use them to compare feedback uses a time-aligned recording of each sentence by an
the magnitude of recency and learning effects. We find that adult narrator.
features computed by correlating the student‟s prosodic
2.1. Data set
contours with those of an adult narration of the same text are
generally not as sensitive to gains as features based solely on The data for this paper came from children in grades 2-4 (ages
the student‟s speech. We also find that rereadings on the same 7-10) who used the Reading Tutor during the 2005-2006
day show greater improvement than those on later days: school year. They read a total of 77,693 sentences, including
statistically reliable recency effects are almost twice as strong 4,901 distinct sentences that they reread a total of 29,794
as learning effects for the same features. times, averaging 1.66 rereadings per reread sentence, with a
median of 1. Our 164 students ranged from 1 to 1891 data
1. Introduction
points (pairs of successive readings of sentences). To reduce
the number of outliers, we excluded students with fewer than 5
An important task of any intelligent tutor is to detect
data points, which left us with 133 students.
improvement in the skills it is trying to help students learn. In
the case of oral reading fluency, it is important to distinguish
3. Features of oral reading prosody
between reading a new text and rereading a text the student
has seen before, whether earlier the same day or less recently. To measure students‟ oral reading prosody, we extract various
The ultimate goal of fluency practice and instruction is skilled features from each sentence of their recorded speech. We use
reading of new text. However, repeated reading of the same the same features that were explored in previous work [5].
text is a popular and effective form of fluency practice [1-4], They are of two types: raw features and correlational features.
thanks in part to the presumed motivational value of giving Raw features are based solely on the student‟s speech.
students feedback on their improvement in reading speed. They include average word production time, average inter-
We recently [5] developed a method to assess oral reading word latency, and average word reading time, which is the
prosody automatically based on several features, and evaluated sum of production and latency. Inter-word latency (or simply
it on children‟s reading of new text in Project LISTEN‟s „latency‟) is the time that elapses between reading successive
Reading Tutor, both by comparing to human scoring, and by text words, including “false starts, sounding out, repetitions,
predicting test scores and gains in fluency and comprehension. and other insertions, whether spoken or silent” [9, 10]. We
Here we apply the same assessment method to rereading: normalize these time features by word length, yielding three
Section 2 summarizes relevant aspects of the Reading Tutor. more features. The last raw feature is pause frequency, which
Section 3 describes prosodic features of oral reading. measures how often a student pauses for more than 10 ms
Section 4 measures the relative sensitivity of those features. before a word, or the Reading Tutor‟s ASR rejects a word as
Section 5 compares the size of recency and learning effects. read incorrectly.
Section 6 tests whether any features are sensitive enough for Correlational features are inspired by previous analyses of
individual students‟ improvements to be statistically reliable. children‟s oral reading prosody by Schwanenflugel and
Section 7 outlines contributions, limitations, and future work. colleagues, based on the insight that the more expressive a
child‟s reading of a text, the more its prosody tends to
2. Project LISTEN’s Reading Tutor
resemble fluent adult reading of the same text [11-13]. Each
correlational feature is computed as the Pearson correlation
Our data consist of assisted oral reading recorded by Project
coefficient between the prosodic contour of a student and that
LISTEN‟s Reading Tutor, which listens to children read
of the adult narration. We compute correlations for word
aloud, and helps them learn to read [6]. The Reading Tutor
production time, latency, and word reading time (both
and the child take turns choosing what to read from a
unnormalized and normalized), as well as the mean
collection of several hundred stories with recorded adult
fundamental frequency and intensity for each word. F0 and
SpeechandLanguageTechnologyinEducation(SLaTE2009) 105
32-9002.ETaLS/73412.01
intensity are computed using the Praat pitch tracker [14]. the mean of this sample divided by its standard deviation [15].
Finally, we also include in this group the sentence‟s pitch We quantified the sensitivity of each feature as the median of
variation, computed as the standard deviation of the words‟ these per-student individual effect sizes.
fundamental frequencies. It is not based on any correlation, The “Any day” column in Table 2 lists the median effect
but shares a common characteristic with all other correlational size of each feature, in decreasing order. (Section 5 explains
features: a higher value indicates more fluent, expressive the “Same day” and “Later day” columns.) From Table 2, we
reading. observe that all raw features have larger effect sizes than
correlational features. Why? Correlational features are
3.1. Descriptive statistics computed by correlation between a student‟s prosodic
contours and those of the adult narrations of the same
Here we report some descriptive statistics about the original
sentences. Their values, therefore, depend not only on the
data set (before excluding outliers). To analyze improvement
student‟s speech but also on the particular adult‟s, a source of
in rereading the same text, we considered only sentences the
additional variability and measurement noise. Correlational
student saw more than once. For each such sentence, we
features are useful for assessing the quality of students‟
computed the gain between successive values of each feature
prosody, since better readers read more like adults [13]. But
as the decrease from the prior value of a raw feature or the
apparently raw features are more sensitive to its improvement.
increase from the prior value of a correlational feature, so that
positive gains all represent improvement. For each feature, we Table 2: Median effect sizes for different features
computed each student‟s mean feature value, mean gain, and
relative gain (mean gain / mean prior value). Table 1 shows
Any Same Later
the medians of these means. We use medians to counteract ID Feature
day day day
distortion of means by outliers or small, noisy samples.
1 avg_duration 0.138 0.218 0.130
(Using medians at the individual level would have lost too
2 avg_norm_duration 0.133 0.222 0.138
much information about features where over half of the values
3 avg_norm_production 0.127 0.232 0.117
are the same.)
4 pause_frequency 0.101 0.146 0.095
Table 1: Descriptive statistics of features 5 avg_production 0.097 0.187 0.084
6 avg_norm_latency 0.084 0.133 0.083
7 avg_latency 0.077 0.124 0.086
Median Median Median
8 correl_duration 0.050 0.034 0.061
Feature of mean of mean relative
9 correl_production 0.049 0.045 0.046
value gain gain (%)
10 correl_latency 0.034 0.042 0.036
avg_duration (s) 0.552 0.030 5.2
11 correl_norm_latency 0.034 0.061 0.027
avg_norm_duration (s) 0.137 0.007 5.6
12 correl_norm_duration 0.023 0.018 0.024
avg_norm_production (s) 0.112 0.005 4.4
13 pitch_variation 0.019 -0.015 0.012
pause_frequency (%) 27.2 2.2 10.5
14 correl_norm_production 0.015 -0.034 0.021
avg_production (s) 0.467 0.017 3.4
15 correl_pitch -0.001 -0.001 -0.011
avg_norm_latency (s) 0.026 0.002 12.4
16 correl_intensity -0.016 -0.009 -0.015
avg_latency (s) 0.094 0.010 12.9
correl_duration 0.496 0.022 3.2
correl_production 0.619 0.020 3.1
correl_latency 0.430 0.012 3.0
correl_norm_latency 0.354 0.019 3.5
correl_norm_duration 0.284 0.014 1.6
pitch_variation (Hz) 40.451 0.604 1.6
correl_norm_production 0.342 0.010 1.4
correl_pitch 0.134 -0.001 -10.2
correl_intensity 0.238 -0.003 -5.9
As Table 1 shows, words took a median of 0.094 seconds
latency plus 0.467 seconds to say the word, totaling 0.552
seconds, or 0.137 seconds per letter. The pause_frequency of
27.2% reflects disfluent reading. The features with the highest
relative gains (> 10%) were avg_latency, avg_norm_latency,
and pause_frequency, indicating successively fewer and
shorter pauses as fluency increased. Children‟s production,
duration, and latency correlated the most strongly with the
adult narrators, and pitch and intensity the least.
Figure 1: Confidence intervals of median effect sizes
4. Compare sensitivity of features
To analyze the reliability of the median effect sizes, we
Here we present comparisons between features. For each
computed confidence intervals around them, using the
feature and student, we had a sample of change values. We
bootstrapping method [16]. Assuming normality among the
computed Cohen‟s d effect size for each individual student as
medians of the 100 samples that we generated with R‟s
SpeechandLanguageTechnologyinEducation(SLaTE2009) 106
boot::boot function, we computed a 95% confidence interval We italicize percentages that fell below 5% to indicate that
around each feature‟s median. (Without the normality they are likely due to chance, because in any random set of
assumption, some of the confidence intervals aren‟t quite as samples, the expected number of samples having p-value
tight.) Figure 1 shows the resulting confidence intervals. It smaller than 0.05 is 5%. Table 3 lists features in the same
shows, for example, that the median effect size (0.138) for order as in Table 2, from largest to smallest median effect size.
avg_duration (feature 1 in Table 2) is reliably greater than for As Table 3 shows, the raw features, which were shown to have
features 8-16. Improvement in this sentence feature greater effect sizes in Table 2, also have higher percentages of
corresponds to reduction in the time to read the sentence. students with significant improvement. There are some slight
Thus speed-up in oral reading rate is the most sensitive changes in the ranking of the features, but in general, features
indicator of improvement, which is consistent with the with greater median effect sizes also have higher percentages
widespread use of timed oral (re-)reading for that purpose. of students with significant improvement.
The small effect size reflects the subtlety of the effect – a The largest such percentage was 38.3. The actual number
reduction of a few milliseconds in average word reading time. of students whose reading improved was much closer to 100%
Conversely, correl_intensity (feature 16) is less sensitive to -- presumably about the same as the percentage of students
improvement than any other feature, significantly less so for with positive improvements whether significant or not. The
all but correl_pitch, and neither of their effect sizes differs reason for analyzing individual reliability is that it is important
significantly from 0. However, effect sizes for most of the to know not only whether a class is progressing overall, but
other features are significantly greater than 0, though some of whether each individual student is improving or not, and this
them are very small. determination should be statistically reliable. The point of the
analysis is to see how often we can meet that standard.
5. Compare learning vs. recency effects
Table 3: % of students with significant improvement
When a student reads the same text twice in a row it is not
surprising if reading is more fluent the second time around, ID Feature Any Same Later
due to short-term memory recency effects. It is more day day day
impressive when the improved rereading occurs on a later day, 1 avg_duration 33.8 38.3 28.6
because it indicates learning and retention. 2 avg_norm_duration 38.3 35.8 32.8
To compare the relative magnitudes of these two effects, 3 avg_norm_production 34.6 33.3 30.3
we disaggregated our analysis of improvement in reading a 4 pause_frequency 29.5 25.9 27.1
sentence into two cases. In one case, the rereading occurred 5 avg_production 30.8 34.6 25.2
on the same day as the previous reading. In the other case, the 6 avg_norm_latency 25.6 19.8 24.4
rereading occurred on a later day. For both cases, we compute 7 avg_latency 25.8 22.2 28.0
each feature‟s median effect size as described in Section 5. 8 correl_duration 13.9 10.5 9.6
Table 2 compares these two effect sizes side by side in the 9 correl_production 9.8 5.3 12.3
“Same day” and “Later day” columns. Most of them are 10 correl_latency 3.4 4.3 4.6
higher for same-day rereading than for later-day rereading. 11 correl_norm_latency 8.3 9.6 7.1
To see which such differences are statistically reliable, we 12 correl_norm_duration 9.0 5.3 10.5
did a one-tailed, paired t-test for each feature, pairing each 13 pitch_variation 8.3 7.4 9.2
student‟s effect sizes for the two cases. Table 2 indicates the 14 correl_norm_production 7.4 1.3 7.0
results of these tests by boldfacing median effect sizes that are 15 correl_pitch 2.6 5.5 2.8
significantly greater (at the 0.05 level) than for the other case. 16 correl_intensity 3.5 4.1 2.8
The results confirm our hypothesis that same-day
rereading should show greater improvement than later-day
rereading due to recency effects. Moreover, it quantifies the 7. Contributions, limitations, and future work
difference. For every feature where the difference is
significant, same-day improvement is higher than later-day In this paper, we have presented a method for detecting
improvement – by a ratio of 1.8, on average. prosody improvement in rereading a given text and applied it
to a data set of recorded speech from 133 students. We
6. Are individual improvements reliable? computed the improvement of each feature value in
successive readings of the same sentence and computed its
The statistical significance tests described above are for effect size for each student. We used each feature‟s median
overall differences between features or same- vs. later-day. effect size as an index of its sensitivity. Our experiments
What about for individuals? Are any features sensitive enough showed that raw features were more sensitive to growth than
to detect improvements that are statistically reliable for correlational features. We also found that same-day
particular students? To answer this question, we conducted a rereadings exhibited nearly twice as much improvement as
paired t-test for each feature and student to evaluate the later-day rereading – that is, recency effects were almost twice
significance of the hypothesis that the student‟s mean gain as strong as learning effects that persist overnight or longer.
exceeds 0. For each feature, Table 3 reports the percentage of A limitation of this work is the lack of a “gold standard”.
students whose individual improvement in that feature was We attempted to detect improvement, and succeeded in doing
statistically significant at the 0.05 level. As before, the “Any so, but did not verify this detected gain by any other methods.
day,” “Same day,” and “Later day” columns shows results for The difficulty arises from the lack of a paper test that reliably
all rereadings, same-day rereadings, and later-day rereadings. measures prosody improvement. Previous work [5] used a
laboriously human-scored rubric [17] to assess the prosody of
SpeechandLanguageTechnologyinEducation(SLaTE2009) 107
each sentence being read. However, the same work also [6] Mostow, J., G. Aist, P. Burkhead, A. Corbett, A. Cuneo,
showed that the rubric was not reliable at the sentence level. S. Eitelman, C. Huang, B. Junker, M.B. Sklar, and B.
The previous work [5] assessed oral reading prosody for Tobin. Evaluation of an automated Reading Tutor that
“cold reads” (first encounters) of sentences. The work listens: Comparison to human tutoring and classroom
reported here is complementary to it in two respects: it instruction. Journal of Educational Computing Research,
focuses on rereading instead of cold reading, and it moves 2003. 29(1): p. 61-117.
beyond assessing prosody to detecting improved prosody. [7] CMU. The CMU Sphinx Group Open Source Speech
The advantage of using rereading to detect improvement is Recognition Engines [software at
that comparing successive readings of the same sentence http://cmusphinx.sourceforge.net]. 2008.
controls for text differences that affect oral reading prosody, [8] Mostow, J., S.F. Roth, A.G. Hauptmann, and M. Kane. A
thereby eliminating a major source of variance in the data we prototype reading coach that listens [AAAI-94
use to compare sensitivity of different features of prosody. Outstanding Paper]. Proceedings of the Twelfth National
One next step is to generalize from detecting improvement in Conference on Artificial Intelligence, 785-792. 1994.
rereading the same text to detecting improvement in reading Seattle, WA: American Association for Artificial
new text. Another limitation of the current work is its Intelligence.
reliance on adult narrations to evaluate against adult prosody. [9] Mostow, J. and G. Aist. The sounds of silence: Towards
This requirement exploits a resource that happened to exist automated evaluation of student learning in a Reading
for the Reading Tutor‟s current text, but introduces variance Tutor that listens. Proceedings of the Fourteenth
among different narrators, and prevents assessment of oral National Conference on Artificial Intelligence (AAAI-97),
reading prosody on novel text. To address both limitations, 355-361. 1997. Providence, RI: American Association for
we are working to generalize the correlational features into a Artificial Intelligence.
normative model of prosody induced from our corpus of [10] Beck, J.E., P. Jia, and J. Mostow. Automatically
narrations, so that given a new text, we can predict how it assessing oral reading fluency in a computer tutor that
should be read – not in the sense of prescribing a single listens. Technology, Instruction, Cognition and Learning,
prosodic contour as a speech synthesizer must do [e.g., 18], 2004. 2(1-2): p. 61-81.
but in the sense of evaluating a given prosodic contour by [11] Schwanenflugel, P.J., A.M. Hamilton, M.R. Kuhn, J.M.
estimating the likelihood that a skilled narrator would produce Wisenbaker, and S.A. Stahl. Becoming a Fluent Reader:
it. Reading Skill and Prosodic Features in the Oral Reading
of Young Readers. Journal of Educational Psychology,
Acknowledgements 2004. 96(1): p. 119-129.
[12] Schwanenflugel, P.J., E.B. Meisinger, J.M. Wisenbaker,
The research reported here was supported by the Institute of
M.R. Kuhn, G.P. Strauss, and R.D. Morris. Becoming a
Education Sciences, U.S. Department of Education, through
fluent and automatic reader in the early elementary school
Grant R305A0628. The opinions expressed are those of the
years. Reading Research Quarterly, 2006. 41(4): p. 496-
authors and do not necessarily represent the views of the
522.
Institute or the U.S. Department of Education. We also thank
[13] Miller, J. and P.J. Schwanenflugel. A Longitudinal Study
Dr. Paula Schwanenflugel for her expertise, and the educators,
of the Development of Reading Prosody as a Dimension
students, and LISTENers who helped generate our data.
of Oral Reading Fluency in Early Elementary School
Children. Reading Research Quarterly, 2008. 43(4): p.
References (ours at www.cs.cmu.edu/~listen)
336–354.
[14] Boersma, P. and D. Weenink. Praat: doing phonetics by
[1] O'Connor, R.E., A. White, and H.L. Swanson. Repeated
computer (Version 5.0.33) [Computer program
reading versus continuous reading: Influences on reading
downloaded from http://www.praat.org/]. 2008.
fluency and comprehension. Exceptional Children, 2007.
[15] The Incorporation of Effect Size in Information
74(1): p. 31-46.
Technology, L., and Performance Research. ITL&P
[2] Kuhn, M.R. and S.A. Stahl. Fluency: A review of
Journal, 2003. 21(1).
developmental and remedial practices. Journal of
[16] Efron, B. Bootstrap Methods: Another Look At The
Educational Psychology, 2003. 95(1): p. 3–21.
Jackknife. The Annals of Statistics, 1979. 7(1): p. 1-26.
[3] Dowhower, S.L. Repeated reading revisited: Research into
[17] Zutell, J. and T.V. Rasinski. Training Teachers to Attend
practice. Reading & Writing Quarterly: Overcoming
to Their Students' Oral Reading Fluency. Theory into
Learning Difficulties, 1994. 10(4): p. 343-358.
Practice, 1991. 30(3): p. 211-17.
[4] NRP. Report of the National Reading Panel. Teaching
[18] Jokisch, O., H. Kruschke, and R. Hoffmann. Prosodic
children to read: An evidence-based assessment of the
Reading Style Simulation for Text-to-Speech Synthesis.
scientific research literature on reading and its
First International Conference on Affective Computing
implications for reading instruction. 2000, National
and Intelligent Interaction, 426-432. 2005. Beijing,
Institute of Child Health & Human Development. At
China: Springer-Verlag.
www.nichd.nih.gov/publications/nrppubskey.cfm:
Washington, DC.
[5] Mostow, J. and M. Duong. Automated Assessment of Oral
Reading Prosody. Proceedings of the 14th International
Conference on Artificial Intelligence in Education
(AIED2009), 189-196. 2009. Brighton, UK: IOS Press.
SpeechandLanguageTechnologyinEducation(SLaTE2009) 108
