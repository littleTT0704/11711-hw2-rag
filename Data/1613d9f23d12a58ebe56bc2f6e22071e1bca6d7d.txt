TheThirty-ThirdAAAIConferenceonArtificialIntelligence(AAAI-19)
What’s Most Broken? A Tool to Assist Data-Driven
Iterative Improvement of an Intelligent Tutoring System
MononitoGoswami∗ ShivenMian∗ JackMostow
DelhiTechnologicalUniversity IIIT-Delhi CarnegieMellonUniversity
NewDelhi,India NewDelhi,India Pittsburgh,PA,USA
mononitog@hotmail.com shiven15094@iiitd.ac.in mostow@cs.cmu.edu
+91-8800592994 +91-8130562083
Abstract • Reliability: How often and under what conditions does
RoboTutorcrashorhang?Howfastdoesachildrecover
Intelligent Tutoring Systems (ITS) have great potential to
fromthecrashorhang?
change the educational landscape by bringing scientifically
testedone-to-onetutoringtoremoteandunder-servedareas. • Recognition:HowaccuratelydoesRoboTutorrecognize
However,effectiveITSsaretoocomplextoperfect.Instead,a bothwrittenandspokeninput?
practicalguidingprincipleforITSdevelopmentandimprove-
• Usability: How easily and efficiently can children oper-
ment is to fix what’s most broken. In this paper we present
SPOT(StatisticalProbeofTutoring):atoolthatminesdata ateRoboTutor?Whichactivitiesdotheyfindhardtonav-
loggedbyanIntelligentTutoringSystemtoidentifythe‘hot igate?
spots’mostdetrimentaltoitsefficiencyandeffectivenessin
• Engagement: When are the children disengaged the
termsofitssoftwarereliability,usability,taskdifficulty,stu-
most,andwhy?
dentengagement,andothercriteria.SPOTusesheuristicsand
machinelearningtodiscover,characterize,andprioritizesuch ToanswerthesequestionswepresentStatisticalProbeof
hot spots in order to focus ITS refinement on what matters Tutoring(SPOT):anEducationalDataMiningtoolintended
most.WeappliedSPOTtodataloggedbyRoboTutor,anITS
to help ITS developers identify ‘what’s most broken’ – i.e,
thatteacheschildrenbasicreading,writingandarithmetic.
‘hot spots’ with respect to design criteria such as software
reliability, student engagement etc. SPOT uses metrics to
INTRODUCTION identify and predict the occurrence of undesirable events,
andtrainsadecisiontreetodiscoverhotspots.Ahotspotis
AnIntelligentTutoringSystem(ITS)isacomputersystem
asubtreewithahighproportionofundesirableevents.
that enables learning in an effective and meaningful man-
Theintuitionsthatinspiredthisapproachareasfollows:
ner by providing personalized instruction to learners. Prior
research has demonstrated that ITSs take extensive time to • Withinadecisiontree,undesirableeventsinthesamesub-
author, with reported estimates of 200-300 hours of devel- treearelikelytohavethesameunderlyingcause.
opment per hour of instruction (Aleven et al. 2006). As a
• The feature combination associated with a subtree - that
result,manyauthoringtoolssuchastheCognitiveTutorAu-
is,thesequenceoftestsfromtheroottothesubtree-char-
thoring Tool (CTAT) have been built to make ITS develop-
acterizes when the undesirable events tend to occur and
mentmoreefficient.But,despiteourgrowingunderstanding
mayreflectthisunderlyingcause.
of human cognition and the tutor authoring process, devel-
oping effective tutoring systems with limited development • Screencapturevideosofarandomsampleofundesirable
resourcesremainshard.Inthissituation,apracticalguiding events in the subtree may shed further light on a certain
principle towards ITS development and improvement is to causeandinspireideasforhowtoaddressit.
fixwhatismostbroken.
Henryetal(Henry,Lin,andPark2017)designedaUI/UX
ThedesignofRoboTutor(RoboTutor2015)wasinspired
for SPOT and prototyped it using simulated data. Here we
bythisprinciple.RoboTutorisanITSdevelopedasanopen-
describe an implementation that uses automated decision
source Androidapplication that teacheschildren aged 7-10
tree learning and runs on real data from RoboTutor. We
in developing countries basic reading, writing, and arith-
briefly describe the SPOT workflow and its findings on
metic.Inthispaper,weaddressthequestion:isthereaway
RoboTutordatainthenextsections.
to use data from RoboTutor to automate discovery of de-
sign issues and highlight them? To best address this issue,
Methodology
wemustanswerthefollowingsubquestionspertainingtothe
developmentanddesignprocessofRoboTutor: DataCollection
∗authorscontributedequally RoboTutorusesavarietyofactivitiessuchasstoryreading,
Copyright(cid:13)c 2019,AssociationfortheAdvancementofArtificial math activities etc. to teach children. The dataset used by
Intelligence(www.aaai.org).Allrightsreserved. SPOTtodiscoverhotspotsisderivedfromstudentattempt
9941
videos from this hot spot, we realized that the writing rec-
ognizeroftenmis-recognizes7intheabsenceofitsmiddle
stickas1,leadingchildrentoconfusebetweenthetwo.
Conclusions
Table1presentssomekeySPOTfindingsandcorresponding
designimplicationsforRoboTutor.WeevaluatedSPOTand
Figure1:RoboTutormis-recognizing7as1becauseofab-
selectedfeaturesqualitatively,sincedesignchangesarefun-
senceofmiddlestick-instanceprovidedbySPOT
damentallysubjectivedecisionsonpartofthedevelopers.
Criterion SPOTFindings DesignImplications
performancelogsrecordedfromRoboTutor’sbetafieldtest-
Counting and Implement crash log-
ing sites in Tanzania. We also extract activity and item-
Story Reading ging,ExamineCount-
level aggregates from these performance logs. SPOT also Reliability
actvities have high ingandStoryReading
usesscreencapturevideosofRoboTutorrecordedusingAZ crashrates. activitiesforbugs
ScreenRecorder1,usedbydeveloperstofurtherexaminethe
Bias data sources of
Children confuse
obtainedhotspots. appropriate activities
between number
Recognition towards frequently
pairs like 1 and 7,
Approach confused digits for
5and3.
betterpractice
Toautomatediscoveryofdesignissues,SPOTusesawork
Childrenspendun-
flowsummarizedasfollows: usually long time Addtimeoutstostory
Usability
in Story Reading readingactivities
1. Developersspecifyadesigncriterion,andpickmetric(s).
activities
A design criterion is any property of an Intelligent Tu-
Children bail
tor that we wish to analyze. We classify design issues out of activities Children should not
into one of these design criteria: Reliability, Recogni- Engagement when given the be given the same
tion,UsabilityandEngagement.Usingpre-definedmet- same problems problemsrepeatedly
rics(heuristics),SPOTapproximatelylabelseachrowof repeatedly
thedataas:suspiciousinstanceindicatingadesignissue,
Table1:SPOTFindingsandImplications
or a non-suspicious instance. For example: the rejection
rateofresponsesinwritingactivitiesisametricofwrit-
ingrecognition,andasuspiciousinstanceisanywritten WebelieveSPOTwouldbenefitmanytutordevelopersby
responseotherthantheexpectedanswer. helpingthemiterativelyimprovetheirtutorsandsavetime.
SPOTmaybeespeciallyusefulwhenuser-testinginperson
2. SPOT trains a decision tree on the labeled data and dis-
is impractical, such as in situations where the users are far
covers the top N hot spots using the F score for each
1 away,whenchildrenmaybehavedifferentlywhenadultsare
subtree. SPOT uses features such as activity name, stu-
present,andwhenhotspotsareimportanttofixbuttoorare
dent input, expected answer, attempt duration etc, with
toobserveinperson.SPOTcanalsobeusedforotherITSs,
differentfeaturesforattempt,itemandactivity-leveldata.
since it relies on simple data sources such as log files and
The F score enables SPOT to discover hot spots in the
1 screenrecordvideos,bothofwhichareeasytorecord.
decisiontreeandbalancesboththeconcentrationandthe
numberofsuspiciousinstancesinthehotspots.
Acknowledgements
3. SPOT automatically characterizes each of the hot spots
SpecialthankstoothermembersoftheRoboTutorteam,es-
by conjoining every test on the path from the root node
pecially Evelyn Yarzebinski for data parsing and cleaning.
ofthetreetothehotspot.Inourwork,weuseDecision
ThisworkwassponsoredbytheRoboticsInstituteSummer
Trees strictly for finding and characterizing hot spots,
Scholars(RISS)program,CarnegieMellonUniversity.
ratherthanclassifyingunseendata.
4. SPOTpicksuparandomsampleofsuspiciousinstances References
ofahotspot,andpresentstheircorrespondingscreencap-
Aleven, V.; McLaren, B. M.; Sewall, J.; and Koedinger,
turevideosscrolledtothestartoftheinstancesalongwith
K. R. 2006. The cognitive tutor authoring tools (ctat):
the hot spot characterization, to the developers. Devel-
Preliminary evaluation of efficiency gains. In Interna-
opers examine the videos and characterization for clues
tional Conference on Intelligent Tutoring Systems, 61–70.
todiagnosethedesignissue,anddevisesolutionsforre-
Springer.
designingRoboTutor.
Henry, G.; Lin, J.; and Park, C. Y. 2017. SPOT: Refin-
Figure1illustratesascreenshotfromthescreencapture ing robotutor. HCI senior capstone project presentation,
videosforarecognitionhotspotcharacterizedas:‘expected CarnegieMellonUniversity.
answer = 7’. After examining the sample of screen capture
RoboTutor. 2015. RoboTutor. http://robotutor.org.
1http://bit.ly/azurl
9942
