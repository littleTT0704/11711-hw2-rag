How people talk about each other:
Modeling Generalized Intergroup Bias and Emotion
VenkataS.Govindarajan1 KatherineAtwell2 BareaSinno3
MaliheAlikhani2 DavidI.Beaver1 JunyiJessyLi1
1 DepartmentofLinguistics,TheUniversityofTexasatAustin
2 DepartmentofComputerSciences,UniversityofPittsburgh
3 DepartmentofPoliticalScience,RutgersUniversity
venkatasg@utexas.edu,kaa139@pitt.edu,barea.sinno@gmail.com,
malihe@pitt.edu,dib@utexas.edu,jessy@utexas.edu
Abstract incontext(VanDijk,2009);assuch,biasrefersto
differencesinbehavior(inthiscaselanguageuse)
Current studies of bias in NLP rely mainly
asaresultofdifferencesintherelationshipbetween
on identifying (unwanted or negative) bias to-
speakerandtarget. Thelanguageweproduceisbi-
wards a specific demographic group. While
asedinonewayoranother,whetherweintendtoor
this has led to progress recognizing and mit-
not,andwhetherthatbiasispositive,negative,or
igating negative bias, and having a clear no-
tion of the targeted group is necessary, it is notclearlyassociatedwithanyvaluation(Beaver
not always practical. In this work we extrap- andStanley,2018).
olate to a broader notion of bias, rooted in
InpsychologicalworkonLinguisticIntergroup
social science and psychology literature. We
Bias (Maass, 1999), bias originates from the re-
move towards predicting interpersonal group
lationship between the speaker and target of an
relationship (IGR) — modeling the relation-
utterance,i.e. theirinterpersonaldynamics,and
ship between the speaker and the target in
anutterance—usingfine-grainedinterpersonal manifestslaterinsubtleways. Considertheutter-
emotions as an anchor. We build and release ances(tweets)in(1),drawnfromourcollecteddata
a dataset of English tweets by US Congress inwhichtheidentityofthespeakerandtargetare
members annotated for interpersonal emotion masked:
– the first of its kind, and ‘found supervision’
(1) a. In-group: Westandw@Doe, whohasseenalot
for IGR labels; our analyses show that subtle
worse than cheap insults from an insecure bully.
emotionalsignalsareindicativeofdifferentbi-
#MLKDAYweekend.
ases. While humans can perform better than b. Out-group:Parentsandfamiliesliveinconstantfear
chance at identifying IGR given an utterance, fortheirchildrenwithfoodallergies. Aworthybi-
weshowthatneuralmodelsperformmuchbet- partisancause-thankyou@Doeforyourleadership
onthisissue.
ter; furthermore, a shared encoding between
IGR and interpersonal perceived emotion en- Bothexpresssupportandadmirationtowardsthe
abledperformancegainsinbothtasks. targetreferentDoe–however,thesecondexample
uses words indicative that the speaker and target
1 Introduction
donotsharearelevantsocialidentity(inthiscase,
Currently,mostworkstudyingbiasinNLPsituates their political party), expressed by words like bi-
biasasnegativeorpejorativelanguageusetowards partisan. Theintensityofadmirationexpressedis
anindividualorgroupbasedontraitslikerace,gen- also greater in (1-a) than (1-b). Thus, these two
der,etc(KanekoandBollegala,2019;Shengetal., seeminglysimilarstatementsdifferalonginterper-
2019;Sapetal.,2020;Websonetal.,2020;Pryzant sonaldimensionsthatareinstructiveastohowthe
et al., 2020; Sheng et al., 2020). While these ap- biasofthespeakerseepsintotheutterance.
proachesgreatlyadvanceourunderstandingofbias We now introduce two new tasks that directly
inlanguageanditsimpactandmitigationinNLP, modellanguageuseintermsoftwointerpersonal
focusingonspecificdemographicdimensionsoran dimensions: (i)interpersonalgrouprelationship
individual’sintentislimitingandnotalwaysprac- (IGR) prediction, where we seek to understand
tical. Research in psychology and social science how people talk about others who they consider
suggestsadifferentperspective. Biascanbeseenas tobeintheirsamesocialgroup(in-group),versus
arelationshipbetweenpeopleandgroups,situated thosetheyconsideroutsidetheirsocialgroup(out-
3202
beF
41
]LC.sc[
3v78660.9022:viXra
group),and(ii)perceived interpersonalemotion github.com/venkatasg/interpersonal-bias.
detection, where we situate these differences in
2 InterpersonalContexts&Emotions
termsoftheemotionexpressedintexttowardsor
in connection with a target individual described
Ouraimistobuildageneralized, data-drivenap-
intheutterance. Notethatinterpersonalemotion
proachtowardsstudyingbiassituatedininterper-
isdifferentfromamorestandard, utterancelevel
sonalutterances,whichwedefineasanyutterance
emotion detection task, as illustrated in row 2 of
wherethereisatargetindividualbeingtalkedabout
Table1whichhasseeminglyopposingemotions.
orreferredto. Ourgoalistomodeltwonoveltasks
Wepresentafirst-of-its-kind,annotated dataset describedbelow;examplesareshowninTable1.
for fine-grained interpersonal emotion detection,
Interpersonal Group relationship IGR is de-
consisting of 3,033 tweets from members of the
finedbytherelationshipbetweenthespeakerand
US Congress; all of these tweets mention an-
target of an utterance. People belong to multiple
otherCongressmember,henceprovidinguswith
socialgroupsaspartoftheiridentity,howeverusu-
‘found supervision’ for IGR prediction (whether
allyonlysomeidentitiesaresalientinanutterance
thespeakerandthetargetbelongtothesamepolit-
incontext. Wedefinein-grouputterancesasones
icalparty). Ouranalysesshowthatwhilepositive
wherethespeakerandtargetareinthesamesocial
interpersonalemotionsappearinbothin-andout-
group,andout-grouputterancesasonewherethey
groupsituations,negativeemotionslikeangerand
areindifferentsocialgroups. Givenanutterance
disgust are overwhelmingly present in the latter.
uwrittenbyanindividualswithtargett,theIGR
Meanwhile,humanjudgmentsforinvs. out-group
predictiontaskclassifieswhethersandtbelongto
membership on this dataset are overly reliant on
thesamesocialgroupwithinthecontextofu.
thepolarityofemotion;specifically,humanjudges
aremuchlesslikelytoattributepositiveemotions InterpersonalEmotion Wedefineperceived in-
towardsout-grouptargets. terpersonal emotion as the emotion expressed by
Baseline performances for perceived interper- aspeakerstowards,orinconnectionwiththetar-
sonal emotion detection shows that this is a chal- get t of the utterance u, as perceived by a reader.
lenging task, as is consistent with existing work We use the Plutchik wheel of emotions, which is
in emotion detection in general (Demszky et al., widelyadoptedinthecommunity, asthebasisof
2020). In particular, emotions in this dataset are our emotion taxionomy (Plutchik, 2001); we use
oftenexpressedwithconsiderablesubtlety,likelya the8fundamentalemotions(admiration,anger,dis-
characteristicofofficialpoliticalspeech. Toinvesti- gust,fear,interest,joy,sadness,surprise)instead
gatewhetherIGRandemotionsareintertwinedand of the full 24 emotions in the wheel due to data
usefultowardseachother,wefurtherdevelopeda sparsity. Interpersonalemotionsmaybedifferent,
multi-task model for the prediction of both. We or a subset of, emotion for the whole of an utter-
foundcompellingevidencethatmulti-taskingIGR ance, as illustrated in rows 2, 3 and 4 of Table 1.
andinterpersonalemotionimprovesperformance Given an utterance u written by an individual s
on both tasks with over 10% improvement in de- withtargett, the interpersonalemotion detection
tection of disgust in out-group contexts, and 3% taskidentifiestheperceivedemotionofstowards
improvementinIGRprediction. thetargett.
To summarize the contributions of this paper,
3 DataCollection
wetacklegeneralizedintergroupbias,anotionof
biasrootedinsocialpsychologythatappliestoall Inourareaoffocus, werequirenaturallanguage
thevariousdifferencesinthewaysthatpeopletalk datawhichsatisfiesthefollowingcriteria: (1)Each
aboutothersintheirin-grouporout-group. Stan- utterancemusthaveatleastonetargetaboutwhom
dard bias tasks in NLP, and the broader goal of theutterancemainlyconcerns. (2)Therelationship
debiasingmodelscouldthusbesetinamoregen- betweenthespeakerandthetargetmustbeinferred
eral context. We present the first dataset to study based on metadata or other information. Specifi-
bothinterpersonalgroupmembershipandemotion, cally, we are interested in aspects of their social
whichallowsustoanalyzebothhumanandmodel identitythattheyshareordifferon.
behavior in terms of how the two interact with The dataset we collect comes from tweets by
eachother. Wereleaseourcodeanddataonlineat members of US Congress where other members
Tweet InterpersonalEmotion In/Outgroup?
As@Doesays,thetimeshavefoundeachandeveryoneofustoDefend Admiration In-group
ourDemocracyForThePeople.Worthreadingeveryline.
Freedomhasnogreaternortougherchampionthan@Doe.Myprayers Admiration&Sadness In-group
arewithhimandhisfamily.
Youdon’tgettodecidewhat’s“fine,” @Doe. Theconstitutiondoes. Anger&Disgust Out-group
#DefendOurDemocracy#WednesdayThoughts
ThankyouagainSenator@DoeforleadingtheSRFWINAct[...]I’m Admiration&Joy Out-group
proudtobeaco-sponsor
Table1: Exampleutterancesfromourdatasetwithin/outgroupandinterpersonalemotionlabels
are mentioned in the same tweet. We use this as 300tweetseachyear.
aconvenienttestbed: eachmember’sgroupaffili-
3.2 InterpersonalEmotionAnnotation
ation (i.e., their party identity) is public, thus we
caneasilyknowwhetherthespeakeristweetingto Whilewecaninferwhetheratweetisin-groupor
atargetintheirownpartyornot.1 Inotherwords, out-groupbasedontheidentityofspeakerandtar-
this dataset gives us “found supervision” for our getwhosepoliticalaffiliationsareknown,westill
first task of IGR prediction. For our second task, requireannotateddataonperceivedinterpersonal
weannotateasubsetofthesetweetsforperceived emotions. Interpersonal emotions vary in subtle
interpersonal emotion; this is, to our knowledge, waysfromsentimentoroverallsentimentofutter-
thefirstdatasetdedicatedtointerpersonalemotion. ances: an utterance can have negative sentiment
overall,butstillconveypositiveemotionstowards
3.1 DataSourcesandPreprocessing the target of the sentence (expressing admiration
atsomeone’sdeathforinstance). Forthisreason,
Socialmediatextliketweetsofferafertileground
wedeviseanannotationschemaforannotatingthe
forourstudy. Afocusontweetswithmentionsin
emotionexpressedbyspeakerstowardstargett.
themsatisfiesourfirstcriterion–peoplegenerally
use mentions to say something about or towards Instructions Annotators are presented with a
anotherindividualontwitter. Tweetsbymembers tweet, with the identity of the speaker unknown
ofUSCongressareamatterofpublicrecord,and and that of the target masked with a placeholder
we can infer the social relationship (in terms of name @Doe to minimize potential biases of the
partyaffiliation)betweenspeakerandtargetusing annotators’priorknowledgeofpartyaffiliationin-
publiclyavailableinformation. Weprioritizework- trudingintotheannotation:
ing with a dataset of tweets by members of US
(2) If @Doe can get her hair done in person,
Congress(downloadedusingtheTwitterAPI)be-
Congresscanvoteinperson...
tween2010and2021,spanningtwopresidencies,
Annotatorsareinstructedtoreadthetweetandse-
duringwhichbothpartiesheldpowerinCongress.
lect only the most notable emotion(s) they think
Wefilterthesetweetstoexcluderetweets,andin-
are expressed by the tweet author in connection
cludethosetweetsthatmentionatmostoneother
with@Doe. Toaidannotators,weprovideexam-
member of Congress whose party affiliation is
ples of the 8 Plutchik emotions (joy, admiration,
known. We believe these 2 assumptions are suf-
fear, suprise,sadness,digust, angerandinterest)
ficient to arrive at a dataset of tweets where the
expressedasinterpersonalemotionsintweets. An-
speakeristalkingtowards/aboutonetarget. Thus,
notatorsarealsoshownaschematicofthePlutchik
we restrict ourselves to two social groups in this
wheelofemotions,whichacquaintsthemwithhow
sphere—DemocratandRepublicanpartiesinthe
theemotionsarerelatedtooneanotherinourframe-
US.Wesampleanequalnumberofin-groupand
work. Annotatorsareallowedtoselectmorethan
out-group tweets from a large sample consisting
oneemotiontoaccountforemotionco-occurrence.
ofalltweetsbymembersofCongress. Apartfrom
We also explicitly tell annotators that more than
years2010–2012and2021whichcontainedfewer
oneoftheemotionscanbepresentinthetweets,to
tweetsduetosparsityissues,wesampledatleast
encouragethemtoselectallinterpersonalemotions
expressed. Theyarealsoallowedtonotchooseany
1Forsimplicity,wedonotconsiderotherfactorssuchas
thehomestateofacongressmember. emotion.
Emotion Train Dev Test
Admiration 467 64 58
Anger 225 40 46
Disgust 206 32 43
Fear 1 0 0
Interest 701 83 84
Joy 801 107 106
Sadness 72 11 11
Surprise 1 0 0
NoEmotion 519 56 63
Figure1:Emotionsorderedbythenumberofexamples
Table2: Distributionofemotionsintrain-dev-testsplit
where at least one rater uses a particular label. The
colorindicatestheaverageinterratercorrelation.
Emotion All In-Group Out-Group
Annotation To obtain reliable annotations, we
Admiration 15.5 22.2 9.1
prequalifyannotatorsusingaqualifyingtask. An- Anger 8.2 1.0 15.1
Disgust 7.4 0.3 14.2
notatorswererecruitedonMechanicalTurkusing
Interest 22.9 27.2 18.6
a qualifying task where they were asked to anno- Joy 26.7 32.2 21.4
tate6tweetsusingtheschemashownabove. We Sadness 2.5 2.6 2.4
NoEmotion 16.8 14.5 19.1
restrictedthequalificationtasktoannotatorsliving
intheUSAwhohadattemptedatleast500HITS
Table 3: Proportion of emotions in different interper-
and had a HIT approval rate ≥ 98%. After man-
sonalcontexts
ualinspection,6annotatorswerequalifiedforbulk
annotation. Eachtweetwasannotatedbythreedif-
80-10-10train-dev-testsplitonourdata.
ferentannotators. Toensureannotatorswerepaid
Thenumberofannotatedexamples(tweets)per
afairwageofatleast10$anhour,wepaidannota-
emotion is shown in Table 2. We omit fear and
tors$0.50perHIT.EachHITinvolvedannotating
surprise from future tables due to the absence of
3tweets,whichweestimatetotakeonaverage3
annotatedexamples.
minutestocomplete. Intotal,3,033tweetsbetween
2010and2021wereannotatedwithperceivedin-
4 PreliminaryAnalysis
terpersonalemotion.
How are emotions distributed? When observ-
Agreement Tomeasureagreementbetweenan-
ing the distribution of aggregated emotion labels
notatorsonthePlutchik-8emotionwheel,weuse
themselves,aclearpatternemergesasseeninTa-
thePlutchikEmotionAgreement(PEA)scorefrom
ble 3. Negative emotions such as anger and dis-
Desaietal.(2020). ThePEAscoreaddressesthe
gustarealmostalwaysexpressedinout-groupset-
issue of penalizing all disagreements equally, by
tings,whilepositiveemotionsarepresentinboth
penalizingdissimilar emotionannotationshigher
in-groupandout-groupsettings. Asimilardistribu-
thanmoresimilarones(accordingtothePlutchik
tionofemotionswasobservedforDemocratsand
wheel). OurPEAscoreis0.73. TheoriginalPEA
Republicans—membersofbothpartiesreserved
formulationusedthebest(max)pairofemotionan-
theirpublicangeranddisgustformembersofthe
notationsbetweentwoworkers. Takingtheworst
otherparty. Thisreflectsaninnatebiasintermsof
combinationofemotionsbetweentwoworkers(av-
thedistributionofinterpersonalemotionspersitua-
eragedoveralltweetsandworkers),thePEA(min)
tion,andwarrantsfutureworktoexplorenegative
score is 0.60. Overall, we find moderate to high
interpersonalemotionsinanin-groupsetting.
agreementonfine-grainedinterpersonalemotions.
Figure 2 shows the co-occurrence of interper-
InFigure1wealsopresentinterratercorrelation,a
sonal emotions in our dataset. We can see that
metricusedinDemszkyetal.(2020);weseethat
emotionsthatarefartherapartandmoredissimilar,
distributionsaresimilar.
such as admiration and disgust, joy and sadness,
Aggregation Weconsideratweettohaveacer- co-occur infrequently. Emotions that are closer
tainemotionlabelifatleast2outof3annotators suchasangeranddisgust,admirationandjoy,co-
agree that the particular emotion was present in occur much more often. The only outlier is the
thetweet. Atotalof638tweetshavenointerper- higher than normal co-occurrence of admiration
sonalemotionassociatedwiththem. Weemploya withsadness—afteracloserexamination,thiscan
scores on these 50 tweets were 0.67 and 0.63,
whichaswewilldiscussinSection6,onlymatch
simple baselines of supervised systems. Annota-
torscommentsindicatethattheyoverlyreliedon
thesentimentoftweetstomaketheclassification
—positivesentimentmeansin-groupandnegative
sentimentmeansout-group. Whilenegativeemo-
tionsareover-representedinout-groupsituations
asTable3shows,ourdatasetcontainsasubstantial
presenceofout-grouptweetswithpositiveinterper-
Figure2: Co-occurenceofemotionsinourdataset. sonal emotions as well. Annotators also noticed
somelexicalcueslike‘bipartisan’thatareindica-
tiveofout-grouptweets.
beattributedtotweetsexpressingadmirationand
sadness at the passing, or end of the career, of a Do pre-trained representations capture inter-
fellowcongressperson. personalemotions? Pre-trainedlanguagemod-
els have been found to learn sentence represen-
Who were the targets of negative emotions?
tations that cluster by domain without supervi-
On further analysis, it appears that most of the
sion (Aharoni and Goldberg, 2020). We wished
out-groupdisgustandangerisdirectedat3handles
to investigate if any of our annotated properties
– @speakerryan, @speakerpelosi, and @speaker-
clusterinherentlyinreducedrepresentationsofthe
boehner who were all Speakers of the House of
tweetsinourdata. Toobtainunsupervisedrepresen-
Representativesovermostofthetimeperiodofour
tations, we use BERTweet (Nguyen et al., 2020),
dataset. 63.7% of disgust and 64.3% of anger is
a language model pre-trained on 850M English
directedtowardsthesethreetwitterhandles. 11.9%
tweets. Wetakethe768dimensionalembeddings
of all tweets in our dataset are directed at these
fromthefinallayerofthe<s>tokeninBERTweet,
handles,indicatingthepreponderanceofnegative
and dimensionally reduce them to 2 dimensions
interpersonalemotiondirectedattheSpeakerofthe
using UMAP (Sainburg et al., 2021). Figure 3
house. However, we note that negative emotions
shows the distribution of tweets, color coded for
likeangeranddisgustwerestillexpressedtowards
interpersonal emotions. While there is a lot of
51 and 45 different individuals in our dataset, re-
overlapbetweenrepresentationswhenstratifiedby
spectively.
emotion, we can see that some emotions that are
intuitivelyopposite,likeadmiration&disgust,joy
Canhumanspredictin/out-group? Whileour
&sadnessaremoderatelyseparable. Thisindicates
datanaturallycomeswith“gold”IGRlabels,what
that interpersonal emotions do define some topic
is unexplored is whether the distinction between
ordomainlevelpropertiesofatweet.
in-groupandout-groupspeechisprominentandno-
ticeablebyhumans. Additionally,itisalsounclear
5 Experiments
ifhumansmighthavetheirownexpectationofhow
in/out-groupspeechshouldbecharacterized. Wedetailourexperimentsforthetwonoveltasks
Concretely,weinvestigateifhumanannotators discussed in Section 2: predicting the IGR (in-
were capable of accurately performing the IGR group or out-group) given a tweet, and predict-
prediction task when the speaker and target are ing the interpersonal emotion given a tweet. We
masked. Two authors of this paper, one a social presentbaselinesforthetwotasksseparately,and
science graduate student, and the other a compu- alsopresentamulti-taskmodeltogaugetheextent
tationallinguisticsgraduatestudent,annotated50 towhichknowledgeofIGRmayhelpinpredicting
randomtweetsfromourvalidationdatawhichthey interpersonalemotion,andviceversa.
had not been exposed to earlier for in/out group
5.1 InterpersonalGroupRelationship
labels. Their Fleiss κ agreement score was 0.64,
indicatingmoderateagreement. Sentiment-Rule Our first baseline is a rule-
To check how accurate their judgements were, basedoneleveragingcoarsesentiment: ifatweet’s
we calculate for each annotator their F1 score sentiment is predicted to be negative, classify it
against our “gold” in/out group labels. Their F1 as out-group; if positive, classify it as in-group;
Figure3: Distributionofinterpersonalemotionsinunsupervisedrepresentationsoftweetsinourdataset. Orange
indicatestheemotionwaspresentforthattweet. Eachpointrepresentsonetweetfromourdataset.
andifneutral,classifyitaseitherin-grouporout- thepretrainedmodelforthepurposesoffinetuning,
grouprandomly. WeuseaRoBERTa-Basemodel withasigmoidcrossentropylossfunctiontosup-
finetunedforsentimentontweets(Barbierietal., portmulti-labelclassification. Thelossisweighted
2020)toextractthesentimentofeachtweetinour for each of the 8 emotion labels with the ratio of
dataset. positive and negative examples to increase preci-
sion. If none of the 8 emotion labels are flipped
NB-SVM As a second baseline, we build an
on, we consider that to be the ‘No Emotion’ la-
SVMmodelthatusesNaive-Bayeslog-countsra-
bel,i.e. thereisnointerpersonalemotionbetween
tiosofunigramsandbigrams(WangandManning,
speaker and target in the tweet. We experiment
2012).
with a version of the model where the language
BERTweet We use BERTweet (Nguyen et al., modelparametersarefrozenandonlythelabelling
2020),alanguagemodelpre-trainedon850MEn- headparametersarefinetuned(BERTweet-ft).
glish tweets as our dataset consists purely of En-
5.3 Multi-TaskModel
glish language tweets. A classification head is
In § 4, we observed that the emotions anger and
placedontopofthelanguagemodel. Wealsoex-
disgust are overwhelmingly present in out-group
perimentwithaversionwherethelanguagemodel
situations. Thus,wehypothesizethatIGRinforma-
parametersarefrozen,andonlytheclassification
tionwouldbeusefultowardsinterpersonalemotion
headparametersarefinetuned(BERTweet-ft).
identification,andviceversa. Totestthishypoth-
Theinputtoallmodelsisonlythetweetwithno
esis we train a multi-task model. The model is
othercontext,andthetargetmaskedwithaplace-
trainedtopredictboththeIGRlabelandemotion
holder@USER.
usingsharedparameterfinetuning.
5.2 InterpersonalEmotion WeusethesameBERTweetmodelasearlier. We
addtwodenseoutputlayersontopofthepretrained
EmoLex As a baseline model for interpersonal
model, one for classifying IGR and another for
emotion identification, we rely on EmoLex (Mo-
labellinginterpersonalemotion. Bothheadsshare
hammadandTurney,2013). EmoLexconsistsof
thesameparametersbelow. Thesearetrainedwith
14,182crowdsourcedwordsassociatedwiththe8
samelossasearlierindividualmodels. Themodel
basicPlutchikemotions. Critically,thesewordsap-
alternatesbetweenfinetuningforgrouprelationship
pearinemotionalcontexts,butarenotnecessarily
andemotionovereverytrainingitem.
emotionwordsthemselves. EmoLexcountsoccur-
rences of words from its lexicon in an utterance,
5.4 Implementation
and assigns a normalized score for each emotion
We use bertweet-base pretrained embeddings
based on occurrence frequency. We consider an
fromHuggingface’smodelshub(Wolfetal.,2020).
emotion to be on, if it’s normalized score is ≥
All models are finetuned for a maximum of 20
0.001. While EmoLex has issues with regards to
epochs with early stopping. Early-stopping pa-
itscontextinsensitivityandthesocialbiasesbuilt
tience for models trained on each task separately
intoitslexicon(Zadetal.,2021),weincludeitasa
is 3. The patience for the multi-task model is set
baselinetounderstandtowhatextentinterpersonal
at 5 as the multi-tasking setup led to slower con-
emotionscanbededucedusingalexicon.
vergence. The learning rate for the classification
BERTweet We use the same BERTweet model heads was set at 5e-3 while the learning rate for
as earlier. We add a dense output layer on top of theinternallanguagemodelparameterswassetat
Model F1 Model F1 Emo BERTweet BERTweet Multi-
Lex -ft task
Majorityclass 51.1 BERTweet 74.1(3.3)
Sentiment-Rule 56.3 BERTweet-ft 66.5(1.6) Admir. 37.5 70.3(3.7) 40.7(1.1) 68.9(1.6)
NB-SVM 62.5 Multitask 77.3(0.8) Anger 26.6 71.3(11.2) 23.0(3.4) 69.3(3.3)
Human 66.7 Disgust 25.5 47.1(21.6) 13.0(4.1) 74.5(7.1)
Interest 0 53.1(3.3) 5.8(2.4) 51.5(8.5)
Joy 48.4 85.9(1.9) 71.3(1.4) 83.6(1.3)
Table4:Resultsontestset,withSDinparentheses,for
Sadness 4.3 11.1(9.6) 0 33.6(18.5)
interpersonalgrouprelationshippredictiontask.
NoEmotion 22.2 49.1(1.2) 43.4(3.8) 71.6(1.2)
Table6: F1scoresontestset, withSDinparentheses,
In-group Out-group
forinterpersonalemotionlabellingtask.
thanks,love,countme thanks,bipartisan,restore
birthday,mycolleague kind,resignation
Emotion BERTweet MultiTask
Table 5: Top unigram and bigram features from NB-
Admiration 77.9(2.6) 72.8(3.9)
SVMmodelforeachclass. Anger 71.7(9.9) 69.4(3.4)
Disgust 48.2(22.4) 75.9(6.5)*
2e-5. Dropoutprobabilitiesinclassificationheads Table 7: F1 scores on test set, SD in parentheses on
out-group tweets. * indicates statistical significance
wassetat0.1. Thebestperformingmodelbefore
(p<0.05)
earlystoppingonvalidationdatawaschoseninall
cases. WereportF1scoresaveragedover3random
restartsforallmodels,withthestandarddeviation
Multitask Model As Table 4 shows, Multi-
inparenthesesnexttothemean.
taskingthetwotasksleadstoanoticeableimprove-
ment in F1 for IGR prediction, with the differ-
6 ResultsandAnalysis ences being statistically significant using a boot-
straptest(p<0.05;Berg-Kirkpatricketal.,2012);
InterpersonalGrouprelationship Inmodeling themulti-taskmodelisalsomorestablewithmuch
IGR, we find that Sentiment-Rule performs not lowervarianceacrossruns. Theseresultssuggest
much better than chance (Table 4). This under- that interpersonal emotion is useful towards IGR
scoresonestrengthofourdata, whichcontainsa prediction.
sizablenumberofout-grouptweetswithpositivein-
Table6showsthattheperformanceofthemul-
terpersonalemotionattachedtothem. TheNB-SVM
titaskmodelonpredictinginterpersonalemotions
model based on unigrams and bigrams performs
is significantly better that the BERTweet model
slightlybetter,andpicksuponsomeobviousout- (p<0.05)onemotionslikedisgust,whichsuggests
grouplexicalcueslikethelemma‘bipartisan’,as
thatIGRisusefultowardsthetaskofemotioniden-
showninTable5. TheBERTweetmodelperforms
tification. Furthermore,multitaskingboostedper-
substantiallybetter,performingover10pointsbet- formanceatpredictingthenoemotionlabelby20%.
terthanhumans. Themodel,withonlytheclassifi-
Table 7 compares the multitask model’s perfor-
cationheadfinetuned,leavingthelanguagemodel manceagainsttheBERTweetmodelinout-group
parameters intact(BERTweet-ft) performs about
settings(wheremostofthegainswerefound)for3
10 points above chance — indicating that there
emotions—illustratingtheboostinperformance
maybefeaturesadvantageoustowardsthistaskin
affordedbyjointmodelingofIGRandemotionfor
thevanillaLMitself. digust. The3emotionslistedalsoshowedsignif-
icant differences in their distribution in in-group
InterpersonalEmotion WefindthattheEmoLex andout-groupsettings.
baseline,whichreliespurelyonlexicalcues,per-
formsdismallyonourdata,withpoorperformance Humansvs.Models Comparatively,wefindthat
in both in-group and out-group settings(Table 6). model performance exceeds human performance
This is a strong indication that emotions are ex- onthetaskofin-groupversusout-groupprediction,
pressed more implicitly in this dataset. The albeitnotonthesamedataset. Themodel’smain
BERTweetmodelperformssubstantiallybetter,in- driverofperformanceisitshighaccuracyonposi-
dicating that interpersonal emotions, even if im- tiveintergroupemotionout-grouptweets,suchas
plicit,canbelearned. thoseexpressingadmirationorjoy. Humananno-
tators consistently fall back on the heuristic that overallaffecttowardsthetargetexpressedbythe
sentenceswithpositiveaffectprobablyimplythat speakermighthelpinmodelingIGRbetter.
the speaker is talking about someone in their in-
7 RelatedWork
group. Butitisnotthecaseinthepoliticaldomain,
where overtures to bipartisanship serve as useful
Emotion and Stance Detection A wealth of
signals. Forinstance,both(3-a)and(3-b)express
work has looked at corpora and models for the
admirationtowardsthetargetDoe,wherethefirst
detection of perceived emotion in social media
isin-groupwhilethesecondisout-group. Thecall
text (Mohammad, 2012; Wang et al., 2012; Mo-
tocivilityistheonlysubtlelinguisticcuethatthis
hammad and Kiritchenko, 2015; Abdul-Mageed
tweetmayconstituteout-groupspeech.
andUngar,2017;Desaietal.,2020;Demszkyetal.,
(3) a. Admire@OfficialCBCChairman@Doe’s 2020). Howeverexistingworkdoesn’tdistinguish
moralvoiceonissuesofracismandrestora- between emotion of a sentence as a whole, ver-
tivejustice. Heisarealleaderforournation sus interpersonal emotion towards a target. The
andCongress. task closest to our study of interpersonal emo-
b. Adecadehaspassed,butourfriendshipis tions is stance detection: whether the author has
the same. Proud to work with @Doe to afavourable,neutral,ornegativepositiontowards
#ReviveCivility. #tbtReadmoreaboutour a proposition or target. Mohammad et al. (2016)
effortshere: looked at stance in five target domains are given:
Future work needs to look into what information abortion, atheism, climate change, feminism and
theembeddingsareusingtomaketheirclassifica- Hillary Clinton. While stance detection focuses
tiondecision. on a collectionof utterances with thesame topic,
ourinterest isin modelinginterpersonal emotion
ModelErrors Whilethemultitaskingsetupim- towards a target individual which is more fine-
provesmodelperformanceonthetaskofpredicting grainedandcanvaryineachutterance.
IGR,andoutperformshumanlabelersinoursmall
Intergroup bias in Psychology The Linguistic
pilot,itstillgetssomeeasyexampleswrong,such
IntergroupBias(LIB)theory(Maassetal.,1989;
aslabelling(4)asin-groupeventhoughitexpresses
Maass,1999)statesthatthereisasystematicasym-
somedisgustatthetarget. Themodelalsofallsinto
metryinlanguageproductionqualitiesofaspeaker
thesametrapashumanlabelers—forinstanceas-
asafunctionofthesocialcategorytowhichtheref-
sumingthatatweetexpressingadmirationmustbe
erentofanutterancebelongs. Throughpsycholin-
in-group(5).
guistic experiments, LIB seeks to explain why
(4) Trump selected @USER for HHS Secretary.
stereotypesaretransmittedandpersistindailylife:
Pricehasundeniablehistoryofcuttingaccess
inaninterpersonalsituation,sociallydesirablein-
tohealthcaretomillions,especiallywomen.
groupbehaviorsandundesirableout-groupbehav-
(5) Inspiring speech from @USER - we have a
iors are encoded at a higher level of abstraction,
duty to represent our country with respect &
whereas socially undesirable in-group behaviors
dignity. #NationalDayofCivility.
anddesirablein-groupbehaviorsareencodedata
ToensurethatmodelperformanceonIGRpredic- lowerlevelofabstraction. Workinpsychologyand
tionisnotlimitedbythesizeofourtrainingdata, psycholinguistics reproduced LIB in various do-
we experimented with training BERTweet models mainssuchaspoliticalnewsreporting(Anollietal.,
on larger datasets. Since we have ‘found super- 2006)andcrimereporting(Gorham,2006);aswell
vision’ for IGR labels, we only need to increase asworkexploringhowLIBcanbeusedasanindi-
trainingdatasizebysamplingmoretweetsfromrel- catorforaspeaker’sprejudicialattitudes(Hippel
evantaccountsusingthesameproceduredetailed etal.,1997),orasapredictorforracism(Schnake
in§3.1. WefoundthatF1scoredoesnotincrease andRuscher,1998).
withmoretrainingdata. ContemporaneousstudiesonLIB,however,are
Futureworkneedstolookintolinguisticallymo- hand-coded and have so far tended to focus on
tivated ways to improve model performance on narrow concepts such as abstractness of the verb
the IGR task. Since we have observed that the andcoarsenotionsofsentiment. Nonetheless,the
multi-tasksetupimprovesmodelperformance,per- LIB hypothesis connects the two dimensions of
hapsothermulti-tasksetups,suchasmodelingthe interpersonal dynamics studied here with a third
dimensiondirectlyrelatedtosemanticproperties ferentfine-grainedemotionalconstructsandstudy
oftheutterance. theircorrelationswiththeunderlyinglinguisticbi-
ases. Future work may also look into the gener-
8 Conclusion
alizability of the results presented here in other
domainsoflanguageuse.
Takingacuefromstudiesofbiasinsocialscience
Whilewepresenttheutterancesasconstituting
and psychology, we situate bias in language use
naturalspeechbyonespeaker(thecongressperson
throughthelensofinterpersonalrelationshipsbe-
whosentthetweet),itislikelymostcongresspeo-
tweenthespeakerandtargetofanutterance, and
pleemploysocialmediateamsthathelpincrafting
the speaker’s interpersonal emotional state with
thelanguageofsomeoftheirtweets. However,we
respect to the target. Over a corpus of tweets by
believe for the sake of interpersonal group mem-
membersofUSCongress,weintroducetwonovel
bership,therelationshipbetweenthespeakersand
tasks–interpersonalgrouprelationshipprediction
theirtargetswouldnotbeaffected.
(IGR)andinterpersonalemotionlabelling,tobet-
Finally, while we show that transformer based
terunderstandvariationinlanguageasafunction
modelsperformbetteratIGRpredictionthanhu-
of social relationship between speaker and target
mans,wenotethatthehumanperformancewason
in interpersonal utterances. We find certain inter-
asmallsubsetoftestdata. Whileitispossiblethat
personalemotionslikeangeranddisgustareover-
thesemodelsdiscoveredlatentfeaturesthatcould
representedinout-groupsituations,withthemajor-
explaintheirbetterperformance,themodelcould
ityofthenegativeemotionsdirectedatleadersof
alsobeusingspuriousfeaturesidiosyncratictoour
thetwopoliticalparties. Throughmodelingstud-
dataset,ratherthantruedifferencesinin-groupver-
ies,wefindthattransformerbasedmodelsperform
susout-groupspeech.
betterthanhumansatpredictingIGRgivenanutter-
ance,raisingthequestionastowhatlatentfeatures
Acknowledgements
oflanguagethemodelusestomakethisdecision.
Finally, we also find that joint modelling of the ThisresearchispartiallysupportedbyNSFgrants
two dimensions is beneficial to prediction of cer- IIS-2107524,IIS-2145479andGoodSystems,2 a
taininterpersonalemotionsinout-groupsituations. UT Austin Grand Challenge to develop respon-
Future work needs to look into what information sible AI technologies. We also acknowledge the
is useful for predicting IGR and emotions – with TexasAdvancedComputingCenter(TACC)3atUT
the Linguistic Intergroup Bias literature offering Austinforprovidingthecomputationalresources
a clue as to which higher level semantic features formanyoftheresultswithinthispaper.
varysystematically.
EthicsStatement References
Forourcorpusoftweetsonwhichweperformed Muhammad Abdul-Mageed and Lyle Ungar. 2017.
EmoNet: Fine-Grained Emotion Detection with
annotations,wedownloadedthetweetsusingthe
Gated Recurrent Neural Networks. In Proceedings
officialTwitterAPI.InaccordancewiththeTwitter
of the 55th Annual Meeting of the Association for
Terms of Service, we release tweet IDs and user- ComputationalLinguistics(Volume1:LongPapers),
names,butnotthetweettextitself. Ourdatasetwas pages718–728,Vancouver,Canada.Associationfor
ComputationalLinguistics.
built through crowdsourced annotations on Ama-
zonMechanicalTurk. Toensureannotatorswere
RoeeAharoniandYoavGoldberg.2020. Unsupervised
paid a fair wage of at least $10 an hour, we paid DomainClustersinPretrainedLanguageModels. In
annotators$0.50perHIT.EachHITinvolvedan- Proceedingsofthe58thAnnualMeetingoftheAsso-
ciation for Computational Linguistics, pages 7747–
notating 3 tweets, which we estimate to take on
7763, Online. Association for Computational Lin-
average3minutestocomplete.
guistics.
Limitations Luigi Anolli, Valentino Zurloni, and Giuseppe Riva.
2006. Linguistic Intergroup Bias in Political Com-
Ourresultsshowtheimportanceofhavingreliable munication. The Journal of General Psychology,
andaccurateemotionpredictionmodels,whichis 133:237–255.
anopenprobleminpsychologyandcomputersci- 2http://goodsystems.utexas.edu
ence. Futureworkmightlookintoidentifyingdif- 3https://www.tacc.utexas.edu
Francesco Barbieri, Jose Camacho-Collados, Luis Es- SaifMohammad.2012. #EmotionalTweets. In*SEM
pinosa Anke, and Leonardo Neves. 2020. Tweet- 2012: The First Joint Conference on Lexical and
Eval: Unified Benchmark and Comparative Evalu- ComputationalSemantics–Volume1: Proceedings
ation for Tweet Classification. In Findings of the ofthemainconferenceandthesharedtask,andVol-
AssociationforComputationalLinguistics: EMNLP ume2: ProceedingsoftheSixthInternationalWork-
2020, pages 1644–1650, Online. Association for shoponSemanticEvaluation(SemEval2012),pages
ComputationalLinguistics. 246–255, Montréal, Canada. Association for Com-
putationalLinguistics.
DavidBeaverandJasonStanley.2018. TowardaNon-
Ideal Philosophy of Language. Graduate Faculty Saif Mohammad, Svetlana Kiritchenko, Parinaz Sob-
PhilosophyJournal,39(2):503–547. hani, Xiaodan Zhu, and Colin Cherry. 2016.
SemEval-2016 Task 6: Detecting Stance in Tweets.
Taylor Berg-Kirkpatrick, David Burkett, and Dan In Proceedings of the 10th International Workshop
Klein. 2012. An Empirical Investigation of Statis- onSemanticEvaluation(SemEval-2016),pages31–
tical Significance in NLP. In Proceedings of the 41,SanDiego,California.AssociationforComputa-
2012JointConferenceonEmpiricalMethodsinNat- tionalLinguistics.
ural Language Processing and Computational Nat-
Saif M. Mohammad and Svetlana Kiritchenko. 2015.
ural Language Learning, pages 995–1005, Jeju Is-
UsingHashtagstoCaptureFineEmotionCategories
land,Korea.AssociationforComputationalLinguis-
fromTweets. ComputationalIntelligence, 31:301–
tics.
326.
Dorottya Demszky, Dana Movshovitz-Attias, Jeong-
Saif M. Mohammad and Peter D. Turney. 2013.
woo Ko, Alan Cowen, Gaurav Nemade, and Su-
Crowdsourcing a Word-Emotion Association Lexi-
jith Ravi. 2020. GoEmotions: A Dataset of Fine-
con. ComputationalIntelligence,29.
Grained Emotions. In Proceedings of the 58th An-
nual Meeting of the Association for Computational Dat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen.
Linguistics, pages 4040–4054, Online. Association 2020. BERTweet: A pre-trained language model
forComputationalLinguistics. for English Tweets. In Proceedings of the 2020
Conference on Empirical Methods in Natural Lan-
Shrey Desai, Cornelia Caragea, and Junyi Jessy Li. guageProcessing:SystemDemonstrations,pages9–
2020. Detecting Perceived Emotions in Hurricane 14.AssociationforComputationalLinguistics.
Disasters. InProceedingsofthe58thAnnualMeet-
ingoftheAssociationforComputationalLinguistics, RobertPlutchik.2001. TheNatureofEmotions. Amer-
pages5290–5305,Online.AssociationforComputa- icanScientist,89(4):344–350.
tionalLinguistics.
Reid Pryzant, Richard Diehl Martinez, Nathan Dass,
BradleyW.Gorham.2006. NewsMedia’sRelationship Sadao Kurohashi, Dan Jurafsky, and Diyi Yang.
With Stereotyping: The Linguistic Intergroup Bias 2020. Automatically Neutralizing Subjective Bias
in Response to Crime News. Journal of Commu- inText. ProceedingsoftheAAAIConferenceonAr-
nication, 56(2):289–308. Place: United Kingdom tificialIntelligence,34(01):480–489.
Publisher: BlackwellPublishing.
Tim Sainburg, Leland McInnes, and Timothy Q Gen-
tner.2021. ParametricUMAPEmbeddingsforRep-
W.Hippel,DeniseSekaquaptewa,andP.Vargas.1997.
resentation and Semisupervised Learning. Neural
The Linguistic Intergroup Bias As an Implicit Indi-
Computation,33(11):2881–2907.
cator of Prejudice. Journal of Experimental Social
Psychology,33:490–509.
Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-
sky, Noah A. Smith, and Yejin Choi. 2020. Social
Masahiro Kaneko and Danushka Bollegala. 2019.
Bias Frames: Reasoning about Social and Power
Gender-preserving Debiasing for Pre-trained Word
Implications of Language. In Proceedings of the
Embeddings. In Proceedings of the 57th Annual
58thAnnualMeetingoftheAssociationforCompu-
Meeting of the Association for Computational Lin-
tational Linguistics, pages 5477–5490, Online. As-
guistics,pages1641–1650,Florence,Italy.Associa-
sociationforComputationalLinguistics.
tionforComputationalLinguistics.
SherryBSchnakeandJanetBRuscher.1998. Modern
AnneMaass.1999. LinguisticIntergroupBias: Stereo- Racism as a predictor of the Linguistic Intergroup
type Perpetuation Through Language. In Mark P. Bias. Journal of Language and Social Psychology,
Zanna,editor,AdvancesinExperimentalSocialPsy- 17(4):484–491.
chology,volume31,pages79–121.AcademicPress.
Emily Sheng, Kai-Wei Chang, Prem Natarajan, and
Anne Maass, Daniel Anthony Salvi, Luciano Arcuri, Nanyun Peng. 2020. Towards Controllable Biases
and Gün R. Semin. 1989. Language use in inter- inLanguageGeneration. InFindingsoftheAssoci-
groupcontexts: thelinguisticintergroupbias. Jour- ationforComputationalLinguistics: EMNLP2020,
nalofPersonalityandSocialPsychology,576:981– pages3239–3254,Online.AssociationforComputa-
93. tionalLinguistics.
Emily Sheng, Kai-Wei Chang, Premkumar Natarajan,
and Nanyun Peng. 2019. The Woman Worked as a
Babysitter: On Biases in Language Generation. In
Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the
9th International Joint Conference on Natural Lan-
guage Processing (EMNLP-IJCNLP), pages 3407–
3412,HongKong,China.AssociationforComputa-
tionalLinguistics.
TeunAVanDijk.2009. SocietyandDiscourse: How
SocialContextsInfluenceTextandTalk. Cambridge
UniversityPress.
SidaWangandChristopherManning.2012. Baselines
and Bigrams: Simple, Good Sentiment and Topic
Classification. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics(Volume2:ShortPapers),pages90–94,Jeju
Island, Korea. Association for Computational Lin-
guistics.
Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,
and Amit P. Sheth. 2012. Harnessing Twitter "Big
Data" for Automatic Emotion Identification. In
2012InternationalConferenceonPrivacy,Security,
Risk and Trust and 2012 International Confernece
onSocialComputing,pages587–592.
AlbertWebson,ZhizhongChen,CarstenEickhoff,and
Ellie Pavlick. 2020. Are “Undocumented Workers”
theSameas“IllegalAliens”?DisentanglingDenota-
tionandConnotationinVectorSpaces. InProceed-
ings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
4090–4105, Online. Association for Computational
Linguistics.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, ClementDelangue, AnthonyMoi, Pier-
ric Cistac, Tim Rault, Rémi Louf, Morgan Fun-
towicz, Joe Davison, Sam Shleifer, Patrick von
Platen, Clara Ma, Yacine Jernite, Julien Plu, Can-
wen Xu, Teven Le Scao, Sylvain Gugger, Mariama
Drame, Quentin Lhoest, and Alexander M. Rush.
2020. Transformers: State-of-the-Art Natural Lan-
guageProcessing. InProceedingsofthe2020Con-
ferenceonEmpiricalMethodsinNaturalLanguage
Processing: System Demonstrations, pages 38–45,
Online.AssociationforComputationalLinguistics.
Samira Zad, Joshuan Jimenez, and Mark Finlayson.
2021. Hell Hath No Fury? Correcting Bias in
the NRC Emotion Lexicon. In Proceedings of the
5thWorkshoponOnlineAbuseandHarms(WOAH
2021),pages102–113,Online.AssociationforCom-
putationalLinguistics.
