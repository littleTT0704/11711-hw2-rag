PublishedasaconferencepaperatICLR2023
AANG: AUTOMATING AUXILIARY LEARNING
LucioM.Dery1∗ PaulMichel2 MikhailKhodak1 GrahamNeubig1 AmeetTalwalkar1,3
1CarnegieMellonUniversity 2ENSPSLUniversity 3HewlettPackardEnterprise
ABSTRACT
Auxiliaryobjectives,supplementarylearningsignalsthatareintroducedtohelp
aid learning on data-starved or highly complex end-tasks, are commonplace in
machinelearning. Whilstmuchworkhasbeendonetoformulateusefulauxiliary
ICMLExperiments
objectives,theirconstructionisstillanartwhichproceedsbyslowandtedioushand-
derylucio
design. Intuitionforhowandwhentheseobjectivesimproveend-taskperformance
November2021
has also had limited theoretical backing. In this work, we present an approach
forautomaticallygeneratingasuiteofauxiliaryobjectives. Weachievethisby
deconstructingexistingobjectiveswithinanovelunifiedtaxonomy, identifying
connections between them, and generating new ones based on the uncovered
structure. Next, we theoretically formalize widely-held intuitions about how
auxiliary learning improves generalization on the end-task. This leads us to a
principledandefficientalgorithmforsearchingthespaceofgeneratedobjectives
tofindthosemostusefultoaspecifiedend-task. Withnaturallanguageprocessing
(NLP)asourdomainofstudy,wedemonstratethatourautomatedauxiliarylearning
pipelineleadstostrongimprovementsovercompetitivebaselinesacrosscontinued
trainingexperimentsonapre-trainedmodelon5NLPtasks1.
1 INTRODUCTION
The auxiliary learning paradigm,
Objective Data( ) Transform( ) Representation( ) Output( )
where we augment a primary D T R O
BERT Out-of-domain BERT-Op Bidirectional DenoiseToken
objective with extra learning TAPT Taskdata BERT-Op Bidirectional DenoiseToken
signals to boost end-task DAPT In-domain BERT-Op Bidirectional DenoiseToken
performance, is a staple of ELMO Out-of-domain No-Op Left-to-Right NextToken
andRight-to-Left
many machine learning (ML)
GPT Out-of-domain No-Op Left-To-Right NextToken
domains. In natural language XLNet Out-of-domain No-Op Randomfactorized NextToken
processing (NLP), well known Electra NeuralLMData Replace Bidirectional Real/Synthetic
models like SpanBERT (Joshi ... ... ... ... ...
et al., 2020) and RoBERTa (Liu
Figure 1: We present the dec1omposition of some auxiliary
et al., 2019b) are trained on
objectivesinNLPwithinourframework.
masked language modelling
(MLM)auxiliaryobjectives(Devlinetal.,2018)beforefine-tuningontheend-task. Andforspeech
processingandreinforcementlearning(RL),Oordetal.(2018)introducedthepopularcontrastive
predictive coding objective which achieved state of the art performance in many settings when
multi-taskedwiththeend-task. Despitethesesuccessesandmanymore,researchintodevisingsuch
objectiveshasprogressedinaverylocal,objective-by-objectivemanner(Raffeletal.,2019;Clark
etal.,2020;Grilletal.,2020;Chenetal.,2020). Auxiliaryobjectivesareconstructedbyhand-design
andwithoutmuchoverarchingstructure,relyingontheexperienceandintuitionofaselectgroup
ofresearchersversedatmakingappropriatedesignchoices. Unfortunately,thisstatus-quonotonly
createsatechnicalbarrierofentryforexploringauxiliaryobjectivesinnewdomainsbutalso,by
virtueofitsincrementalnature,limitstherateatwhichnewobjectivesarediscoveredandinvestigated.
Toaddresstheabovechallenges,thispaperpresentsaframeworkforautomaticallygeneratingand
utilizingalargesetofcandidateauxiliaryobjectives. Ourframeworkisseededbythefollowingkey
observation: leadingauxiliaryobjectivesacrossmultipledomainscanbeviewedasmakingdifferent
design decisions within a 4 stage pipeline: Input Data ( ) Input Transformation ( )
D → T →
∗Correspondenceto:ldery@andrew.cmu.edu
1Codeavailableat:https://github.com/ldery/Automating-Auxiliary-Learning.
1
3202
beF
72
]GL.sc[
2v28041.5022:viXra
PublishedasaconferencepaperatICLR2023
Model Representation ( ) Output ( ). For instance, in RL, a common auxiliary objective
R → O
istopredicttheenvironment’sforwarddynamics(Agrawaletal.,2016;Hafneretal.,2019). To
construct this objective, the current task state-action pair ( ) is corrupted ( ) and then passed
D T
throughthemodeltoproducealatentrepresentation( )whichisfinallyusedtopredictthenext
R
state( ). Similarly,inNLP,theXLNet(Yangetal.,2019)objective—whichperformslanguage
O
modellingonarandomlyfactorizedpermutationoftheinput—canbewrittenwithinourtaxonomyas
=Out-of-Domain, =No-op, =Random-Factorized, =NextToken . Thesetwoexamples
{D T R O }
(alongwithotherslistedinFigure1)fallwithinaclasswetermnamedobjectives: objectivesthat
havebeenpreviouslyproposedintheauxiliarylearningliterature.
Decomposing named objectives Data( ) Transform( ) Representation( ) Output( )
D T R O
within our taxonomy provides Out-of-domain No-Op Bidirectional NextToken
a unified view of the auxiliary In-domain Replace Left-to-Right Real/Synth
Taskdata Mask Right-to-Left DenoiseToken
learning landscape. From this NeuralLMData ⇥ Noisingembeds ⇥ Rand. factorized ⇥ TF-IDF
vantage point, it becomes clear ... ... ... ...
that there are many unexplored
#
combinations of the various
TAPT= Taskdata BERT-Op Bidirectional DenoiseToken
primitives used across named GPT={ Out-of-dom! ain No-Op! Left-to-Righ! t NextToken }
{ ! ! ! }
objectives. This presents a New-Obj1= {Taskdata !BERT-Op !Left-to-Right !DenoiseToken }
simpleformulaforautomatically
New-Obj2= {In-domain !No-Op
..! .
RandomFactorized !TF-IDF
}
Figure 2: Our framework in the context of NLP. We
generatingalargesetofcandidate
decomposenamedobjectiveswithinourfourstagedtaxonomy:
objectives: take the cartesian
, , , . Bytakingthecartesianproductofchoicesacross
product of the design decisions
{D T R O}
stages,wereproducenamedobjectivesanddiscovernewones.
across given stages (Figure 2).
Using this compositional process, not only can we reconstruct existing named objectives, we
canalsogeneratenewcombinations. Thisovercomesthetediumofimplementingeachobjective
independentlysincewecanjustreuseasmallsetofsimplestage-wiseprimitives.
Generatingalargesetofobjectivesraisesthenaturalquestionofhowtoefficientlyselectthemost
helpfulonesforagivenendtask.Insteadofleavingthistopractitionerintuition,wedevelopprincipled
guidelinestoaddressthisquestionbytheoreticallystudyingtheimpactofauxiliarylearningona
particularend-task. Specifically,usingargumentsbasedonalgorithmicstability(Hardtetal.,2016;
2
Bousquet&Elisseeff,2002),wederiveend-taskgeneralizationerrorboundsthataredependenton
thechoiceofauxiliarytask. Thiscontributestoexistingtheory(Saunshietal.,2020;Xieetal.,2021)
onhowauxiliarylearningimpactstheend-taskbysuggestinganewcandidatemechanism: auxiliary
learningresultsinmorestableoptimizationend-pointsinthesenseofBousquet&Elisseeff(2002),
whichintheoryimprovesgeneralizationofthefinalmodel.
Guidedbyourtheory,weintroduceAANG(AutomatingAuxiliaryLearniNG),anefficient,structure-
awarealgorithmforadaptivelycombiningasetofrelatedobjectivestoimprovegeneralizationona
specificend-task. AANGincorporatesthefollowingprescriptionsfromourtheory: (i)auxiliarytasks
thataremoresimilartotheend-taskaredesirable. Givenasetofobjectives,AANGlearnsadaptive
weightstobringthecompositeobjectiveclosertotheend-task;(ii)ingeneral,moreauxiliarydatais
better. AANGmaximizestheeffectiveamountofdatausedintrainingbyusingallthegenerated
objectivesinsteadoftakingtask-specificsubsets.
Toempiricallyvalidateourmethodforautomaticallygeneratingandutilizingauxiliaryobjectives,
we experiment on five NLP tasks. We do so in the widely-used setting of continued pre-
training(Gururanganetal.,2020;Aghajanyanetal.,2021;Deryetal.,2021b;Zhangetal.,2022),
where a model trained with a single auxiliary objective on large-scale data is further trained on
end-taskrelateddata. Withoutintroducinganyexternaldataorarchitecturalmodifications,variants
of AANG outperform strong and widely used baselines in 4 out of 5 tasks. AANG achieves an
averageimprovementof4.2%overstandardfine-tuningofRoBERTaacrossourchosentasks. We
believeourresultswillspurfurtherresearchintoexploringautomatingauxiliarylearningacrossa
varietyofsettings. Notably,whilewefocusonNLPwhendiscussingthespaceofauxiliaryobjectives
(Section3)andinourempiricalevaluation(Section6),ourtheoreticalresults(Section4)andAANG
itselfaredomain-agnostic2.
2OurideascouldbeappliedtodomainslikeRLorcomputervision(CV),whereasimilardissectionof
existingobjectivescanbeperformed.
2
PublishedasaconferencepaperatICLR2023
2 RELATED WORK
Toproperlyscopethiswork,wedefineauxiliarylearningastrainingamodelonalternativeobjectives
with the goal of improving performance on some primary end-task. Auxiliary learning is an
instantiation of transfer learning (Caruana, 1997; Baxter, 2000; Ruder et al., 2019). It covers
thepretrain-then-finetuneparadigm(Huhetal.,2016;Devlinetal.,2018;Schneideretal.,2019;
Gururanganetal.,2020)aswellasend-taskawaremultitaskingapproaches(Linetal.,2019;Dery
etal.,2021a;b). Whilstauxiliaryobjectivesmaybemeta-learned(Liuetal.,2019a;Navonetal.,
2020),forsimplicity–sinceincorporatingthesewouldrequirefurthercomplicationofourdesign
space–suchobjectivesareoutofthescopeofthispaper.
This work bears many parallels to the area of neural architecture search (NAS) (Stanley &
Miikkulainen,2002;Zoph&Le,2016;Robertsetal.,2021). Whilstweseektoautomateauxiliary
learning,theobjectiveofNASistoautomatethediscoveryoftherightneuralarchitecturegivena
specificend-task. Searchspacesofcandidatearchitecturesarecreatedbytakingthecartesianproduct
ofarchitecturedesignchoicesacrossthedepthofthenetwork. Thedesignofsuitablearchitectural
searchspacesforavarietyofsettingshasbeenanactiveareaofresearch(Tan&Le,2019;Howard
etal.,2019;Daoetal.,2020;Robertsetal.,2021). TodevelopAANG,weborrowideasfromthe
NAS literature on efficient algorithms for sifting through spaces of architectures. Mirroring the
populardifferentiableNASmethodDARTSLiuetal.(2018),weperformacontinuousrelaxation
overthesearchspaceofobjectives,allowingforefficientsearchbygradientdescent. Wealsousea
factoredapproachtomodelrelationshipsbetweenobjectivesthatshareprimitives. Thisisinspiredby
recentworkonstochastic-relaxationweightsharing(Dong&Yang,2019;Lietal.,2020).
Asatheoreticalcontribution, thisworkderivesanend-taskawaregeneralizationerrorboundfor
auxiliarylearning. OurboundisbuiltonthatofHardtetal.(2016),whoderivegeneralizationbounds
forparametricmodelstrainedwithstochasticgradientdescent(SGD).Toderivetheirbounds,they
leveragetheconceptofalgorithmicstabilityintroducedbyBousquet&Elisseeff(2002). Informally,a
randomizedalgorithmisuniformlystableifchangingasingletrainingdatapointinthegivensamples
doesnotchangeitsend-pointtoomuch. Saidchangeischaracterizedastheaveragedifferencein
predictionsbetweenthetwolearnedmodels. Stabilityimpliesgeneralizationinexpectation(Hardt
etal.,2016;Kuzborskij&Lampert,2018).
3 AUTOMATICALLY GENERATING AUXILIARY OBJECTIVES
Tobegin,wetakeahigh-levelviewofthelandscapeofnamedobjectives. Usingrunningexamples
from NLP, we propose the following coarse structure for the sequence of choices made in the
hand-designofauxiliaryobjectives:
1. Data, : Auxiliaryobjectivepipelinesbeginwithachoiceofinputdata. Here,optionscanrange
D
fromheterogeneousout-of-domaindata(Radfordetal.,2019),in-domaindatawithrespecttothe
finalend-task(Beltagyetal.,2019)orthetaskdataitself(Gururanganetal.,2020). Itmayeven
includedataoutsidethemodalityoftheend-task.
2. Input-Transformation, : Manyauxiliaryobjectivesareself-supervisedwithrespecttotheir
T
input data. They corrupt or transform the input and then reconstruct it in whole or part. For
example,inputtexttokenscanbemasked,replacedordeleted. Operationscanalsobeaggregated
asinBERT-Op: mask80%ofselectedtokensandrandomlyreplace50%oftheremainingDevlin
etal.(2018);Liuetal.(2019b).
3. Representation, : After transformation, representations of the input data can be computed
R
fromagivenmodelindifferentways. Achosentoken’srepresentationcandependononlyits
leftcontext(Left-to-Right)(Radfordetal.,2018)oritsrightcontext(Right-to-Left)(Petersetal.,
2018). Itcouldalsodependontherepresentationsofarandomlyselectedpermutationofother
tokens(RandomFactorized)Yangetal.(2019).
4. Output, : Finally,representationsobtainedfromthepreviousstagearefedintoalossfunction
O
producing a final output. The choice of output loss is usually coupled with the choice of
transformation made in stage 2. Choices include but are not restricted to denoising tokens,
predictingthenexttokenorpredictingtheTF-IDF(TermFrequency-InverseDocumentFrequency)
ofatoken.
3
PublishedasaconferencepaperatICLR2023
Theabovetaxonomy isexpansiveenoughtocoverarangeofnamedauxiliary
objectivesofinterest{ inD N→ LPT (F→ iguR re→ 1)3O
.
F}
orexample,wecanwriteanymemberoftheGPTseries
(Radfordetal.,2018;2019;Brownetal.,2020)whichperformleft-to-rightlanguagemodellingon
out-of-domaindataas =Out-of-Domain, =No-op, =Left-To-Right, =NextToken . We
{D T R O }
cansummarizethepre-existingchoiceswithineachdesignstagetoobtainauniquesetofoptions. For
example,wecanreducethesetofmodelrepresentationtypesusedbytheobjectivesenumeratedin
Figure1totheuniqueset = Bi-directional,Left-To-Right,Right-To-Left,Random-Factorized .
R { }
Havingsummarizedthelistofprimitiveswithineachstage,asimpleformulaforgeneratingaspaceof
auxiliaryobjectivesbecomesapparent: takethecartesianproductofthedesignchoicesateachstage
(seeFigure2). Ingeneral,givenaninstanceofourtaxonomy,wecanconstructaspaceofobjectives
= ofsize . ConsiderNew Obj fromFigure2. This
A D×T ×R×O |A|≤|D|×|T|×|R|×|O| 1
previouslyunexploredobjectivecanbeobtainedbycombiningthespecialmaskingoperationfrom
BERT(BERT-Op)withcomputingmodelrepresentationsbasedonleft-to-rightcausalmaskingasin
GPT.Infact,thisobjectiveprovedoneofthemostusefulonesinourexperimentsbelow(seeFigure5).
Ourframeworkalsoallowsustoreasonaboutwholefamiliesofobjectives, ,bythinkinginterms
F
ofdesignstagesandchoices. Forexample,givenaparticularend-taskEwithinputtextE ,we
D
can create a family of objectives based solely on task data by fixing to that option in our input
datastage;wecallthisfamily . notonlyincludespre-existingTAPTGururangan
FD=ED FD=ED
etal.(2020)butalsounexploredobjectivesliketask-datadependentvariantsofXLNET,ELMO
etc. Auxiliarylearningwith canbeseenasarelaxedformofdataaugmentationwhichwe
FD=ED
dubtaskaugmentation. Whilstdataaugmentationrequiresapplyingtransformationsthatpreserve
thedata-point’slabel,taskaugmentationhasnosuchrestrictionandthusoffersgreaterflexibility
intermsofspecifying , , . Wecanalsoreasonaboutexpandingparticularstagestoinclude
{T R O}
newprimitives. Anysupervisedlosscanbeaddedtotheoutputstage, ,allowingustopotentially
O
exploreauxiliaryobjectivesbasedonsupervisedsignalslikeNERorPOStagging(Carrerasetal.,
2003;Charniak,1997). Aspecialexampleissetting totheend-tasksupervisedoutputE . This
O
leadsto O=EO whichisasubsetof . O=OEO includesmanyobjectiveslikepredicting
FD=ED FD=ED FD=ED
the end-task signal from corrupted input data. In Section 6, we will introduce a search space of
objectivesthatleveragestaskaugmentation.
4 THE IMPACT OF AUXILIARY LEARNING ON END-TASK GENERALIZATION
Inthissection,werelieverelianceonpractitionerintuitionbyderivingasetofguidingprinciples
onhowtoeffectivelyutilizetheautomaticallygeneratedobjectivesfromSection3.
Auxiliarylearninginfluencestheend-taskthroughbothtrainingandgeneralizationerror. Previous
theoryhaslargelyfocusedoncharacterizingtheimpactonend-tasktrainingerror. Liuetal.(2021),
forexample,showthatend-taskagnosticpre-trainingcancreateaperformancegapintrainingerror
comparedtotrainingwiththeend-taskalone. Thesizeofthisgapdependsonhowdissimilarthe
pre-trainingauxiliaryobjectiveisfromtheend-task. Theyintroducethefollowingassumption(which
wewillborrow)toformalizetheirnotionoftasksimilarity:
AssumptionA.1: Letf representtheend-taskobjectiveandf betheauxiliaryobjective. There
e a
exists∆ 0suchthat f (θ) f (θ) ∆ θ.
a e
≥ (cid:107)∇ −∇ (cid:107)≤ ∀
Notethatθrepresentsalltheparametersofthemodel. Smaller∆impliesf ismoresimilartothe
a
primarytaskf .Liuetal.(2021)boundtheend-taskagnostictrainingerrorgaptobelogarithmicin∆.
e
Unlike training error, end-task generalization error has gone unstudied in the auxiliary learning
setting.Boundingthegeneralizationerrornotonlyaddstoourtheoreticalunderstandingoftheimpact
ofauxiliarylearningbutalsoprovidesinsightstoguidealgorithmdesign. Toarriveatabound,we
adaptthetechniqueofHardtetal.(2016)whoderiveageneralizationboundontrainingwithonlythe
end-taskviastochasticgradientdescent. Weconsidertheend-taskawaresettingwheretheend-task
ismulti-taskedwiththeauxiliaryobjective. Thissettinghasrecentlybeenshowntoimproveend-task
performanceoverthepretrain-then-finetuneparadigm(Deryetal.,2021a;b;Yaoetal.,2021).
AuxiliarylearningwithDynamicSampling: Wearegivenanauxiliaryobjectivef (;z) [0,1]
a
· ∈
withN samplesS =(z ,...,z )fromthedistribution . f caneitherbeasingleobjectiveor
a a 1 Na Da a
3Althoughthistaxonomyisquiteexpansive, itobviouslydoesnotconsiderotherelementsofobjective
creationsuchaschoiceofmodelarchitecture,optimizersettings,etc.
4
PublishedasaconferencepaperatICLR2023
aweightedlinearcombinationofobjectives: f =(cid:80) wkfk. AtanyiterationofSGD,wesample
a k a
achoiceoftheend-taskfunctionf ortheauxiliaryobjectivef accordingtotheprobabilitiesλ ,
e a e
λ [0,1] λ +λ =1. Giventhechosenobjective,wesampleadata-pointandperformstochastic
a e a
∈ |
gradientdescentbasedonthesampleddata-point. Wenowpresentourboundinthesettingdescribed.
Theorem4.1(AuxiliarylearningwithDynamicSampling). Assumethatf (;z ),f (;z ) [0,1]
e e a a
∈
are both L-Lipschitz with β and β -smooth loss functions respectively. Consider that we have
e a
N(cid:48) =N e+N atotalsampleswheref eandf ahaveN eandN asamplesrespectively. r e = N Ne (cid:48) isthe
fractionoftheavailabledatarepresentedbytheend-task. Supposethatwerunstochasticgradient
descentforTstepswithmonotonicallynon-increasingstepsizesα c bydynamicallysampling
t ≤ t
thetasksaccordingtoλ andλ . Then,withrespecttof ,thegeneralizationerrorisboundedby:
e a e
(cid:15)
gen
(cid:47) (cid:0) ∆)1+cλ1
∗β∗(cid:18)
γ NT
(cid:48)(cid:19)1− cλ∗β1
∗+1 Where γ = λ re (1)
e
Hereβ∗ =min β ,β andλ∗istheweightingofthefunctionwithsmallersmoothness.
e a
{ }
Proof. SeeAppendixEforfullproofandAppendixFformorediscussion
Asadetailedinspectionoftheproofwillshow,wederiveEquation1byappealingtoalgorithmic
stability (Bousquet& Elisseeff, 2002; Hardt etal., 2016; Kuzborskij & Lampert,2018) (Section
2). To our knowledge, ours is the first work to present an algorithmic stability view to formally
explainhowauxiliarylearninginfluencesend-taskperformance. Equation1surfacesthefollowing
prescriptionsaboutlearningwithauxiliarytasks:
(P ) Smaller∆improves(cid:15) . Thisimpliesthatthemoresimilartheauxiliaryobjectiveistothe
1 gen
end-task(underAssumptionA.1),thelowerthegeneralizationerror.
(P ) LargerN(cid:48)leadstosmaller(cid:15) 4. SinceweusuallyhaveafixedamountoftaskdataN ,wecan
2 gen e
increaseN(cid:48)byaddingmoreauxiliarydataN .
a
5 END-TASK AWARE SEARCH OF STRUCTURED OBJECTIVE SPACES
Guided by Section 4, we build a practical
Algorithm1AANG
methodforexploringasetofobjectives, .
Input:SearchSpace-A A
Factorvectors-{WAll,WI,WT,WR,WO} Whilst the dynamic sampling setting
End-task-E,End-taskweight-λ described in Section 4 is amenable to
e
InitialModelParams-θ ∈RD theoretical consideration, we make a few
0
repeat practical changes to it. First, instead of
Sample a batch of n objectives performing alternating gradient descent
Kn ∼A
by sampling f ,f according to λ ,λ ,
Weighting of objectives in Kn a e e a
we instead use them as multitask weights
Constructwn
and perform joint training. Joint training
fork=1tondo
(d, t, r, o)=[Kn].stages hasbeenfoundtoproducesuperiorresults
k
wk ∝exp(cid:0) WAll +WI+WT+WR+WO(cid:1) comparedtoalternatingoptimizationwhen
(d,t,r,o) d t r o leveragingauxiliaryobjectives(Aghajanyan
wn ←wk etal.,2021). Weperformgradientdescent
k
endfor onthefollowingtotallosswhichinterpolates
Get losses from batches of data betweentheend-taskandtheauxiliaryloss
Lˆ A(Kn,wn)=(cid:80)n k=1wkL k total = λ e E +(1 λ e) K. Here, is
L =λ L +(1−λ )Lˆ L achosensubL setof .− L K
total e E e A
Get gradients and update factors A
(cid:0) Second,asindicatedinSection4,given ,
θ U Ut p p+ d d1 a a, t t{ e e∇ { λWw en uA, sλ ill ne , g} W ∇← I λ, eM WE TTA ,W-TA RR ,WTA ON }θ ut s, inE g, ∇L t wot nal) w
f
ae =can (cid:80)w kr ∈it Ke wth ke
f
akse .t Bas ya Prs ein scg rl ie pto iob njec (Ptiv 1K )e
,
untildone we want to choose wk such that f has
a
Return: θ T asmall∆withthee{ nd-t} askf e. Wewould
also like to set λ such that the bound on (cid:15) is minimized. Whilst a closed form exists for the
e gen
optimalweightingsλ , wk ,itdependsonvariableslike ∆k , βk ,Lthatarehardtoestimate.
e { } { } { a}
4Thisholdsatfixedγwhichweachievebyadjustingλ toaccountforintroducingmoreauxiliarydata.
e
5
PublishedasaconferencepaperatICLR2023
We therefore propose to learn λ , wk in an online, data-driven way. To do this, we build on
e
{ }
top of the META-TARTAN algorithm proposed by Dery et al. (2021b). META-TARTAN is a
meta-learning algorithm that learns adaptive weights for different auxiliary tasks in a way that
prioritizesend-taskgeneralization. Itlearns wk byminimizingthelossontheend-taskvalidation
{ }
set: ∂ ∂L wv E kal ≈−(cid:0) ∇θ Lf ak(cid:1)T(cid:0) ∇θ Lv Eal(cid:1) . Thiscorrespondstolearning {wk }suchthat(cid:0) ∇θf a(cid:1)T(cid:0) ∇θf e)
is maximized. This minimizes one of the terms that contributes to ∆ and thus attempts to fulfil
Prescription(P ). Wecansimilarlylearnλ tominimizetheend-taskvalidationloss. Foramore
1 e
detaileddiscussionofMETA-TARTAN,pleaseseeAppendixB.
So far, we have introduced independent weights, wk , for each objective. This is sufficient in
{ }
thecaseofunrelatedobjectives. However,theobjectivesin shareanunderlyingstructure. We
recognizethisbyusingafactoredapproachtomodeleachwk.A
Weintroduceafactorvectorforeach
ofthe4stagesintroducedinSection3: WD R|D|,WT R|T|,WR R|R| andWO R|O|.
∈ ∈ ∈ ∈
Thistiestogethertheweightsofobjectivesthatshareprimitivesincommon. Tocapturethefact
that an objective can be more than the sum of it parts, we also introduce an independent weight
for each objective : WAll R|D|×|T|×|R|×|O|. Consider the objective k which is generated by
∈
thecompositionoftheoperations d , t , r , o ,itsweightingiscomputedas
: wk exp(cid:0) WAll +WI +W{ T∈ +D WR∈ +T WO(cid:1)∈ . OR urfa∈ ctoO re} dapproachnotonlyallowsus
∝ (d,t,r,o) d t r o
toshareinformationbetweenobjectivesbutitalsoallowsustoanalyzewhichstagesandprimitives
aremostimportanttoaparticularend-taskaftertrainingiscompleted(Section7).
Prescription(P )fromSection4,advocatesforintroducingasmuchauxiliarydataaspossible. As
2
such,insteadoffixingtoaspecificsubsetthroughouttrainingforaparticularend-task,weproposeto
utilizealltheobjectivesin . Thisalsoavoidsthecombinatorialexplosionthatcomeswithexploring
A
subsetsof atatime. canbelargeanddescendingonallof atoncecanbecomputationally
A |A| A
prohibitive. Asanefficientworkaround,ateachtrainingstep,wesampleasubsetof forexecution
A
withMETA-TARTAN.Oursamplesaredrawnfromallof soanyobjectivecangetusedatany
timestep. Becausewemodeleachwk viaafactoredapproaA ch,evenifanobjectiveisnotsampled
itsweightisimplicitlyupdated. Ourapproachisreminiscentofstochastic-relaxationweightsharing
(Phametal.,2018;Dong&Yang,2019;Lietal.,2020)wheresampledarchitecturalprimitivesresult
inupdatestosharedmodelweightswhichcanbeusedbyotherprimitivesthatarenotsampled.
We coalesce all the ideas we have introduced so far into Algorithm 1 which we dub
AANG (AutomatedAuxiliaryLearniNG).Atahigh-level,givenanend-taskE:
1. Wegenerateaspaceofauxiliaryobjectives byleveragingthetaxonomydiscussedinSection3.
A
maycontainauxiliarytasksthatcanimproveourperformanceonE.
A
2. WeleverageMAML-style(Finnetal.,2017)meta-learningtoadaptivelyweighttheobjectivesin
basedonmeasuringeachobjective’sinfluenceonE’svalidationsetloss.
A
3. We make our algorithm scalable by sub-sampling the tasks . By exploiting the underlying
A
structureoftheobjectivesin viaafactoredapproachtomodelingtaskweights,wereducethe
A
impactoftheinexactsub-sampling.
6 EXPERIMENTAL SETTING
Ourexplorationofauxiliarylearninghasmadethefollowingtransitionsfromthestatus-quo: manual
toautomated,singletasktomultitask,end-taskagnostictoend-taskaware. Inthissection,wesetup
experimentstovalidatethesedeviationsfromthestandard.
We focus on continued pre-training (Gururangan et al., 2020; Aghajanyan et al., 2021). In this
setting,weperformfurtherauxiliarylearningonanalreadypre-trainedmodel. Wefavorthissetting
overpre-trainingfromscratch(Liuetal.,2019b;Yangetal.,2019)notonlybecauseitisamore
computationallyfeasiblearenaforexperimentationbutalsobecauseitismorerelevanttomodern
MLsystemswherebuildinguponpre-trainedmodelsisthenorm(Qiuetal.,2020;Duetal.,2020).
ModelDetailsandDatasets: Weuseapre-trainedRoBERTa (Liuetal.,2019b)astheshared
base
modelbase. Weimplementeachauxiliaryobjectiveasaseparateheadontopofthissharedbase.
For classification based objectives, the output head is a 2-layer multi-layer perceptron (MLP)
thatreceivesrepresentationsforthespecialclassificationtoken[CLS](Devlinetal.,2018)from
RoBERTa . Forsequencegenerationobjectives,wemakeacopyofthepre-trainedoutputlayer
base
of RoBERTa for each task. Table 4 in Appendix C provides details of the 5 datasets used.
base
6
PublishedasaconferencepaperatICLR2023
All datasets are low-resource classification tasks. Not only are these datasets more amenable to
meta-learningfromacomputationalstandpoint,butlow-resourcetasksalsobenefitthemostfrom
auxiliarylearning. Wealsochoosethesetasksbecausetheyfeatureinpreviousworkwhichweuse
asbaselines(Gururanganetal.,2020;Deryetal.,2021b)
BaselinesandSearchSpaces: Thefollowingmethodsareend-taskagnosticbaselines. Byend-task
agnostic,wemeanthatthesedonotmultitaskwiththeend-task. Finetuningontheend-taskoccurs
aftertrainingontheauxiliaryobjective.
1. RoBERTa(Liuetal.,2019b): Wesimplyfinetuneapre-trainedRoBERTa ontheend-task.
base
2. TAPT (Gururangan et al., 2020): Continue training RoBERTa on masked language
base
modellingonend-taskdataitselfbeforefinetuningontheend-task.
Thefollowingnamedobjectivesareend-taskawarebaselinesthatuseMETA-TARTAN(Deryetal.,
2021b)bututilizeonly1auxiliarytask. Eachauxiliaryobjectiveismulti-taskedwiththeend-task.
1. GPT-style: Weperformend-taskawaretrainingwithadenoisingauxiliaryobjectivebasedon
left-to-rightcausalmaskingforcomputingrepresentations. =End-taskdata, =No-op, =
{I T R
Left-To-Right, =DenoiseToken .
O }
2. XLNET-style:Thisisadenoisingauxiliaryobjectivethatusesrandomizedmaskingforcomputing
representations. =End-taskdata, =No-op, =Random-factorized, =DenoiseToken .
{I T R O }
3. BERT-style/TAPT:DenoisinginputscorruptedviaBERT-Op: 80%maskingand10%random
replacement. =End-taskdata, =BERT-Op, =Bi-directional, =DenoiseToken . Please
{I T R O }
notethatthisbaselineisequivalenttoMETA-TARTANasintroducedinDeryetal.(2021b).
Table1:AANG-TD(taskdata)has24objectivesandisbasedon
Table1detailsthesearchspaces
onlyend-taskdata. AANG-TD+ED(taskdata+externaldata)
thatweevaluateagainsttheabove
has40objectivesandusesbothend-taskandin-domaindata.
baselines.Thisisbynomeansthe
mostencompassingsearchspace
I T R O
but we leave more expansive
space design to future work. TD End-task BERT-op Bi-directional DenoiseToken
Mask Left-to-Right End-task
Please note that all tasks within
TD+ED End-task Replace Right-to-Left
AANG-TD,andthosewith =
In-Domaindata No-op Random-Factorized
{I
End-task inAANG-TD+ED,areinstantiationsoftaskaugmentationasintroducedinSection3.
}
TrainingDetails: PleaseseeAppendixDformoredetailsabouthyper-parameterconfigurations.
7 RESULTS AND DISCUSSION
Inthissection,weexperimentallyvalidateourcaseforautomatingthecreationofauxiliaryobjectives
andusingtheminanend-taskawaremultitaskfashion.
7.1 GOINGALONGWAYWITHOUTEXTERNALDATA
Wefirstconsiderthesettingwherewerelysolelyonend-taskdata(taskaugmentation),andworkwith
theAANG-TDsearchspace. Thissearchspacehas24objectives. Table2showsthatautomatically
generatingauxiliaryobjectivesfromonlytaskdataandusingthemappropriatelyisproductive.
End-taskawarenessiskey: FromTable2,methodsthatareend-taskawareresultinover1.12%
averageimprovementoverthosethatareend-taskagnosticevenunderthemostgenerouscomparison
(GPT-style 79.84% vs task-agnostic TAPT 78.72%). Knowing the end-task means that at each
iteration, AANG can make informed gradient updates by adapting task weights so the resulting
auxiliarytaskbetteralignswiththeend-task(Prescription(P )). Amongstthesingletaskobjectives,
1
BERT-styleperformsbest. WepositthatthisisbecauseRoBERTawastrainedfromscratchona
similarobjectiveandsothisobjectiverepresentsminimalshiftintrainingdistributions.
Adaptivemulti-taskauxiliarylearningimprovesperformance: Wecomparesingle-taskend-
taskawareauxiliarylearningtoitsmultitaskvariant. Table2showsthatmultitaskingour3different
types of language modelling tasks results in improved average performance over using the tasks
individually(81.12%fortheBERT-styleand81.55%forcombiningthethreesingletaskobjectives).
Wegetourbestperformancewhenwemultitask24auxiliaryobjectivesautomaticallygenerated
withourframeworkusingAANG-TD.Boostingthenumberofobjectivesfrom3to24resultedin
a0.66%improvementinaverageperformanceacrosstasks. ThisisinlinewithPrescription(P )
2
fromSection4sinceweareincreasingtheeffectiveamountofauxiliarydata. Wefurtherpositthat
introducingmoreauxiliaryobjectivesalsoservestoimplicitlyregularizetheend-taskduringtraining.
7
PublishedasaconferencepaperatICLR2023
Table2: OurframeworkandAANGontasksusingonlytaskdata. Withoutusinganyexternaldata,
weareabletogetsignificantaverageperformanceimprovementoverbaselines. Superscriptsare
p-valuesfrompairedt-tests(bestmultitaskversusbestsingle-task).
TaskAdaptive Method # CS BIOMED NEWS STANCE
ACL-ARC SCIERC CHEMPROT H.PARTISAN SE-2016-6 AVG
No RoBERTa 1 66.033.55 77.962.96 82.100.98 93.392.26 70.371.51 77.97
TAPT 1 67.743.68 79.531.93 82.170.65 93.422.87 70.741.21 78.72
[OURS]StaticMultitask-TD 24 69.603.80 83.370.58 83.420.26 97.950.73 71.020.43 81.07
Yes X.GPT-style 1 67.220.44 81.620.84 83.291.21 96.410.73 70.671.46 79.84
Y.XLNET-style 1 69.762.42 81.810.42 83.390.31 96.411.92 71.180.58 80.51
Z.BERT-style(Deryetal.,2021b) 1 70.084.70 81.480.82 84.49 0(0 .5.0 09) 96.841.72 72.700.60 81.12
[OURS]AANG-[X+Y+Z] 3 71.513.19 82.890.78 83.680.45 96.921.26 72.75( 00 .8.9 24) 81.55
[OURS]AANG-TD 24 73.26( 10 .3.2 28) 82.98( 10 .5.2 27) 83.910.32 98.46( 00 .0.14) 72.461.65 82.21
7.2 INTRODUCINGEXTERNALDATA
For the ACL-ARC task, we experiment with introducing
auxiliary tasks based on external data. AANG-TD+ED
has 40 tasks, 16 of which are based on domain data. We
introduce CS domain data (from the S2ORC dataset (Lo
etal.,2019))thatisn=10 thesizeofthetaskdata. From
×
Figure 3 we see that AANG-TD+ED makes better use of
domain-datathandoingend-taskawaretrainingusingonly
BERT-style objective with task (TAPT) and domain-data
(DAPT) jointly as in Dery et al. (2021b). However,
AANG-TD+ED(73.70)doesnotsignificantlyimproveover
AANG-TD(73.26)ontheACL-ARCtask(Figure3). This
mightseematoddswithPrescription(P )sincetheTD+ED
2
searchspaceintroducesmoredata. However,notethatthe
AANGsearchalgorithmisapproximateandassuch,witha
largersearchspace,itcanbehardertofindcompositetasks
Figure3: AANGeffectivelyleverages
withasmall∆assuggestedbyPrescription(P ). Weposit
1
out-of-taskdata.P-values(inbrackets)
thatweneedmoreexternaldatathann = 10 inorderto
× arecomparisonsto(Deryetal.,2021b)
see marked improvements to offset our inexact search of
thespaceofcompositefunctions. However,suchscalesareoutsideourcomputationalbudget.
7.3 WHYDOESAANGWORK?
Tobetterunderstandwhyourauxiliarylearningpipelineimprovesend-taskperformance,weperform
multipleablationsunderAANG-TD.
StaticversusDynamicWeighting: Weablatetheimpactofusingstatictaskweightsthroughout
training, as against adaptive task weights. Just as with AANG, we sub-sample n tasks from the
searchspaceateveryiteration(niscross-validatedexactlyasAANGis–Table??). Eachsampled
tasksweightisinitializedto 1 andthisremainsunchangedthroughouttraining. ThisistheStatic
n
Multitask-TDbaselineinTable2. AANG-TDimprovesuponthestaticmultitaskbaselinebyover
1.1%onaverage. Withadaptiveweighting,AANGdown-weightsobjectivesthatareharmfultothe
end-taskwhilstup-weightingrelevantones(Prescription(P )). However,usingstaticweightingsis
1
morecomputefriendlysincewedonothavetocalculatetask-weightmeta-gradients. Thiscompute-
vs-performancetrade-offisleftforpractitionerstoresolvebasedontheiravailableresources.
Impactofnumberofsampledobjectives: Duetocomputationalconstraints,AANGsub-samples
thesetofgeneratedobjectives. Whilstthissamplingcanresultinapproximationerrorwheninferring
taskweightings,itcanalsointroducestochasticitywhichcanhelpregularizethelearnedmodel. From
Table3(AppendixA)wefindthatforsometasks(ACL-ARCandSCIERC)samplingalargernumber
oftaskshelps.SE-2016-6andCHEMPROTontheotherhandbenefitfromsmallernumberofsampled
tasks. Ourrecommendationisthatthenumberofsampledtasksbecross-validatedonaper-taskbasis.
Learnedtaskweighttrajectories: AANGlearnsinterestingtrajectoriesforweightingdesignstage
primitives. FromTable2,thefactthatAANG-TDroughlymatchesthebestsingletaskperformance
(72.46 versus72.70 forBERT-style)ontheSE-2016-6tasksuggeststhatitmaybelearning
1.65 0.60
tomostlyup-weightthistask. Figure4providesevidenceofthis. FortheSE-2016-6task(row1),
composingthehighestweightedprimitivefromeachstage[BERT None DENOISE]resultsin
◦ ◦
BERT-style,thebestsingletaskobjective. Figure4alsoshowsthatAANGcanadapttooverfitting.
Theverticalblacklinesindicatethepointofbestvalidationsetperformance. AANGrespondsto
8
PublishedasaconferencepaperatICLR2023
1.05 = SE-2016-6 0.75 = BERT 0.75 = Left-To-Right 1.0 = Mask = None
0.50 = None 0.50 = Random-Factorized = DENOISE
1.00 = Replace = Right-To-Left 0.5 = SE-2016-6
0.25 0.25
0.95 0.00 0.00 0.0
0 200 400 600 800 0 200 400 600 800 0 200 400 600 800 0 200 400 600 800
Iteration Iteration Iteration Iteration
1.05 = SCIERC 0.30 0.6
0.26
1.00 0.24 = =
=
B M NE oaR ns ekT 00 .. 22 05 = =
=
L N Re aof nnt- deT oo m-R -Fig ah ct
torized
0.5 = = D SCE IN EO RI CSE
0.95 0.22 = Replace 0.15 = Right-To-Left 0.4
0 500 1000 1500 0 500 1000 1500 0 500 1000 1500 0 500 1000 1500
Iteration Iteration Iteration Iteration
Figure4: LearnedtrajectoriesforAANG-TDforruninstancesofSE-2016-6andSCIERCtasks.
over-fitting by down-weighting objectives based on the output loss being over-fit to. Thus, after
severaliterations,theobjectivethatdominateswhenthevalidationperformanceisatitshighest(black
verticalline)getsdown-weightedinresponsetoitbecomingsaturated.
Whattasksareimportantandwhentheyareimportant? Westudywhichtasksaremosthighly
weighted early in training (first 10% of learning trajectory) and later in training (last 50%). We
aggregate statistics across 3 datasets. Note that early in training, objectives based on the self-
Tasks with highest average weight during first 10% of training Tasks with highest average weight during later half of training
T R O T R O
None Left-To-Right Denoise (GPT-Style) Mask Rand-Fact Task
None None Denoise (Reconstruct Input) Replace Rand-Fact Task
M Ma as sk k Left- NT oo n-R eight D De en no oi is se e Bert-op Rand-Fact Task
Bert-op Left-To-Right Denoise Replace None Task
None None Task (Copy of End-Task) Bert-op None Task
None Rand-Fact Task Mask None Task
Bert-op None Denoise (BERT-Style) Replace Rand-Fact Denoise
Replace Rand-Fact Denoise None None Task
Replace None Denoise
None Rand-Fact Denoise ReplaceLeft-To-Right Denoise
Replace Left-To-Right Denoise Bert-op Rand-Fact Denoise
Replace Rand-Fact Task None Rand-Fact Task
Mask Rand-Fact Denoise Mask Left-To-Right Denoise
Replace Right-To-Left Denoise Mask Rand-Fact Denoise
Bert-op Rand-Fact Denoise H.PARTISAN SCIERC ACL-ARC None Left-To-Right Denoise (GPT-Style)
Bert-op Right-To-Left Denoise
Replace None Task None Right-To-Left Denoise H.PARTISAN SCIERC ACL-ARC
Bert-op Rand-Fact Task ReplaceRight-To-Left Denoise
Mask None Task Bert-op None Denoise (BERT-Style)
Mask Rand-Fact Task None Rand-Fact Denoise (XLNET-Style)
0 0.1 0.2 0.3 0.4 0.5 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
Fraction of Runs Fraction of Runs
Figure5: Toprankedobjectives(averagedweight)earlyintraining(left)andlaterintraining(right)
supervisedoutput = DENOISE arehighlyweightedbutlater,objectivesbasedonsupervised
O { }
signal, = Task play a larger role. AANG rediscovers the common practice of training on
O { }
self-supervised objectives before introducing supervised ones. It is also interesting to note that
manynewlygeneratedobjectives(outsideofthe3namedsingletaskbaselinesinTable2)suchas
simpleinputreconstructionwerediscoveredtohaverelevantimpactontheend-tasks. Thismeans
AANGcanautomaticallysurfacenew,previouslyunexploredobjectivesrelevanttotheend-task.
8 LIMITATIONS AND CONCLUSION
Our work has some limitations that we leave for future work. First, because AANG relies on
meta-learning,itpresentsextracomputeburdenoversimplemultitasking. Thisisbecause,wehaveto
independentlycomputemeta-gradientsforeachauxiliarytaskthusrequiring (n)forward-backward
O
operationsfornsampledtaskscomparedto (1)forstaticmultitasking. InTable2,weshowthat
O
ourstaticMultitask-TDmethodoutperformsallothernon-task-adaptivemethodsby 2.4%and
≈
isthusaviablealternativewhenruntimeisasignficantconstraint. Secondly,AANGaspresented
isanapproximatealgorithm–primarilyduetosub-samplingthespaceoftasks. Thusasmentioned
inSection7.2,wedonotgetasmuchgainasdesiredwhenoursearchspacebecomeslarger. We
leavefindinganefficientexactsearchalgorithmforfutureexploration.
This paper presents a procedure for automating the creation of auxiliary objectives. We showed,
theoretically,howauxiliarylearningimpactsend-taskgeneralization. Thisresultedinprescriptions
thatinformedthedesignofAANG,analgorithmtosearchthespaceofgeneratedobjectivesinan
end-task aware multitaskfashion. Our experiments show that AANG is apromising firststep in
automatingauxiliarylearning.
9
6-6102-ES
CREICS
PublishedasaconferencepaperatICLR2023
9 ACKNOWLEDGEMENTS
This work was supported in part by DSO National Laboratories, an ENS-CFM Data Science
Chair,DARPAFA875017C0141,theNationalScienceFoundationgrantsIIS1705121,IIS1838017,
IIS2046613andIIS-2112471,anAmazonWebServicesAward,aFacebookFacultyResearchAward,
funding from Booz Allen Hamilton Inc., and a Block Center Grant. Any opinions, findings and
conclusions or recommendations expressed in this material are those of the author(s) and do not
necessarilyreflecttheviewsofanyofthesefundingagencies. Wearegratefulforhelpfulfeedback
fromUriAlon,PatrickFernandes,JoonSikKim,HanGuo,VictorAkinwandeandClaraNa.
REFERENCES
Armen Aghajanyan, Anchit Gupta, Akshat Shrivastava, Xilun Chen, Luke Zettlemoyer, and
SonalGupta. Muppet: Massivemulti-taskrepresentationswithpre-finetuning. arXivpreprint
arXiv:2101.11038,2021.
PulkitAgrawal,AshvinVNair,PieterAbbeel,JitendraMalik,andSergeyLevine. Learningtopoke
bypoking: Experientiallearningofintuitivephysics. Advancesinneuralinformationprocessing
systems,29,2016.
JonathanBaxter. Amodelofinductivebiaslearning. Journalofartificialintelligenceresearch,12:
149–198,2000.
IzBeltagy,ArmanCohan,andKyleLo. Scibert: Pretrainedcontextualizedembeddingsforscientific
text. CoRR,abs/1903.10676,2019. URLhttp://arxiv.org/abs/1903.10676.
OlivierBousquetandAndre´Elisseeff. Stabilityandgeneralization. TheJournalofMachineLearning
Research,2:499–526,2002.
TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielM.Ziegler,
JeffreyWu,ClemensWinter,ChristopherHesse,MarkChen,EricSigler,MateuszLitwin,Scott
Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya
Sutskever,andDarioAmodei. Languagemodelsarefew-shotlearners. CoRR,abs/2005.14165,
2020. URLhttps://arxiv.org/abs/2005.14165.
XavierCarreras,Llu´ısMa`rquez,andLlu´ısPadro´. Asimplenamedentityextractorusingadaboost.
InProceedingsoftheseventhconferenceonNaturallanguagelearningatHLT-NAACL2003,pp.
152–155,2003.
RichCaruana. Multitasklearning. Machinelearning,28(1):41–75,1997.
EugeneCharniak. Statisticaltechniquesfornaturallanguageparsing. AImagazine,18(4):33–33,
1997.
TingChen,SimonKornblith,MohammadNorouzi,andGeoffreyHinton. Asimpleframeworkfor
contrastivelearningofvisualrepresentations. InInternationalconferenceonmachinelearning,pp.
1597–1607.PMLR,2020.
KevinClark,Minh-ThangLuong,QuocVLe,andChristopherDManning. Electra: Pre-trainingtext
encodersasdiscriminatorsratherthangenerators. arXivpreprintarXiv:2003.10555,2020.
TriDao,NimitSSohoni,AlbertGu,MatthewEichhorn,AmitBlonder,MeganLeszczynski,Atri
Rudra,andChristopherRe´. Kaleidoscope: Anefficient,learnablerepresentationforallstructured
linearmaps. arXivpreprintarXiv:2012.14966,2020.
LucioMDery,YannDauphin,andDavidGrangier. Auxiliarytaskupdatedecomposition: Thegood,
thebadandtheneutral. arXivpreprintarXiv:2108.11346,2021a.
LucioMDery,PaulMichel,AmeetTalwalkar,andGrahamNeubig. Shouldwebepre-training? an
argumentforend-taskawaretrainingasanalternative. arXivpreprintarXiv:2109.07437,2021b.
10
PublishedasaconferencepaperatICLR2023
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. Bert: Pre-trainingofdeep
bidirectionaltransformersforlanguageunderstanding. arXivpreprintarXiv:1810.04805,2018.
XuanyiDongandYiYang.Searchingforarobustneuralarchitectureinfourgpuhours.InProceedings
oftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.1761–1770,2019.
Jingfei Du, Edouard Grave, Beliz Gunel, Vishrav Chaudhary, Onur Celebi, Michael Auli, Ves
Stoyanov, and Alexis Conneau. Self-training improves pre-training for natural language
understanding. arXivpreprintarXiv:2010.02194,2020.
ChelseaFinn,PieterAbbeel,andSergeyLevine. Model-agnosticmeta-learningforfastadaptationof
deepnetworks,2017. URLhttps://arxiv.org/abs/1703.03400.
Jean-Bastien Grill, Florian Strub, Florent Altche´, Corentin Tallec, Pierre Richemond, Elena
Buchatskaya,CarlDoersch,BernardoAvilaPires,ZhaohanGuo,MohammadGheshlaghiAzar,
etal. Bootstrapyourownlatent-anewapproachtoself-supervisedlearning. AdvancesinNeural
InformationProcessingSystems,33:21271–21284,2020.
SuchinGururangan, AnaMarasovic´, SwabhaSwayamdipta, KyleLo, IzBeltagy, DougDowney,
andNoahASmith. Don’tstoppretraining: adaptlanguagemodelstodomainsandtasks. arXiv
preprintarXiv:2004.10964,2020.
DanijarHafner,TimothyLillicrap,IanFischer,RubenVillegas,DavidHa,HonglakLee,andJames
Davidson. Learninglatentdynamicsforplanningfrompixels. InInternationalconferenceon
machinelearning,pp.2555–2565.PMLR,2019.
MoritzHardt,BenRecht,andYoramSinger. Trainfaster,generalizebetter: Stabilityofstochastic
gradientdescent. InInternationalConferenceonMachineLearning,pp.1225–1234.PMLR,2016.
AndrewHoward,MarkSandler,GraceChu,Liang-ChiehChen,BoChen,MingxingTan,Weijun
Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et al. Searching for mobilenetv3. In
Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 1314–1324,
2019.
Minyoung Huh, Pulkit Agrawal, and Alexei A Efros. What makes imagenet good for transfer
learning? arXivpreprintarXiv:1608.08614,2016.
MandarJoshi,DanqiChen,YinhanLiu,DanielSWeld,LukeZettlemoyer,andOmerLevy. Spanbert:
Improvingpre-trainingbyrepresentingandpredictingspans. TransactionsoftheAssociationfor
ComputationalLinguistics,8:64–77,2020.
David Jurgens, Srijan Kumar, Raine Hoover, Dan McFarland, and Dan Jurafsky. Measuring
the evolution of a scientific field through citation frames. Transactions of the Association for
ComputationalLinguistics,6:391–406,2018.
JohannesKiesel,MariaMestre,RishabhShukla,EmmanuelVincent,PayamAdineh,DavidCorney,
Benno Stein, and Martin Potthast. SemEval-2019 task 4: Hyperpartisan news detection. In
Proceedingsofthe13thInternationalWorkshoponSemanticEvaluation,pp.829–839,Minneapolis,
Minnesota, USA, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/
S19-2145. URLhttps://aclanthology.org/S19-2145.
Jens Kringelum, Sonny Kim Kjaerulff, Søren Brunak, Ole Lund, Tudor I Oprea, and Olivier
Taboureau. Chemprot-3.0: aglobalchemicalbiologydiseasesmapping. Database,2016,2016.
IljaKuzborskijandChristophLampert. Data-dependentstabilityofstochasticgradientdescent. In
InternationalConferenceonMachineLearning,pp.2815–2824.PMLR,2018.
LiamLi,MikhailKhodak,Maria-FlorinaBalcan,andAmeetTalwalkar. Geometry-awaregradient
algorithmsforneuralarchitecturesearch. arXivpreprintarXiv:2004.07802,2020.
XingyuLin,HarjatinBaweja,GeorgeKantor,andDavidHeld. Adaptiveauxiliarytaskweightingfor
reinforcementlearning. Advancesinneuralinformationprocessingsystems,32,2019.
11
PublishedasaconferencepaperatICLR2023
HanxiaoLiu,KarenSimonyan,andYimingYang. Darts: Differentiablearchitecturesearch. arXiv
preprintarXiv:1806.09055,2018.
ShikunLiu,AndrewJDavison,andEdwardJohns.Self-supervisedgeneralisationwithmetaauxiliary
learning. arXivpreprintarXiv:1901.08933,2019a.
YinhanLiu, MyleOtt, Naman Goyal, JingfeiDu, MandarJoshi, DanqiChen, OmerLevy, Mike
Lewis,LukeZettlemoyer,andVeselinStoyanov. Roberta: Arobustlyoptimizedbertpretraining
approach. arXivpreprintarXiv:1907.11692,2019b.
Ziquan Liu, Yi Xu, Yuanhong Xu, Qi Qian, Hao Li, Antoni B. Chan, and Rong Jin. Improved
fine-tuningbyleveragingpre-trainingdata: Theoryandpractice. CoRR,abs/2111.12292,2021.
URLhttps://arxiv.org/abs/2111.12292.
KyleLo,LucyLuWang,MarkNeumann,RodneyKinney,andDanSWeld. S2orc: Thesemantic
scholaropenresearchcorpus. arXivpreprintarXiv:1911.02782,2019.
Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2017. URL https:
//arxiv.org/abs/1711.05101.
Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh Hajishirzi. Multi-task identification of
entities,relations,andcoreferenceforscientificknowledgegraphconstruction. arXivpreprint
arXiv:1808.09602,2018.
SaifMohammad,SvetlanaKiritchenko,ParinazSobhani,XiaodanZhu,andColinCherry. SemEval-
2016task6: Detectingstanceintweets. InProceedingsofthe10thInternationalWorkshopon
SemanticEvaluation(SemEval-2016),pp.31–41,SanDiego,California,June2016.Association
forComputationalLinguistics. doi: 10.18653/v1/S16-1003. URLhttps://aclanthology.
org/S16-1003.
AvivNavon,IdanAchituve,HaggaiMaron,GalChechik,andEthanFetaya. Auxiliarylearningby
implicitdifferentiation. arXivpreprintarXiv:2007.02693,2020.
AaronvandenOord,YazheLi,andOriolVinyals. Representationlearningwithcontrastivepredictive
coding. arXivpreprintarXiv:1807.03748,2018.
MatthewE.Peters,MarkNeumann,MohitIyyer,MattGardner,ChristopherClark,KentonLee,and
LukeZettlemoyer. Deepcontextualizedwordrepresentations. CoRR,abs/1802.05365,2018. URL
http://arxiv.org/abs/1802.05365.
HieuPham,MelodyGuan,BarretZoph,QuocLe,andJeffDean. Efficientneuralarchitecturesearch
viaparameterssharing. InInternationalConferenceonMachineLearning,pp.4095–4104.PMLR,
2018.
XipengQiu,TianxiangSun,YigeXu,YunfanShao,NingDai,andXuanjingHuang. Pre-trained
modelsfornaturallanguageprocessing: Asurvey. ScienceChinaTechnologicalSciences, pp.
1–26,2020.
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language
understandingbygenerativepre-training. 2018.
AlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,IlyaSutskever,etal. Language
modelsareunsupervisedmultitasklearners. OpenAIblog,1(8):9,2019.
ColinRaffel,NoamShazeer,AdamRoberts,KatherineLee,SharanNarang,MichaelMatena,Yanqi
Zhou,WeiLi,andPeterJLiu. Exploringthelimitsoftransferlearningwithaunifiedtext-to-text
transformer. arXivpreprintarXiv:1910.10683,2019.
Nicholas Roberts, Mikhail Khodak, Tri Dao, Liam Li, Christopher Re´, and Ameet Talwalkar.
Rethinkingneuraloperationsfordiversetasks. arXivpreprintarXiv:2103.15798,2021.
SebastianRuder,MatthewEPeters,SwabhaSwayamdipta,andThomasWolf. Transferlearning
innaturallanguageprocessing. InProceedingsofthe2019ConferenceoftheNorthAmerican
ChapteroftheAssociationforComputationalLinguistics: Tutorials,pp.15–18,2019.
12
PublishedasaconferencepaperatICLR2023
NikunjSaunshi,SadhikaMalladi,andSanjeevArora. Amathematicalexplorationofwhylanguage
modelshelpsolvedownstreamtasks. arXivpreprintarXiv:2010.03648,2020.
SteffenSchneider,AlexeiBaevski,RonanCollobert,andMichaelAuli. wav2vec: Unsupervised
pre-trainingforspeechrecognition. arXivpreprintarXiv:1904.05862,2019.
KennethOStanleyandRistoMiikkulainen.Evolvingneuralnetworksthroughaugmentingtopologies.
Evolutionarycomputation,10(2):99–127,2002.
MingxingTanandQuocLe.Efficientnet:Rethinkingmodelscalingforconvolutionalneuralnetworks.
InInternationalConferenceonMachineLearning,pp.6105–6114.PMLR,2019.
SangMichaelXie,AditiRaghunathan,PercyLiang,andTengyuMa. Anexplanationofin-context
learningasimplicitbayesianinference. arXivpreprintarXiv:2111.02080,2021.
ZhilinYang,ZihangDai,YimingYang,JaimeCarbonell,RussRSalakhutdinov,andQuocVLe.
Xlnet: Generalizedautoregressivepretrainingforlanguageunderstanding. Advancesinneural
informationprocessingsystems,32,2019.
XingchengYao,YananZheng,XiaocongYang,andZhilinYang.Nlpfromscratchwithoutlarge-scale
pretraining: Asimpleandefficientframework. arXivpreprintarXiv:2111.04130,2021.
Tong Zhang, Peng Gao, Hao Dong, Yin Zhuang, Guanqun Wang, Wei Zhang, and He Chen.
Consecutive pretraining: A knowledge transfer learning strategy with relevant unlabeled data
forremotesensingdomain. arXivpreprintarXiv:2207.03860,2022.
BarretZophandQuocVLe. Neuralarchitecturesearchwithreinforcementlearning. arXivpreprint
arXiv:1611.01578,2016.
13
PublishedasaconferencepaperatICLR2023
A MORE ABLATION TABLES
Table3: Varyingnumberofsampledobjectivesper-iteration.
Task 3 tasks 6 tasks
24 24
ACL-ARC 72.11 73.26
2.12 1.32
SCIERC 82.35 82.98
1.76 1.52
SE-2016-6 72.46 72.46
1.65 0.90
CHEMPROT 83.91 83.69
0.32 0.98
H.PARTISAN 98.46 97.95
0.0 0.73
B DISCUSSION OF META-TARTAN (DERY ET AL., 2021B)
META-TARTAN(Deryetal.,2021b)isaMAMLstyle(Finnetal.,2017)meta-learningalgorithm
thatlearnstoadaptivelyweightagivensetoftasksbasedontheirinfluenceontheend-taskvalidation
performance. META-TARTAN achieves this by formulating the following bi-level optimization
problem:
θ∗,w∗ =argmin (θ) (2)
{θ∈g(θ0),w}LE
where
(cid:18) (cid:19)
(cid:88)
θ 0 =argmin θ Ltotal(θ,w)=argmin θ w∗ LE(θ) + w i LTi(θ) (3)
Ti∈A
NotethatEistheend-taskand isthesetofauxiliarytasks.
A
Sincetheabovebi-levelproblemisdifficulttosolvedirectly,Deryetal.(2021a)relaxtheproblemand
intoanalternatingoptimizationproblemwheretaskweightsareupdatedbasedon1-stepimprovement
tothevalidationperformanceoftheend-task:
∂ Lv Eal(θ t+1(w)) β(cid:0) (cid:1)T(cid:0) val(θ )(cid:1) (4)
∂w ≈− ∇LTi ∇LE t
i
Topreventtheaboverelaxationfromfindingthetrivialsolutionofjustupweigtingsolelytheend-task,
Deryetal.(2021b)introduceaspecialdev-headwhichtheyuseforestimatingthemeta-gradient:
∂ Lv Ta ∗l(θ∗(w)) β(cid:0) (cid:1)T(cid:0) val([θ ;φ∗] )(cid:1) (5)
∂w ≈− ∇θ LTi ∇θ LE body t
i
Whereφ∗ isthespecialdev-headandθ isthebodyofthemodel. Forevenmoredetailsabout
t body
META-TARTAN,pleaseseeSection3ofDeryetal.(2021b).
Though we leverage MET-TARTAN, compared to Dery et al. (2021b), we make three distinct
contributionstothefieldofauxiliarylearning. Welistthembelow
1. Novel Problem Formulation: As far as we are aware of, we are the first to formulate
theproblemofautomatedauxiliarylearning. Specifically,wepresentedanapproachfor
automaticallyconstructingasuiteofauxiliaryobjectivesbasedonexistingobjectives.Please
notethatDeryetal.(2021b)performauxiliarylearningwithonlytheDAPT/TAPTvariants
oftheBERTobjective. Theyeffectivelyassumethatthesearchspaceofobjectives(the2
theyexplore)isgivenbefore-hand. Ourapproachautomaticallycreatesthesearchspace.
2. Theoretical Novelty: To the best of our knowledge, we are the first work to provide an
explorationofwhyauxiliarylearningimprovesprimarytaskperformanceviaalgorithmic
stability. Dery et al. (2021b) in introducing META-TARTAN do not attempt to give a
theoreticalcharacterizationofwhythealgorithmimprovesend-taskperformance.
3. Algorithm Improvements to META-TARTAN: Please note that META-TARAN as
presentedinDeryetal.(2021b)wasusedwithonly2auxiliarytasks. Whenscalingtomore
tasks,usingMETA-TARTANnaivelybecomescomputationallyprohibitive. Specifically,
onasearchspaceofNtasks,META-TARTANrequiresO(N)ordercomputationperstep.
14
PublishedasaconferencepaperatICLR2023
Weimproveuponthisbyintroducingthetasksub-samplingof(k N)whichreducesthe
(cid:28)
computeoverheadtoO(k). Toaccountfortheimpactofsub-samplingasanapproximation,
weintroducedthefactorisedmodellingoftaskweightswhichallowssharingofinformation
betweenauxiliarytasksthatmightthemselvesberelated.
C DATASET DETAILS
Table4: Specificationsofdatasetsusedtoevaluateourmethods.
Domain Task LabelType TrainSize DevSize TestSize Classes Metric
BIOMED CHEMPROTKringelumetal.(2016) relationclassification 4169 2427 3469 13 Accuracy
CS SCIERCLuanetal.(2018) relationclassification 3219 455 974 7 F1
STANCE SE-2016-6Mohammadetal.(2016) stancedetection 2497 417 1249 3 Accuracy
CS ACL-ARCJurgensetal.(2018) citationintent 1688 114 139 6 F1
NEWS H.PARTISANKieseletal.(2019) partisanship 515 65 65 2 Accuracy
D MORE TRAINING DETAILS
Weruneachhyper-parameterconfigurationacross3seeds 0, 1, 2 . Weuseabatchsizeof128
{ }
forallend-taskstasksexceptH.PARTISANwhereweuseabatchsizeof64. Theauxiliarytask
batch-size,aux bsz,issharedacrossallthensub-sampledauxiliaryobjectivesaccordingtothe
objective’sweight.
We use the AdamW optimizer (Loshchilov & Hutter, 2017), with weight decay of 0.01 for all
experiments.
Table5: AANG-TDspecificHyper-parameters
Hyper-parameter Values Description
aux lr 1.0,0.1 Learningrateforfactorvectors-{WAll,WI,WT,WR,WO}
sopt lr 0.1,0.01 Learningrateforprimarytaskweightingλ
e
nconf subsamp 3,6 Numberofsub-sampledauxiliarytasks.
learningrate 1e-3,1e-4 LearningrateusedforfurthertrainingofRoBERTa
base
aux bsz 256 Batchsizeofforauxiliaryobjectives
Table6: AANG-TD+EDspecificHyper-parameters
Hyper-parameter Values Description
aux lr 1.0,0.5,0.1 Learningrateforfactorvectors-{WAll,WI,WT,WR,WO}
sopt lr 0.1 Learningrateforprimarytaskweightingλ
e
nconf subsamp 6,12,24 Numberofsub-sampledauxiliarytasks.
learningrate 1e-4 LearningrateusedforfurthertrainingofRoBERTa
base
aux bsz 1024 Batchsizeofforauxiliaryobjectives
Table7: META-TARTANHyper-parametersforsingletaskauxiliarytasks
Hyper-parameter Values Description
sopt lr 1.0,0.1,0.01 Learningrateforprimarytaskweightingλ
e
learningrate 1e-3,1e-4,5e-5 LearningrateusedforfurthertrainingofRoBERTa
base
META-TARTANintroducesadev-headwhichistrainedsporadicallyduringtrainingforestimating
themeta-gradients. Weusethefollowinghyper-parametersfortrainingthisdev-head: wesample32
examples(8examplesinthecaseofH.PARTISAN)andperformfullbatchgradientdescentwith
15
PublishedasaconferencepaperatICLR2023
alearningrateof1e-2for10iterations. Thedev-headistrainedwiththeAdamWoptimizerwith
weightdecaysetto0.1.
Wecopytheend-taskagnosticbaselineresultsfrom(Deryetal.,2021b)whenavailable. Weusethe
hyper-parametersspecifiedforTAPTinGururanganetal.(2020)totrainfortheSE-2016-6task.
Allmodelsweretrainedononeoftwotypesofgpus: NVIDIAA100orNVIDIAA6000. Allmodels
fitwithinasinglegpu. Weusedgradientaccumulationtoexpandtheeffectivebatchsizesusedfor
ourexperiments.
E GENERALIZATION ERROR BOUND FOR END-TASK AWARE TRAINING
E.1 DEFINITIONS
DefinitionE.1. Afunction,f :Ω RisL-Lipschitzif u,v dom(f):
→ ∀ ∈
f(u) f(v) L u v
(cid:107) − (cid:107)≤ (cid:107) − (cid:107)
NotethatL-Lipschitzimpliesboundedgradients.
f(w) L w
(cid:107)∇ (cid:107)≤ ∀
DefinitionE.2. Afunction,f :Ω Risβ-smoothif u,v Ω:
→ ∀ ∈
f(u) f(v) β u v
(cid:107)∇ −∇ (cid:107)≤ (cid:107) − (cid:107)
DefinitionE.3. Anupdaterule,Gisσ-boundedif:
sup w G(w) σ
w∈Ω (cid:107) − (cid:107)≤
Considerthefollowinggeneralsetting. Thereisanunknowndistribution overexamplesfrom
e
D
somespace . WereceiveasampleS =(z ,...,z )ofN examplesdrawni.i.d. from . Our
Z
1 Ne e De
goalistofindamodelw,thatparameterizesthefunctionf ,withsmallpopulationriskdefinedas:
e
DefinitionE.4. PopulationRisk
R[w]=E f (w;z)
z∼De e
DefinitionE.5. EmpiricalRisk
Sincewehaveafinitenumberofsamples,wecanonlycomputetheempiricalriskwhichis:
1 (cid:88)
R [w]= f (w;z ),
S N e i
e
i
LetAbeapotentiallyrandomizedalgorithm(suchasStochasticGradientDescent)thatisafunction
oftheS suchthatw =A(S).
DefinitionE.6. GeneralizationError(cid:15) (A,N )
gen e
(cid:2) (cid:3)
(cid:15) (A,N )=E R [A(S)] R[A(S)]
gen e S,A S
−
DefinitionE.7. UniformStability
ArandomizedalgorithmAis(cid:15)-uniformlystableifforalldatasetsS,S(cid:48) , S = S(cid:48) =N such
e
thatS andS(cid:48)differinatmostoneexample,wehave ∈Z | | | |
sup E
(cid:2)
f (A(S);z) f
(A(S(cid:48));z)(cid:3)
(cid:15)
A e e
z − ≤
Here,theexpectationistakenonlyovertheinternalrandomnessofA.Wewilldenoteby(cid:15) (A,N )
stab e
theinfimumoverall(cid:15)forwhichtheaboveholds.
E.2 RELEVANTTHEOREMS
Theorem E.1 (Uniform Stability implies Generalization in expectation). Let Algorithm A be (cid:15)-
uniformlystable. Then,
(cid:12) (cid:12)
(cid:12) (cid:2) (cid:3)(cid:12)
(cid:15) gen(A,N e)=(cid:12)E S,A R S[A(S)] R[A(S)] (cid:12) (cid:15) stab(A,N e)
(cid:12) − (cid:12)≤
ForfullproofseeTheorem2.2ofHardtetal.(2016).
16
PublishedasaconferencepaperatICLR2023
TheoremE.2(StochasticGradientMethodisstable). Assumethatf (;z) [0,1]isanL-Lipschitz
e
∈
andβ -smoothlossfunctionforeveryz. SupposethatwerunSGMforT stepswithmonotonically
e
non-increasingstepsizesα c. Then,SGMhasuniformstabilitywith:
t ≤ t
1+ 1
(cid:15) sgm ≤ N q 1(cid:0) 2cL2(cid:1) q+1 1Tq+q 1
e
−
where q =β c
e
WecansimplifythistoonlytermsinvolvingT andN
e
(cid:15) (cid:47)
T1− cβe1
+1 (6)
sgm N
e
Proof. Forthefullproof,seeTheorem3.12ofHardtetal.(2016)
E.3 GROWTHFUNCTIONS
LemmaE.3(GrowthRecursionUnderDynamicSampling). WeconsidertheStochasticGradient
updateruleG:Ω Ω:
→
G (w)=w α f(w)
f
− ∇
FixanarbitrarysequenceofupdatesG ,...,G andanotherG(cid:48) ,...,G(cid:48) . Letw =w(cid:48) bea
startingpointinΩgiventhatf :Ω
Rf1 anddefinfT
e
f1 fT 0 0
→
δ =E (cid:2) w w(cid:48) (cid:3)
t f1...ft∼Pλ (cid:107) t − t(cid:107)
wherew ,w(cid:48) aredefinedrecursivelythrough:
t t
w =G (w ) w(cid:48) =G(cid:48) (w(cid:48) ) t 0
t ft t−1 t ft t−1 ≥
Thenwehavetherecurrencerelation:
δ =0
0
(cid:26) min(cid:8)(cid:0) 1+αλ β (cid:1) δ +αλ (cid:0) ∆+2L(cid:1) , (cid:0) 1+α(cid:0) λ β +λ β )(cid:1) δ (cid:9) G =G(cid:48)
δ t+1 ≤ 1 1 t 2 δ t+2σ t 1 1 2 2 t Gf ft t,G(cid:48) ftf at reσ-bounded
Notethat isadistributionoverthesupport f1,f2 accordingtoprobabilities λ ,λ λ +λ =
f 1 2 1 2
P { } { |
1 . f ,f havesmoothnessβ ,β respectively.
1 2 1 2
} { }
17
PublishedasaconferencepaperatICLR2023
Proof. Thesecondboundonδ istakendirectlyfromLemma2.5ofHardtetal.(2016). Wenow
t
derivethefirst-halfofthefirstbound
δ =E (cid:2) w w(cid:48) (cid:3)
t+1 f1...ft+1∼Pλ (cid:107) t+1 − t+1(cid:107)
(cid:20) (cid:21)
=E λ G (w ) G(cid:48) (w(cid:48)) +λ G (w ) G(cid:48) (w(cid:48))
f1...ft∼Pλ 1 (cid:107) f1 t − f1 t (cid:107) 2 (cid:107) f2 t − f2 t (cid:107)
(cid:20) (cid:21)
=E λ w α f1(w ) w(cid:48) +α f1(w(cid:48)) +λ w α f2(w ) w(cid:48) +α f2(w(cid:48))
f1...ft∼Pλ 1 (cid:107) t − ∇ t − t ∇ t (cid:107) 2 (cid:107) t − ∇ t − t ∇ t (cid:107)
(cid:18) (cid:19)
E (cid:2) w w(cid:48) (cid:3) +αE λ f1(w(cid:48)) f1(w ) +λ f2(w(cid:48)) f2(w )
≤ f1...ft∼Pλ (cid:107) t − t(cid:107) f1...ft∼Pλ 1 (cid:107)∇ t −∇ t (cid:107) 2 (cid:107)∇ t −∇ t (cid:107)
(TriangleInequalityusedforabovestep)
(cid:18) (cid:19)
=δ +αE λ f1(w(cid:48)) f1(w ) +λ f2(w(cid:48)) f2(w )
t f1...ft∼Pλ 1 (cid:107)∇ t −∇ t (cid:107) 2 (cid:107)∇ t −∇ t (cid:107)
(WithoutLossofGenerality,letβ β )
1 2
≤
(cid:20) (cid:21)
δ +αE λ β w w(cid:48) +λ f2(w(cid:48)) f2(w ) (Smoothness)
≤ t f1...ft∼Pλ 1 1 (cid:107) t − t(cid:107) 2 (cid:107)∇ t −∇ t (cid:107)
(cid:20) (cid:21)
=δ +αλ β δ +αλ E f2(w(cid:48)) f2(w ) (TriangleInequality)
t 1 1 t 2 f1...ft∼Pλ (cid:107)∇ t −∇ t (cid:107)
(cid:13) (cid:13)
=(cid:0) 1+αλ 1β 1(cid:1) δ t+αλ 2(cid:13) (cid:13) (cid:13)∇f2(w t(cid:48)) −∇f1(w t(cid:48))+ ∇f1(w t(cid:48)) −∇f2(w t)(cid:13) (cid:13)
(cid:13)
(addzero)
(cid:18) (cid:19)
(cid:0) 1+αλ β (cid:1) δ +αλ f2(w(cid:48)) f1(w(cid:48)) + f1(w(cid:48)) f2(w ) (TriangleInequality)
≤ 1 1 t 2 (cid:107)∇ t −∇ t (cid:107) (cid:107)∇ t −∇ t (cid:107)
(cid:18) (cid:19)
(cid:0) 1+αλ β (cid:1) δ +αλ ∆+ f (w(cid:48)) f (w ) UsingAssumptionA.1
≤ 1 1 t 2 (cid:107)∇ 1 t −∇ 2 t (cid:107)
(cid:18) (cid:19)
(cid:0) 1+αλ β (cid:1) δ +αλ ∆+ f (w(cid:48)) + f (w ) TriangleInequality
≤ 1 1 t 2 (cid:107)∇ 1 t (cid:107) (cid:107)∇ 2 t (cid:107)
(cid:0) (cid:1) (cid:0) (cid:1)
1+αλ β δ +αλ ∆+2L L-Lipschitzfunction
1 1 t 2
≤
Toobtainthesecondhalfofthefirstbound:
δ =E (cid:2) w w(cid:48) (cid:3)
t+1 f1...ft+1∼Pλ (cid:107) t+1 − t+1(cid:107)
(cid:20) (cid:21)
=E λ G (w ) G(cid:48) (w(cid:48)) +λ G (w ) G(cid:48) (w(cid:48))
f1...ft∼Pλ 1 (cid:107) f1 t − f1 t (cid:107) 2 (cid:107) f2 t − f2 t (cid:107)
(cid:20) (cid:21)
=E λ w α f1(w ) w(cid:48) +α f1(w(cid:48)) +λ w α f2(w ) w(cid:48) +α f2(w(cid:48))
f1...ft∼Pλ 1 (cid:107) t − ∇ t − t ∇ t (cid:107) 2 (cid:107) t − ∇ t − t ∇ t (cid:107)
(cid:18) (cid:19)
E (cid:2) w w(cid:48) (cid:3) +αE λ f1(w(cid:48)) f1(w ) +λ f2(w(cid:48)) f2(w )
≤ f1...ft∼Pλ (cid:107) t − t(cid:107) f1...ft∼Pλ 1 (cid:107)∇ t −∇ t (cid:107) 2 (cid:107)∇ t −∇ t (cid:107)
(TriangleInequalityusedforabovestep)
(cid:20) (cid:21)
δ +αE λ β w w(cid:48) +λ β w w(cid:48) (Smoothness)
≤ t f1...ft∼Pλ 1 1 (cid:107) t − t(cid:107) 2 2 (cid:107) t − t(cid:107)
(cid:20) (cid:21) (cid:20) (cid:21)
=δ +αλ β E w w(cid:48) +αλ β E w w(cid:48)
t 1 1 f1...ft∼Pλ (cid:107) t − t(cid:107) 2 2 f1...ft∼Pλ (cid:107) t − t(cid:107)
=δ +α(λ β +λ β )δ
t 1 1 2 2 t
=(1+α(λ β +λ β ))δ
1 1 2 2 t
E.4 STABILITYOFDYNAMICSAMPLING
WerepeatthedescriptionofourAuxiliaryLearningwithDynamicSamplingSettinghereforeaseof
access.
18
PublishedasaconferencepaperatICLR2023
Setting: Wearegivenanauxiliaryobjectivef (;z) [0,1]withN samplesS =(z ,...,z )
a
· ∈
a a 1 Na
fromthedistribution . AtanyiterationofSGD,wesampleachoiceofeithertheend-taskfunction
a
D
f or the auxiliary objective f according to the probabilities λ , λ λ + λ = 1. Given the
e a e a e a
|
chosenobjective,wesampleadata-pointandperformstochasticgradientdescent(SGD)basedon
thesampleddata-point.
AnequivalentwaytoinstantiatethisproceduretocreateS bydrawingN(cid:48) =N +N totalsamples
A e a
fromtheend-taskandauxiliarytaskaccordingto . S(cid:48) isthencreatedbyreplacing1end-task
sampleinS . Ateachstep,asampleisdrawnfromP aλ distrA ibution: z ,z(cid:48) P ,P andagradient
A i i ∼ SA S A(cid:48)
stepistakenonthefunctioncorrespondingtothesetthesamplewasdrawnfrom.
LemmaE.4(Stabilityofdynamicsampling). WedenotetheoutputsofT stepsofSGMonS and
A
S(cid:48) withthedynamicallysampledfunctions,asw andw(cid:48) respectively. Then,foreveryz Z and
A T T e ∈ e
everyt >0,underboththerandomupdateruleandtherandompermutationrule,wehave:
0
E(cid:12) (cid:12)f e(w T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12) ≤ γ Nt 0 (cid:48) wsu ,zp ef e(w;z e)+LE[δ T |δ t0 =0]
WhereN(cid:48) =N e+N aandγ = λe N·N
e
(cid:48) = λλ re.
Proof. Let =1[δ =0]denotetheeventthatδ =0. Wehave
E(cid:12) (cid:12)f e(E w T;z)t −0 f e(w T(cid:48) ;z)(cid:12) (cid:12)=P {E}E(cid:2)(cid:12) (cid:12)f e(wt0 T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12) |E(cid:3)
+P {Ec }E(cid:2)(cid:12) (cid:12)f e(w T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12) |Ec(cid:3)
≤E(cid:2)(cid:12) (cid:12)f e(w T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12) |E(cid:3) +P {Ec }·wsu ,zp ef e(w;z e)
(7)
becausef isnon-negative
e
LE(cid:2) w w(cid:48) (cid:3) +P c supf (w;z )
≤ (cid:107) T − T(cid:107)|E {E }·w,ze e e
becausef isL-Lipschitz
e
WenowproceedtoboundP c . Leti [N(cid:48)]denotethepositioninwhichS ,S(cid:48) differand
{E } ∗ ∈ A A
consider the random variable I assuming the index of the first time step in which SGM uses the
example z ei∗. Note that when I > t 0, then wemust have that δ
t0
= 0 since the two samples are
identicalupuntilthispoint.
P c =P δ =0 P I t
0 0
{E } { (cid:54) }≤ { ≤ }
Usingtheselectionrulespecifiedabove(sampleeitherf ,f accordingtotheprobabilitiesλ ,λ
e a e a
andthensampleuniformlyfromtheselectedtaskdata)wehavethat:
P I t
=(cid:88)t0
P I =t
=(cid:88)t0
(cid:0) λ 1 (cid:1) = λ et 0 = γt 0
{ ≤ 0 } { 0 } e · N N N(cid:48)
e e
t=1 t=1
TheoremE.5(StabilityBoundonDynamicSampling). Assumethatf (;z ),f (;z ) [0,1]are
e e a a
L-Lipschitz and β and β -smooth loss functions. Consider that we have N(cid:48) = N +∈ N total
e a e a
sampleswheref andf haveN andN samplesrespectively. SupposethatwerunSGMforTsteps
e a e a
withmonotonicallynon-increasingstepsizesα c bydynamicallysamplingthetasksaccordingto
t ≤ t
λ andλ . Then,withrespecttof ,SGMhasuniformstabilitywith:
e a e
(cid:18) 1 (cid:19)(cid:18) 2γL2c (cid:19) cβ¯1 +1(cid:18) γT(cid:19) 1+cβ¯ cβ¯
(cid:15) 1+ +ρLc
stab ≤ cβ¯ N(cid:48) γ N(cid:48)
−
λ N(cid:48)
Where γ = e
N
e
Giventhatβ∗ = min β ,β andλ∗ isthecorrespondingweightingofthefunctionwithsmaller
e a
{ }
smoothness.
Dependingonwhichonegivesatighterboundthepair(β¯,ρ)canbe:
(β¯,ρ) =(λ∗β∗, (1 λ∗)(cid:0) ∆+2L(cid:1) )
1
−
or
(β¯,ρ) =(λ β +λ β , 0)
2 e e a a
19
PublishedasaconferencepaperatICLR2023
When(β¯,ρ) givesthetighterbound,wecansimplifyto:
1
(cid:15)
gen
(cid:47) (cid:0) ∆)1+cλ1
∗β∗(cid:18)
γ NT
(cid:48)(cid:19)1− cλ∗β1
∗+1
AspresentedinSection4.
Proof. LetS ,S(cid:48) betwosampleofsizeN(cid:48) =N +N asdescribedinlemmaE.4. Considerthe
A A e a
gradientupdatesG ,...,G andG(cid:48) ,...,G(cid:48) inducedbyrunningSGMonsamplesS andS(cid:48)
f1 fT f1 fT A A
respectively. Letw andw(cid:48) denotethecorrespondingoutputsofSGM.BylemmaE.4wehave:
T T
E(cid:12) (cid:12)f e(w T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12) ≤ γ Nt 0 (cid:48) wsu ,zp ef e(w;z e)+LE[δ T |δ t0 =0] (8)
LetΨ =E[δ δ =0]. WewillboundΨ asfunctionoft andthenminimizefort . Notethe
T T
|
t0 T 0 0
following:
• Atanystept,withprobability(cid:0) 1 γ (cid:1) ,thesampleselectedisthesameinbothS and
− N(cid:48) A
S(cid:48) . InthiscaseG =G(cid:48) andweusethecorrespondingexpansivityrulefromlemmaE.4.
A ft ft
Thisgives:
δ
min(cid:8)(cid:0)
1+α
λ∗β∗(cid:1)
δ +α (1
λ∗)(cid:0) ∆+2L(cid:1)
,
(cid:0)
1+α
(cid:0)
λ β +λ β
)(cid:1)
δ
(cid:9)
t+1 t t t t e e a a t
≤ −
Where β∗ = min β ,β and λ∗ is the corresponding weighting of the function with
e a
{ }
smallersmoothness. Toavoidderivingtheboundindependentlyforeachcase,weperforma
variablesubstituationthatcapturesthetwocases:
δ
(cid:0)
1+α
β¯(cid:1)
δ +α ρ
t+1 t t t
≤
β¯ = (cid:8) λ∗β∗, λ β +λ β (cid:9) andρ = (cid:8) (1 λ∗)(cid:0) ∆+2L(cid:1) ,0(cid:9) . Wecanpresentthefinal
e e a a
−
boundinternsofthesevariableswhichcanbesubstituteddependingontheminimizer.
• Withprobability γ theselectedexampleisdifferent. Notethatinthiscase,weknowthat
N(cid:48)
weareevaluatingtheend-taskfunctionf . WeusethatbothG andG(cid:48) are(σ =α L)-
e ft ft t t
boundedaccordingtolemmaE.3sincef isL-Lipschitz.
e
Combiningtheabovewehave:
(cid:18) (cid:19)
Ψ
(cid:0)
1
γ (cid:1) (cid:0)
1+α
β¯(cid:1)
Ψ +α ρ +
γ (cid:0)
Ψ +2α
L(cid:1)
t+1 ≤ − N(cid:48) t t t N(cid:48) t t
(cid:18) (cid:19)
=
γ +(cid:0)
1
γ (cid:1)(cid:0)
1+α
β¯(cid:1)
Ψ +
2γα tL
+α
(cid:0)
1
γ (cid:1)
ρ
N(cid:48) − N(cid:48) t t N(cid:48) t − N(cid:48)
=(cid:18) 1+(cid:0)
1
γ (cid:1)
α
β¯(cid:19)
Ψ +
α t(cid:0) 2γL+(N(cid:48) −γ)ρ(cid:1)
− N(cid:48) t t N(cid:48)
≤(cid:18) 1+(cid:0)
1
−
Nγ (cid:48)(cid:1)c tβ¯(cid:19)
Ψ t+
c(cid:0) 2γL+ t( NN (cid:48)(cid:48) −γ)ρ(cid:1)
(9)
exp(cid:18) (cid:0)
1
γ (cid:1)c β¯(cid:19)
Ψ +
c(cid:0) 2γL+(N(cid:48) −γ)ρ(cid:1)
≤ − N(cid:48) t t tN(cid:48)
Weuse1+x exp(x) x
≤ ∀
(cid:18) (cid:19)
exp (cid:0) 1 γ (cid:1)c β¯ Ψ + cρ¯
≤ − N(cid:48) t t tN(cid:48)
Whereρ¯=(cid:0) 2γL+(N(cid:48) γ)ρ(cid:1)
−
20
PublishedasaconferencepaperatICLR2023
WecanunwindtherecurrenceuntilΨ =0.
t0
(cid:88)T (cid:18) (cid:89)T (cid:0) γ cβ¯ (cid:1)(cid:19)(cid:18) cρ¯ (cid:19)
Ψ exp (1 )
T ≤ − N(cid:48) k tN(cid:48)
t=t0+1 k=t+1
T (cid:18) (cid:19) (cid:18) T (cid:19)
(cid:88) cρ¯ γ (cid:88) 1
= exp (1 )cβ¯
tN(cid:48) − N(cid:48) k
t=t0+1 k=t+1
T (cid:18) (cid:19) (cid:18) (cid:19)
(cid:88) cρ¯
exp (1
γ )cβ¯log(cid:0)T(cid:1)
≤ tN(cid:48) − N(cid:48) t
t=t0+1
=
cρ¯Tcβ¯(1− Nγ (cid:48)) (cid:88)T
t−cβ¯(1− Nγ (cid:48))−1 (10)
N(cid:48)
t=t0+1
Wecanupperboundthesumovertwithanintegral+dropnegativeterms
cρ¯ (cid:18) T (cid:19)cβ¯(1− Nγ (cid:48))
≤ N(cid:48)cβ¯(1
−
Nγ (cid:48)) t 0
ρ¯ (cid:18) T (cid:19)cβ¯(1− Nγ (cid:48))
=
β¯(N(cid:48) γ) t
0
−
ρ¯
(cid:18)
T
(cid:19)cβ¯
≤ β¯(N(cid:48) γ) t
0
−
PluggingthisboundbackintoEquation8andusingthefactthatf [0,1]:
e
∈
E(cid:12) (cid:12)f e(w T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12)
≤
γ Nt 0
(cid:48)
+ β¯(NL (cid:48)ρ¯
γ)(cid:18)
tT
0(cid:19)cβ¯
(11)
−
Weletq∗ =cβ¯,wecanminimizetheR.H.Sbysetting:
(cid:18) N(cid:48)Lcρ¯ (cid:19) q∗1 +1 q∗
t
0
=
γ(N(cid:48) γ)
Tq∗+1
−
Pluggingthisingivesus:
E(cid:12) (cid:12)f e(w T;z) −f e(w T(cid:48) ;z)(cid:12) (cid:12) ≤(cid:18)(1+ N(cid:48)c1 β¯)(cid:19)(cid:18)N(cid:48)Lc(cid:0) 2γ (NL (cid:48)+(N γ)(cid:48) −γ)ρ(cid:1)(cid:19) cβ¯1 +1(cid:0) γT(cid:1) 1+cβ¯ cβ¯
− (12)
(cid:18) 1 (cid:19)(cid:18) 2γL2c (cid:19) cβ¯1 +1(cid:18) γT(cid:19) 1+cβ¯ cβ¯
= 1+ +ρLc
cβ¯ N(cid:48) γ N(cid:48)
−
Recallthat:
β¯=(cid:8) λ∗β∗, λ β +λ β (cid:9)
e e a a
ρ=(cid:8)
(1
λ∗)(cid:0) ∆+2L(cid:1) ,0(cid:9)
−
Wecanchoosewhicheverofthepairsforβ¯,ρthatminimizesthebound:
F DISCUSSION OF GENERALIZATION ERROR BOUNDS
F.1 WHATDOESTHEOREME.5SAY.
Weconsiderthesettingwhere
β¯=λ∗β∗
ρ=(1
λ∗)(cid:0) ∆+2L(cid:1)
−
21
PublishedasaconferencepaperatICLR2023
AssumingtheρtermdominatesEquation12inthissettingis:
(cid:18) (cid:19) cβ¯
(cid:15)auxdyn (cid:15)auxdyn(cid:12) (cid:12) (cid:47) 1+c(cid:112) β¯ (1 λ∗)(∆+2L) γT 1+cβ¯
gen ≤ stab (β¯,ρ)1 − N(cid:48)
(cid:47) (cid:0) ∆)1+cλ1
∗β∗(cid:18) γT(cid:19)1− cλ∗β1
∗+1 ThisisEquation1fromSection4
N(cid:48)
(13)
Ingoingfromthefirstlinetothesecondweconsiderthesettingwhere∆ 2L. Thisisacasewhere
(cid:29)
theauxiliarytaskissufficientlydifferentfromtheprimarytask. Someobservationsaboutthissetting:
1. Smaller∆impliesauxiliarytaskissimilartomaintaskandleadstoimprovingthebound.
2. DependenceoftheboundonN(cid:48)isabitmorenuanced. NotethatincreasingN(cid:48)increases
γ unlesswereduceλ appropriately. Rememberthatλ istherateatwhichwesample
e e
theprimarytask. Thus,ifweaddmoreauxiliarydatabutstillsampletheprimarytaskatthe
originalrate,thenweareeffectivelyignoringtheextraauxiliarydata.
3. Itmightbetemptingtoassumethatwecangetarbitraryimprovementsinthissettingby
settingλ =0. However,notethatwhilstthismightreducethegeneralizationerror,it
e
meansthatweareseeingnoneoftheend-taskwhichwouldresultinlargeincreaseinthe
trainingerror
4. Note that (β¯ = λ∗β∗ β ) always. So we get improvements on the dependence on T
e
≤
comparedtoTheoremE.2.
5. Wecanoptimizeλ ,λ tominimize(cid:15)auxdyn.
e a stab
22
