Unsupervised Alignment of Privacy Policies using Hidden Markov Models
RohanRamanath FeiLiu NormanSadeh NoahA.Smith
SchoolofComputerScience
CarnegieMellonUniversity
Pittsburgh,PA15213,USA
{rrohan,feiliu,sadeh,nasmith}@cs.cmu.edu
Abstract taskismotivatedbyanexpectationthatmanypoli-
cies will address similar issues,1 such as collec-
To support empirical study of online pri-
tion of a user’s contact, location, health, and fi-
vacy policies, as well as tools for users
nancialinformation,sharingwiththirdparties,and
with privacy concerns, we consider the
deletion of data. This expectation is supported
problemofaligningsectionsofathousand
by recommendation by privacy experts (Gellman,
policydocuments,basedontheissuesthey
2014) and policymakers (Federal Trade Commis-
address. WeapplyanunsupervisedHMM;
sion, 2012); in the financial services sector, the
intwonew(andreusable)evaluations,we
Gramm-Leach-Bliley Act requires these institu-
findtheapproachmoreeffectivethanclus-
tions to address a specific set of issues. Aligning
teringandtopicmodels.
policysectionsisafirststeptowardouraforemen-
1 Introduction tionedsummarizationandextractiongoals.
Wepresentthefollowingcontributions:
Privacy policy documents are verbose, often eso-
• A new corpus of over 1,000 privacy policies
teric legal documents that many people encounter
gathered from widely used websites, manually
as clients of companies that provide services on
segmentedintosubtitledsectionsbycrowdwork-
the web. McDonald and Cranor (2008) showed
ers(§2).
that, if users were to read the privacy policies of
every website they access during the course of a • Anunsupervisedapproachtoaligningthepolicy
year, they would end up spending a substantial sections based on the issues they discuss. For
amount of their time doing just that and would example, sections that discuss “user data on the
often still not be able to answer basic questions company’s server” should be grouped together.
about what these policies really say. Unsurpris- The approach is inspired by the application of
ingly, many people do not read them (Federal hiddenMarkovmodelstosequencealignmentin
TradeCommission,2012). computationalbiology(Durbinetal.,1998;§3).
Such policies therefore offer an excellent op- • Two reusable evaluation benchmarks for the re-
portunity for NLP tools that summarize or ex- sulting alignment of policy sections (§4). We
tract key information that (i) helps users under- demonstratethatourapproachoutperformsna¨ıve
stand the implications of agreeing to these poli- methods(§5).
cies and (ii) helps legal analysts understand the Our corpus and benchmarks are available at
contentsofthesepoliciesandmakerecommenda- http://usableprivacy.org/data.
tionson howthey canbe improvedormade more
clear. Past applications of NLP have sought to 2 DataCollection
parse privacy policies into machine-readable rep-
We collected 1,010 unique privacy policy
resentations (Brodie et al., 2006) or extract sub-
documents from the top websites ranked by
policiesfromlargerdocuments(Xiaoetal.,2012).
Alexa.com.2 Thesepolicieswerecollectedduring
Machine learning has been applied to assess cer-
a period of six weeks during December 2013 and
tain attributes of policies (Costante et al., 2012;
January 2014. They are a snapshot of privacy
Ammar et al., 2012; Costante et al., 2013; Zim-
policies of mainstream websites covering fifteen
meckandBellovin,2013).
This paper instead analyzes policies in aggre-
1Personalcommunication,JoelReidenberg.
gate, seeking to align sections of policies. This 2http://www.alexa.com
605
Proceedingsofthe52ndAnnualMeetingoftheAssociationforComputationalLinguistics(ShortPapers),pages605–610,
Baltimore,Maryland,USA,June23-252014.(cid:13)c2014AssociationforComputationalLinguistics
Business Computers Games Health 3 Approach
Home News Recreation Shopping
Arts KidsandTeens Reference Regional Given the corpus of privacy policies described in
Science Society Sports §2, we designed a model to efficiently infer an
alignmentofpolicysections. Whileweexpectthat
Table1: FifteenwebsitecategoriesprovidedbyAlexa.com.
differentkindsofwebsiteswilllikelyaddressdif-
Wecollectprivacypoliciesfromthetop100websitesineach.
ferent privacy issues, we believe that many poli-
cies will discuss roughly the same set of issues.
Aligningthepoliciesisafirststepinalargereffort
ofAlexa.com’sseventeencategories(Table1).3
to(i)automaticallyanalyzepoliciestomakethem
Findingawebsite’spolicyisnottrivial. Though less opaque to users and (ii) support legal experts
manywell-regulatedcommercialwebsitesprovide who wish to characterize the state of privacy on-
a “privacy” link on their homepages, not all do. line and make recommendations (Costante et al.,
We found university websites to be exceptionally 2012;Ammaretal.,2012;Costanteetal.,2013).
unlikelytoprovidesuchalink. Evenoncethepol- Weareinspiredbymultiplesequencealignment
icy’sURLisidentified,extractingthetextpresents methods in computational biology (Durbin et al.,
theusualchallengesassociatedwithscrapingdoc- 1998) and by Barzilay and Lee (2004), who de-
uments from the web. Since every site is differ- scribed a hidden Markov model (HMM) for doc-
ent in its placement of the document (e.g., buried ument content where each state corresponds to a
deepwithinthewebsite,distributedacrossseveral distinct topic and generates sentences relevant to
pages,ormingledtogetherwithTermsofService) that topic according to a language model. We
andformat(e.g.,HTML,PDF,etc.),andsincewe estimate an HMM-like model on our corpus, ex-
wish to preserve as much document structure as ploiting similarity across privacy policies to the
possible(e.g.,sectionlabels),fullautomationwas extent it is evident in the data. In our formula-
notaviablesolution. tion, each hidden state corresponds to an issue or
We therefore crowdsourced the privacy policy topic, characterized by a distribution over words
document collection using Amazon Mechanical and bigrams appearing in privacy policy sections
Turk. For each website, we created a HIT in addressing that issue. The transition distribution
which a worker was asked to copy and paste the captures tendencies of privacy policy authors to
following privacy policy-related information into organize these sections in similar orders, though
text boxes: (i) privacy policy URL; (ii) last up- withsomevariation.
dateddate(oreffectivedate)ofthecurrentprivacy
Thegenerativestoryforourmodelisasfollows.
policy; (iii) privacy policy full text; and (iv) the
LetS denotethesetofhiddenstates.
section subtitles in the top-most layer of the pri-
1. Choose a start state y from S according to the
1
vacy policy. To identify the privacy policy URL,
start-statedistribution.
workerswereencouragedtogotothewebsiteand
2. Fort = 1,2,...,untily isthestoppingstate:
t
search for the privacy link. Alternatively, they
couldformasearchqueryusingthewebsitename (a) Sample the tth section of the document by
and “privacy policy” (e.g., “Amazon.com privacy drawing a bag of terms, o t, according to the
policy”) and search in the returned results for the emission multinomial distribution for state y t.
most appropriate privacy policy URL. Given the NotethedifferencefromtraditionalHMMs,in
privacy policy full text and the section subtitles, which a single observation symbol is drawn
wepartitionthefullprivacydocumentintodiffer- at each time step. o t is generated by repeat-
ent sections, delimited by the section subtitles. A edly sampling from a distribution over terms
privacypolicyisthenconvertedintoXML. that includes all unigrams and bigrams except
EachHITwascompletedbythreeworkers,paid those that occur in fewer than 5% of the doc-
$0.05, for a total cost of $380 (including Ama- uments and in more than 98% of the docu-
zon’ssurcharge). ments. This filtering rule was designed to
eliminate uninformative stopwords as well as
3The “Adult” category was excluded; the “World” cate- company-specific terms (e.g., the name of the
gorywasexcludedsinceitcontainsmainlypopularwebsites
company).4
indifferentlanguages, andweoptedtofocusonpoliciesin
Englishinthisfirststageofresearch,thoughmulitlingualpol-
icyanalysispresentsinterestingchallengesforfuturework. 4The emission distributions are not a proper language
606
Websiteswith Uniqueprivacy Uniqueprivacy Ave.sections Ave.tokens
Category privacyURL policies policiesw/date perpolicy perpolicy
Arts 94 80 72 11.1(±3.8) 2894(±1815)
Business 100 95 75 10.1(±4.9) 2531(±1562)
Computers 100 78 62 10.7(±4.9) 2535(±1763)
Games 92 80 51 10.2(±4.9) 2662(±2267)
Health 92 86 57 10.0(±4.4) 2325(±1891)
Home 100 84 68 11.5(±3.8) 2493(±1405)
KidsandTeens 96 86 62 10.3(±4.5) 2683(±1979)
News 96 91 68 10.7(±3.9) 2588(±2493)
Recreation 98 97 67 11.9(±4.5) 2678(±1421)
Reference 84 86 55 9.9(±4.1) 2002(±1454)
Regional 98 91 72 11.2(±4.2) 2557(±1359)
Science 71 75 49 9.2(±4.1) 1705(±1136)
Shopping 100 99 84 12.0(±4.1) 2683(±1154)
Society 96 94 65 10.2(±4.6) 2505(±1587)
Sports 96 62 38 10.9(±4.0) 2222(±1241)
Average 94.2 85.6 63.0 10.7(±4.3) 2471(±1635)
Table2: Statisticsofeachwebsitecategory, including(i)thenumberofwebsiteswithanidentifiedprivacypolicylink; (ii)
numberofuniqueprivacypoliciesineachcategory(notethatinrarecases, multipleuniqueprivacypolicieswereidentified
forthesamewebsite, e.g., awebsitethatcontainslinkstobothnewandoldversionsofitsprivacypolicy); (iii)numberof
websiteswithanidentifiedprivacymodificationdate;(iv)averagenumberofsectionsperpolicy;(v)averagenumberoftokens
perpolicy.
(b) Sample the next state, y , according to the s totransitionto{s ,s ,...,s }. “StrictFor-
t+1 k k k+1 K
transitiondistributionoverS. ward”onlyallowss totransitiontos ors .
k k k+1
This model can nearly be understood as a hid-
densemi-Markovmodel(BaumandPetrie,1966), 4 Evaluation
though we treat the section lengths as observable.
Developing a gold-standard alignment of privacy
Indeed, our model does not even generate these
policies would either require an interface that al-
lengths, since doing so would force the states to
lowseachannotatortointeractwiththeentirecor-
“explain” the length of each section, not just its
pus of previously aligned documents while read-
content. The likelihood function for the model is
ingtheonesheisannotating,orthedefinition(and
showninFigure1.
likely iterative refinement) of a set of categories
The parameters of the model are almost iden-
formanuallylabelingpolicysections. Thesewere
tical to those of a classic HMM (start state dis-
too costly for us to consider, so we instead pro-
tribution, emission distributions, and transition
pose two generic methods to evaluate models
distributions), except that emissions are char-
for sequence alignment of a collection of docu-
acterized by multinomial rather than a cate-
mentswithgenerallysimilarcontent. Thoughour
gorical distributions. These are learned us-
model (particularly the restricted variants) treats
ing Expectation-Maximization, with a forward-
the problem as one of alignment, our evaluations
backward algorithm to calculate marginals (E-
consider groupings of policy sections. In the se-
step) and smoothed maximum likelihood estima-
quel,agroupingonasetX isdefinedasacollec-
tion for the M-step (Rabiner, 1989). After learn-
tion of subsets X ⊆ X; these may overlap (i.e.,
ing, the most probable assignment of a policy’s i
theremightbex ∈ X ∩X )andneednotbeex-
sectionstostatescanberecoveredusingavariant i j S
haustive(i.e.,theremightbex ∈ X \ X ).
oftheViterbialgorithm. i i
WeconsiderthreeHMMvariants. “Vanilla”al-
4.1 EvaluationbyHumanQA
lows all transitions. The other two posit an order-
ing on the states S = {s ,s ,...,s }, and re- This study was carried out as part of a larger col-
1 2 K
strictthesetoftransitionsthatarepossible,impos- laboration with legal scholars who study privacy.
ingbiasonthelearner. “AllForward”onlyallows Inthatwork,wehaveformulatedasetofninemul-
tiple choice questions about a single policy that
models(e.g.,abigrammaybegeneratedbyasmanyasthree
ask about collection of contact, location, health,
drawsfromtheemissiondistribution:onceforeachunigram
itcontainsandonceforthebigram). and financial information, sharing of each with
607
!
Yn Y‘t
P (hy ,o in | h‘ in ) = π(y ) η(o | y ) γ(y | y )
π,η,γ t t t=1 t t=1 1 t,i i t+1 t
t=1 i=1
Figure1: Thelikelihoodfunctionforthealignmentmodel(oneprivacypolicy).y tisthehiddenstateforthetthsection,otis
thebagofunigramandbigramtermsobservedinthatsection,and‘ isthesizeofthebag.Start-state,emission,andtransition
t
distributionsaredenotedrespectivelybyπ,η,andγ.y isthesilentstoppingstate.
n+1
third parties, and deletion of data.5 The questions byasimplemeasureoftextsimilarity. Wederived
wereinspiredprimarilybythesubstantiveinterest unigram tfidf vectors for each section in each of
ofthesedomainexperts—notbythisparticularal- 50 randomly sampled policies per category. We
gorithmicstudy. then binned pairs of sections by cosine similarity
For thirty policies, we obtained answers from (into four bins bounded by 0.25, 0.5, and 0.75).
eachofsixdomainexpertswhowerenotinvolved Wesampled994sectionpairsuniformlyacrossthe
indesigningthequestions. Forthepurposesofthis 15categories’fourbinseach.
study, the experts’ answers are not important. In Crowdsourcingwasusedtodetermine,foreach
addition to answering each question for each pol- pair, whether the two sections should be grouped
icy, we also asked each expert to copy and paste together. A HIT consisted of a pair of policy sec-
the text of the policy that contains the answer. tions and a multiple choice question, “After read-
Experts were allowed to select as many sections ing the two sections given below, would you say
for each question as they saw fit, since answering that they broadly discuss the same topic?” The
somequestionsmayrequiresynthesizinginforma- possibleanswerswere:
tionfromdifferentsections. 1. Yes, both the sections essentially convey the
For each of the nine questions, we take the samemessageinaprivacypolicy.
union of all policy sections that contain text se- 2. Although, the sections do not convey the same
lectedbyanyannotatorassupportforheranswer. message, the broadly discuss the same topic.
This results in nine groups of policy sections, (For ease of understanding, some examples of
which we call answer-sets denoted A ,...,A . contenton“thesametopic”wereincluded.)
1 9
Our method allows these to overlap (63% of the 3. No,thesectionsdiscusstwodifferenttopics.
sectionsinanyA occurredinmorethanoneA ), The first two options were considered a “yes” for
i i
and they are not exhaustive (since many sections the majority voting and for defining a gold stan-
ofthepolicieswerenotdeemedtocontainanswers dard. Everysection-pairwasannotatedbyatleast
toanyoftheninequestionsbyanyexpert). three annotators (as many as 15, increased until
Together, these can be used as a gold standard an absolute majority was reached). Turkers with
groupingofpolicysections,againstwhichwecan an acceptance rate greater than 95% with an ex-
compareoursystem’soutput. Todothis,wedefine perience of at least 100 HITs were allowed and
the set of section pairs that are grouped together paid $0.03 per annotation. The total cost includ-
in answer sets, G = |{ha,bi | ∃A 3 a,b}|, and ing some initial trials was $130. 535 out of the
i
a similar set of pairs H from a model’s grouping. 994pairswereannotatedtobesimilarintopic. An
From these sets, we calculate estimates of preci- exampleisshowninFigure2.
sion(|G∩H|/|H|)andrecall(|G∩H|/|G|). Asin§4.1,wecalculateprecisionandrecallon
One shortcoming of this approach, for which pairs. Thisdoesnotpenalizethemodelforgroup-
thesecondevaluationseekstocompensate,isthat ing together a “no” pair; we chose it nonetheless
averysmall,andlikelybiased,subsetofthepolicy becauseitisinterpretable.
sectionsisconsidered.
5 Experiment
4.2 EvaluationbyDirectJudgment
In this section, we evaluate the three HMM vari-
We created a separate gold standard of judgments
ants described in §3, and two baselines, using the
of pairs of privacy policy sections. The data se-
methods in §4. All of the methods require the
lectedforjudgmentwasasampleofpairsstratified
specification of the number of groups or hidden
states,whichwefixtoten,theaveragenumberof
5The questions are available in an online appendix at
http://usableprivacy.org/data. sectionsperpolicy.
608
Section5ofclassmates.com:
[46words]... YoumayalsoberequiredtouseapasswordtoaccesscertainpagesontheServiceswherecertain
typesofyourpersonalinformationcanbechangedordeleted. ... [113words]
Section2of192.com:
[50words]... ThisPolicysetsoutthemeansbywhichYoucanhaveYourPersonalInformationremovedfrom
theService.192.comisalsocommittedtokeepingPersonalInformationofusersoftheServicesecureandonlyto
useitforthepurposessetoutinthisPolicyandasagreedbyYou.... [24words]
Figure2: Selectionsfromsectionsthatdiscusstheissueof“deletionofpersonalinformation”andwerelabeledasdiscussing
thesameissuebycrowdworkers.Bothna¨ıvegroupingandLDAputthemintwodifferentgroups,buttheStrictForwardvariant
ofourmodelcorrectlygroupsthemtogether.
Precision Recall F 1 ten runs was very high (67% and 53% F 1 on the
Mean S.D. Mean S.D. Mean S.D.
two tasks), suggesting the potential benefits of
Clust. 0.63 – 0.30 – 0.40 –
LDA 0.56 0.03 0.20 0.05 0.29 0.06 goodinitializationormodelselection.
Vanilla 0.62 0.04 0.41 0.04 0.49 0.03
AllF. 0.63 0.03 0.47 0.12 0.53 0.06 6 Conclusion
StrictF. 0.62 0.05 0.46 0.18 0.51 0.07
Clust. 0.62 – 0.23 – 0.34 – We considered the task of aligning sections of
LDA 0.57 0.03 0.18 0.01 0.28 0.02
a collection of roughly similarly-structured legal
Vanilla 0.57 0.01 0.30 0.03 0.39 0.02
documents, based on the issues they address. We
AllF. 0.58 0.02 0.32 0.06 0.41 0.04
StrictF. 0.58 0.03 0.32 0.14 0.40 0.08 introduced an unsupervised model for this task
along with two new (and reusable) evaluations.
Table3: EvaluationbyhumanQA(above)anddirectjudg-
ment(below),aggregatedacrosstenindependentrunswhere Ourexperimentsshowtheapproachtobemoreef-
appropriate (see text). Vanilla, All F(orward), and Strict fectivethanclusteringandtopicmodels. Thecor-
F(orward)arethreevariantsofourHMM.
pusand evaluationdata havebeen made available
athttp://usableprivacy.org/data. In
Baselines. Ourfirstbaselineisagreedydivisive future work, policy section alignments will be
clustering algorithm6 to partition the policy sec- usedinautomatedanalysistoextractusefulinfor-
tions into ten clusters. In this method, the de- mationforusersandprivacyscholars.
sired K-way clustering solution is computed by
Acknowledgments
performing a sequence of bisections. The imple-
mentation uses unigram features and cosine simi-
The authors gratefully acknowledge helpful com-
larity. OursecondbaselineislatentDirichletallo-
ments from Lorrie Cranor, Joel Reidenberg, Flo-
cation(LDA;Bleietal.,2003),withtentopicsand
rian Schaub, and several anonymous reviewers.
onlinevariationalBayesforinference(Hoffmanet
ThisresearchwassupportedbyNSFgrantSaTC-
al., 2010).7 To more closely match our models,
1330596.
LDA is given access to the same unigram and bi-
gramtokens.
References
Results. Table 3 shows the results. For LDA
Waleed Ammar, Shomir Wilson, Norman Sadeh, and
andtheHMMvariants(whichuserandominitial-
NoahA.Smith. 2012. Automaticcategorizationof
ization), we report mean and standard deviation
privacy policies: A pilot study. Technical Report
across ten independent runs. All three variants CMU-LTI-12-019,CarnegieMellonUniversity.
of the HMM improve over the baselines on both
Regina Barzilay and Lillian Lee. 2004. Catching the
tasks, in terms of F . In the human QA evalu-
1 drift:Probabilisticcontentmodels,withapplications
ation, this is mostly due to recall improvements
to generation and summarization. In Proc. of HLT-
(i.e., more pairs of sections relevant to the same NAACL.
policyquestionweregroupedtogether).
Leonard E. Baum and Ted Petrie. 1966. Statistical
Thethreevariantsofthemodelperformedsim-
inference for probabilistic functions of finite state
ilarly on average, though Strict Forward had very Markov chains. Annals of Mathematical Statistics,
high variance. Its maximum performance across 37:1554–1563.
6AsimplementedinCLUTO,http://glaros.dtc. David M Blei, Andrew Y Ng, and Michael I Jordan.
umn.edu/gkhome/cluto/cluto/overview 2003. Latent Dirichlet allocation. the Journal of
7Asimplementedingensim(Rˇehu˚ˇrekandSojka,2010). machineLearningresearch,3:993–1022.
609
CarolynA.Brodie,Clare-MarieKarat,andJohnKarat.
2006. Anempiricalstudyofnaturallanguagepars-
ingofprivacypolicyrulesusingtheSPARCLEpol-
icy workbench. In Proc. of the Symposium on Us-
ablePrivacyandSecurity.
Elisa Costante, Yuanhao Sun, Milan Petkovic´, and
Jerry den Hartog. 2012. A machine learning solu-
tiontoassessprivacypolicycompleteness. InProc.
of the ACM Workshop on Privacy in the Electronic
Society.
Elisa Costante, Jerry Hartog, and Milan Petkovi.
2013. What websites know about you. In Roberto
Pietro, Javier Herranz, Ernesto Damiani, and Radu
State, editors, Data Privacy Management and Au-
tonomous Spontaneous Security, volume 7731 of
LectureNotesinComputerScience,pages146–159.
SpringerBerlinHeidelberg.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological Sequence
Analysis: ProbabilisticModelsofProteinsandNu-
cleicAcids. CambridgeUniversityPress.
Federal Trade Commission. 2012. Protecting con-
sumer privacy in an era of rapid change: Recom-
mendationsforbusinessesandpolicymakers.
Robert Gellman. 2014. Fair information prac-
tices: a basic history (v. 2.11). Available at
http://www.bobgellman.com/rg-docs/
rg-FIPShistory.pdf.
Matthew D Hoffman, David M Blei, and Francis R
Bach. 2010. OnlinelearningforlatentDirichletal-
location. InNIPS.
AleeciaM.McDonaldandLorrieFaithCranor. 2008.
Thecostofreadingprivacypolicies. I/S:AJournal
ofLawandPolicyfortheInformationSociety,4(3).
LawrenceRabiner. 1989. AtutorialonhiddenMarkov
modelsandselectedapplicationsinspeechrecogni-
tion. ProceedingsoftheIEEE,77(2):257–286.
RadimRˇehu˚ˇrekandPetrSojka. 2010. Softwareframe-
work for topic modelling with large corpora. In
Proc.oftheLRECWorkshoponNewChallengesfor
NLPFrameworks.
Xusheng Xiao, Amit Paradkar, Suresh Thum-
malapenta, and Tao Xie. 2012. Automated ex-
traction of security policies from natural-language
softwaredocuments. InProc.oftheACMSIGSOFT
International Symposium on the Foundations of
SoftwareEngineering.
Sebastian Zimmeck and Steven M. Bellovin. 2013.
Machinelearningforprivacypolicy.
610
