Joint Event Trigger Identification and Event Coreference Resolution with
Structured Perceptron
JunArakiandTerukoMitamura
LanguageTechnologiesInstitute
CarnegieMellonUniversity
Pittsburgh,PA15213,USA
{junaraki,teruko}@cs.cmu.edu
Abstract (2) ThePalestinianAuthoritycondemnedtheattack(E3),
sayingit(E4)woulddivertinternationalsympathy
Events and their coreference offer use- awayfromthefarhigherPalestinianciviliandeathtoll.
ful semantic and discourse resources.
E1 corefers to E2, and E3 does to E4. E2 is more
We show that the semantic and dis-
abstract than E1, and has less evidence of being
courseaspectsofeventsinteractwitheach
an event. E4 is a pronoun, and thus may seem
other. However,traditionalapproachesad-
to refer to an entity rather than an event. Thus,
dressed event extraction and event coref-
E2andE4arerelativelydifficulttoberecognized
erence resolution either separately or se-
as events by themselves. However, event coref-
quentially, which limits their interactions.
erence E1-E2, which is supported primarily by
This paper proposes a document-level
E2’sparticipantsBarclaysandZaragozanoshared
structured learning model that simultane-
with E1, helps determine that E2 is an event. The
ouslyidentifieseventtriggersandresolves
same logic applies to E3 and E4. On the other
event coreference. We demonstrate that
hand,previousworkstypicallyrelyonapipelined
the joint model outperforms a pipelined
model that extracts events (e.g., E1 and E3) at
modelby6.9BLANCF1and1.8CoNLL
the first stage, and then resolves event corefer-
F1 points in event coreference resolution
enceatthesecondstage. Althoughthismodularity
usingacorpusinthebiologydomain.
is preferable from development perspectives, the
1 Introduction
pipelined model limits the interactions. That is,
thefirststagealoneisunlikelytodetectE2andE4
Events convey semantic information such as who
as events due to the difficulties described above.
did what to whom where and when. They also
These missing events make it impossible for the
corefer to each other, playing a role of discourse
second stage to resolve event coreference E1-E2
connectionpointstoformacoherentstory. These
andE3-E4.
aspects of events have been already utilized in
In this work, we address the problem using the
a wide variety of natural language processing
ProcessBankcorpus(Berantetal.,2014). Follow-
(NLP)applications,suchasautomatedpopulation
ing the terminology defined in the corpus, we in-
ofknowledgebases(JiandGrishman,2011),topic
troduceseveralterms:
detectionandtracking(Allan,2002),questionan-
swering (Bikel and Castelli, 2008), text summa-
• Event: anabstractrepresentationofachangeofstate,
rization (Li et al., 2006), and contradiction detec- independentfromparticulartexts.
tion(deMarneffeetal.,2008). Thisfactillustrates • Eventtrigger:mainword(s)intext,typicallyaverbor
anounthatmostclearlyexpressesanevent.
theimportanceofeventextractionandeventcoref-
• Event arguments: participants or attributes in text,
erenceresolution. typicallynouns,thatareinvolvedinanevent.
• Eventmention:aclauseintextthatdescribesanevent,
Thosesemanticanddiscourseaspectsofevents
andincludesbothatriggerandarguments.
are not independent from each other, and in fact • Eventcoreference: alinguisticphenomenonthattwo
often work in interactive manners. We give two eventmentionsrefertothesameevent.
examplesoftheinteractions:
We aim to explore the interactions between event
(1) BritishbankBarclayshadagreedtobuy(E1)Spanish mentionsandeventcoreference. Asafirststepto-
rivalBancoZaragozanofor1.14billioneuros.The
wardthegoal, wefocusonthetaskofidentifying
combination(E2)ofthebankingoperationsof
BarclaysSpainandZaragozanowillbringtogether eventtriggersandresolvingeventcoreference,and
twocomplementarybusinesses.
2074
Proceedingsofthe2015ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages2074–2080,
Lisbon,Portugal,17-21September2015.(cid:13)c2015AssociationforComputationalLinguistics.
proposeadocument-leveljointlearningmodelus- intotheirmodel.
ing structured perceptron (Collins, 2002) that si- Event coreference resolution is more chal-
multaneously predicts them. Our assumption is lengingandlessexplored. Tosetupeventtriggers
that the joint model is able to capture the interac- asastartingpointofthetask,someworksusehu-
tionsbetweeneventtriggersandeventcoreference manannotationinacorpus(BejanandHarabagiu,
adequately, and such comprehensive decision im- 2014; Liu et al., 2014), and others use the output
proves the system performance. For instance, the of a separate event extraction system (Lee et al.,
joint model is likely to extract E2 as well as E1 2012). Berantetal. (2014)presentedamodelthat
successfully via their event coreference by simul- jointly predicts event arguments and event coref-
taneouslylookingatcoreferencefeatures. erence (as well as other relations between event
Ourcontributionsareasfollows: triggers). However, none of them tries to predict
1. Thisisthefirstworkthatsimultaneouslypre- eventtriggersandeventcoreferencejointly.
dictseventtriggersandeventcoreferenceus- Joint structured learning has been applied
ing a single joint model. At the core of the to several NLP tasks, such as word segmenta-
modelisadocument-levelstructuredpercep- tionandpart-of-speech(POS)tagging(Zhangand
tron algorithm that learns event triggers and Clark,2008a),POStagginganddependencypars-
eventcoreferencejointly. ing (Bohnet and Nivre, 2012), dependency pars-
2. The incremental token-based prediction in ing and semantic role labeling (Johansson and
joint decoding poses a challenge of synchro- Nugues,2008),theextractionofeventtriggersand
nizing the assignments of event triggers and arguments (Li et al., 2013), and the extraction of
coreference. To avoid this problem, we pro- entity mentions and relations (Li and Ji, 2014).
pose an incremental decoding algorithm that Their underlying ideas are similar to ours. That
combines the segment-based decoding and is, one can train a structured learning model to
best-firstclusteringalgorithm. globally capture the interactions between two rel-
3. Ourexperimentsindicatethatthejointmodel evant tasks via a certain kind of structure, while
achieves a substantial performance gain in making predictions specifically for these respec-
event coreference resolution with a corpus tive tasks. However, no prior work has studied
in the biology domain, as compared to a the interactions between event trigger identifica-
pipelinedmodel. tionandeventcoreferenceresolution.
2 RelatedWork 3 Approach
No previous work deals with event extraction and We formalize the extraction of event triggers and
event coreference resolution simultaneously. We event coreference as a problem of structured pre-
thus describe how these two tasks have been ad- diction. The output structure is a document-level
dressedseparately,andhowjointstructuredlearn- event graph where each node represents an event
inghasbeenstudiedinotherNLPtasks. trigger,andeachedgerepresentsaneventcorefer-
Event extraction has been studied mainly in encelinkbetweentwoeventtriggers.
the newswire domain and the biomedical domain
3.1 Corpus
as the task of detecting event triggers and deter-
miningtheireventtypesandarguments. Inthefor- The ProcessBank corpus consists of 200 para-
merdomain,mostworktookapipelinedapproach graphs from the textbook Biology (Campbell and
where local classifiers identify triggers first, and Reece, 2005). Table1showsstatisticsofourdata
then detect arguments (Ji and Grishman, 2008; splits. The original corpus provides 150 para-
LiaoandGrishman,2010;Hongetal.,2011). Liet graphsastrainingdata,andwesplittheminto120
al.(2013)presentedastructuredperceptronmodel and 30 for our training and development, respec-
to detect triggers and arguments jointly. Simi- tively. We chose ProcessBank instead of a larger
larly, joint dependencies in events were also ad- corpus such as the Automatic Content Extraction
dressed in the latter domain (Poon and Vander- (ACE)2005corpusforthefollowingtworeasons.
wende, 2010; McClosky et al., 2011; Riedel and First, the human annotation of event coreference
McCallum, 2011; Venugopal et al., 2014). How- linksinProcessBankenablesustoapplythebest-
ever,noneofthemincorporatedeventcoreference first clustering directly; on the other hand, this is
2075
not readily feasible in ACE 2005 since it anno- date(CollinsandRoark,2004)andmax-violation
tates event coreference as clusters, and gold stan- update (Huang et al., 2012) to our model. Our
dardeventcoreferencelinksrequiredforthebest- initial experiments indicated that early updates
first clustering are not available. Second, event happen too early to gain sufficient feedback on
coreferenceresolutionusingProcessBankisnovel weights from entire documents in training exam-
since almost no previous work on the task used ples, ending up with a poorer performance than
that corpus. The only exception could be (Berant the standard update. This contrasts with the fact
etal.,2014),wheretheyextractedseveraltypesof thattheearly-updatestrategywassuccessfullyap-
relations between event triggers, including event plied to other NLP tasks such as constituent pars-
coreference. However, they did not report any ing (Collins and Roark, 2004) and dependency
performancescoresoftheirsystemspecificallyon parsing (Zhang and Clark, 2008b). The main rea-
eventcoreference,andthustheirworkisnotcom- son why the early update fell short of the stan-
parabletoours. dardupdateinoursettingisthatjointeventtrigger
identificationandeventcoreferenceresolutionisa
Train Dev Test Total
much more difficult task since they require more
#ofparagraphs 120 30 50 200
complexknowledgeandargumentstructures. Due
#ofeventtriggers 823 224 356 1403
#ofeventcoreferences 73 28 30 131 tothedifficultlyofthetask,itisalsoverydifficult
to develop such an effective feature set that beam
Table1: Statisticsofourdataset.
search can explore the search space of an entire
documentthoroughlywithearlyupdates. Thisob-
Unlike previous work (Berant et al., 2014; Li
servationfollows(Bjo¨rkelundandKuhn,2014)on
et al., 2013), we explicitly allow an event trigger
entitycoreferenceresolution. Incontrast,themax-
tohavemultipletokens,suchasverbphrase‘look
violation update showed almost the same perfor-
into’ and compound proper noun ‘World War II’.
mance as the standard update on the development
This is a more realistic setting for event trigger
data. From these results, we chose the standard-
identification since in general there are a consid-
updatestrategyforsimplicity.
erablenumberofmulti-tokeneventtriggers1.
3.3 JointDecoding
3.2 EventGraphLearning
Given that an event trigger has one or more to-
Let x denote an input document with n to-
kens, event trigger identification could be solved
kens where x is the i-th token in the docu-
i as a token-level sequential labeling problem with
ment. Foreventgraphlearning,weusestructured
BIOorBILOUschemeinthesamewayasnamed
perceptron (Collins, 2002), and average weights
entity recognition (Ratinov and Roth, 2009). If
to reduce overfitting as suggested in (Collins,
one uses this approach, a beam state may repre-
2002). Thealgorithminvolvesdecodingtogener-
sentapartialassignmentofaneventtrigger. How-
ate the best event graph for each input document.
ever,eventcoreferencecanbeexploredonlyfrom
We elaborate on our decoding algorithm in Sec-
complete assignments of an event trigger. Thus,
tion 3.3. Since an event graph has an exponen-
onewouldneedtosynchronizethesearchprocess
tially large search space, we use beam search to
of event coreference by comparing event corefer-
approximate exact inference. We extract a range
ences from the complete assignment at a certain
offeaturesbyusingStanfordCoreNLP(Manning
position with those from complete assignments at
et al., 2014), MATE (Bjo¨rkelund et al., 2009),
following positions. This makes it complicated
OpenNLP2, Nomlex (Macleod et al., 1998), and
to implement the formalization of token-level se-
Levin verb classes (Levin, 1993). For brevity, we
quential labeling for joint decoding in our task.
provide details of the structured perceptron algo-
One possible way to avoid this problem is to ex-
rithmandfeaturesinthesupplementarymaterial.
tracteventtriggercandidateswithapreferenceon
We use the standard-update strategy in our
highrecallfirst,andthensearcheventcoreference
structuredperceptronmodel. Asvariantsofstruc-
from those candidates, regarding them as com-
tured perceptron, one could employ the early up-
plete assignments of an event trigger. This recall-
1Forexample,around13.4%ofthe1403eventtriggersin oriented pre-filtering is often used in entity coref-
ProcessBankhavemultipletokens. erence resolution (Lee et al., 2013; Bjo¨rkelund
2http://opennlp.apache.org/
2076
Algorithm1Jointdecodingforeventtriggersand implements the best-first clustering. Once a new
coreferencewithbeamsearch. event trigger is appended to an event subgraph at
Input: inputdocumentx=(x 1,x 2,...,x n) line 6, the decoder uses it as a referring mention
Input: beamwidthk,maxlengthofeventtriggerl
max regardless of whether the event subgraph is in the
Output: besteventgraphyˆforx
1: initializeemptybeamhistoryB[1..n] beam, and seeks the best antecedent for it. This
2: fori←1..ndo enables the joint model to make a more global
3: forl←1..l do
max decision on event trigger identification and event
4: fory∈B[i−l]do
5: e←CREATEEVENTTRIGGER(l,i). coreferencedecision,asdescribedinSection1.
6: APPENDEVENTTRIGGER(y,e)
7: B[i]←k-BEST(B[i]∪y) 4 ExperimentalSettings
8: forj ←1..i−1do
9: c←CREATEEVENTCOREF(j,e).
When training our model, we observed that 20-
10: ADDEVENTCOREF(y,c)
11: B[i]←k-BEST(B[i]∪y) iterationtrainingalmostreachedconvergence,and
12: returnB[n][0] thus we set the number of iterations to 20. We
setl to6becauseweobservedthatthelongest
max
and Farkas, 2012). In our initial experiments, we eventtriggerintheentireProcessBankcorpushas
observed that our rule-based filter gained around sixtokens. Whentuningbeamwidthk onthede-
97%recall,butextractedaround12,400falseposi- velopmentset, largebeamwidthdidnotgiveusa
tivesagainst823truepositivesinthetrainingdata. significant performance difference. We attribute
Thismadeitdifficultforourstructuredperceptron this result to the small size of the development
to learn event triggers, which underperformed on data. In particular, the development data has only
eventcoreferenceresolution. 28 event coreferences, which makes it difficult to
We, therefore, employ segment-based decod- revealtheeffectofbeamwidth. Wethussetkto1
ing with multiple-beam search (Zhang and Clark, inourexperiments.
2008a; Li and Ji, 2014) for event trigger identi-
4.1 BaselineSystems
fication, and combine it with the best-first clus-
tering (Ng and Cardie, 2002) for event coref- Our baseline is a pipelined model that divides the
erence resolution in document-level joint decod- event trigger decoding and event coreference de-
ing. Thekeyideaofsegment-baseddecodingwith coding in Algorithm 1 into two separate stages.
multiple-beam search is to keep previous beam It uses the same structured perceptron with the
states available, and use them to form segments same hyperparameters and feature templates. We
from previous positions to the current position. choose this baseline because it clearly reveals the
Let l denote the upper bound on the number effectiveness of the joint model by focusing only
max
of tokens in one event trigger. The k-best partial onthearchitecturaldifference. Onecoulddevelop
structures(eventsubgraphs)inbeamB atthej-th otherbaselinesystems. Oneofthemisadetermin-
tokeniscomputedasfollows: isticsieve-basedapproachbyLeeetal.(2013). A
natural extension to the approach for performing
B[j] = k-BEST Φ(x,y)·w
event trigger identification as well as event coref-
y∈{y ∈B[j−l],y =s}
[1:j−l] [j−l+1,j]
erence resolution would be to develop additional
where 1 ≤ l ≤ l , y is an event subgraph
max [1:j] sievestoclassifysingletonsintorealeventtriggers
endingatthej-thtoken,andy = smeans
[j−l+1,j] orspuriousones. Weleaveitforfuturework.
that partial structure y is a segment, i.e.,
[j−l+1,j]
an event trigger candidate with a subsequence of 4.2 Evaluation
tokens x . This approximates Viterbi de-
[j−l+1,j] We evaluate our system using a reference
codingwithbeamsearch.
implementation of coreference scoring algo-
The best-first clustering incrementally makes
rithms (Pradhan et al., 2014; Luo et al., 2014).
coreferencedecisionsbyselectingthemostlikely
As for event trigger identification, this scorer
antecedent for each trigger. Our joint decoding
computes precision (P), recall (R), and the F1
algorithm makes use of the incremental process
score. With respect to event coreference reso-
tocombinethesegment-baseddecodingandbest-
lution, the scorer computes MUC (Vilain et al.,
first clustering. Algorithm 1 shows the summary
1995),B3 (BaggaandBaldwin,1998),twoCEAF
ofthejointdecodingalgorithm. Line3-7imple-
metrics CEAF and CEAF (Luo, 2005), and
m e
mentsthesegment-baseddecoding,andline8-11
2077
MUC B3 CEAF CEAF BLANC CoNLL
m e
System R P F1 R P F1 R P F1 R P F1 R P F1 F1
Baseline 26.66 19.51 22.53 55.47 58.64 57.01 53.08 60.38 56.50 52.68 63.14 57.44 30.13 25.10 25.05 45.66
Joint 20.00 37.50 26.08 53.37 63.36 57.93 53.93 62.95 58.09 55.06 62.11 58.38 27.51 38.43 31.91 47.45
Table2: Resultsofeventcoreferenceresolution. ‘Baseline’referstothesecondstageofourbaseline.
BLANC (Recasens and Hovy, 2011) extended by do not share key semantic roles (e.g., agents and
Luo et al. (2014). We also report the CoNLL av- patients)inaclearargumentstructure.
erage (Denis and Baldridge, 2009), which is the
(3) Whenthecellisstimulated,gatedchannelsopenthat
averageofMUCF1,B3 F1,andCEAF F1.
e facilitateNa+diffusion(E5).Sodiumionsthen
”fall”(E6)downtheirelectrochemicalgradient,...
5 ResultsandDiscussions
(4) Thenextsevenstepsdecompose(E7)thecitrateback
Wefirstshowtheresultofeventcoreferencereso- tooxaloacetate.Itisthisregeneration(E8)of
oxaloacetatethatmakesthisprocessacycle.
lutiononthetestdatainTable2. Thejointmodel
outperforms the baseline by 6.9 BLANC F1 and 6 ConclusionandFutureWork
1.8CoNLLF1points. Weobservedthatthisover-
Wepresentajointstructuredpredictionmodelfor
all performance gain comes largely from a preci-
event trigger identification and event coreference
siongain,morespecifically,substantiallyreduced
resolution. Toourknowledge,thisisthefirstwork
false positives. We explain the superiority of the
that solves these two tasks simultaneously. Our
jointmodelasfollows. Inthebaseline,thesecond
experiment shows that the proposed method ef-
stageusestheoutputofthefirststage. Sinceevent
fectively penalizes false positives in joint search,
triggers are fixed at this point, the baseline ex-
therebyoutperformingapipelinedmodelsubstan-
plores coreference links only between these event
tiallyineventcoreferenceresolution.
triggers. In contrast, the joint model seeks event
Thereareanumberofavenuesforfuturework.
triggersandeventcoreferencesimultaneously,and
One can further ensure the advantage of the joint
thus it explores a larger number of false positives
model using a larger corpus. Our preliminary ex-
inthesearchprocess,therebylearningtopenalize
perimentontheACE2005corpusshowsthatdue
falsepositivesmoreadequatelythanthebaseline.
to its larger document size and event types, one
System Recall Precision F1 will need to reduce training time by a distributed
Baseline 57.02 64.85 60.68
learningalgorithmsuchasmini-batches(Zhaoand
Joint 55.89 65.24 60.21
Huang,2013). Anotherfutureworkistoincorpo-
Table 3: Results of event trigger identification. rate other components of events into the model.
‘Baseline’referstothefirststageofourbaseline. These include event types, event arguments, and
otherrelationssuchassubevents. Onecouldlever-
age them as other learning targets or constraints,
Table 3 shows the results of event trigger iden-
andinvestigatefurtherbenefitsofjointmodeling.
tification on the test data. We observed that the
joint model also reduced false positives, similarly
Acknowledgments
in event coreference resolution. However, its im-
provement on precision is small, ending up with This research was supported in part by DARPA
almostthesameF1pointasthebaseline. Wespec- grant FA8750-12-2-0342 funded under the Deep
ulatethatthisisduetothesmallsizeofthecorpus, Exploration and Filtering of Text (DEFT) Pro-
andthejointmodelwasunabletoshowitsadvan- gram, and by U.S. Army Research Office (ARO)
tagesineventtriggeridentification. grantW911NF-14-1-0436undertheReading,Ex-
Below are two error cases in event coreference traction, and Assembly of Pathways for Eviden-
resolution, where our model fails to resolve E5- tiary Reading (REAPER) Program. Any opinion,
E6 and E7-E8. The model was unable to ade- findings,andconclusionsorrecommendationsex-
quatelyextractfeaturesforbotheventtriggersand pressed in this material are those of the authors
event coreference, particularly because their sur- anddonotnecessarilyreflecttheviewofDARPA,
face strings are not present in training data, they ARO,ortheU.S.government. JunArakiispartly
are lexically and syntactically different, and they supportedbyaFunaiOverseasScholarship.
2078
References Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Us-
James Allan. 2002. Topic Detection and Tracking:
ing cross-entity inference to improve event extrac-
Event-based Information Organization. Kluwer
tion. In Proceedings of ACL-HLT 2011, pages
AcademicPublishers.
1127–1136.
Amit Bagga and Breck Baldwin. 1998. Algorithms
Liang Huang, Suphan Fayong, and Yang Guo. 2012.
for scoring coreference chains. In Proceedings of
Structured perceptron with inexact search. In Pro-
LREC 1998 Workshop on Linguistics Coreference,
ceedingsofNAACL-HLT2012,pages142–151.
pages563–566.
HengJiandRalphGrishman. 2008. Refiningeventex-
CosminAdrianBejanandSandaM.Harabagiu. 2014.
tractionthroughcross-documentinference. InPro-
Unsupervisedeventcoreferenceresolution. Compu-
ceedingsofACL-HLT2008,pages254–262.
tationalLinguistics,40(2):311–347.
Heng Ji and Ralph Grishman. 2011. Knowledge
Jonathan Berant, Vivek Srikumar, Pei-Chun Chen,
base population: Successful approaches and chal-
Abby Vander Linden, Brittany Harding, Brad
lenges. In Proceedings of ACL-HLT 2011, pages
Huang, Peter Clark, and Christopher D. Manning.
1148–1158.
2014. Modeling biological processes for reading
comprehension. In Proceedings of EMNLP 2014,
Richard Johansson and Pierre Nugues. 2008.
pages1499–1510.
Dependency-based semantic role labeling of Prop-
Bank. In Proceedings of EMNLP 2008, pages 69–
Daniel M. Bikel and Vittorio Castelli. 2008. Event
78.
matchingusingthetransitiveclosureofdependency
relations. InProceedingsofACL2008,pages145–
Heeyoung Lee, Marta Recasens, Angel Chang, Mihai
148.
Surdeanu,andDanJurafsky. 2012. Jointentityand
event coreference resolution across documents. In
Anders Bjo¨rkelund and Richa´rd Farkas. 2012. Data-
Proceedings of EMNLP/CoNLL 2012, pages 489–
drivenmultilingualcoreferenceresolutionusingre-
500.
solver stacking. In Proceedings of EMNLP/CoNLL
2012,pages49–55.
Heeyoung Lee, Angel Chang, Yves Peirsman,
NathanaelChambers,MihaiSurdeanu,andDanJu-
Anders Bjo¨rkelund and Jonas Kuhn. 2014. Learn-
rafsky. 2013. Deterministic coreference resolu-
ingstructuredperceptronsforcoreferenceresolution
tionbasedonentity-centric, precision-rankedrules.
with latent antecedents and non-local features. In
ComputationalLinguistics,39(4):885–916.
ProceedingsofACL2014,pages47–57.
Anders Bjo¨rkelund, Love Hafdell, and Pierre Nugues. BethLevin. 1993. EnglishVerbClassesandAlterna-
2009. Multilingual semantic role labeling. In Pro- tion:APreliminaryInvestigation. TheUniversityof
ceedingsofCoNLL2009,pages43–48. ChicagoPress.
Bernd Bohnet and Joakim Nivre. 2012. A transition- QiLiandHengJi. 2014. Incrementaljointextraction
basedsystemforjointpart-of-speechtaggingandla- ofentity mentionsand relations. In Proceedingsof
beled non-projective dependency parsing. In Pro- ACL2014,pages402–412.
ceedings of EMNLP/CoNLL 2012, pages 1455–
Wenjie Li, Mingli Wu, Qin Lu, Wei Xu, and Chunfa
1465.
Yuan. 2006. Extractive summarization using
Neil Campbell and Jane Reece. 2005. Biology. Ben- inter- andintra- event relevance. In Proceedings of
jaminCummings. ACL/COLING2006,pages369–376.
Michael Collins and Brian Roark. 2004. Incremental Qi Li, Heng Ji, and Liang Huang. 2013. Joint event
parsingwiththeperceptronalgorithm. InProceed- extractionviastructuredpredictionwithglobalfea-
ingsofACL2004,pages111–118. tures. InProceedingsofACL2013,pages73–82.
MichaelCollins. 2002. Discriminativetrainingmeth- Shasha Liao and Ralph Grishman. 2010. Using doc-
odsforHiddenMarkovModels: Theoryandexper- ument level cross-event inference to improve event
iments with perceptron algorithms. In Proceedings extraction. InProceedingsofACL2010,pages789–
ofEMNLP2002,pages1–8. 797.
Marie-Catherine de Marneffe, Anna N. Rafferty, and ZhengzhongLiu,JunAraki,EduardHovy,andTeruko
Christopher D. Manning. 2008. Finding contra- Mitamura. 2014. Supervised within-document
dictions in text. In Proceedings of ACL-HLT 2008, eventcoreferenceusinginformationpropagation. In
pages1039–1047. ProceedingsofLREC2014.
PascalDenisandJasonBaldridge. 2009. Globaljoint XiaoqiangLuo,SameerPradhan,MartaRecasens,and
modelsforcoreferenceresolutionandnamedentity Eduard Hovy. 2014. An extension of BLANC
classification. ProcesamientodelLenguajeNatural, to system mentions. In Proceedings of ACL 2014,
42:87–96. pages24–29.
2079
XiaoqiangLuo. 2005. Oncoreferenceresolutionper- Yue Zhang and Stephen Clark. 2008b. A tale of two
formance metrics. In Proceedings of HLT/EMNLP parsers: Investigating and combining graph-based
2005,pages25–32. and transition-based dependency parsing. In Pro-
ceedingsofEMNLP2008,pages562–571.
Catherine Macleod, Ralph Grishman, Adam Meyers,
LeslieBarrett,andRuthReeves. 1998. Nomlex: A KaiZhaoandLiangHuang. 2013. Minibatchandpar-
lexicon of nominalizations. In Proceedings of EU- allelizationforonlinelargemarginstructuredlearn-
RALEX1998,pages187–193. ing. In Proceedings of NAACL-HLT 2013, pages
370–379.
Christopher Manning, Mihai Surdeanu, John Bauer,
JennyFinkel,StevenBethard,andDavidMcClosky.
2014. TheStanfordCoreNLPnaturallanguagepro-
cessing toolkit. In Proceedings ACL 2014: System
Demonstrations,pages55–60.
David McClosky, Mihai Surdeanu, and Christopher
Manning. 2011. Event extraction as dependency
parsing. In Proceedings of ACL-HLT 2011, pages
1626–1635.
Vincent Ng and Claire Cardie. 2002. Improving ma-
chinelearningapproachestocoreferenceresolution.
InProceedingsofACL2002,pages104–111.
Hoifung Poon and Lucy Vanderwende. 2010. Joint
inference for knowledge extraction from biomedi-
calliterature. InProceedingsofNAACL-HLT2010,
pages813–821.
SameerPradhan,XiaoqiangLuo,MartaRecasens,Ed-
uardHovy,VincentNg,andMichaelStrube. 2014.
Scoring coreference partitions of predicted men-
tions: Areferenceimplementation. InProceedings
ofACL2014,pages30–35.
Lev Ratinov and Dan Roth. 2009. Design challenges
andmisconceptionsinnamedentityrecognition. In
ProceedingsofCoNLL2009,pages147–155.
Marta Recasens and Eduard Hovy. 2011. BLANC:
Implementing the Rand index for coreference eval-
uation. NaturalLanguageEngineering,17(4):485–
510.
Sebastian Riedel and Andrew McCallum. 2011. Fast
androbustjointmodelsforbiomedicaleventextrac-
tion. InProceedingsofEMNLP2011,pages1–12.
Deepak Venugopal, Chen Chen, Vibhav Gogate, and
Vincent Ng. 2014. Relieving the computational
bottleneck: Joint inference for event extraction
with high-dimensional features. In Proceedings of
EMNLP2014,pages831–843.
MarcVilain,JohnBurger,JohnAberdeen,DennisCon-
nolly, and Lynette Hirschman. 1995. A model-
theoretic coreference scoring scheme. In Proceed-
ingsofMUC-6,pages45–52.
YueZhangandStephenClark. 2008a. Jointwordseg-
mentation and POS tagging using a single percep-
tron. InProceedingsofACL-HLT2008,pages888–
896.
2080
