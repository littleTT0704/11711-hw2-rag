
learningrateof0.0002,abatchsizeof32,andastepsched- rectpredictionontheirownwithminordeviation,suchone-
ulerthatshrinksthelearningratebyafactorof0.1every60 candidate-kernel setting leads to a significant performance
epochs. We use AdamW optimizer [Loshchilov and Hutter, drop on the overall datasets shown in Table 2. Thus, we
2017]withaweightdecay = 10âˆ’4 forallexperiments. We conclude that QCM uses a diverse set of candidate kernels
choose ResNet-50 [He et al., 2015] as the visual backbone toachievecompetentperformance.
RefCOCO RefCOCO+ RefCOCOg Time
Models
val testA testB val testA testB val-g val-u test-u (ms)
Two-stage:
LGRANs[Wangetal.,2019] - 76.60 66.40 - 64.00 53.40 61.78 - - -
DGA[Yangetal.,2019] - 78.42 65.53 - 69.07 51.99 - - 63.28 -
RvG-Tree[Hongetal.,2019] 75.06 78.61 69.85 63.51 67.45 56.66 - 66.95 66.51 -
NMTree[Liuetal.,2019] 76.41 81.21 70.09 66.46 72.02 57.52 64.62 65.87 66.44 -
One-stage:
RCCF[Liaoetal.,2020] - 81.06 71.85 - 70.35 56.32 - - 65.73 -
ReSC-large[Yangetal.,2020] 77.63 80.45 72.30 63.59 68.36 56.81 63.12 67.30 67.20 -
VGTR[Duetal.,2021] 78.29 81.49 72.38 63.29 70.01 55.64 61.64 64.19 64.01 -
TransVG[Dengetal.,2021] 80.18 82.53 75.25 65.47 70.09 57.20 66.23 66.87 67.94 30.99
Ours:
VGQCw/fusion 82