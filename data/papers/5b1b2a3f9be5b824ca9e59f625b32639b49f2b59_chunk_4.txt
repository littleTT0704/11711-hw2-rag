 𝑡
show the performance of our framework in different settings
and examine the effectiveness of the key modules in ablation
Reference data Instance emb. 𝑒!"#
studies.
ContextFusion
Seg.map
II. RELATEDWORK
Target frame 𝐼!"# (b) Timestamp 𝑡+1 Instance mask 𝑀!"#
Video instance segmentation. Video instance segmentation
Fig. 1. We propose a robust context fusion (RCF) network for the online [66], [7], [38], [54], [54], [68], [31] requires classifying and
VIS task. Considering the redundancy and noise in the reference visual or segmenting each instance in a frame and assigning the same
audiocontext,theRCFmoduleextractscompactandrepresentativecontexts
instance with the same identity across frames. There are
from features (extracted by backbones B and B(cid:48)), and then fuses them into
the target feature with expressive attentions. The fused context is decoded mainlytwotypesofmethodsforVIStasks:onlineandoffline.
intoaninstancecodeandsegmentationmaps.Wedirectlycomposethefinal Online VIS: Given a small set of preceding reference
instancemasksbyleveragingtheorder-preservinginstancecodeandtracking
frames, online VIS aims to segment, classify and track object
instanceidentitieswithoutadditionalmatching.
instances in each target frame. Mask-Track-RCNN [66] is
the first attempt to address the VIS problem in an online
setting. It extends the Mask-RCNN [20] with a tracking head
formation interaction, in which we compress the reference
to associate instance identities. SipMask [7] and SG-Net [38]
features to mitigate redundancy, improve robustness, and also
build the tracking head on top of the modified one-stage still-
introduce audio cues. An order-preserving instance code is
imageinstancesegmentationmethodFCOS[54]andBlender-
further learned by the transformer decoder with a fixed-length
Mask[9],andachievebetterspeedandperformancecompared
instance query. Also, by leveraging the Lipschitz continuity
to MaskTrack-RCNN. CrossVIS [68] introduces the cross-
