isintendedtomaximizethelikelihoodof
wewanttomaximizethelikelihoodthatthecorrect correctlyidentifyingmentionswheretheindicator
antecedentsetY(i)∩GOLD(i)islinkedwiththe functiong(x i) = 1iffx i isaGOLDmention. The
current span. The distribution over all possible distribution over the set of mention candidates is
antecedentsforagivenspaniisdefinedusingthe definedusingthementionscores m. Themention
scoringfunctionsdescribedin§2: detectorislearnedusingafeed-forwardneuralnet-
work that takes the span representation produced
es(i,y) bytheencoderasinput. Thementionidentification
P(y) =
(cid:80) es(i,y′) lossrequiresonlymentionlabelstooptimize.
y′∈Y
4.4 AuxiliaryMaskingTask vices(DHS).3 Thesenotes,writtenbycaseworkers
andserviceproviders,logcontactwithfamiliesin-
We additionally use a masked language model-
volvedinchildprotectiveservices. Becauseofthe
ingobjective(MLM)asdescribedinDevlinetal.
extremelysensitivenatureofthisdata,thisdataset
(2019). We randomly sample 15% of the Word-
has not been publicly released. However, we re-
Piecetokenstomaskandpredicttheoriginaltoken
port results in this setting, as it reflects a direct,
usingcross-entropyloss. Thisauxiliaryobjective
real-wordapplicationofcoreferenceresolutionand
is intended to train the encoder to produce better
this work. Despite interest in using NLP to help
spanrepresentations. Sincecontinuedtrainingwith
practitionersmanageinformationacrossthousands
anMLMobjectiveiscommonfordomainadapta-
of notes (Saxena et al., 2020), notes also contain
tionGururanganetal.(2020),wealsoincludeitto
domain-specific terminology and acronyms, and
verifythatoptimizingtheMDlossisnotimplicitly
no prior work has annotated coreference data in
capturingthevalueoftheMLMloss.
thissetting