 implement an MLP-GCN using the same GCN
structureastheoneinSiameseGCNframework. Wealsotakeadeeperlookintowhichcorrelation
matricescanprovidethebestimprovementinperformance. Amongthe3correlationmatrices,we
foundlabelsco-occurrencebasedcorrelationmatrixworksbesttofittheweaklabelscenarioand
modeltheontologyinformation. Thus,wefurthermoredidmoreexperimentsonthetwotrainable
parameters: t,p(seesection3.5.1).
Fromourexperiments(seeAppendixA.4),wefoundp=0.2,t=0.08achievedthebestresults. We
couldseethatalthoughthismodelperformsbetterthanthepreviousmodels,theimprovementfrom
MLPwithoutOntologicalLayerisstilllimited. Thissuggeststhatevenwiththeontologyinformation
embeddedintotheGCN,itisstillhardtogetsignificantimprovementinclassificationresults. It
8
Figure6: AUCacrossdifferentlowlevellabels
Figure7: APacrossdifferentsuperclasslabels Figure8: AUCacrossdifferentsuperclasslabels
alsofurtherdemonstratesthatthearchitectureoftheSiamesenetisnotagreatfitforthismulti-label
scenario. ByusingasimpleMLPnetworktolearnembeddings,itcanalreadyachieverelativelygood
performancewiththeGCN.Overall,wefoundthattherewerecertainclassesforwhichitwasalways
difficulttoachievehighAPorAUCscoresasdemonstratedinFigures5,6,7,8. Fortheseclasses,
suchasglass,fire,orsilence,weanalyzedwhichdatapointscontainthoseclassesandfoundthatthey
areoftenmulti-labeledwithmorecommonlyfoundclassesinthetrainingset,suchashumanvoice,
ordomesticsounds. Thiscouldmakeitdifficultforthemodeltolearndifferentrepresentationsfor
thoseclasses.
5 Conclusions
Toconclude,weobservedthattheSiamesemodelwithontologylayerhastheworstperformance,
whilesimpleMLPisgettingrelativelybetterresults,andthecombinationofMLP