, N. Cesa-Bianchi,
& R. Garnett (Eds.), Proceedings of the 32nd International Conference on Neural Information Processing
Systems (Vol. 31; 7298–7309). Curran Associates Inc.
https://papers.nips.cc/paper/2018/file/398475c83b47075e8897a083e97eb9f0-Paper.pdf
↩
Yu, J., Yang, M.-S., & Lee, E. S. (2011). Sample-weighted clustering methods. Computers & Mathematics
with Applications, 62(5), 2200–2208. https://doi.org/10.1016/j.camwa.2011.07.005
↩
72
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
Zellner, A. (1988). Optimal information processing and Bayes’s theorem. The American Statistician, 42(4),
278–280. https://doi.org/10.2307/2685143 ↩
Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., & Torr, P. H. (2015).
Conditional random fields as recurrent neural networks. In Proceedings of the IEEE International
Conference on Computer Vision (pp. 1529–1537). https://doi.org/10.1109/ICCV.2015.179
↩
Zheng, Z., Oh, J., & Singh, S. (2018). On learning intrinsic rewards for policy gradient methods. In S.
Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, & R. Garnett (Eds.), Proceedings of the
32nd International Conference on Neural Information Processing Systems (Vol. 31; 4649–4659). Curran
Associates Inc. https://papers.nips.cc/paper/2018/file/51de85ddd068f0bc787691d356176df9-Paper.pdf
↩
Zhu, J., & Xing, E. P. (2009). Maximum entropy discrimination Markov networks. Journal of Machine
Learning Research