fine-tuningsmallerLMsonthe
classification task is that the definition of sexism
generateddatatoteachthemaboutvalue-aligned
haschangedovertimeasvalueshaveevolvedand
judgements. Formally,webuildVA-MODEL (pa-
alteredanditstillvariesacrosscultures. Thus,we
rameterizedbyθ)tomaximizethefollowinglikeli-
can verify the effect of varying values in a more
hood:
evident manner in the sexism classification task.
Furthermore,theimportanceofafine-grainedun- L(θ) = logP(Y|V,C;θ). (1)
4.1 Value-AlignedKnowledgeDistillation: 4.2 Fine-tuningSmallerModels–
Prompt-basedDataGeneration Value-AlignedModels
Inthenextphase,webuildclassifiersbyfine-tuning
Prompt Construction with Few-shot Examples
relativelysmallertransformer-basedmodels(e.g.,
The prompt construction of in-context few-shot
ALBERT-base,RoBERTa-base,BART-base)with
examplesaffectperformance. Thuswerefertothe
thegeneratedtrainingdatatoenablethemtomake
existingliteratureondifferentprompt-techniques
value-aligned judgements. We add a linear layer
(ReynoldsandMcDonell,2021;Zhaoetal.,2021;
ontopofthepooledoutputofthesmallermodels
Yoo et al., 2021). For the few-shot examples, we
toconstructourproposedVA-MODEL. Inorderto
createapoolof10human-labeledsamples(value,
makethemodelintakebothvaluesandcontentin
content, and value-aligned labels) for each value.
thelearningphase,theinputtextisformattedinto
AccordingtoLuetal.(2021),theorderofthefew-
“value [sep] content [sep]”andtheoutputis
shot samples in the prompt affects the in-context
avalue-alignedjudgement.
learningforLLMs. Therefore,werandomlyselect
The classifiers need to predict different labels
andorderfivesamplesoutofthepool.