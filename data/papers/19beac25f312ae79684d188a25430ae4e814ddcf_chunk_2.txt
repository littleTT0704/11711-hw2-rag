 dataset of expert demonstrations, as well as Figure1: Learn-to-Raceinterfaceswitharacingsimulator,
aseriesofbaselineexperimentsandreferenceimplementa- whichfeaturesnumerousreal-worldracetrackssuchastheThrux-
tions. We make all code available: https://github. tonCircuit(top-left)andLasVegasMotorSpeedway(top-right).
com/learn-to-race/l2r. Simulatedracecars(bottom)areempoweredwithlearningagents,
tasked with the challenge of learning to race for the fastest lap-
timesandbestmetrics.
1.Introduction
Progress in the field of autonomous driving relies on tionmetrics,whichenableresearcherstoeffectivelyassess
theexistenceofchallengingtasksandwell-definedevalua- andimprovealgorithms. Modelsdevelopedinlearning-to-
drive settings continue to struggle with issues in sample-
*Equalcontribution. complexity, safety, and unseen generalisation, calling for
1202
guA
81
]OR.sc[
3v57511.3012:viXra
moresuitablebenchmarks[9,16,28]. Wehypothesisethat 2.RelatedWork
high-fidelity simulation environments, together with well-
2.1.ReinforcementLearningEnvironments
defined metrics and evaluation procedures, are conducive
todevelopingmoresophisticatedagents;and,inturn,such
ResearchprogressinthefieldsofReinforcementLearn-
agentswillbebetter-suitedtoreal-worlddeployment.
ing(RL),Planning,andControlhasreliedonvarioussim-
Simulated autonomous racing exhibits task complexity ulationenvironments,forbenchmarkingagentperformance
on several factors: (i) agents must perform real-time deci- ongame-playingandrobotcontroltasks[32,8,33,18,30].
sionmaking,requiringcomputationally-efficientpolicyup- These tasks require sequential decision-making in order
dates as well as robustness to latency; (ii) agents must be to complete objectives and are generally characterised by
abletodealwithrealisticvehicleandenvironmentaldynam- their state dimensionality, the nature of their action space
ics(whereas