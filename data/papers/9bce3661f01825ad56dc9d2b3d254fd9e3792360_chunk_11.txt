PT.†indicatesstatistically
significant scores according to McNemar’s test (p <
cussion. Here, the data for the acceptance and 0.01).
objection settings are half and half. Therefore, if
thediscussionisnotproperlyconducted, suchas
that few-shot-discussion can generate discussion
byacceptingallhumanlabelsorrefutingallhuman
utteranceswithhigheraccuracythanzero-shotand
labels,theperformancewillnotimprove.
few-shot, which do not use discussion examples
WealsoinvestigatetheperformanceoftheNLI
data. Theperformanceofzero-shotandfew-shot
whenusingargumentationprompts. Wecompared
is almost the same, suggesting that just showing
theperformanceofNLIinzero-shot,few-shot,and
examplesdoesnotimprovethediscussionability.
few-shot-discussionsystems. Thepredictedlabel
Also,thedifferencebetweensupportiveandunsup-
after “Label:” in the prompt of Figure 2 is con-
portiveutteranceaccuraciesisgreaterinfew-shot-
sideredastheprediction,anddiscussionbetween
discussionthaninzero-shotandfew-shotsystems.
humansandsystemsisnotperformed. Intheeval-
Therefore, because the few-shot-discussion can
uation of NLI performance, in addition to SNLI
generatemoresupportiveutterances,itisthought
data, we also use Adversarial NLI (ANLI) data
thatsuchdiscussionscanresultinmoreappropriate
(Nieetal.,2020). ANLIcreatesdatabyrepeatedly
labels.
performingadversarialannotationagainstNLIsys-
Table 2 shows the accuracy of the label deter-
tems;thus,theresultingNLIexamplesarepartic-
minedbydiscussioninthesettingsforevaluating
ularly difficult for the system to solve. There are
theacceptanceabilityandobjectionability,respec-
three data sets R1, R2, and R3 with differences
tively. In terms of the objection, it can be seen
in the number of iterations, and the evaluation is
thatthefew-shot-disc