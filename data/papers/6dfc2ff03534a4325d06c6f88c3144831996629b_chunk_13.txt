: one to
match the answers and rationales invidually for each fold.
computetherelevancebetweenaqueryandaresponse,P,
rel Twofoldsarepulledasideforvalidationandtesting.
andanothertocomputethesimilaritybetweentworesponse
choices, P sim. Here,weemploystate-of-the-artmodelsfor 5.RecognitiontoCognitionNetworks
NaturalLanguageInference: BERT[15]andESIM+ELMo
[10, 57], respectively.6 Then, given dataset examples We introduce Recognition to Cognition Net-
(q,r),weobtainacounterfactualforeachq byper- works (R2C), a new model for visual commonsense
i i 1≤i≤N i
formingmaximum-weightbipartitematching[55,40]ona reasoning. Toperformwellonthistaskrequiresadeepun-
weightmatrixW∈RN×N,givenby derstandingoflanguage, vision, andtheworld. Forexam-
ple,inFigure5,answering‘Whyis[person4 ]pointing
W =log(P (q,r ))+λlog(1−P (r,r )). (1)
i,j rel i j sim i j at [person1 ]?’ requires multiple inference steps.
First, we ground the meaning of the query and each
Here,λ>0controlsthetradeoffbetweensimilarityandrel-
response, which involves referring to the image for the
6WefinetunePrel(BERT),ontheannotateddata(takingstepstoavoid 7We tuned this hyperparameter by asking crowd workers to answer
dataleakage),whereasPsim (ESIM+ELMo)istrainedonentailmentand multiple-choice questions at several thresholds, and chose the value for
paraphrasedata-detailsinappendixSecC. whichhumanperformanceisabove90%-detailsinappendixSecC.
4
… …
Grounding Contextualization Reasoning
Image
I
+ CNN
LSTM1 LSTM2 LSTM3
He
Why is... f
<<<<llllaaaatttteeeexxxxiiiitttt
sssshhh