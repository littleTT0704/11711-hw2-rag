reshold(adv-
while named entities are filtered by removing all concepts question).Herewedefinesimilarityoftwonodestobetheir
whoselabelsstartwithacapitalletter. proximityintheembeddingspace,measuredbycosinesim-
ilarity.Theintuitionisthat,bygeneratingmorechallenging
Generating negative samples (distractors) We seek to QA pairs for the models, we could achieve better general-
generate distractor options that satisfy two criteria: infor- izationacrosstasks.WeusetheRoBERTasentenceembed-
mativeness and fairness. Namely, a good distractor has se- ding model (Reimers and Gurevych 2020) to compute em-
manticrelatednesswiththecontext(informative),whilebe- beddingsforallKGnodes.Forthesetwostrategies,weset
ing relatively easy to discriminate from the correct answer an upper bound on the similarity score to avoid unfair dis-
(fair). We create the pool of distractors D for every sam- tractors, i.e., paraphrases of the correct answer. Based on
ple as follows: 1. The distractor candidates are the tails of manualobservations,wesettheirdistractorsimilarityupper
knowledgetriples(h0,r0,t0)withthesamerelationr0 = r, boundtobe0.6forCWWVand0.4forATOMIC.
randomlysampledfromtheKGs.Thiswouldensurethatthe
distractorscanfillthesamesemanticroleasthecorrectan- Samplefiltering Besidesthesedistractorsamplingstrate-
swer. 2. The head h0 of the sampled triples does not have gies,wetestanothercondition(3),whereweselectthedis-
non-stopwordoverlapwithh.3.Thedistractortailt0 isnot tractors randomly, but only keep the questions whose dis-
partofthecorrectanswerset,i.e.,thereexistnotriples,(h, tractors are sufficiently challenging at training time (adv-
filter). The intuition is that QA pairs generated using the
3https://pypi.org/project/