, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and
L.Zettlemoyer. Bart: Denoisingsequence-to-sequencepre-trainingfornaturallanguagegen-
eration,translation,andcomprehension. InACL,2020.
[66] K.Song,X.Tan,T.Qin,J.Lu,andT.-Y.Liu.Mass:Maskedsequencetosequencepre-training
forlanguagegeneration. InICML,2019.
[67] T. Schick and H. Schu¨tze. It’s not just size that matters: Small language models are also
few-shotlearners. arXivpreprintarXiv:2009.07118,2020.
[68] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig. Pre-train, prompt, and predict:
A systematic survey of prompting methods in natural language processing. arXiv preprint
arXiv:2107.13586,2021.
[69] K. He, G. Gkioxari, P. Dolla´r, and R. Girshick. Mask r-cnn. In Proceedings of the IEEE
internationalconferenceoncomputervision,pages2961–2969,2017.
[70] P.Anderson,A.Chang,D.S.Chaplot,A.Dosovitskiy,S.Gupta,V.Koltun,J.Kosecka,J.Ma-
lik,R.Mottaghi,M.Savva,etal. Onevaluationofembodiednavigationagents. arXivpreprint
arXiv:1807.06757,2018.
12
A HardwareExperiments
A.1 Real-worldpromptdemonstration
Herewedescribehowwecollectedandprocessedavisual,humandemonstrationinthereal-world
to treat as a prompt for the trained TTP policy (Fig. 8). Essentially, we collect demonstration
pointcloudsequencesandmanuallysegmentthemintodifferentpick-placesegments, followedby
extractingobjectstates. Ate