Bversionwithouttherelevanceandtextsimi- 700values/rights/dutiesforrelevance,andcorrelatetherel-
laritycomponents(-relevance,-textsimilarity);andtweaked evance score with the percentage of people who marked
3Bsystemparameterstooutputmoreorfewervalues,rights, the value as relevant (See Table 3). We find correlations of
andduties9(verbose,concise).Tounderstandthebenefitof 0.25-0.31 for the suite of model sizes 11 (all significant at
oursystem,wealsotrainabaselineseq2seq3Bmodelonthe p < 10âˆ’10).Whilewewouldliketoexplicitlytrainmodels
samedatathattriestopredictabatchofvalues,rights,and to predict human relevance scores in future work, we take
duties in one generation pass. We test each version against thisasevidencethatoursyntheticrelevancescorecorrelates
GPT-4onasetof200testsituationsby2annotatorseach. positivelywithhumanjudgments.
From Table 2, we make several observations. The three
largestversionsofoursystemoutperformGPT-4onalleval- 10This is in line with prior work showing that humans prefer
uated dimensions, with the largest variant (11B) being the longeroutputswithmoreuniquen-grams(Wangetal.2023b)
most favored overall. Moreover, the models generating a 11Interestingly,wenotethatthecorrelationdoesnotstrictlyim-
higher number of values (>11) are preferred by humans provewithmodelsize.Whileweareunsureofthereasonforthis,
wenotethat11Bgivesmuchmoreconfidentrelevancescores,and
9Tobetterunderstandhowchangingtheparameterscanaffect hypothesizethatthisoverconfidencemaybemiscalibratedtohu-
theoutput/precision/recall,seeFigure4 manjudgments.
5.3 Zero-shotperformanceonETHICS Model SBIC ETH. MoSt SoCh
While our model is explicitly trained to recognize values, KALEIDODEC 64.4 77.9 75.4 48.2
rights, and duties, we want to understand how much the
+