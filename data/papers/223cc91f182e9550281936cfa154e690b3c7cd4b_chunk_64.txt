 functions such as inverse RL
(Ziebart et al., 2008) or learning implicit reward (Zheng et al., 2018), for learning the experience function f in
ϕ
our problems. For instance, following (Ziebart et al., 2008), one can acquire and update the experience function
at each iteration in Equation 6.2 through min
ϕ
−Et∗∼p~
data
[logq(t∗)], where q taking the form in
Equation 3.3 now depends on ϕ. The resulting procedure induces an importance reweighting scheme that is
shown to stabilize the discriminator training in GANs (Wu et al., 2020), as well as learn meaningful constraints
(Hu et al., 2018). Figure 6 provides a demonstration that learning the constraints together with the target model
within the dynamic SE framework leads to substantial improvement.
10. Related Work
It has been a constant aspiration to search for basic principles that unify the different paradigms in machine
learning (Bishop, 2013; Domingos, 2015; Gori, 2017; Hu, Wilson et al., 2019; Langley, 1989). Extensive
efforts have been made to build unifying views of methods on particular fronts. For example, Roweis and
Ghahramani (1999) unified various unsupervised learning algorithms with a linear Gaussian model;
Wainwright and Jordan (2006) presented the variational method for inference in general exponential-family
graphical models; Domingos (2015) and Richardson and Domingos (2006) presented Markov logic networks
that combine Bayesian Markov network with first-order logic for uncertain inference; Knoblauch et al. (2019)
developed a generalized form of variational Bayesian inference by allowing losses and divergences beyond the
standard likelihood and KL divergence, which subsumes existing variants for Bayesian posterior
approximation; Altun and Smola (2006) showed the duality between regularized divergence (e.g., Bregman
and f-divergence) minimization and statistical inference (e.g., MAP estimation); Arora et al. (2012) presented
a common formulation of different multiplicative weights update methods; Mohamed and Lakshminarayanan
(2016) connected generative adversarial learning with a rich set of other statistical learning principles; Wu et
al. (2019) discussed connections between