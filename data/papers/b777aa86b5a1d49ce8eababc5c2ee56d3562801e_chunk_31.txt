 second
sequences sampled at 16 kHz to create 32,000-
In Figures 11 and 12, we examine vision models dimensional floating point inputs. In Figure 13,
utilizingâ€œefficient"modeldesignchoicesthrough weobservethatWavLMexhibitsframeworkbound
scalingandefficientoperationvariants. Imagein- behaviorbutquicklytransitionstobeingcompute-
putsaresimulated byrandomlygeneratingthree- boundduetothelargeaudiosequencelengths.
channel224x224RGBimages. Aswithlanguage
models,deepermodelsintroduceadditionalframe- WavLM (fp16) WavLM (fp32)
PyTorch
workoverheadandlow-FLOPalternativesaremore 101 TorchScript
frameworkbound.
101
102 102
100 101 102 100 101 102
Batch Size Batch Size
Figure 13: Transformer-based speech models exhibit
framework boundedness but transition to compute-
boundatsmallbatchsizesduetolongsequencelengths.
Figure11: Latencyofvisionmodelsthatscalemodel
depthandnumberofhiddendimensions.
)s(
ycnetaL
