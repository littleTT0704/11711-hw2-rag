agentsinless-realisticenvironmentshavebeen (e.g.,discreteorcontinuous),agentcardinality(i.e.,single-
abletoachievesuper-humanperformance);(iii)agentsmust or multi-agent), and by the capability of the underly-
leveragemoreinformativeintrinsicrewardschemesthaten- ing simulator in capturing real-world physical dynamics
ablereplicationofhuman-likedrivingbehaviour,e.g.,trad- [18]. Whereas the vast majority of tasks offered by, e.g.,
ing off safety and performance; and (iv) agents must use the DeepMind Control Suite [32], OpenAI Gym [8], and
offline demonstrations effectively, without overfitting, and the MuJoCo physics engine [33] have been solved—with
must leverage interactions with the environment sample- agentsoftenachievingsuperhumanperformance—noexist-
efficiently. We highlight simulated racing (Figure 1) as an ingenvironmentsfocusonhigh-fidelitysimulationofhigh-
opportunityfordevelopinglearningstrategiesthatarecapa- speeddriving,indynamicallyunstablecontexts.
bleofmeetingthesestringentrequirements.
In this work, we release the Arrival Autonomous Rac- 2.2.SimulationofAutonomousDriving
ingSimulator,whichincludesnumerousinterfacesforboth
Urbandriving. CARLA[14]isanopen-sourcesimulator
simulated and real vehicle instrumentation. Furthermore,
for autonomous driving, wherein various tasks have been
weintroduceLearn-to-Race(L2R),amultimodaland
definedtochallengeagents’street-legalurbandrivingabili-
continuous control environment for training and evaluat-
ties. Duckietown[29,10]providesacustomisableplatform
ing autonomous racing agents. Through the L2R envi-
forurbanautonomousdriving,aswellashardwaresupport
ronment, wesimulatecompetition-styleracetracksthatare
forminiaturevehiclescontrolledviaRaspberryPi’s. Inthis
basedoffreal-worldcounterparts, weprovidemechanisms
paper, we focus primarily on autonomous racing environ-
forfully