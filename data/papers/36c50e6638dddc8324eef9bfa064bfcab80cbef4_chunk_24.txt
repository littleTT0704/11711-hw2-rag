atingconstructive
with multiple workers (see §3.2 for details), they
feedbackcanbedisturbingandupsettingforwork-
mayallsharegroupcharacteristicsthatcanbiasthe
ers. Therefore,weonlyallowworkerswhoarenot
RoTannotationinaspecificdirection.
minors. Weinforminadvancethatworker’sdiscre-
Training a conversational agent solely on our
tionisstronglyrecommendedduetotheoffensive
datasetcanresultinanegativity-pronechatbot. As
andupsettingcontentsoftheannotation. Also,we
we pointed out, existing dialogue datasets are bi-
notifyworkerstheyarewelcometoreturnanydata
asedtowardspositivity(seeFigure3formorede-
that makes them feel uncomfortable. In case of
tails);hencedialogueagentstendtoagreeonwide
possiblementalhealthproblems,weguideworkers
rangeofsituations(Bahetietal.,2021). Wedelib-
toreachouttoCrisisTextLine,9 i.e.,anorganiza-
erately design our dataset to include much more
tion providing free, 24/7, high-quality text-based
negativitytocounterbalancetheexcessivepositiv-
mentalhealthsupport.
ityandteachagentstogiveconstructivefeedback.
In addition, we keep a feedback window open
Therefore, we encourage using our dataset along
ontheannotationpagesothatworkerscancontact
withotheronesrichinpositivitytotrainabalanced
us anytime. Responses to the workers’ feedback
conversationalagent.
weregivenwithin24hours. Lastbutnotleast,we
compensateourworkerswithcompetitivewages: Dialogue systems and AI regulation. Since
approximately15$perhouronaverage. technologyisincreasinglyinterfacingwithhumans
Thisstudywasconductedundertheapprovalof intheireverydaylives,itisimportanttoconsider
ourinstitution’sethicsboard(IRB). dialogueagentsaspartofthelargersocio-technical
ecosystem. Specifically,webelievethatdialogue
Riskfactorsfromdatasetrelease. Althoughwe
agents should be designed such that the conver-
trainourdialogueagentonly