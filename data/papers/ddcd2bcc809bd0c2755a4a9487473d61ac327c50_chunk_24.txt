ossibletoquan-
tifythedegreeofthepotentialdataleakage.10 We Limitedtext-onlyLLMs Ourexperimentswere
echo calls by Dodge et al. (2021) for increased conducted with a limited number of LLMs that
transparencyandopen-accesstothetrainingdata wereaccessibleatthetimeofwriting,andwedid
of LLMs, which is crucial for scientifically valid not explore the full spectrum of LLMs that are
andreproducibleexperiments(Rodgers,2023). currentlyavailable. Futureworkcouldexplorethe
N-ToM abilities displayed by other LLMs, and
Improving neural ToM abilities (with CoT or
additionally,exploremultimodalmodels.
other methods) Our objective in this study is
not to measure benchmark performance or climb
leaderboards. Itisfeasiblethattechniquessuchas EthicalStatement
chain-of-thoughtprompting(CoT;Weietal.,2022)
wouldenhancetheperformanceofGPT-4ontasks Data. Alltheexistingandnewdatasetsusedin
whereitcurrentlyperformspoorly. Nevertheless, this study are publicly available. The narratives
we need to exercise caution to ensure that the were evaluated by the authors to ensure that they
utilization of methods like CoT or others does donotcontainoffensivecontent.
notexcessivelyguidethemodelsbyessentiallyre-
vealingthetaskstructuretothemâ€”justlikeClever Models. LLMsmaygenerateoffensivecontent
Hanswhoappearedproficientinmathmerelydue ifpromptedwithcertaininputs. However,weused
tosubtlehintsgivenbytheowner. themforevaluationonly,withnon-offensiveinputs,
andwedidnotrecordtheirresponses.
7 Conclusion
Basedonourresearchandreplicationstudies,we Acknowledgements
concludethatcontemporaryLLMsdemonstratean
enhanced yet limited degree of Theory of Mind We would like to thank Uri Katz, Royi Rassin,
abilities. WefindthattheirToMabilitiesareoften OriShapira,AlonJacoby,RotemDror,andAmir
notrobust,andinsomeinstances,weidentifyev- DNCohenforhelpfuldiscussions. W