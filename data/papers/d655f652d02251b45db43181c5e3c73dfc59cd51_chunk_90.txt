wedonotclaimorbelievethatthedatasetisneces-
(e.g.,howmuchwerecrowdworkerspaid?) sarilyacomprehensivesetofrepresentativehumanvalues.
Data was collected and by the authors of the paper.
Arethereanyknownerrors,sourcesofnoise,orredun-
The dataset was not collected through crowdworkers, but
danciesinthedata?
throughdemousersandtheOpenAIAPI.
No known errors, sources of noise, or redundancies, al-
However,tounderstandthedataset’squalityandrepresen-
thoughwehopefutureworkwillhelptoshedmorelighton
tativeness,wedocarryoutseveralhumanstudiesonsubsets
weaknesses.
ofthedata(seeSection4.1and4.2).Weensuredthat,forall
tasks, crowdworkers were paid a minimum hourly wage of
N.4 DataPreprocessing
$15-25USD.
Whatpreprocessing/cleaningwasdone?(e.g.,discretiza-
Over what time-frame was the data collected? Does the
tion or bucketing, tokenization, part-of-speech tagging,
collection time-frame match the creation time-frame?
SIFT feature extraction, removal of instances, process-
Thesituationswerecollectedfrom2021-2023ontheDelphi
ingofmissingvalues,etc.)
userdemo,andthevalues,rights,anddutiesweregenerated
The main preprocessing was extraction of the features
usingtheOpenAIAPIfromMay2023-July2023.
from raw text output from GPT-4 to the semi-structured
How was the data associated with each instance ac- datasetthatwehave.Weusedregexexpressionsforthisex-
quired?Wasthedatadirectlyobservable(e.g.,rawtext, traction.
movie ratings), reported by subjects (e.g., survey re-
Was the “raw” data saved in addition to the prepro-
sponses), or indirectly inferred/derived from other data
cessed/cleaned data? (e.g., to support unanticipated fu-
(e.g.,partofspeechtags;model-basedguessesforageor
t