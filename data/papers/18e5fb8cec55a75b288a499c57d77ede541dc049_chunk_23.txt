Qns.html.
13513
Acknowledgements Y. 2020. SenseBERT: Driving Some Sense into BERT. In
Proc.ofACL,4656–4667.
We would like to thank all of the anonymous reviewers
for their valuable feedback. We also thank Ehsan Qasemi Li,Z.;Wang,W.;Dong,L.;Wei,F.;andXu,K.2020. Har-
and Soumyaroop Nandi for participating in our human an- vesting and Refining Question-Answer Pairs for Unsuper-
notation study. This material is based upon work spon- visedQA. InProc.ofACL,6719–6728.
sored by the DARPA MCS program under Contract No.
Lin,B.Y.;Chen,X.;Chen,J.;andRen,X.2019. KagNet:
N660011924033withtheUnitedStatesOfficeOfNavalRe-
Knowledge-AwareGraphNetworksforCommonsenseRea-
search.
soning. InProc.ofEMNLP-IJCNLP,2829–2839.
References Liu,W.;Zhou,P.;Zhao,Z.;Wang,Z.;Ju,Q.;Deng,H.;and
Banerjee, P.; and Baral, C. 2020. Self-supervised Knowl- Wang, P. 2020. K-BERT: Enabling Language Representa-
edge Triplet Learning for Zero-shot Question Answering. tionwithKnowledgeGraph. InAAAI.
ArXivabs/2005.00316. Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;
Bauer, L.; Wang, Y.; and Bansal, M. 2018. Commonsense Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V.
for Generative Multi-Hop Question Answering Tasks. In 2019. RoBERTa:ARobustlyOptimizedBERTPretraining
Proc.ofEMNLP,4220–4230. Approach. ArXivabs/1907.11692.
Bhagavatula, C.; Bras, R. L.; Malaviya, C.;