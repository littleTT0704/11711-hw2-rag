�𝑡⨁…⨁𝑎𝑡−𝛿 portant information about spatial and semantic cues, we only
compress the feature map along the channel dimension and
Fig. 3. Robust context fusion module. The target frame feature ft is
preserve the spatial dimension.
projectedtoalowerdimension,andthenflattenedandaddedwithpositional
encodingtobetokensOtgt.Consideringtheimportancetothetargetpredic-
O =P(ϕ (f )), (1)
tion, features from reference frames fref are first reweighted by a learned tgt C(cid:55)→C(cid:48) t
t
mask W, and then compressed to lower spatial and channel dimensions as
whereϕ isa1×1convlayertoprojectthefeaturemap
O Or ae uf d. aT fth ee rbo ip -Lti So Tna Ml.a Wud eio cof ne ca atu ter nes atear te hep sr oo uje rc ct eed tokto ena salo nw de fr eed dim the en msio ton tha es f
t
∈ RC×C H(cid:55)→ ×C W(cid:48) to a lower dimension RC(cid:48)×H×W, P denotes
transformerencodertomodeltheircorrelations. operations to flatten the feature and add it with positional
encoding.
Referencetoken.Referencetokensareusedtoenhancetarget
III. METHOD
tokens according to their correlations with the target, while
theirownrepresentationislessimportant.Weemploycompact
A. Overview
andrepresentativereferencetokenstoalleviatematchingnoise
Pipeline overview. We first introduce our transformer-based andenhancetheimportanceofthetarget.Featurecompression
networktargetingonlinevideoinstancesegmentation,andthen in both spatial and channel dimensions is applied.
extend it by adding optional synchronized audio signals. The O =P(ϕ (φ (W ·fref))), (2)
pipeline is illustrated in Figure 2. For each iteration t with ref δ