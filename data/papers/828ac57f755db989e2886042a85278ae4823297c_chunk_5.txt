 cannot reflect human judg- rentneuralnetworklanguagemodeltoautomaticallygener-
ment [19, 39]. Following [22], we evaluate our question ateasequenceofwordsconditionedonthevisualfeatures,
and answering approach in the form of “fill-in-the-blank” whichisinspiredbythegeneralrecurrentencoder-decoder
(FITB)frommultiplechoices. Underthistheme, weman- framework[33]. However,captioningtaskonlygeneratesa
aged to collect a new dataset consisting of over 100,000 generic description for entire image or video clip and it is
real-world videos clips, and 400,000 designed questions difficulttoevaluatethequalityofgeneratedsentences,i.e.,
with more than 1,000,000 candidate answers. This dataset it’shardtojudgeonedescriptionisbetterthananotherone
willbereleasedtothepublic,whichcanbeusedasbench- ornot.Inaddition,itisstillanopenresearchproblemofde-
marks for this research. The main advantage is that it is signingapropermetricforvisualcaptioning,whichcanre-
more convenient for quantitative evaluation than free-style flecthumanjudgment[8,39].Inthiswork,weinsteadfocus
questionanswering.Notethatthedifficultyofthequestions onmorefine-graineddescriptiononvideocontent,andour
canbecontrolledindesigningcandidateanswers. method is simple to evaluate in multiple-choice form, i.e.,
In this paper, we propose a new framework for video correctorwronganswer. Recently,abunchofQAdatasets
QAbycarefullyaddressingthethreeaforementionedchal- andsystemshavebeendevelopedonimages[2,10,23,28].
lenges. Therestofthispaperisorganizedasfollows. After Renetal.[28]useafixed-lengthanswerwithonlyoneword
2
foransweringquestionsaboutimages. Gaoetal.[10]usea cooking scenario. It provides multiple sentence de-
morecomplexdatasetwithfree-stylemultilingualquestion- scriptionsinfine-grainedlevels,i.e.,foreachshortclip
answer pairs, however it is hard to