 meaning
Glucose relations are event relations from an- that a higher number of Realis event words sug-
other commonsense knowledge dataset contain- gestsgreaterlikelihoodofthesentencecontaining
ingrelationsbetweenevent-pairsin10dimensions aneweventboundary(expectedorsurprising). We
(Mostafazadehetal.,2020). Glucoserelationfea- trained a BERT-base model (Devlin et al., 2019)
turesareusedtocomplementAtomicrelationfea- on an annotated corpus of literary novel extracts
tures in its coverage of commonsense relations. (Sims et al., 2019). We achieved a validation F1
Dim-1to5aredescribedbelowwhileDim-6to10 of 81.85%, inspired by and on par with Sap et al.
arethereverse/passiveformofDim-1to5respec- (2020). Then, we use the trained model to make
tively. inferenceonstorysentencesintheEvent-annotated
Dim-1: Eventthatcauses/enables dataset. Finally,weusedthenumberofRealis
4
wordsineachsentenceasafeature. Trainingand sentences,whichmimicstheannotatorâ€™sprocedure
otherexperimentaldetailsareintheAppendix. of identifying event boundaries as they read one
sentence at the time. As seen in Figure 2 (right),
Sequentiality is a measure of the difference in
weusethreefeatureencodingmodestodetermine
conditionalnegativelog-likelihoodofgenerating
thefeaturesthatareusedasinputintotheGRU,as
a sentence given the previous sentence or other-
inspiredbyliteratureoneventsegmentation(Petti-
wise(Sapetal.,2020,2022). Sequentialitycanbe
johnandRadvansky,2016;Baldassanoetal.,2018;
a predictor for unlikely events, which can cause
Zacks,2020). Thesethreemodesrepresentdiffer-
surprise(FosterandKeane,2015). WeuseGPT-2
entwaysoffacilitatinginformationflowbetween
(Radfordetal.,2019)tomeasurethisnegativelog-
sentences,whichcanhavedistincteffectsoniden-
likelihoodsinceit