iablymeasurecodecorrectness. shotresultsasbaselinesandleavefew-shotresults
to §7. Creating zero-shot prompts only requires
4 ExperimentSetup content from the test sample. Following Chen
etal.(2021),weconstructpromptsbyconcatenat-
CodeLLMshaveachievedstrongresultsonmul-
ingfunctioncontextandadocstring. Adocstring
tiplecodegenerationtasks,yettheiropen-domain
includestheNLintentandoptionalunittests(com-
proficiencyisunderstudiedduetothelimiteddo-
paredin§7). Figure6showsanexampleprompt.
mainsettingsofpastdatasets. Toexaminemodel
capabilities in the open domain, we evaluate two Function Context
top-performingmodelfamilies,CODEXandCODE-
DocString
GEN,onODEX.Weperformevaluationsusinga
promptingsetting,withoutfinetuninganymodel.
Function Context
We introduce the baseline models, the prompt
settings,andlayoutthemetricsforevaluation. Figure 6: Zero-shot prompt with one test case in doc-
string. Thegrayboxnotestheplaceforcodesolution.
The CODEX Family At the time of this work,
CODEXhadthreepubliclyavailablemodels. CODE-
Evaluation Metrics We follow Chen et al.
CUSHMAN-001 (C1) is a 12B CODEX model in
(2021)andmeasuretheexecutionaccuracyusing
Chenetal.(2021). CODE-DAVINCI-001/002(D1,
the pass@k metric, by computing the fraction of
D2)aretwo175BGPT-3models.6
problems having at least one correct prediction
withink samples. Wealsocompareitwithaseries
The CODEGEN Family CODEGEN (Nijkamp
ofexecution-freemetricslaterin§5.
et al., 2022) models are auto-regressive models
trainedonacombinationofNLandcodecorpora,
Implementation Details We follow Chen et al.
differinginmodelsizes(350M,2.7B,6.1B,16.1B)
(20