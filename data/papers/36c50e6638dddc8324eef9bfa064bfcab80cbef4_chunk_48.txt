ParlAI12 (Miller
ment of everyday situations from Commonsense
etal.,2017).
NormBank.
We follow their default setting with 2 encoder
Details of training datasets. We also incorpo-
layers,24decoderlayers,2560dimensionalembed-
rateDailyDialog(Lietal.,2017),EmpatheticDia-
dings,and32attentionheads. Fortokenization,we
logues(Rashkinetal.,2019),andBlendedSkillTalk
useByte-LevelBPE(Radfordetal.,2019)trained
(Smithetal.,2020)(descriptionsin§E)toinclude
onourtrainingdata. Weuseadam(KingmaandBa,
variouscasualconversations. Themulti-tasktrain-
ing weight for Canary is PROSOCIALDIALOG: 12https://parl.ai
2014) optimizer with initial learning rate 1e−5. 2. Engaged: “Whichresponseismoreengaged,
Weconductalinearwarm-upof100steps,andre- inquisitive, or empathetic towards the other
ducethelearningratewhenperplexityhasstopped speaker?”
improving. WetrainProstforapproximately150K
3. Respect: “Whichresponseismorerespectful,
stepswithbatchsizeof32.
kind,andpolitetowardstheotherspeaker?”
Details of training datasets. The multi-task
4. Coherency: “Whichresponseismorecontex-
trainingweightforeachdatasetisPROSOCIALDIA-
tuallyrelevant,andcoherentinthecontextof
LOG: DailyDialog : TopicalChat : PersonaChat
theconversation?”
: Wizard of Wikipedia : EmpatheticDialogues :
BlendedSkillTalk=9:3:3:3:3:3:1. 5. Overall: “Whichresponsedoyouthinkisthe
best/mostsuitedgiventhefullconversation?”
B.3 DetailsofTrainingComputation
Automatic evaluation results for other base-
Computinginfrastructure. WetrainourCanary
line models and dialogue datasets. In Table 8,
withaNVIDIAQuadroRTX8000GPU.Wescaled
wereportthe