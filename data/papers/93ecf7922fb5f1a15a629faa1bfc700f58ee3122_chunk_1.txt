Alpha Matte Generation from Single Input for Portrait Matting
DogucanYaman1 HazımKemalEkenel2 AlexanderWaibel1,3
1KarlsruheInstituteofTechnology,2IstanbulTechnicalUniversity,3CarnegieMellonUniversity
{dogucan.yaman, alexander.waibel}@kit.edu, ekenel@itu.edu.tr
Abstract Therearevariouschallengesintheportraitmattingprob-
lem due to the complex visual details of a person’s body,
In the portrait matting, the goal is to predict an alpha e.g.,thebordersaroundthebody,thehair,andtheclothes,
matte that identifies the effect of each pixel on the fore- particularly if the hair flutters and the clothes have some
groundsubject. Traditionalapproachesandmostoftheex- opacity.Themattingproblemcanbeformulatedasfollows:
istingworksutilizedanadditionalinput,e.g.,trimap,back-
groundimage,topredictalphamatte. However,(1)provid- I =α F +(1−α )B (1)
i i i i i
ingadditionalinputisnotalwayspractical,and(2)models
whereirepresentseachpixelinanimageI,alpharepresents
aretoosensitivetotheseadditionalinputs.Toaddressthese
alpha value for the corresponding pixel in the alpha matte
points, inthispaper, weintroduceanadditionalinput-free
α, and F and B are foreground and the new background
approach to perform portrait matting. We divide the task
images,respectively.
intotwosubtasks,segmentationandalphamatteprediction.
Inthetraditionalapproach,thealphamatteisgenerated
Wefirstgenerateacoarsesegmentationmapfromtheinput
using an image and a trimap which represents the fore-
imageandthenpredictthealphamattebyutilizingtheim-
ground,background,andunknownareasontheimage. The
ageandsegmentationmap. Besides,wepresentasegmen-
basic idea is to enhance the unknown areas in the trimap,
tationencodingblocktodownsamplethecoars