XQuAD.
and CommonCrawl. XLM-R was the strongest
MLQA Similarly to XQuAD, the Multilingual
baseline in XTREME (Hu et al., 2020) and is the
Question Answering dataset (Lewis et al., 2020)
foundationforsomesubsequentwork. Ithasbeen
is another cross-lingual question answering task.
fine-tuned on English data of a related task prior
Theevaluationdatainsevenlanguageswasauto-
totask-specificfine-tuning(STILTs;Phangetal.,
maticallyminedfromWikipedia,annotationswere
2020). Thefollowingmodelsfurthermorepropose
crowd-sourced,andanswerspansaligned. Forboth
newmethodstoleverageparalleldataduringpre-
XQuADandMLQA,weusetheirrespectivedata
trainingorfine-tuning. FILTER(Fangetal.,2021),
forevaluationandtrainonSQuADv1.1.
basedonXLM-R,fusesrepresentationsindifferent
languages. VECO(Luoetal.,2020)isa24-layer TyDiQA-GoldP Weusethegoldpassage(GoldP)
encoder-decodermodelthatusesadditionalMLM version of TyDiQA (Clark et al., 2020), a bench-
variantsduringpre-training. T-URLv2andHiCTL markforinformation-seekingquestionanswering,
(Wei et al., 2021), based on InfoXLM (Chi etal., whichcoversninetypologicallydiverselanguages.
2021)andXLM-Rrespectively,employcontrastive The GoldP version is a simplification of the pri-
losses. ERNIE-M (Ouyang et al., 2020) incorpo- marytask,usingonlythegoldpassageascontext
ratesback-translationintolanguagemodeling.7 andexcludingunanswerablequestions. Weusethe
Englishtrainingdatafortrainingandevaluateon
B Taskscoreson XTREME thetestsetsofthetargetlanguages.
Tatoeba We evaluate on the Tatoeba dataset
We show the performance of the models on the
(Artetxe and