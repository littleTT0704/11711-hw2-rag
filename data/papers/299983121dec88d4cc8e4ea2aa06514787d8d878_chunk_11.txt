elinesonallmetricsacrossthemodelsontest.Perfor-
CG
For each model, we choose the epoch corresponding to
mancegainsarestrongandstatisticallysignificantforBART-
highestROUGE-2ondev,andusebeamsearchforde-
CG base,BART-large,andT5-base.VisCTGappearsrelatively
coding. NTC itself is a hyperparameter, so while we train
less effective for T5-large which is the strongest baseline,
separateversionsofeachmodelcorrespondingtodifferent
andhenceimprovingitsperformancemaybemoredifficult.
NTCvalues,thefinalchosenmodelscorrespondtotheNTC
FromTable8,weseethatVisCTGmodelssubstantially
values that performed best on dev when averaged over
CG outperform corresponding baselines reported in Lin et al.
bothseeds.Wethenusethefinalchosenmodelstogenerate
(2020)ontest.T5-baseVisCTGoutperformsthereported
O
onbothtest andtest,andreporttheresultsinÂ§6.
CG O T5-baseandlargebaselinesacrossmetrics,andBART-base
VisCTGperformssimilarlytothereportedBART-largebase-
5.2 HumanEvaluation
line.BART-largeVisCTGoutperformsthereportedbaseline,
Weconducttwohumanevaluations:oneusingAmazonMe- EKI-BART(Fanetal.2020),andKG-BART(Liuetal.2021).
chanicalTurk(AMT),andoneusinganexpertlinguist.6For TheseareSOTApublishedCommonGenBARTmodelsthat
the AMT study, we ask annotators to evaluate 86 test useexternalknowledgefromcorporaandKGs.Weshowthat
CG
examples per model. Our evaluation is based on pairwise visualgroundingismoreeffective,andBART-largeVisCTG
comparisonofVisCTGandbaselinemodeloutputs.Weask places high on the leaderboard.9 T5-large VisCTG outper-
humanannotatorstochoosewhichamongstthetwooutputs forms the