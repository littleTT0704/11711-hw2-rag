max Diversity(x)×Uncertainty(x)
x∈U
The diversity and uncertainty expressions are identical to those used in the previous
sampling strategies. With this method we follow two objectives: to choose instances
that are useful for improving the current model (i.e. high uncertainty), and to avoid
getting caught in a local optimum by selecting a diverse sample of the training data.
We found it effective to take the product of the two selection criteria, but of course
one could also combine the terms in a different way, e.g. using a weighted average.
Diversity → Uncertainty. This strategy also combines diversity and uncertainty-
based query selection. However, instead of applying both criteria at once, we first
select a diverse sample of queries and then switch entirely to uncertainty sampling.
Based on the first set of queries we can reliably fit a relevance model that is already
quiteeffective. Inthesecondphase,thedecisionboundaryisfine-tunedbyfocusingon
hard queries the model is still uncertain about. This hybrid method can be expected
to have lower variance than uncertainty sampling because it selects a more diverse set
of instances, and to yield a more accurate model than a diversity-based approach that
does not leverage the current decision boundary to select the most useful queries.
In our experiments, we selected the first 200 instances by maximizing diversity,
and each of the following queries based on the uncertainty criterion. The cross-over
8.1. ACTIVE LEARNING 125
point was chosen manually based on the shape of the learning curves for diversity
and uncertainty sampling. Of course the parameter should ideally be tuned on an
independent development set, but this was impractical because we used all available
labeled data to evaluate the active learning models and obtain results that are com-
parable to the supervised learning results in Chapter 5. However, we found that the
ranking performance of the final model is not overly sensitive to the precise cross-over
point, so we chose a single parameter value and used it in experiments with different
learning methods and feature sets.
This multi-strategy approach is similar in spirit to the DUAL sampling strategy
introduced by Donmez et al. [2007]. The main differences are that DUAL uses a den-
sity criterion instead of maximizing diversity, and that it gradually shifts the focus
from density-based sampling towards queries with a higher degree of uncertainty. In