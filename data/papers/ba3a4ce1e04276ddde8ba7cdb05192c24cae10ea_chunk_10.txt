
-
a2 (cid:80)T t=1eσ(Zp1WaT 2+ba2) p1 c2 c2 derconsiderationismicroprecision(micro-p),asitusesglobal
countsoftruepositives, falsenegativesandfalsepositivesfor
(cid:88)T metric computation against macro precision which does sim-
Z = Z ·Z (7)
p2 c2 a2 ple unweighted averaging disregarding class-imbalance. The
t=0 VGGish(dil.) encoderhereindicatesVGGisharchitecturebut
whereZ p2 ∈[0,1]anddenotesthepresenceprobabilityofeach withdilated/atrousconvolutionsknowntoprovidebenchmark
soundeventintheaudioclip. Figure1subsectionc,provides performanceforsoundeventdetection,[14]. TheVGGishen-
anoverviewofasingleattentionstep. Inrelationtofigure,Z a, coderwithreconstructionbasedauxiliarytaskandtwostepat-
Z c,Z paretheoutputsafterattentionmatrix,classificationma- tention pooling outperforms the existing benchmark of atrous
trixandP(.)respectivelyinthefirststageandsecondstagede- attentionpooling[14]onSNR20,10and0dBby5.9%,12.8%
pendingonsubscript. Bybreakingtheattentionintotwosteps, and22.3%respectively.Apartfromimprovingperformance,by
itmakesthepoolingmoreinterpretablebyansweringtheques- breakingtheattentionintotwosteps,itallowsfortheinterme-
tionsofwhatfrequencybinsandwhattimestepscontributesto diateuseofsigmoidwhichhelpsinensuringtheoutputsdon’t
whichaudioeventsbyvisualisingnormalisedattentionweights overflowabove1duringtraining.
Z,Z andoutputZ,Z. Also,thesigmoid(σ)ensures
a1 a2 p1 p2
the attention output stays between 0 to 1 and avoids unstable 2https://github.com/soham97/MTL_Weakly_
trainingformultilabeltrainingwithcross-