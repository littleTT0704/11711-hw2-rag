 81.5 14.6
Model-Expl 61.8 46.5 53.9 85.1 15.0
Human-Expl 66.5 51.3 63.7 84.4 14.9
40 60 80 40 60 80 40 60 80 40 60 80 0 5 10 15
(a)Averageannotator(4-way)accuracy(%). (b)Medianlabelingtime(s).
Figure 2: Accuracy and efficiency results for the user study across evaluation sets and conditions. Error bars
represent95%confidenceintervals.
incorporates examples of varying difficulties and correctlyclassified.5 Amongthese,wefurtherre-
differentformsofexplanationsasdetailedbelow. movedmislabeledexamples,andselected20exam-
plesthatatleasttwoauthorsagreedwerehardbut
3.1 ExperimentSetup
couldbeunambiguouslylabeled.
Conditions. Participantsindifferentconditions
Explanation generation. To generate explana-
haveaccesstodifferentkindsofexplanationassis-
tions for MODEL-EXPL, the authors manually
tance. To answer Q.1 and Q.2, we set two base-
wrote explanations for a prompt of 6 training ex-
lineconditions: (1)NO-EXPL,whereparticipants
amplesfromSBIC(3toxicand3non-toxic),and
make decisions without seeing any explanations;
promptedGPT-3.5(Ouyangetal.,2022)forexpla-
(2) LIGHT-EXPL, where we provide only the tar-
nationgeneration.6 Wereportadditionaldetailson
geted group as the explanation. This can be con-
explanationgenerationinAppendixA.1. Forthe
sidered an ablation of BIASX with the detailed
HUMAN-EXPLcondition,theauthorscollectively
impliedstereotypeontoxicpostsandjustification
wroteexplanationsafterdeliberation.
onnon-toxicpostsremoved,andhelpsusverifythe
effectivenessofourexplanationformat. Further,to Moderation labels. Granularity is desirable in
answerQ.3,weaddtwo BIASX conditions,with
contentmoderation(DÃ­azandHecht-Felella,2021