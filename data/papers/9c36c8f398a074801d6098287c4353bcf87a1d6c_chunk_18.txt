-
generateddatacangainfurtherimprovements,we
tionproblem. Weleavehowtoimprovethemodels’
fine-tuneVA-MODELswithdifferenttrainingdata
generalizationabilityinvalue-alignedjudgement
size. In Figure 5, we show that the W-F1 score
taskforfuturework.
doesnotshowanygainwhenthesizeexceeds200
samplesexceptforVA-ALBERT.Asweanalysed
6.4 AblationStudies
in Section 6.2, the generated data has noise. We
LLMscapacityforprompting Wefirstinvesti- conjecture that when using more generated data,
gatehowthesizeofLLMsaffectsthecapacityfor theadditionaldatawillnotonlybringmorevalue
generatingvalue-alignedtrainingdatabyevaluat- alignmentknowledge,butalsoaddmorenoiseto
ing the final performance of VA-MODEL trained thetrainingset. Therefore,whenthedegradation
on data from varying sizes of LLMs. Unsurpris- in model performance caused by the noisy data
ingly, as is shown in Table 4, we can continually is greater than the improvement in model perfor-
boost the model’s performance when the LLMs mancefromtheadditionalknowledge,theoverall
sizeincrease. resultsdecrease.
WealsotrainVA-BARTwiththedataprompted
from GPT-Jurassic. Results for GPT-Jurassic 6B 7 ConclusionandFutureWork
are slightly higher than those of OPT-6.7B, al-
In this paper, we propose a task that focuses on
thoughthemodelsizeissmaller. However,when
teaching a model human value alignment knowl-
theLLMsbecomeextremelylarge,GPT-Jurassic
edge. We also introduce value-aligned models
178B performs similar to OPT-175B with only
0.12%difference. Sincesimilarmodelsizesshow
(VA-MODEL)thatgeneratevalue-alignedtraining
datafromLLMsbyprompt-baseddatageneration
similarperformancewithminimaldifferences,the
and fine-tune smaller classification models with
types of LLMs do not have much effect on the
the value-aligned generated