achwindowislost[6].
We evaluated our approach on TIMIT [9] and YOHO [10]
3. Model datasetsusingthestandardtrain/val/testsplits. Weevaluated
theproposedmethodontheaforementioneddatasetstoassess
Similarlytothemodelsproposedin[1,2],ourarchitectureis themodelundervariousrecordingconditions. Eachutterance
composedofthefollowingcomponents: (i)EncoderNetwork wassampledat16kHzandrepresentedasitspowerspectrum
denotedE;(ii)CarrierDecoderNetworkdenotedD ;and(iii) byapplyingtheSTFTwithW =256FFTfrequencybinsand
c
MessageDecoderNetworkdenotedD.Themodelisschemat- slidingwindowwithashiftL=128.Trainingexampleswere
m
ically depicted in Figure 1A. The Encoder Network E, gets generatedbyrandomlyselectingoneutteranceascarrierand
asinputacarrierC,andoutputsalatentrepresentationofthe k other utterances as messages for k ∈ {1,3,5}. Thus, the
carrier,E(C).Then,wecomposeajointrepresentationofthe matchingofcarrierandmessageiscompletelyarbitraryandnot
encodedcarrierE(C),messageM,andoriginalcarrierCby fixed.Further,itmayoriginatefromdifferentspeakers.
concatenating all three along the convolutional channel axis, AllmodelsweretrainedusingAdamfor80epochswith
H = [E(C);C;M]asproposedin[2],wherewedenotethe aninitiallearningrateof10−3andadecayingfactorof10ev-
concatenationoperatorby;. ery20epochs. Webalancedbetweenthecarrierandmessage
Table1: AbsoluteError(lowerisbetter)andSignaltoNoise Table2:AEandSNRforbothcarrierandmessageconcealing
Ratio(higherisbetter)forbothcarrierandmessageusingsingle 3and5messagesusingeithermultipledecodersoronecondi-
messageembedding. ResultsarereportedforbothTIMITand tionaldecoder.ResultsarereportedforbothTIMITand