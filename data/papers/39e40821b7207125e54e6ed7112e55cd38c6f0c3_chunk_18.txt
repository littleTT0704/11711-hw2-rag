2021). Wealsoexperimentedwithsuch
tion of the graphs generated by COCOGEN and
dynamic creation of the prompt, that depends on
DAVINCItosupplementautomatedmetrics. There-
theparticulartestexample. Specifically,following
sults(AppendixC)indicatethathumanevaluation
Poesiaetal.(2021),weperformedknowledgesim-
is closely correlated with the automated metrics:
ilaritytuning(KST): wetrainedaretrievermodel
for EXPLAGRAPHS, graphs generated by COCO-
toretrievethek closestexamplesforagiveninput.
GENarefoundtobemorerelevantandcorrect. For
PROSCRIPTgeneration,bothDAVINCIandCOCO-
Setup p r F 1 GEN have complementary strengths, but COCO-
COCOGEN 57.34 55.44 56.52 GENisgenerallybetterintermsofrelevance.
COCOGEN+KST 67.11 64.57 65.71
Table6:Ourretrievalmechanismishighlyeffectivefor 5 Relatedwork
edgeprediction: theclosestexamplesarefromsimilar
domainsandthemodelisabletoleveragetheinforma- Structured commonsense reasoning using
tionforbetterperformance. LLMs Existingmethodsforstructuredcommon-
sensegenerationtypicallyflattentheoutputgraphs
Theresultsindicatethattheefficacyofdynamic asstrings(MadaanandYang,2021;Madaanetal.,
promptsdependsonboththetrainingdataandtask. 2021a; Sakaguchi et al., 2021). Consequently,
In the edge-prediction sub-task of PROSCRIPT, these methods struggle with generation of well-
edges between events in similar scripts are help- formed outputs (Sakaguchi et al., 2021; Madaan
ful,andTable6showsthatthemodelwasableto etal.,2021b). Incontrast,weaddresstheproblem
effectivelyleveragethisinformation. Inthescript ofstructuredgenerationby(1)translatingthetask
generationsub-taskofPROSCRIPT,Table8shows into Python code, and (2) generating