-
3.1 GeneratingDialogueModelResponses
chanicalTurkplatformtoannotatethe2000threads
Tostudythebehaviorofneuralchatbotsinoffen-
fromourcorpus,withfiveworkersannotatingeach
sivecontexts,weextendthesampled2,000Reddit
thread. Overall statistics for TOXICHAT are pre-
threadswithmodel-generatedresponses. Wecon-
sentedinTable5intheAppendix. Theinter-rater
siderthefollowingpretrainedmodelsinthisstudy:
agreementwasmeasuredusingKrippendorff’sal-
DGPT - A GPT-2 architecture trained on 147M
pha(Krippendorff,2011)andpairwiseagreement,
Redditcommentthreads(Zhangetal.,2020). To
whichwasfoundtobeα = 0.42and82.8%respec-
reducetheriskofoffensivebehavior, theauthors tivelyforoffensivelabels8andα = 0.22and85.1%
filteredoutcommentthreadscontainingoffensive forstancelabels.9 WefoundKrippendorff’salpha
phrasesduringtraining. WeuseDialoGPT-medium
onthehuman-onlyresponsesissomewhathigher
model(345Mparameters)implementationbyhug-
(α = 0.45foroffensiveandα = 0.26forstance)
gingface(Wolfetal.,2020).
thanthechatbot-onlyresponses(α = 0.32forof-
GPT-3-Recently,OpenAIreleasedAPIaccessto
fensiveandα = 0.18forstance). Loweragreement
GPT-3languagemodel,amodelequippedtosolve
forchatbotresponsesislikelyduetotheirhigher
many tasks using text-based interaction without
proportionofincoherentresponses. Approximately
additionaltraining(Brownetal.,2020). Wefollow
25%ofDGPTresponsesand12.5%ofGPT-3re-
theAPIguidelinestouseGPT-3asadialogueagent.
sponseswereidentifiedasnotplausible.
Togeneratearesponseforacommentthread