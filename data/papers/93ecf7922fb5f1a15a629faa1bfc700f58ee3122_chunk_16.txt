SEresultsonAIM
testsetinthetoppartofthetable. Weadditionallyshowthere-
sultswithalllossfunctionsbyusingonlyalphamatteandusing
worse, and much worse to compare our results with four foregroundsubjectandalphamattetogetherinthelossfunctions.
different methods. The scores indicate how much the out-
putimageofourmethodisbetterorworsethantheoutput
Cases MSE
of other methods. For the comparison, we extracted sub-
Basemodel 2.20
jectsfromtheimageusingpredictedalphamatteandcom-
Basemodel+SEblock 1.57
bined with a green background to make the details of the
Basemodel+SEblock+refinementnetwork 1.06
subject more visible for the users. During the survey, we
showed the original input image and the combination of a
green background and outputs of the models. We utilized Table4. Ablationstudyforthearchitecture. Weindividuallyin-
8 subjects for each test benchmark, except PPM100 since vestigatedtheeffectofthesegmentationencodingblockandthe
wecouldnottesttheBGM-V2modelonthem,fortheuser refinementmodule. TheexperimentsareperformedontheAIM
studyandwemadepairswithourresultsandotherresultsto dataset.
showthemtotheparticipants. Intotal,wehave24images
for each model to create questions. According to the ta-
ble,ourmodeloverperformstheMODNetanditisslightly alphamatte. Accordingtotheresults,MSEscoresindicate
better than BGM-V2 and MGM. On the other hand, par- that using the foreground subject in addition to the alpha
ticipants could not easily distinguish our results and FBA matteenablesthenetworktoproduceamoreaccuratemap.
resultsandmajority,52.44%,saidtheyarethesame. ModulesWefurtherexaminedtheeffectofthesegmen-
tation encoder block and the refinement network. Accord-
4.2.Ablationstudy
ingtotheresultsinTable4,boththesegmentationencoding
LossfunctionsWeperformedanablationstudytoeval