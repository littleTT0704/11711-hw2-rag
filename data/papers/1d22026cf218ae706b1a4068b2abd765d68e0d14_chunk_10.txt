beneficialand
Table3summarizestheresultsonthevalidationsetforeach
generalizebetteronthetestset.
oftheindividualfeatures,encodersandfrontends. Forthe
log-melandSTRFfeatures,weonlyusetheoriginalunpro-
4.4.AnalysisofBestModelResult
cessed waveform provided by the challenge. For the Hu-
From our best test score, we observe that the model ob-
BERTfeatures,weusetheoriginalunprocessedwaveform
tains the highest CCC on awe, amusement, and surprise.
andalsoinvestigatethebenefitsofusingdenoisedspeech.
Thisislikelybecauseofhowdistinctivetheexpressionof
On the validation set, all three features outperformed the
theseemotionsis,whileemotionssuchasawkwardnessand
challenge baseline. Interestingly, we also observed addi-
triumpharemoreconfusable.
tionalbenefitswhenweusedtheHuBERTencoderwiththe
denoisedspeech. Wehypothesizethatdenoisingthespeech 5.Conclusion
isbeneficialsincebackgroundnoisedecreasestheintelligi-
In this paper, we examined the task of jointly predicting
bilityofspeech. Furthermore,weinvestigatedtheimpact
emotionalstate,speakerage,andcountryoforiginfromex-
ofspeedperturbationsforthistaskandfoundthatitslightly
pressivevocalburstsfortheEXVO-MULTITASKtrack. The
improvescountrypredictionandemotionrecognitionwhile
useofsequence-basedfeaturesoutperformsutterance-level
performingworseonageprediction.
functionalsreportedinthebaseline, whichhighlightsthe
Inadditiontoanalyzingtheperformanceoftheindividual importanceoftimesequenceinformationforthethreetasks
features,weexplorewhetherthefeaturesprovidecomple- underconsideration. Weevaluatetherelativestrengthsof
mentarybenefits. Sinceeachofthefeaturesextractinfor- differentfeatures—log-mel,STRFs,andcontent-basedself-
mation from different domains, we believe there will be supervisedHuBERTfeatures—foreachofthesetasksand
benefitsfromcombiningdifferentfeaturescores. Wedis- findthatwhile