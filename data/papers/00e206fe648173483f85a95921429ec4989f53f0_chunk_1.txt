Annotating Mentions Alone Enables Efficient Domain Adaptation for
Coreference Resolution
NupoorGandhi,AnjalieField,EmmaStrubell
CarnegieMellonUniversity
{nmgandhi, anjalief, estrubel}@cs.cmu.edu
Abstract
Althoughrecentneuralmodelsforcoreference
resolution have led to substantial improve-
ments on benchmark datasets, transferring
thesemodelstonewtargetdomainscontaining
out-of-vocabulary spans and requiring differ-
ing annotation schemes remains challenging.
Typicalapproachesinvolvecontinuedtraining
onannotatedtarget-domaindata,butobtaining
annotationsiscostlyandtime-consuming. We
showthatannotatingmentionsaloneisnearly
twice as fast as annotating full coreference
chains. Accordingly, we propose a method
for efficiently adapting coreference models,
which includes a high-precision mention de- Figure1:Modelcoreferenceperformance(avgF1)asafunc-
tection objective and requires annotating only tionofcontinuedtrainingonlimitedtargetdomaindatarequir-
mentions in the target domain. Extensive ingvaryingamountsofannotatortime.Thesourcedomainis
news/conversation(OntoNotes)andthetargetdomainismedi-
evaluation across three English coreference
calnotes(i2b2/VA).Usingourmethodtoadaptcoreference
datasets: CoNLL-2012 (news/conversation),
modelsusingonlymentionsinthetargetdomain,weachieve
i2b2/VA (medical notes), and previously un- strongcoreferenceperformancewithlessannotatortime.
studiedchildwelfarenotes,revealsthatourap-
proach facilitates annotation-efficient transfer
and results in a 7-14% improvement in aver- ersneedtoquicklyobtaininformationfromlarge
ageF1withoutincreasingannotatortime1.
volumesoftext(Uzuneretal.,2012;Saxenaetal.,
2020). However,successesovercurateddatasets
1 Introduction
havenotfullytranslatedtotextcontainingtechnical
Neural coreference models have made substan- vocabulary,frequenttypos,orinconsistentsyntax.
tialstridesin