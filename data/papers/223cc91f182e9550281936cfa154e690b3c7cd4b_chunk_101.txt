ference on Artificial Intelligence, 31(1), 4885–4890). https://doi.org/10.1609/aaai.v31i1.11146
↩
Roweis, S., & Ghahramani, Z. (1999). A unifying review of linear gaussian models. Neural Computation,
11(2), 305–345. https://doi.org/10.1162/089976699300016674 ↩
Samdani, R., Chang, M.-W., & Roth, D. (2012). Unified expectation maximization. In E. Fosler-Lussier, E.
Riloff, & S. Bangalore (Eds.), Proceedings of the 2012 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies (pp. 688–698).
https://aclanthology.org/N12-1087.pdf
↩
Santambrogio, F. (2015). Optimal transport for applied mathematicians. Birkäuser.
https://doi.org/10.1007/978-3-319-20828-2
↩
69
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
Schmidhuber, J. (2010). Formal theory of creativity, fun, and intrinsic motivation (1990–2010). IEEE
Transactions on Autonomous Mental Development, 2(3), 230–247.
https://doi.org/10.1109/TAMD.2010.2056368
↩
Settles, B. (2012). Active learning. Springer. https://doi.org/10.1007/978-3-031-01560-1
↩
Shalev-Shwartz, S. (2012). Online learning and online convex optimization. Foundations and Trends in
Machine Learning, 4(2), 107–194. https://doi.org/10.1561/2200000018
↩
Shen, T., Lei, T., Barzilay, R., & Jaakkola, T. (2017). Style transfer from non-parallel text by cross-
alignment. In I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus