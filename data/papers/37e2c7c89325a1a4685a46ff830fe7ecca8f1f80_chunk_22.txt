.51 0.60 0.54 0.61 0.49 0.64 0.59 0.58 0.51 0.61 0.54
IntegratedGradients 0.59 0.60 0.63 0.49 0.60 0.52 0.64 0.48 0.64 0.59 0.60 0.51 0.62 0.53
Attention(alllayers) 0.60 0.63 0.68 0.52 0.60 0.61 0.58 0.55 0.66 0.70 0.62 0.55 0.62 0.59
Attention(lastlayer) 0.51 0.49 0.61 0.49 0.51 0.50 0.55 0.48 0.52 0.57 0.56 0.50 0.54 0.50
Attention(SMaT) 0.64 0.65 0.68 0.52 0.66 0.64 0.66 0.54 0.71 0.70 0.61 0.54 0.66 0.60
Attention(bestlayer)* 0.64 0.65 0.69 0.64 0.64 0.68 0.68 0.68 0.71 0.76 0.64 0.59 0.65 0.65
Attention(besthead)* 0.67 0.67 0.70 0.65 0.70 0.70 0.70 0.69 0.73 0.75 0.67 0.60 0.67 0.66
Interpreting quality scores of machine translated outputs is a problem that has received recent
interest[Fomichevaetal.,2021a]sinceitallowsidentifyingwhichwordswereresponsibleforabad
translation. WeusetheMLQE-PEdataset[Fomichevaetal.,2020],whichcontains7,000training
samplesforeachofsevenlanguagepairsalongsideword-levelhumanannotation. Weuseasthebase
modelapretrainedXLM-R-base[Conneauetal.,2019],amultilingualmodelwith12layersand12
headsineach(totalof144heads).
Weexcludeoneofthelanguagepairsinthedataset(si-en)sincetheXLM-Rmodeldidnotsupport
it,leadingtoatrainingsetwith42,000samples