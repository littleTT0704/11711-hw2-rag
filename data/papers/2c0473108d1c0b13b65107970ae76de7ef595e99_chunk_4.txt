ontrasttopair-basedmetriclearningwhichcomputeslosses
inthetrainingset.ForatrainingsetofsizeN (recordings),raw entirelyfromauthenticdatainstances, proxy-basedlossesuti-
1202
nuJ
52
]DS.sc[
2v19440.1102:viXra
lizesynthetic,learnableproxiestocomposetriplets. where
s(u,v)=α((uTv)−β) (5)
2.1.1. ProxyNCA
Bothembeddingsandproxiesarenormalizedbylength. αand
ProxyNCA[13]assignsaproxytoeachdatapointaccordingto βarelearnablesmoothingfactorandbias.
itsclasslabel. Theobjectiveistomakeeachembeddingcloser ThenumeratorinEquation4considersthesimilarityofthe
toitsproxythanotherproxies,asshownbelow: instance to its own proxy. The first term in the denominator
invokesthesimilarityoftheinstancetothemini-batchcentroids
1 (cid:88)N e−d(xi,pi) forallclassesintheminibatch,andiseffectivelyentirelyentity-
L =− log( ) (1)
NCA N (cid:80)N e−d(xi,pj) based. Thesecondtermreferstothesimilarityoftheinstance
i=1 j=1,j(cid:54)=i to the proxies of all classes that are not in the minibatch and
whereddenotesEuclideandistance. isproxy-based. Thelossobjectiveovertheentireminibatchis
formulatedasfollows:
2.1.2. ProxyAnchor
1 (cid:88)
IncontrasttoProxyNCA,ProxyAnchor[1]regardstheproxy l = l(x ) (6)
1 |X | i
as an anchor that instances are drawn to. Both positive and Q xi∈XQ
negativepairscontributetothelossobjectivebytheirhardness,
whichisillustratedinEquation6in[1]. Equation 6 does not refer to