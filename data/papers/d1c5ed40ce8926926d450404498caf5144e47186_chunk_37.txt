 wide margin. For instance, this approach ranks a large set of manually
labeled text nuggets with 75% MAP, compared to 43% MAP when using rankings
generated by a web search engine. Furthermore, while this method is outperformed
by a statistical model that combines different relevance estimation strategies, it can
be integrated into the model to further increase its ranking performance. By adding
cosine similarities as an additional feature, we were able to improve MAP by 2.5–3.5
percentage points compared to a model that does not use this feature.
2.5 Sequential Models for Text Segmentation
In the nugget formation and scoring phases of the SE system, relevant text can be
identifiedandseparatedfromirrelevanttextusingsequentialmodels(seeSection8.2).
This problem is related to text segmentation and layout analysis, and some of the
features used in our models are based on ideas drawn from these research areas.
Particularly relevant for our work was the TextTiling algorithm [Hearst, 1997] and
a statistical approach for text segmentation [Beeferman et al., 1999]. The TextTil-
ing algorithm counts word frequencies in adjacent text windows and uses the cosine
similarity between the word frequency vectors as a measure of lexical coherence. The
coherence of a document can be visualized by plotting the cosine similarity at differ-
ent positions in the text, and transitions between topics are predicted at “valleys”,
i.e. areas of low similarity surrounded by more coherent text. Beeferman et al. [1999]
combine language modeling features and trigger words in an exponential model to
predict boundaries between news articles. They estimate the likelihood of a sentence
under long-range and short-range language models trained on previous sentences, and
assume a document boundary to be more likely at sentence boundaries where the like-
lihood ratio is small, i.e. the context captured by the long-range model does not help
in predicting the next sentence. Binary trigger word features increase or decrease the
probability of a document boundary if a given word occurs nearby.
We implemented several variations of the TextTiling algorithm to predict transi-
tions between relevant and irrelevant text based on lexical coherence. The statistical
models proposed by Beeferman et al. were less applicable to nugget formation and
scoring since they were tailored to the