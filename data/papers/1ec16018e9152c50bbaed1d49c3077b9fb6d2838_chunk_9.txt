 0.25 0.27 0.360.36 0.300.32
Subject-Verb Agreement. The number of the 0.2 0.15
-0.21 -0.04-0.01
0.0
subject and its verb must agree. We implement
0.2
thesubj_verbrulebygeneratingthedependency Rand SGN SG*N SGI SG*I SE SE* Rand SGN SG*N SGI SG*I SE SE*
treeusingspaCytoextractthesubjectoftheverb. (a)DotProduct(↑)
GPT-2 GPT-Neo
2.0
4.2 AlignmentMetrics 1.571.521.5 1.47 1.561.501.481.581.57
1.5 1.261.32
1.18 1.17
We use three metrics to quantify the alignment 0.92
1.0
between an explanation and the known evidence
0.5
enforcingalinguisticparadigm. Theexplanationis
avector ofthesamesizeastheinputx,where 0.0 Rand SGN SG*N SGI SG*I SE SE* Rand SGN SG*N SGI SG*I SE SE*
S
thei-thelement givesthesaliencyscoreofthe (b)ProbesNeeded(↓)
i
S GPT-2 GPT-Neo
win ip tu ht ato bk ie nn arx yi. vT eh ce tok rnow
,
an lse ovid oe fn sc ae mis er se ip zr ees ae sn tt hed
e
00.. 68 0.580.570.600.580.640.610.65 0.590.590.610.570.590.640.71
E
input x, where i = 1 if the token x i enforces a 0.4
E
grammaticalruleonthemodeldecision.
0.2
Dot Product. The dot product
S · E
measures 0.0 Rand SGN SG*N SGI SG*I SE SE* Rand SGN SG*N SGI SG*I SE SE*
thesumofsaliencyscoresofallinputtokensthat (c