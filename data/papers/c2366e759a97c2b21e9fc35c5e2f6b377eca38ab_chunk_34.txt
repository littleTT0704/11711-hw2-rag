 have different combinations of objects 1.smallplate
2.trays
loadedperrack. Bottom 2.glasses 3.bigplates
3.cups
4.smallbowl
To describe a preference, let there be k properties,
where each can take m values respectively. For
k
example, a property to describe preference can be
whichrackisloadedfirst,andthiscantaketwovalues;eithertoporbottomrack. Thetotalnumber
ofpossiblepreferencesisG=(cid:81)k
m.
i=1 i
Inourdemonstrationdataset,wehave100uniquesessionsperpreference. Eachsessioncanactas
a prompt to indicate preference as well as provide situation for the policy. Each session is about
∼ 30 steps long. With 7 preferences, this leads to 70,000×30 = 2,100,000 ∼ 2 million total
training samples, creating a relatively large training dataset from only 100 unique demonstrations
perpreference. Individualtaskpreferencesdifferinthesequenceofexpertactions,butcollectively,
preferencessharetheunderlyingtasksemantics.
Dynamicallyappearingobjects Toaddadditionalcomplexitytooursimulationenvironment,we
simulate a setting with dynamically appearing objects later in the episode. During each session,
the scene is initialized with p% of maximum objects allowed. The policy/expert starts filling a
16
dishwasher using these initialized objects. After all the initial objects are loaded and both racks
are closed, new objects are initialized one-per-timestep to the policy. The goal is to simulate an
environmentwherethepolicydoesnothaveperfectknowledgeofthescene,andneedstoreactively
reason about new information. The policy reasons on both object configurations in the racks, and
thenewobjecttypetodecidewhetherto‘openarackandplacetheutensil’or‘droptheobjectin
thesink’.
C Training
InthisSectionwedescribedetailsofthedifferentcomponentsofourlearningpipeline.
C.1 Baseline: GNN
Architecture WeuseGNNwithattention. Theinputconsistsof12dimensionalattributeinputs
(1D-timestep, 3D-category bounding box extents, 7D-pose,