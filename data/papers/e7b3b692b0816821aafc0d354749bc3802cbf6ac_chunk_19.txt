istractorimages. WefindthatincorporatingToMintoourspeaker
modelsleadstoimprovementsinspeakerperformance. Wealsofindthatincorporatingharderdis-
tractorsleadstothedevelopmentofmorecomplexandfluentlanguages.
Futureworkcouldmeasurethesimilarityofthelearningprocessbetweenhumanlearnersandour
models, and whether the changes implemented in this paper lead to a more humanlike learning
process. Furtherworkcouldalsoconsidertheimplicationsofmoredynamicdifficultyadjustment
or curriculum design – for instance, studying whether models trained on a variety of distractor
difficulties are able to adjust their utterances to fit a context. Finally, we can study these effects
inmorecomplexenvironmentsbyvaryingthelistenerarchitectureorbyconsideringmoredifficult
settings, such as object referential games. We encourage the machine learning and psychological
modellingcommunitiestoconsiderthefurtherincorporationofToMintocomputationalmodelsof
languageacquisition,whichcouldhelpdevelopmorepragmatically-awaremodels.
9
PublishedasaconferencepaperatICLR2023
REFERENCES
Jacob Andreas and Dan Klein. Reasoning about pragmatics with neural listeners and speakers.
Proceedingsofthe2016ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,1:
1173–1182,2016.
NolanBard,JakobNFoerster,SarathChandar,NeilBurch,MarcLanctot,HFrancisSong,Emilio
Parisotto,VincentDumoulin,SubhodeepMoitra,EdwardHughes,etal. Thehanabichallenge: A
newfrontierforairesearch. ArtificialIntelligence,280:103216,2020.
Elika Bergelson and Richard Aslin. Semantic specificity in one-year-olds’ word comprehen-
sion. Language Learning and Development, 13:1–21, 06 2017a. doi: 10.1080/15475441.2017.
1324308.
Elika Bergelson and Richard N. Aslin. Nature and origins of the lexicon in 6-mo-olds. Pro-
ceedings of the National Academy of Sciences, 114(49):129