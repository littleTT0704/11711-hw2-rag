is,ChrisPaxton,DieterFox,Animesh
gel. Vision-and-languagenavigation: Interpret-
Garg, and Yoav Artzi. A persistent spatial se-
ing visually-grounded navigation instructions
inrealenvironments. InCVPR,2018. 15 manticrepresentationforhigh-levelnaturallan-
guage instruction execution. In CoRL, pages
[12] RonaldCArkin,RonaldCArkin,etal.Behavior- 706–717,2022. 16
basedrobotics. MITpress,1998. 3
[22] MargaretABoden. 4gofai. TheCambridgehand-
[13] Shikhar Bahl, Abhinav Gupta, and Deepak bookofartificialintelligence,page89,2014. 3
Pathak. Human-to-robot imitation in the wild.
RSS,2022. 19 [23] Rodney A Brooks. Elephants don’t play chess.
Robotics and autonomous systems, 6(1-2):3–15,
[14] BowenBaker,IlgeAkkaya,PeterZhokhov,Joost 1990. 3
Huizinga, Jie Tang, Adrien Ecoffet, Brandon
[24] Tom Brown, Benjamin Mann, Nick Ryder,
Houghton, Raul Sampedro, and Jeff Clune.
Melanie Subbiah, Jared D Kaplan, Prafulla
Video pretraining (vpt): Learning to act by
watching unlabeled online videos. arXiv Dhariwal,ArvindNeelakantan,PranavShyam,
preprintarXiv:2206.11795,2022. 20 Girish Sastry, Amanda Askell, et al. Language
modelsarefew-shotlearners. NeurIPS,33:1877–
[15] Bowen Baker, Ingmar Kanitscheider, Todor 1901,2020. 23
Markov, Yi Wu, Glenn Powell, Bob Mc-
[25] Berk Calli, Arjun Singh, James Bruce, Aaron
Grew, and Igor Mordatch. Emergent tool use
from multi-agent autocurricula. arXiv preprint Walsman,KurtKonolige,SiddharthaSrinivasa,
