 a broad spectrum of speech
tasks, and includes downstream evaluation ranging from simple classification to LSTM-
based sequence modeling. Although the Speech Commands v2 task is shared with HEAR,
the other downstream tasks in SUPERB mainly deal with speech processing applications,
including speech recognition, speaker verification, keyword spotting, etc., and these two
evaluation activities are complementary to each other. The NOn-Semantic Speech Bench-
mark (NOSS, Shor et al. (2020)) comprises 6 paralinguistic tasks. Two tasks are shared
with HEAR: CREMA-D and Speech Commands v2. Unfortunately, SAVEE and Dementia-
Bank require filling out a request form, and VoxCeleb requires scraping YouTube. HARES
(Holistic Audio Representation Evaluation Suite)—not to be confused with our HEAR
benchmark—is concurrently published work (Wang et al., 2021c). HARES comprises 12
well-known downstream tasks including—like HEAR—ESC-50, Speech Commands v2, and
an NSynth Pitch task, benchmarked on 13 models. Where HARES differs from HEAR
includes: a) HARES tasks are well-known benchmarks, whereas HEAR is a mix of well-
known and novel benchmarks, b) HARES includes no few-shot tasks, all tasks have ≥ 2K
samples, c) HARES results currently include no external submissions, d) evaluation code
and dataset links are not provided and e) two of the tasks (AudioSet and VoxCeleb) tasks
involve scraping YouTube. Datasets based upon YouTube require specialized code and
lack reproducibility becausevideos are removed unpredictably(Cramer et al.,2019). These
generic audio evaluation suites, including our HEAR benchmark, intend to make it easy to
evaluate existing models on novel tasks, at the expense of possible SOTA performance.
3.2. Evaluation methodology
Wrapping existing models into the HEAR API requires roughly 75 lines of code, much of
which is boilerplate. New HEAR tasks can be run with no code changes. HEAR includes
twotypesoftasks: 1)Scene-based: Multi-classormulti-labelclassificationofanentireaudio
clip; 2) Timestamp-based: Sound event detection/transcription, which involves detecting
when exactly sound events occur over time by providing a start time, end