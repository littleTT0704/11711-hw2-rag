 q0(t)]+const.
Thus, J(q) can approximately be minimized with an iterative descent procedure: at each iteration n, we
perform a descent step that decreases Eq [ψ q(n)(t)] w.r.t. q, yielding q(n+1) for the next iteration.
Once the functional gradient is defined as above, the remaining problem of the optimization, then, is about how
to obtain the influence function ψ given the functional J(q). In some cases the influence function as defined
q
in Equation 7.3 is not directly tractable and approximations are needed. Chu et al. (2019) developed a
variational approximation method applied when J is convex (which is the case in Equation 3.2 when D is
convex w.r.t q). Concretely, with the convex conjugate of J defined as J∗(φ) = sup hEh[φ(t)]−J(h),
it can be shown under mild conditions that the influence function for J at q is:
ψ q =argmax φ∈C(T)Eq [φ(t)]−J∗(φ), (7.5)
where C(T ) is the space of continuous functions T → R. We thus can approximate the influence function
by parameterizing it as a neural network and training the network to maximize the objective
Eq [φ(t)]−J∗(φ). Plugging the approximation of influence function into the above functional descent
procedure leads to the full PFD optimization:
inf supEq [φ(t)]−J∗(φ),
(7.6)
q φ
which is a saddle-point problem.
7.2.2. The Student Step
The student step optimizes the SE objective w.r.t. the target model parameters θ, given q(n+1) from the
teacher step. The optimization is to minimize the divergence between the student p and the teacher q(n+1):
θ
Student:
θ(n+1)
=argmin θ D
(q(n+1),p
θ ). (7.7)
39
Harvard Data Science Review • Issue 4.4, Fall