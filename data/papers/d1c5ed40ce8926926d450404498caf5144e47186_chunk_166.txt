
8.1.1 Experimental Setup
Weusedlogisticregression(LR)andsupportvectormachines(SVMs)withlinearker-
nels for active learning experiments. LR was very effective in the supervised relevance
estimation experiments in Chapter 5, and outperformed other popular regression and
classification algorithms such as least-squares linear regression and na¨ıve Bayes in a
preliminary analysis. Linear SVMs performed worse than LR in a supervised setting,
but are nevertheless an interesting alternative for active learning because they often
converge rapidly. We also evaluated SVMs with polynomial kernels and radial basis
function (RBF) kernels, but they performed similarly to SVMs with linear kernels on
our relevance estimation dataset. This is because the relevance features were designed
for linear models, i.e. large values indicate that text nuggets are either more likely or
less likely to be relevant. The expected sign of the coefficient for each feature in a
linear model is shown in Figure 5.3 of Section 5.3.
Initially we select one positive instance and one negative instance from the labeled
data described in Section 5.1 to ensure that we can fit and evaluate models after
only two iterations. The initial queries are selected randomly and thus each active
learning run has a different non-deterministic outcome. This allows us to average over
multiple random restarts to reduce the variance of the evaluation results and obtain
smoother learning curves. In practice, of course, it is not possible to automatically
select relevant or irrelevant text nuggets because the labels of the instances in the
pool of training data are not known a priori. Thus a human annotator would need
to initially select an instance of each class. Alternatively, nuggets that have a high
probability of being relevant can be selected automatically using a single predictive
feature, such as cosine similarities or topic likelihood ratios, until at least one relevant
and one irrelevant nugget have been found. After this initial phase, we apply one of
the following query selection strategies.
8.1. ACTIVE LEARNING 123
Random. We select a random query in each iteration to obtain a representative
sampleofthefulldataset. Thisstrategypreservesthedistributionofthedatasinceon
average more instances are selected from dense areas in the feature space, and fewer
instances from sparse areas. Random sampling does