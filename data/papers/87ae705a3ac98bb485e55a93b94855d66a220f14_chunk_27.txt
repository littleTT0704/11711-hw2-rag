EmpiricalMethodsinNaturalLanguage
Advancesinneuralinformationprocessingsystems,3320–
ProcessingandComputationalNaturalLanguageLearning,
3328.
754–765. AssociationforComputationalLinguistics.
Zelle, J. M., and Mooney, R. J. 1996. Learning to parse
Kwiatkowski,T.;Zettlemoyer,L.;Goldwater,S.;andSteed-
databasequeriesusinginductivelogicprogramming. InPro-
man,M. 2010. Inducingprobabilisticccggrammarsfrom
ceedingsofthenationalconferenceonartificialintelligence,
logicalformwithhigher-orderunification. InProceedingsof
1050–1055.
the2010ConferenceonEmpiricalMethodsinNaturalLan-
guage Processing,EMNLP’10, 1223–1233. Stroudsburg, Zettlemoyer, L. S., and Collins, M. 2012. Learning to
PA,USA:AssociationforComputationalLinguistics. map sentences to logical form: Structured classification
with probabilistic categorial grammars. arXiv preprint
Lewis, M.; Lee, K.; and Zettlemoyer, L. 2016. Lstm ccg
arXiv:1207.1420.
parsing. InHLT-NAACL,221–231.
Zhang, Y., and Weiss, D. 2016. Stack-propagation: Im-
Liang,P. 2013. Lambdadependency-basedcompositional
proved representation learning for syntax. arXiv preprint
semantics. CoRRabs/1309.4408.
arXiv:1603.06598.
Ma, X., and Hovy, E. 2016. End-to-end sequence la-
Zhou,J.,andXu,W. 2015. End-to-endlearningofsemantic
beling via bi-directional lstm-cnns-crf. arXiv preprint
rolelabelingusingrecurrentneuralnetworks.InTransactions
arXiv:1603.01354.
oftheAssociationforComputationalLinguistics(TACL).
Mikolov, T.; Chen,