68).369(±.049).327(±.086).393(±.048).422(±.090).415(±.071).319(±.054).402(±.030)
Table 3: Kendall-Tau (τ) and Spearman (r ) correlations of each metric with the functional correctness on Hu-
s
manEval in multiple languages. The correlation coefficients are reported as the average across three runs, along
withthestandarddeviation.
Metric τ r r
p s
BLEU.374(±.025).604(±.016).543(±.018)
CodeBLEU.350(±.037).539(±.033).495(±.037)
ROUGE-1.397(±.023).604(±.016).570(±.018)
ROUGE-2.429(±.025).629(±.015).588(±.022)
ROUGE-L.420(±.037).619(±.014).574(±.022)
METEOR.366(±.033).581(±.016).540(±.022)
chrF.470(±.029).635(±.023).623(±.018)
CrystalBLEU.411(±.030).598(±.019).576(±.034)
CodeBertScore.517(±.024).674(±.012).662(±.012)
Table 4: The Kendall-Tau (τ), Pearson (r ) and Spearman (r ) correlation with human preference. The best
p s
performance is bold. The correlation coefficients are reported as the average across three runs. Numbers inside
parenthesesindicatethestandarddeviations.
Metric Java C++ ThisresultconfirmsthatCodeBERTScoreassigns
higher similarity scores to semantically similar
BLEU 2.36 2.51
CodeBLEU 1.44 1.42 codepairs,comparedtorandomlypairedsnippets
CrystalBLEU 5.96 6.94
thatbelongtodifferentsemanticclasses.
CodeBERTScore 9.56 9.