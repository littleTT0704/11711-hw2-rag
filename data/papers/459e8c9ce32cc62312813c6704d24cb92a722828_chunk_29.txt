neuralnetworks. In
Wang,C.;andSennrich,R.2020. OnExposureBias,Hal-
4thInternationalConferenceonLearningRepresentations,
lucinationandDomainShiftinNeuralMachineTranslation
ICLR2016-ConferenceTrackProceedings.
URLhttp://arxiv.org/abs/2005.03642.
Rechenberg,I.1978. Evolutionsstrategien. doi:10.1007/978-
Welleck, S.; Kulikov, I.; Kim, J.; Pang, R. Y.; and Cho,
3-642-81283-5 8.
K. 2020a. Consistency of a Recurrent Language Model
Ross,S.;Gordon,G.J.;andBagnell,J.A.2011. Areduction With Respect to Incomplete Decoding. arXiv preprint
ofimitationlearningandstructuredpredictiontono-regret arXiv:2002.02492.
onlinelearning. InJournalofMachineLearningResearch.
Welleck,S.;Kulikov,I.;Roller,S.;Dinan,E.;Cho,K.;and
ISSN15324435.
Weston,J.2020b. NeuralTextGenerationWithUnlikelihood
Rubinstein,R.1999. TheCross-EntropyMethodforCom- Training. InInternationalConferenceonLearningRepresen-
binatorialandContinuousOptimization. MethodologyAnd tations. URLhttps://openreview.net/forum?id=SJeYe0NtvH.
Computing In Applied Probability ISSN 1387-5841. doi:
Williams,R.J.1992. Simplestatisticalgradient-following
10.1023/A:1010091220143.
algorithmsforconnectionistreinforcementlearning.Machine
Ru¨ckstieß,T.;Sehnke,F.;Schaul,T.;Wierstra,D.;Sun,Y.; LearningISSN0885-6125. doi:10.1007/bf00992696.
and Schmidhuber, J. 2010. Exploring Parameter Space in
Wiseman,S.;andRush,A.M.2016. Sequence-to-sequence
Reinforcement Learning. Paladyn, Journal of