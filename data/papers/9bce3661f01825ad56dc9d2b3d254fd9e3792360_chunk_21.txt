ettit,ScottHeiner,KamileLukosuite,
AmandaAskell,AndyJones,AnnaChen,etal.2022.
smallerpre-trainedmodels(Wuetal.,2023;Team,
Measuringprogressonscalableoversightforlarge
2023;Touvronetal.,2023). Ourmanuallycreated languagemodels. arXivpreprintarXiv:2211.03540.
discussiondataisrelativelysmallinscale. There-
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
fore,itisnecessarytoexpandthedatasettoalarger
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
scaletomorerobustlytesttheeffectivenessofthe
Neelakantan,PranavShyam,GirishSastry,Amanda
proposedmethod. Askell,etal.2020. Languagemodelsarefew-shot
learners. Advancesinneuralinformationprocessing
EthicsStatement systems,33:1877–1901.
Pre-trained models have serious levels of social PawełBudzianowskiandIvanVulic´.2019. Hello,it’s
biasesregardinggender,race,andreligion(Boluk- GPT-2-howcanIhelpyou? towardstheuseofpre-
trainedlanguagemodelsforTask-Orienteddialogue
basi et al., 2016; Kaneko and Bollegala, 2019,
systems. InProceedingsofthe3rdWorkshoponNeu-
2021b,a,c;Mayetal.,2019;Caliskanetal.,2022;
ralGenerationandTranslation,pages15–22,Hong
Zhouetal.,2022;LucyandBamman,2021;Anan- Kong.AssociationforComputationalLinguistics.
taprayoon et al., 2023; Kaneko et al., 2022c,b,a,
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang
2023b,a, 2024; Oba et al., 2023). Therefore, we
Tseng, Iñ