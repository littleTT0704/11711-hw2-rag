,we
Due to the inherent complexity of our MTurk
provideGPT-3withtheprompt-“Thefollowing
annotation task (see the screenshot of the crowd
is aconversation threadbetween multiple people
annotation interface in Figure 8 in the appendix),
onReddit. U1:u U2:u... ”,whereu,u,...are
1 2 1 2 weobserverelativelylowagreementlevels. How-
the user comments. The model then predicts the
nextturnintheconversation. Weselectthelargest 7DGPTwasonlytrainedonRedditcomments.
8Comparabletoα=0.45and82.4%agreementforoffen-
5Thedatawasacquiredfrompushshift.io sivenessinSBIC(Sapetal.,2020)
6https://www.reddit.com/r/ 9Comparabletostancelabelpairwiseagreementof62.3%
AgainstHateSubReddits/ forrumor-stancedataset(Zubiagaetal.,2016)
ever,wefindthataggregatingworkerannotations
produces gold labels of sufficiently high quality
35
Contextually Offensive
for training and evaluating models (we consider
30 Directly Offensive
thegoldlabelasoffensiveoragreeingifatleast2
of the five workers agree). We manually verified 25
26.38
the quality of the aggregate labels by comparing 20
themwithanin-houseannotator’scarefullylabeled
15
13.10
40 threads. The F1 score of the aggregate anno-
10
tations was 0.91 and 0.94 for offensive language
5.95
5 8.46
andstance,respectively,providingahumanupper- 6.35
3.00
boundestimateforidentifyingstanceandoffensive 0 Reddit user DGPT model GPT3 model
responses responses responses
comments.
Figure2: Distributionofdirectlyvscontextuallyoffen-
4 StanceDynamicsin TOXICHAT
siveresponses.
Directly vs Contextually Offensive Replies.
Our key finding is that most offensive responses
40 Reply to Offensive Comment
are directly offensive, but the occurrence of con-
Reply to Safe Comment
textuallyoffensivedialoguerespons