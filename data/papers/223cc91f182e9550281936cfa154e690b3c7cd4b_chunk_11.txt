 of
the mean-field and other approximation methods. In particular, in the case where p θ(x,y) is an exponential
family distribution with sufficient statistics T(x,y), the exact E-step (Equation 2.10) can be interpreted as
seeking the optimal valid mean parameters (i.e., expected sufficient statistics) for which the free energy is
minimized. For discrete latent variables y, the set of all valid mean parameters constitutes a marginal polytope
8
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
M. In this perspective, the mean-field methods (Equation 2.12) correspond to replacing M with an inner
approximation M′ ⊆ M. With the restricted set M′ of mean parameters, the E-step generally no longer
tightens the bound of the negative marginal log-likelihood, and the algorithm does not necessarily decrease the
negative marginal log-likelihood monotonically. However, the algorithm preserves the property that it
minimizes the upper bound of the negative marginal log-likelihood. Besides the mean-field methods, there are
other approaches for approximation such as belief propagation. These methods correspond to using an outer
approximation M′′ ⊇ M of the marginal polytope, and do not guarantee upper bounds on the negative
marginal log-likelihood.
Another approach to restrict the family of q is to assume a parametric distribution q (y∣x) and optimize the
ω
parameters ω in the E-step. The approach has been used in black-box variational inference (Ranganath et al.,
2014), and variational auto-encoders (VAEs) (Kingma & Welling, 2014) where q is parameterized as a neural
network (a.k.a ‘inference network,’ or ‘encoder’).
It is worth mentioning that the variational approach has also been used for approximate Gaussian processes
(GPs, as a nonparametric methods; Titsias, 2009; Wilson et al., 2016b), where y is the inducing points and the
variational distribution q(y) is parameterized as a Gaussian distribution with a nondiagonal covariance matrix
that preserves the structures within the true covariance (and hence is different from the above mean-