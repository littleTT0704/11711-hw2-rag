 Model' of Machine Learning
projects the current model distribution p (x,y) onto the set of distributions whose marginal over x equals
θ(n)
the empirical distribution, i.e., q(n+1) = argmin KL(q(y∣x)p~ (x)∥p (x,y)), then the
q d θ(n)
subsequent M-step (Equation 2.11) projects
q(n+1)
onto the set of possible model distributions through
min
KL(q(n+1)(y∣x)p~
(x)∥p (x,y)).
θ d θ
In general, the SE in Equation 3.1 or 3.2, with both the model parameters θ and the auxiliary distribution q to
be learned, can naturally be optimized with an alternating-projection style procedure, which we have referred
to as the teacher-student mechanism.
7.2. The Teacher-Student Mechanism
We have seen a special case of the teacher-student mechanism in Equation 3.3 for solving the specifically
instantiated SE (e.g., with cross entropy as the divergence function D). The optimization procedure is also an
example of alternating projection (Figure 3). Specifically, the teacher
q(n+1)
is the projection of the student
p onto the set defined by the experience, and the student p is the projection of the teacher q(n+1)
θ(n) θ(n+1)
onto the set of model distributions.
7.2.1. The Teacher Step
The teacher step in Equation 3.3 has a closed-form solution for the teacher
q(n+1)
due to the choice of cross
entropy as the divergence function D in SE:
βlogp (t)+f(t)
Teacher: q(n+1)(t) =exp θ(n) / Z. (7.1)
{ α }
In the more general case where other complex divergence functions are used (as those in Section 5), a closed-
form teacher is usually not available. The probabilistic functional descent (PFD) mentioned in Section 5.2, with
approximations to the influence function using convex duality, offers a possible way of solving for q for