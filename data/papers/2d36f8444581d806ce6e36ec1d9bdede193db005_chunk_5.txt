id:5)(cid:9) (cid:3)(cid:4) (cid:12)(cid:13)(cid:21)(cid:10) (cid:21)(cid:10) M 2a 0y 1 616 ConclusionsandFutureWork
video content engine relevant answer This demo paper presents a novel and promising Visual
photos/videos
MemoryQAsystem,anintelligentagentorchatbotthatcan
Figure 2: Framework of the proposed Visual Memory QA answerquestionsaboutusersâ€™dailylivesdiscoveredintheir
system. personalphotosandvideos.Wehavedevelopedaprototype
system that can efficiently answer questions over 1 million
personalvideos.Wearestillworkingonobtainingmorean-
Intherecurrentneuralnetwork,thetaskistounderstand
notateddatatoqualitativelyevaluatetheaccuracyofonthe
thequestionandclassifyitintoapredefinedanswertype.We
end-to-end task. In the future, we plan to release a bench-
predefineasetofquestionandanswertypesbasedontheir
markonthisnovelandinterestingproblem.
frequencies in Flickr visual search logs (Jiang et al. 2017).
SeeTable1.Atwo-layerLSTMneuralnetworkisincorpo-
Acknowledgments
ratedastheclassifierwheretheembeddingofeachwordin
thequestionissequentiallyfedintotheLSTMunits.Asthe ThisworkwaspartiallysupportedbyYahooInMindProject
answertypesaremutuallyexclusive,asoftmaxlogisticloss andtheIARPAviaDepartmentofInteriorNationalBusiness
isemployedtotrainthenetwork.Besides,thisquestionun- CentercontractnumberD11PC20068.
derstanding component is also responsible for parsing the
question to extract the named entity (person, organization, References
placeandtime).
Antol, S.; Agrawal, A.; Lu, J.; Mitchell, M.; Batra, D.;
The second component is a content video/photo engine
Lawrence Zitnick, C.; and Parikh, D. 2015. Vqa: Visual
thatcanautomaticallyunderstandandindexpersonalvideos
questionanswering. InICCV.
purelybasedonthevideocontent.Ittakes