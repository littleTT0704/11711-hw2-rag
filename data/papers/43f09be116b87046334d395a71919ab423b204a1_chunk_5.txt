bothwithinoracross domainadaptationsetting: Givenatextcorpusan-
annotationstylesandvocabulary. notatedforcoreferencefromsourcedomainS,an
Ourprimarycontributionsinclude: Timingex- un-annotatedcorpusfromtargetdomainT,anda
perimentsshowingtheefficiencyofmentionanno- limitedannotationbudget,ourgoalistomaximize
tations (§3), and methodology to easily integrate coreferenceF1performanceinthetargetdomain
mentionannotations(§4)intoacommoncorefer- underthegivenannotationbudget. Wedefinethis
encearchitecture(Leeetal.,2018). Furthermore, budgetastheamountofannotationtime.
tothebestofourknowledge,thisisthefirstwork Themoststraightforwardapproachtothistaskis
toexaminecoreferenceresolutioninchildprotec- toannotatedocumentswithfullcoreferencechains
tivesettings. Withempiricalresultsdemonstrating inthetargetdomainuntiltheannotationbudgetis
exhausted. Given an existing coreference model 3 TimedAnnotationExperiments
trained on the source domain, we can continue
In§2weestablishedthatadaptingjustthemention
training on the annotated subset of the target do-
detectioncomponentofacoreferencemodeltoa
main. With a budget large enough to annotate at
new domain can be as effective as adapting both
least100documents,thishasbeenshowntowork
mentiondetectionandantecedentlinking. Inthis
wellforsomedomains(XiaandVanDurme,2021).
sectionwedemonstratethatannotatingmentions
2.3 EffectofIn-DomainTrainingonMention is approximately twice as fast as annotating full
DetectionandAntecedentLinking coreference chains. While coreference has been
established asa time-consumingtask to annotate
Giventhatout-of-domainvocabularyisacommon
fordomainexperts(AralikatteandSøgaard,2020;
aspectofdomainshiftincoreferencemodels(Up-
Li et al., 2020a), no prior work measures the rel-
pundaetal.,2021;LuandNg,2020),wehypoth-