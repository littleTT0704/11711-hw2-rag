and θ in two stages, respectively. At each iteration n, the expectation (E) step maximizes L(q,θ(n)) w.r.t. q.
From Equation 2.9, this is achieved by setting q to the current true posterior:
E-step: q(n+1)(y∣x∗) =p (y∣x∗), (2.10)
θ(n)
so that the KL divergence vanishes and the upper bound is tight. In the subsequent maximization (M) step,
L(q(n+1),θ) is minimized w.r.t. θ:
M-step: maxEq(n+1)(y∣x∗)[logp θ(x∗,y)],
(2.11)
θ
which is to maximize the expected complete data log-likelihood. The EM algorithm has an appealing property
that it monotonically decreases the negative marginal log-likelihood over iterations. To see this, notice that
after the E-step the upper bound
L(q(n+1),θ(n)
) is equal to the negative marginal log-likelihood, and the M-
step further decreases the upper bound (and thus the negative marginal log-likelihood).
Variational EM. When the model p (x,y) is complex (e.g., a neural network or a multilayer graphical
θ
model), directly working with the true posterior in the E-step becomes intractable. Variational EM overcomes
the difficulty with approximations. It considers a restricted family Q′ of the variational distribution q(y) such
that optimization w.r.t. q within the family is tractable:
Variational E-step:
minL(q,θ(t)
).
(2.12)
q∈Q′
A common way to restrict the q family is the mean-field methods, which partition the components of y into
M
sub-groups y = (y 1,…,y M) and assume that q factorizes w.r.t. the groups: q(y) = ∏ i=1q i(y i).
The variational principle summarized in (Wainwright & Jordan, 2008) gives a more principled interpretation