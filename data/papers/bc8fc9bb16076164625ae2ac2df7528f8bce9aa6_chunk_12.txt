
contrastivelearning[18].Inspiredbythat,wetransformagraph usinggradientdescent:
ğº withtransitionmatrixğ‘» viagraphdiffusionandsparsification
S = (cid:205) ğ‘˜âˆ =0ğœƒ ğ‘˜ğ‘»ğ‘˜ intoanewgraphwithadjacencymatrixSasan ğœƒ ğ‘¡â€²â†ğœğœƒ ğ‘¡â€² âˆ’1+(1âˆ’ğœ)ğœƒ ğ‘¡ (3)
augmentedviewinourframework.Whiletherearemanydesign Withtheaboveiterativeself-distillationprocedure,wecanaggre-
choicesincoefficientsğœƒ ğ‘˜ likeheatkernel,weemployPersonalized gateinformationforaveragingmodelweightsovereachtraining
PageRank(PPR)withğœƒğ‘ƒğ‘ƒğ‘… =ğ›¼(1âˆ’ğ›¼)ğ‘˜duetoitssuperiorempirical
stepinsteadofusingthefinalweightsdirectly[1].Itshouldbe
ğ‘˜
performance[18].Asanotheraugmentationchoice,werandomly notedthatmaintainingaslow-movingaveragenetworkisalsoem-
removeedgesofgraphstoattaincorruptedgraphsasaugmented ployedinsomemodelslikeMoCo[20]withdifferentmotivations:
viewstovalidatetherobustnessofmodelstodifferentaugmentation MoCousesanEMAofencoderandmomentumencodertoupdate
choices. theencoder,ensuringtheconsistencyofdictionarykeysinthe
4 ITERATIVEGRAPHSELF-DISTILLATION memorybank.Ontheotherhand,IGSDusesamovingaverage
Intuitively,thegoalofcontrastivelearningongraphsistolearn networktoproducepredictiontargets,enforcingtheconsistency
graphrepresentationsthatarecloseinthemetricspaceforpositive ofteacherandstudentfortrainingthestudentnetwork.
Ljubljanaâ€™21,April19â€“23,2021,Ljubljana,Slovenia Zhangetal.
Augmentation Latent