
contrastivelearning[18].Inspiredbythat,wetransformagraph usinggradientdescent:
𝐺 withtransitionmatrix𝑻 viagraphdiffusionandsparsification
S = (cid:205) 𝑘∞ =0𝜃 𝑘𝑻𝑘 intoanewgraphwithadjacencymatrixSasan 𝜃 𝑡′←𝜏𝜃 𝑡′ −1+(1−𝜏)𝜃 𝑡 (3)
augmentedviewinourframework.Whiletherearemanydesign Withtheaboveiterativeself-distillationprocedure,wecanaggre-
choicesincoefficients𝜃 𝑘 likeheatkernel,weemployPersonalized gateinformationforaveragingmodelweightsovereachtraining
PageRank(PPR)with𝜃𝑃𝑃𝑅 =𝛼(1−𝛼)𝑘duetoitssuperiorempirical
stepinsteadofusingthefinalweightsdirectly[1].Itshouldbe
𝑘
performance[18].Asanotheraugmentationchoice,werandomly notedthatmaintainingaslow-movingaveragenetworkisalsoem-
removeedgesofgraphstoattaincorruptedgraphsasaugmented ployedinsomemodelslikeMoCo[20]withdifferentmotivations:
viewstovalidatetherobustnessofmodelstodifferentaugmentation MoCousesanEMAofencoderandmomentumencodertoupdate
choices. theencoder,ensuringtheconsistencyofdictionarykeysinthe
4 ITERATIVEGRAPHSELF-DISTILLATION memorybank.Ontheotherhand,IGSDusesamovingaverage
Intuitively,thegoalofcontrastivelearningongraphsistolearn networktoproducepredictiontargets,enforcingtheconsistency
graphrepresentationsthatarecloseinthemetricspaceforpositive ofteacherandstudentfortrainingthestudentnetwork.
Ljubljana’21,April19–23,2021,Ljubljana,Slovenia Zhangetal.
Augmentation Latent