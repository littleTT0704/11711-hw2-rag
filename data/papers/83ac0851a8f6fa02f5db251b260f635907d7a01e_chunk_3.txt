ofbuildinganagent thattheagenthasreacheditsgoal.
thatcanefficientlynavigateanenvironment: Noonewould
likely deploy a household robot that re-navigates an entire Greedy FAST BeamSearch
house100times2 beforeexecutingeachcommand, evenif
it ultimately arrives at the correct location. The top per-
formingsystemsontheVLNleaderboard3allrequirebroad
exploration that yields long trajectories, causing poor SPL
performance(SuccessweightedbyPathLength[1]).
To alleviate the issues of exposure bias and expen-
sive, inefficient beam-search decoding, we propose the Figure 2. All VLN agents are performing a search. The orange
FrontierAwareSearchwithbackTracking(FAST NAVIGA- areashighlightthefrontierfordifferentnavigationmethods.
TOR). This framework lets agents compare partial paths
of different lengths based on local and global information
2.1.LearningSignals
andthenbacktrackifitdiscernsamistake. Figure1shows
trajectorygraphscreatedbythecurrentpublishedstate-of-
KeytoprogressinvisualnavigationisthatallVLNap-
the-art(SoTA)agentusingbeamsearchversusourown.
proaches performs a search (Figure 2). Current work of-
Our method is a form of asynchronous search, which
ten goes toward two extremes: using only local informa-
combines global and local knowledge to score and com-
tion,e.g.greedydecoding,orfullysweepingmultiplepaths
pare partial trajectories of different lengths. We evaluate
simultaneously, e.g. beam search. To build an agent that
our progress to the goal by modeling how closely our pre-
can navigate an environment successfully and efficiently,
vious actions align with the given text instructions. To
we leverage both local and global information, letting the
achieve this, we use a fusion function, which converts lo-
agent make a local decision while remaining aware of its
calactionknowledgeandhistoryintoanestimatedscoreof
globalprogressandefficientlybacktrackingwhentheagent
progress. Thisscoredetermineswhichlocalactiontotake
discernsamistake. Inspiredbypreviouswork[10,13],our
andwhethertheagentshouldbacktrack.