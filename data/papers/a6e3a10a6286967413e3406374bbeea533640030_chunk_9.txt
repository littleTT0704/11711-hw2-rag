onemeintervals, angle
manuallysegmentingphonemescanbelaborious,difficult,and
31-30-37 31-29-37 29-30-34
imprecise.
To improve the accuracy of phoneme segmentation, we
employ state-of-the-art phoneme segmentation approaches. Training details. For each phoneme-AM pair, we conduct
Specifically,weusetheWav2Vec2-Large-XLSR-53model[23] 10 repeated experiments to ensure statistical significance. In
developedbyFAIR,whichlearnspowerfulspeechrepresenta-
tionsfrommorethan50.000hoursofunlabeledspeech. This 1https://huggingface.co/facebook/wav2vec2-xlsr-53-espeak-cv-ft
eachexperiment, werandomlysample5000datasamplesand sizethatforaspecificAM,ifitismorefrequentlymovedduring
randomly split them into the D /D /D set in the ratio of thepronunciationofphonemes,theAMisgenerallymorepre-
t v1 v2
70%/10%/20%. WefollowthetypicalsettingsofAdam[29] dictable.Wefurtherverifythishypothesisinthenextsection.
foroptimizationoftheestimator. Thelossfunctionweuseis
the mean squared error loss. The size of the mini-batch and 4.3.3. RelationshipbetweenphonemesandAMs
learningrateissetto128and0.0001,respectively.
Table2:Detailedresultsofphoneme-AMpairs.
4.3. Results
4.3.1. Analysisofphonemes AMs /E/ /D/ /f/ /i:/ /v/ /w/ /æ/
For each phoneme, we calculate the average 1−CI result
u 39-43 0.10 -0.04 0.08 0.23 0.11 0.18 0.18
witheveryAMs.AscanbeseenfromFig.3,/i:/gotthehigh-
31-30-37 0.10 0.04 0.19 0.11 0.10 0.21 -0.09
est avg. 1−CI