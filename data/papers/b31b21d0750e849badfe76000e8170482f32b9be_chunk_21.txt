
RetrievalaugmentedgenerationTheparadigmofretrieve-then-generatehasgainedpopularityin
thefieldofopen-domainquestionanswering(Guuetal.,2020;Lewisetal.,2020;Karpukhinetal.,
2020),wheretheanswerforanopen-domainquestionexistsinonlyfewdocumentsoutofamuch
larger pool. Although DocPrompting takes a similar approach, documentation retrieval in code
generationisevenmorevaluable,sincecodelibrariesareupdatedconstantly,andnewlibrariesare
introduceddaily. Thus,DocPromptingallowsupdatingthedocumentationpoolfrequentlywithnew
contents,withoutre-traininganymodelcomponents.
Documentation conditioned generation The model of Zhong et al. (2019) reads documents to
understandenvironmentdynamicsinagrid-worldgame,andBranavanetal.(2011)controlssituated
agentsinagame(CivilizationII)byreadingthegame’smanual. However,alltheirmodelswere
tailoredtospecificgames;incontrast,DocPromptingisgeneralandisapplicableforavarietyof
programminglanguagesanddatasets.
8 CONCLUSION
WeproposeDocPrompting,asimpleandeffectiveapproachforcodegenerationbyretrievingthe
relevantdocumentation. DocPromptingconsistentlyimprovesNL→codemodelsintwotasks,in
twoPLs,andacrossmultiplestrongbasemodels. DocPromptingimprovesstrongbasemodelssuch
asCodeT5by2.85%inpass@1(52%relativegain)inexecution-basedevaluationonthepopular
PythonCoNaLabenchmark;onanewBashdatasettldr,DocPromptingimprovesCodeT5and
GPT-Neo-1.3Bbyupto6.9%exactmatch,andCodexby6.78charBLEUscore.
TheseresultsopenapromisingdirectionforNL→codegeneration. Webelievethatourresultscanbe
furtherimprovedusingmorecleverencodingofthestructurednatureoflongdocuments,andusing
jointtrainingoftheretrieverandthegenerator,whichhopefullywill