nesshasnotbeenevaluatedtothebestofourknowledge. Furthermore,color
sensitivityisknowntodecreaseintheperipheryofthevisualfield[Hansenetal.,2009,Johnson,
1986],yetmostoftheexistingtechniquesdonotaccountforthisphenomenon.
Similartohowtheretinapreprocessesthevisualstimulibeforeitreachesthevisualcortex,weuse
R-Blur to preprocess the input before it reaches the DNN. To measure the impact of R-Blur, we
evaluate the object recognition capability of ResNets [He et al., 2016] trained with and without
R-Blur on three image datasets: CIFAR-10 [Krizhevsky et al.], Ecoset [Mehrer et al., 2021] and
Imagenet[Russakovskyetal.,2015],underdifferentlevelsofadversarialattacksandcommonimage
corruptions[HendrycksandDietterich,2019]. WefindthatR-Blurmodelsretainmostofthehigh
classificationaccuracyofthebaseResNetwhilebeingmorerobust. ComparedtothebaseResNet,R-
Blurmodelsachieve12-25percentagepoints(pp)higheraccuracyonperturbedimages. Furthermore,
therobustnessachievedbyR-Bluriscertifiableusingtheapproachfrom[Cohenetal.,2019]. We
also compare R-Blur with two biologically inspired preprocessing defenses, namely VOneBlock
[Dapelloetal.,2020],afixedparametermodulethatsimulatestheprimateV1,andanon-uniform
sampling-basedfoveationtechnique[Vuyyuruetal.,2020],whichwerefertoasR-Warp. Weobserve
thatR-Blurinducesahigherlevelofrobustness,achievingaccuracyupto33pphigherthanR-Warp
andupto15pphigherthanVOneBlockagainstadversarialattacks. Comparedtoadversarialtraining
(AT)[Madryetal.,2018,Wongetal.,2019]â€“thestate-of-the-artnon-biologicaldefense,R-Blur
achievesupto7pphigheraccuracyonaverageagainstnon-adversarialcor