 Association for Computational Lin-
guistics. Baolin Peng, Michel Galley, Pengcheng He, Chris
Brockett, Lars Liden, Elnaz Nouri, Zhou Yu, Bill
Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Dolan,andJianfengGao.2022. GODEL:large-scale
Cao,andShuziNiu.2017. DailyDialog: Amanually pre-trainingforgoal-directeddialog. arXivpreprint
labelledmulti-turndialoguedataset. InProceedings arXiv:2206.11309.
oftheEighthInternationalJointConferenceonNat-
uralLanguageProcessing(Volume1: LongPapers), AlecRadford,JeffreyWu,RewonChild,DavidLuan,
pages986–995,Taipei,Taiwan.AsianFederationof DarioAmodei,IlyaSutskever,etal.2019. Language
NaturalLanguageProcessing. ModelsareUnsupervisedMultitaskLearners. Ope-
nAIblog,1(8):9.
ZekunLi,WenhuChen,ShiyangLi,HongWang,Jing
Qian,andXifengYan.2022. Controllabledialogue ColinRaffel,NoamShazeer,AdamRoberts,Katherine
simulation with in-context learning. In Findings Lee,SharanNarang,MichaelMatena,YanqiZhou,
of the Association for Computational Linguistics: WeiLi, andPeterJ Liu.2020. ExploringtheLim-
EMNLP2022,pages4330–4347,AbuDhabi,United itsofTransferLearningwithaUnifiedText-to-Text
ArabEmirates.AssociationforComputationalLin- Transformer. JournalofMachineLearningResearch,
guistics. 21:1–67.
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, HannahRashkin,AntoineBosselut,MaartenSap,Kevin
RuochenXu,andChenguangZhu.2023. GPTeval: Knight,andYejinChoi.2018. Modelingnaivepsy-
NLG Evaluation