18653/v1/2021.emnlp-main.243
↩
Levine, S. (2018). Reinforcement learning and control as probabilistic inference: Tutorial and review. arXiv.
https://doi.org/10.48550/arXiv.1805.00909 ↩
Li, L., Littman, M. L., Walsh, T. J., & Strehl, A. L. (2011). Knows what it knows: A framework for self-
aware learning. Machine Learning, 3(82), 399–443. https://doi.org/10.1007/s10994-010-5225-4 ↩
Li, X. L., & Liang, P. (2021). Prefix-tuning: Optimizing continuous prompts for generation. In C. Zong, F.
Xia, W. Li, & R. Navigli (Eds.), Proceedings of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International Joint Conference on Natural Language Processing
(Volume 1: Long Papers) (pp. 4582–4597). http://doi.org/10.18653/v1/2021.acl-long.353
↩
Liu, G., Feng, Z., Gao, Y., Yang, Z., Liang, X., Bao, J., He, X., Cui, S., Li, Z., & Hu, Z. (2022). Composable
text controls in latent space with ODEs. arXiv. https://doi.org/10.48550/arXiv.2208.00638 ↩
Ma, Y., Tsao, D., & Shum, H.-Y. (2022). On the principles of parsimony and self-consistency for the
emergence of intelligence. Frontiers of Information Technology & Electronic Engineering, 23(9), 1298–
1323. https://doi.org/10.1631/FITEE.2200297
Ma, Y., Tsao, D., & Shum, H.-Y. (2022). On the principles of parsimony and self-consistency for the
emergence of intelligence. Frontiers of Information Technology & Electronic Engineering, 23(9), 1298–
1323. https://doi.org/