l l l l l
wherefunction1((cid:1))outputs1ify = 1and(cid:1) = C and
1 l n1=4
l
n is the number of training data labeled with l and C is a
l
constant. TheLDAMlossisthus: L =L (y;y^m).
LDAM BCE
Figure 2: ZAGRNN as the feature extractor. ZAGRNN extracts 3.2 Zero-shotLatentFeatureGeneration
label-wise features and constructs embedding for each ICD code
Forazero-shotcodel,thecodelabely foranytrainingdata
using GRNN. ZAGRNN makes a binary prediction for each code l
based on the dot product between graph label embedding and the exampleisy l =0andthebinaryclassifierg lforcodeassign-
labelspecificfeature. mentisnevertrainedwithdataexampleswithy l = 1dueto
thedearthofsuchdata. Previousworkshavesuccessfullyap-
pliedGANsforGZSLinthevisiondomain[Xianetal.,2018;
X = [w 1;w 2;:::;w n] where w i 2 Rd is the word embed- Felix et al., 2018]. We propose to use GANs to improve
dingvectorforthei-thword. EachICDcodel hasatextual zero-shotICDcodingbygeneratingpseudodatainthelatent
description.Torepresentl,weconstructanembeddingvector feature space for zero-shot codes and fine-tuning the code-
v l byaveragingtheembeddingsofwordsinthedescription. assignmentbinaryclassifiersusingthegeneratedfeatures.
The word embedding is shared between input and label Morespecifically,weusetheWassersteinGAN[Arjovsky
descriptions for sharing learned knowledge. Adjacent word et al., 2017] with gradient penalty (WGAN-GP) [Gulrajani
embeddings are combined using a one-dimension convolu- et al., 2017] to generate code-specific latent features condi-
tional neural network (CNN) to get the n-gram text features tioned on the textual description of each code. To condi-
H = conv(X)