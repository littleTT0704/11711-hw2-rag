MO, which is trained on texts generated by context:\n[narrative]\ndialogue:\n
GPT-3.5. Therefore,theoriginalhumanevaluation [dialogue]\nWhat is the most appropriate
next utterance (3 sentences max)?.” normsinproblematiccontexts(Kimetal.,2022a).
AbovedatasetsexceptforDailyDialogareallunder
Details of Human Evaluation A total of 77
the CC-BY-4.0 license. We use DailyDialog and
workers participated in comparing responses, re-
BlendedSkillTalk for comparing with our SODA
sulting in a Krippendorf’s alpha of 0.5. This in-
dataset,andProsocialDialogfortrainingCOSMO,
dicates good agreements on the response quality
whichisallcompatiblewiththelicense.
judgments. Figure5showstheannotationpagefor
workersevaluatingtheresponsequality.
E AdditionalRelatedWork
Human-authoredDialogueDatasets Existing
dialoguedatasetsgenerallyderivefromoneofthe
foursources: (1)Onlinelearningwebsitesandtext-
books (Li et al., 2017) for beginners which may
lackcomplexlanguageusage. (2)Movieanddrama
scripts(Danescu-Niculescu-MizilandLee,2011)
thatarelessnaturalcomparedtoday-to-dayscenar-
ios. (3)Crowdsourcing(Rashkinetal.,2019;Zhou
etal.,2021;Tranetal.,2022): potentiallyproneto
collectingresponsesthataresomewhatshortordull
duetoincentivemisalignmentbetweenresearchers
andcrowdworkers (Zhouetal.,2022). (4)Noisy
webinteraction,suchasRedditcomments(Baum-
gartneretal.,2020)andTwitter(Ritteretal.,2011);
while widely used in dialogue agent pretraining
stage due to their scale, these may represent dif-
ferent conversational frames compared to dyadic
conversations. Moreover, as these are unfiltered
conversations,theirusesurfacesacomplexsetof
ethicsandbiasconsiderations. SODA contributes
