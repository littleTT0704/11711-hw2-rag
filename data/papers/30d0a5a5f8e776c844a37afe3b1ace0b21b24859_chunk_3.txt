 em-
telligence emerges from an agentâ€™s interactions with bodied vision-and-language. The navigation chal-
itsenvironment.Aninteractionintheenvironmentin- lenges include Habitat PointNav [1] and Object-
volvesanagenttakinganactionthataffectsitsfuture Nav [17], Interactive and Social Navigation with
state. Forinstance,theagentmayperformnavigation iGibson [210], RoboTHOR ObjectNav [51], Mul-
actions to move around the environment or take ma- tiON [198], RVSU Semantic SLAM [82], and Audio-
nipulation actions to open or pick up objects within Visual Navigation with SoundSpaces [38]; rear-
reach. EmbodiedAIisafocusofagrowingcollection rangement challenges include AI2-THOR Rearrange-
1
2202
ceD
5
]VC.sc[
3v94860.0122:viXra
Hey, is
there any
cereal left?
Cereal
Figure1.AnillustrationofascenariodepictingmanytasksofinteresttoresearchersinEmbodiedAI.Here,wehavemultiple
robotsoperatinginakitchenenvironment,withahumanaskingoneoftherobotsifthereisanycerealleft,whiletheother
onecleansthedishes. Therobotsmustusetheirnavigation,manipulation,andreasoningskillstoanswerandachievetasks
intheenvironment.
ment [200], TDW-Transport [67], and RVSU Scene transfer[188,220].
Change Detection [82]; and embodied vision-and- Abstracting away from real or simulated embodi-
language challenges include RxR-Habitat [102], AL- ments, embodied AI can be defined as the study of
FRED [177], and TEACh [133]. We discuss the setup intelligent agents that can see (or more generally per-
ofeachchallengeanditsstate-of-the-artperformance, ceive their environment through vision, audition, or
analyze common approaches between winning en- othersenses), talk (i.e.holdanaturallanguagedialog
tries across the challenges, and conclude with a dis- grounded in the environment), listen (i.e. understand
cussionofprom