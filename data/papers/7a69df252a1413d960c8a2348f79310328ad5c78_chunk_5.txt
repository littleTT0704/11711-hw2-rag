[35][5][39],autoregressivemod-
els [25] [32] [8], or other techniques [37] [16] [15] [40].
We propose to expand the focus of attention to channel, word and spatial
relationships instead of a subset of these thereby enhancing the quality of gen-
eration.
3 The framework of Combined Attention Generative
Adversarial Networks
3.1 Combined Attention Generative Adversarial Networks
The proposed CAGAN utilises three attention models: word attention to draw
different sub-regions conditioned on related words, local self-attention to model
long-range dependencies, and squeeze-and-excitation attention to capture non-
linear interaction among channels.
The attentional generative model consists of three generators, which receive
imagefeaturevectorsasinputandgenerateimagesofsmall-to-largescales.First,
adeepbidirectionalLSTMencoderencodestheinputsentenceintoaglobalsen-
tencevectorsandawordmatrix.ConditioningaugmentationFCA [44]converts
the sentence vector into the conditioning vector. A first network receives the
conditioning vector and noise, sampled from a standard normal distribution, as
input and computes the first image feature vector. Each generator is a simple
3x3 convolutional layer that receives the image feature vector as input to com-
pute an image. The remaining image feature vectors are computed by networks
receiving the previous image feature vector and the result of the ith attentional
model Fattn (see Figure 2), which uses the word matrix computed by the text
i
encoder.
To compute word attention, the word vectors are converted into a common
semantic space. For each subregion of the image a word-context vector is com-
puted, dynamically representing word vectors that are relevant to the subregion
of the image, i.e., indicating the weight the word attention model attends to
the lth word when generating a subregion. The final objective function of the
attentional generative network is defined as:
m−1
(cid:88)
L=L +λL, where L = L. (1)
G DAMSM G Gi
i=0
Here,λisahyperparametertobalancethetwoterms