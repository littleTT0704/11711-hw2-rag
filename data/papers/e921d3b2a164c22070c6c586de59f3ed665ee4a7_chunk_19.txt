 using the Newton (or Newton-like) update. In the expertsareorderedandthemodelparametersarecarefully
HMEmodels,aNewtoniterationcostisO(n3). Inourcase, initialized.
the complexity of M-step is in solving the SVM. Specif-
Inthefuturework,wewouldliketoprovidemorerigorous
ically, for standard SVM solver with primal-dual interior
studyonthetheoreticallybehaviorsofourHRMEmodel.
pointmethod,thecomplexityisintheNewtonupdateand
evaluation of the kernel, and hence the iteration cost is
5.Conclusions
2usingGaussianexperts;resultstakenfromFerrari&Milioni
(2011) In this paper, we propose a hierarchical routing mixture
3usingGaussianprocessexperts;resultstakenfromTrappetal. ofexperts(HRME)modeltoaddressthedifficultyofdata
(2018)
partitioningandexpertassigninginconventionalregression
4usingGaussianprocessexperts;resultstakenfromTrappetal.
models.Byutilizingnon-leafclassifierexperts,ourmodelis
(2018)
5usingGaussianprocessexperts;resultstakenfromNguyen& abletocapturethenaturaldatahierarchyandroutethedata
Bonilla(2014) tosimpleregressorsforeffectivepredictions. Furthermore,
HierarchicalRoutingMixtureofExperts
wedevelopaprobabilisticframeworkfortheHRMEmodel, Jacobs,R.A.,Jordan,M.I.,Nowlan,S.J.,andHinton,G.E.
and propose a recursive Expectation-Maximization (EM) Adaptivemixturesoflocalexperts. Neuralcomputation,
basedalgorithmtooptimizeboththetreestructureaswell 3(1):79–87,1991.
as the expert models. Comprehensive experiment results
validatetheeffectivenessandsomenicepropertiesofour Jiang, W. and Tanner, M. A. On the approximation rate
model. ofhierarchicalmixtures-of-expertsforgeneralizedlinear
models. Neuralcomputation,11(5):1183–1198,1999a.
References