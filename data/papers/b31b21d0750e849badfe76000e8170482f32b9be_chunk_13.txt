onthetestset
oftldr. Forthe“oraclecommandname”experiments,weselectedthebestmodelofeachtype.
Model CMDAcc(%) EM(%) TokenF1 charBLEU
- 11.96 1.94 28.75 19.99
GPT-Neo-125M
+DocPrompting 25.32 3.56 31.23 24.43
- 14.55 3.12 32.46 24.70
GPT-Neo-1.3B
+DocPrompting 27.59 9.05 37.24 30.57
- 10.02 0.76 19.90 25.48
T5
+DocPrompting 30.28 9.16 37.58 31.97
- 14.60 2.18 30.00 21.50
CodeT5
+DocPrompting 30.72 9.15 36.71 33.83
- 27.48 8.94 36.04 16.94
Codex3-shots
+DocPrompting 31.21 9.29 36.77 23.72
Withtheoraclecommandname
- - 12.96 59.36 45.05
T5
+DocPrompting - 22.55 64.84 54.28
- - 22.44 62.26 50.29
Codex3-shots
+DocPrompting - 32.43 69.73 55.21
Table2: Comparisontoapproachesthatretrieveexamples(Parvezetal.,2021;Pasupatetal.,2021)
.
Model CMDAcc(%) EM(%) TokenF1 charBLEU
+ExPrompting 6.68 0.32 20.49 11.15
GPT-Neo-125M
+DocPrompting 25.32 3.56 31.23 24.43
+ExPrompting 14.01 2.8 30.07 22.11
GPT-Neo-1.3B
+DocPrompting 27.59 9.05 37.24 30.57
tldrproject. WeconductedanoracleexperimentwhereweprovidedT5(whichwasthestrongest
modelusingDocPrompting)andCodexwiththeoraclecommandname(e.g.,awk). Thisor