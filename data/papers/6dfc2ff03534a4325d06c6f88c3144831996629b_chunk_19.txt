ation:
query, response, and image together. This step includes (cid:88)
α =softmax(rWq ) qˆ = α q. (2)
resolvingthereferent‘he,’ andwhyonemightbepointing i,j i j i i,j j
j
j
in a diner. Third, we reason about the interplay of rele-
vant image regions, the query, and the response. In this To contextualize ananswer with theimage, including im-
example, the model must determine the social dynamics plicitly relevant objects that have not been picked up from
the grounding stage, we perform another bilinear attention
between [person1 ] and [person4 ]. We for-
betweentheresponserandeachobjecto’simagefeatures.
mulate our model as three high-level stages: grounding,
Lettheresultoftheobjectattentionbeoˆ.
contextualization, and reasoning, and use standard neural i
Reasoning Last,weallowthemodeltoreasonoverthe
buildingblockstoimplementeachcomponent.
response, attended query and objects. We accomplish this
In more detail, recall that a model is given an image, a
using a bidirectional LSTM that is given as context qˆ, r,
set of objects o, a query q, and a set of responses r(i) (of i i
andoˆ foreachpositioni. Forbettergradientflowthrough
which exactly one is correct). The query q and response i
the network, we concatenate the output of the reasoning
choicesr(i)areallexpressedintermsofamixtureofnatural
LSTMalongwiththequestionandanswerrepresentations
languageandpointingtoimageregions: notation-wise,we
foreachtimestep:theresultingsequenceismax-pooledand
willrepresenttheobjecttaggedbyawordwaso.Ifwisn’t
w
passed through a multilayer perceptron, which predicts a
adetectiontag,o referstotheentireimageboundary. Our
w
logitforthequery-responsecompatibility.
modelwillthenconsidereachresponser separately,using
Neuralarchitectureandtrainingdetails Forourim-
