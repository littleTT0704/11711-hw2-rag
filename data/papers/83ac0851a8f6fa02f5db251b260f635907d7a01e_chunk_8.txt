 two simple strategies: explore structs a “mental map” of the visited space. This lets it
andexploit. search more efficient by refusing to revisit nodes, unless
1. Explorealwaysbacktrackstothemostpromisingpartial theyleadtoahigh-valueunexploredpath.
trajectory. This approach resembles beam search, but,
ratherthansimplymovingtothenextpartialtrajectoryin Q3: Which visited node is most likely to be the goal?
the beam, the agent computes the most promising node Unlikeexistingapproaches,FASTconsiderseverypointthat
tobacktrackto(Q2). theagenthasvisitedasacandidateforthefinaldestination,7
2. Exploit, in contrast, commits to the current partial tra- meaningwemustrerankallcandidates. Weachievethisus-
jectory, always executing the best action available at ingG,atrainableneuralnetworkfunctionthatincorporates
the agent’s current location. This approach resembles all global information for each candidate and ranks them
greedydecoding,exceptthattheagentbacktrackswhen accordingly. Figure4(a)showsasimplevisualization.
itisconfused(i.e,whenthebestlocalactioncausesthe WeexperimentedwithseveralapproachestocomputeG,
agent to revisit a node, creating a loop; see the SMNA e.g., byintegratingL, theprogressmonitor, speakerscore,
examplesinSupplementaryMaterials§A.1). andatrainableensemblein(§4.3).
Q4: Whendoweterminatethesearch? Theflexibility
Q2: Whereshouldwebacktrackto? Makingthisdeci-
of FAST allowsittorecoverboththegreedydecodingand
sioninvolvesusingLtoscoreallpartialtrajectories. Intu-
beamsearchframework.Inaddition,wedefinetwoalterna-
itively,thebetterapartialtrajectoryalignswithagivende-
tivestoppingcriteria:
scription,thehigherthevalueofL. Thus,ifwecanassume
1. Whenapartialtrajectorydecidestoterminate.
the veracity of L, the agent simply returns to the highest
2.