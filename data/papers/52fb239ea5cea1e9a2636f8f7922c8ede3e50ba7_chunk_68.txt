ithequationsasparameters(Kushmanetal.,2014)andotherformsof
arithmetic reasoning (Koncel-Kedziorski et al., 2015; Roy and Roth, 2016; Upad-
hyay et al., 2016; Roy and Roth, 2017, 2018; Ling et al., 2017). Later datasets
increase in complexity and scale, incorporating reading comprehension Dua et al.
(2019b),algebra(Saxtonetal.,2019),andmulti-modalcontexts(Luetal.,2021a,
2022). Still other numerical reasoning datasets focus on diversity (Miao et al.,
2020a) with multiple categories of numerical reasoning tasks (e.g., Amini et al.,
2019). Most recently, new datasets have focused on increasing difficulty, e.g.,
olympiad problems (Hendrycks et al., 2021b) and adversarial problems (Patel
et al., 2021), as well as increasing the knowledge requirements to solve tasks,
with a growing focus on commonsense reasoning (Zhou et al., 2019; Zhang et al.;
Lu et al., 2021b; Mishra et al., 2022c).
A separate line of work in mathematical reasoning includes datasets testing
mathematical theorem proving (e.g., Li et al., 2021; Wu et al., 2021; Welleck
et al., 2021; Zheng et al., 2021; Han et al., 2021). We do not, however, consider
theorem proving in our work, choosing instead to focus on numerical reasoning.
Task Hierarchy and Multi-tasking in Numerical Reasoning. We take
inspiration from the success of multi-task learning in NLP (Weston et al., 2015),
including benchmarks (e.g., Wang et al., 2018, 2019; Dua et al., 2019a) and
multitasking models (e.g., McCann et al., 2018; Khashabi et al., 2020; Lourie
et al., 2021; Aghajanyan et al., 2021). NumGLUE (Mishra et al., 2022c) has
been proposed as a multi-tasking numerical reasoning benchmark that contains
8 different tasks. LÂ¯ila expands NumGLUE to provide wider coverage of mathe-
matical abilities, along with evaluation that captures out-of-domain, robustness,
and instruction-following