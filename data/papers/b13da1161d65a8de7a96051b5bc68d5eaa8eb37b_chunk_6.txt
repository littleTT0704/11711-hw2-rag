. manticsegmentation[45]andadaptationfor3Dsegmenta-
tionusing2Dimagesand3Dpointsclouds[19]. Whilenot
Self-training with pseudo-labels. Application of self-
directly related to our experimental settings, they provide
traininghasbecomepopularinthesphereofdomainadap-
insightandinspirationforourapproach.
tation for semantic segmentation [23,25,60,64]. Here,
pseudo-labels are assigned to observations from the target
domain, based on the semantic classes of high-confidence
(e.g., the closest or least-contrastive) category centroids
[57,60], prototypes [8], cluster centers [21], or superpixel
representations[61]thatarelearnedbyamodeltrainedon 3.Self-TrainingwithObjectnessConstraints
thesourcedomain. Often,toensurethereliabilityofinitial
pseudolabelsfortargetdomain, themodelisfirstwarmed
upviaadversarialadaptation[60,61]. Moreover,forstabil- We begin by introducing preliminary concepts on self-
itypurposes,pseudolabelsareupdatedinastagewisefash- training based adaptation. These concepts serve as bases
ion,thusresultinginanoverallcomplexadaptationscheme. for introducing our objectness constraint in Section 3 that
Towards streamlining this complex adaptation process, re- isusedtoregularisetheself-trainingmethods. Wereferto
centapproacheslike[2,47]proposetotrainwithoutadver- ourframeworkasPAC-UDAwhichusesPseudo-labelsAnd
sarialwarmupandwithamomentumnetworktocircumvent objectness Constraints for self-training in Unsupervised
stagewisetrainingissue. Acommonfactorunderlyingmost Domain Adaptation for semantic segmentation. Although,
self-training methods is their reliance on just RGB inputs we describe a canonical form of self-training for formalis-
thatmaynotprovidesufficientsignalforpredictingrobust ingourregularisationconstraint,PAC-UDAshouldbeseen
target-domainpseudolabels. Thismotivatesustolookfor asageneral