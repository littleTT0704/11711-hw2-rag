destinationstomoveto- 5.Experimentalresults
wards. In total, we have 127 CAs from 7 scenes. We call
This section evaluates various methods, including our
eachCAandtheircorrespondingsceneascenario.
Multiversemodel, formulti-futuretrajectorypredictionon
For each scenario, there are on average 5.9 human an-
the proposed Forking Paths dataset. To allow comparison
notators to control the agent to the defined destinations.
with previous works, we also evaluate our model on the
Specifically, they are asked to watch the first 5 seconds of
challenging VIRAT/ActEV [3, 36] benchmark for single-
video,fromafirst-personview(withthecameraslightlybe-
futurepathprediction.
hindthepedestrian)and/oranoverheadview(togivemore
context). They are then asked to control the motion of the 5.1.EvaluationMetrics
agentsothatitmovestowardsthespecifieddestinationina
Single-FutureEvaluation. Inreal-worldvideos,eachtra-
“natural”way,e.g.,withoutcollidingwithothermovingob-
jectory only has one sample of the future, so models are
jects(whosemotionisderivedfromtherealvideos,andis
evaluated on how well they predict that single trajectory.
thereforeunawareofthecontrolledagent). Theannotation
Following prior work [30, 1, 15, 49, 23, 18, 6, 44], we in-
isconsideredsuccessfuliftheagentreachedthedestination
troducetwostandardmetricsforthissetting.
withoutcollidingwithinthetimelimitof10.4seconds. All
LetYi = Yi bethegroundtruthtrajectoryof
finaltrajectoriesinourdatasetareexaminedbyhumansto t=(h+1)···T
ensurereliability. thei-thsample,andYˆibethecorrespondingprediction.We
Notethatourvideosareupto15.2secondslong. Thisis then employ two distance-based error metrics: i) Average
slightlylongerthanpreviousworks(e.g.[1,15,30,49,26, Dis