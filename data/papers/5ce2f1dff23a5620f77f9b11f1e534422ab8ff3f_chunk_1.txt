Plan, Eliminate, and Track —
Language Models are Good Teachers for Embodied Agents.
Yue Wu1 So Yeon Min1 Yonatan Bisk1 Ruslan Salakhutdinov1 Amos Azaria2 Yuanzhi Li13
Tom M. Mitchell1 Shrimai Prabhumoye4
Abstract
Pre-trained large language models (LLMs)
capture procedural knowledge about the
world. Recent work has leveraged LLM’s abil-
itytogenerateabstractplanstosimplifychal-
lengingcontroltasks, eitherbyactionscoring,
or action modeling (fine-tuning). However,
the transformer architecture inherits several
constraints that make it difficult for the LLM
to directly serve as the agent: e.g. limited in-
putlengths,fine-tuninginefficiency, biasfrom
pre-training, and incompatibility with non-
textenvironments. Tomaintaincompatibility
Figure 1. PET framework. Plan module uses LLM to gen-
withalow-leveltrainableactor,weproposeto erateahigh-levelplan. EliminateModuleusesaQAmodel
insteadusetheknowledge inLLMstosimplify to mask irrelevant objects in observation. Track module
the control problem, rather than solving it. uses a QA model to track the completion of sub-tasks.
We propose the Plan, Eliminate, and Track
(PET) framework. The Plan module trans- Recent work (Huang et al., 2022a;b; Ahn et al., 2022;
latesataskdescriptionintoalistofhigh-level Yao et al., 2020) has used LLMs (Bommasani et al.,
sub-tasks. The Eliminate module masks out 2021) for abstract planning for embodied or gaming
irrelevantobjectsandreceptaclesfromtheob- agents. These have shown incipient success in extract-
servationforthecurrentsub-task. Finally,the ingproceduralworldknowledgefromLLMsinlinguistic
Track module determines whether the agent form with posthoc alignment to executable actions in
has accomplished each sub-task. On the Alf- the environment. However, they treat LLMs as the ac-
World instruction following benchmark, the tor, and focus on adapting LLM outputs to executable
PET framework leads to a