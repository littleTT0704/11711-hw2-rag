wordfreq/(Accessed9Sept.2020) aforementionedmethodsmightstillbetooeasyforthemod-
13509
els, thus we would like to only keep the most challenging Here,(cid:17) representsthemarginandy istheindexofthecor-
subsettotrainourmodels.WeemploytheAFLitealgorithm rectanswer.ForaMLMmodel,thecomputationcostforthe
(Sakaguchi et al. 2019) for our purpose. Given a train and scoring function scales quadratically with the input length.
devsplitofoursyntheticQAset,weuse5%ofthetrainset Tomakethetrainingmoreefficient,weonlymaskoutnon-
tofinetuneaRoBERTamodelwithaclassificationhead(4% stoptokensintheheadandtailnodes.
training,1%validation).These5%arediscardedfromtrain
TrainingRegimes Inordertodisentanglethecontribution
after this step. We then compute the fixed embeddings for
oftheKGsfromthestructureoftheQApairs,weconsider
theremaining95%oftrainandtheentiredev,denotedasTrn
different training methods for augmentation of language
andDev.Next,wefeedTrnandDevalongwiththeirlabels
modelswithKGs.Specifically,wecomparemarginalrank-
to the AFLite algorithm, which iteratively filters out easy
ing(MR)trainingwithmaskedlanguagemodeling(MLM)
examplesusinganensembleoflinearclassifiers.Finally,we
training.ForMLM,wedirectlyconcatenatethequestionand
retain (101K training, 11K dev) samples for ATOMIC and
the correct answer in our synthetic QA set and then train
(29Ktraining,1.5Kdev)samplesforCWWVsubset.Thede-
RoBERTaonthethesesentencesusingtheMLMobjective.
tailsofAFLitecanbefoundintheappendix.
Tasks
LanguageModels
Weselectcommonsensetasksbasedontwocriteria.Firstly,
We consider 2 types of language models: auto-regressive westrivetocoveradiversesetoftasks,