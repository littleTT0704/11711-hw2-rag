izationofwhythealgorithmimprovesend-taskperformance.
3. Algorithm Improvements to META-TARTAN: Please note that META-TARAN as
presentedinDeryetal.(2021b)wasusedwithonly2auxiliarytasks. Whenscalingtomore
tasks,usingMETA-TARTANnaivelybecomescomputationallyprohibitive. Specifically,
onasearchspaceofNtasks,META-TARTANrequiresO(N)ordercomputationperstep.
14
PublishedasaconferencepaperatICLR2023
Weimproveuponthisbyintroducingthetasksub-samplingof(k N)whichreducesthe
(cid:28)
computeoverheadtoO(k). Toaccountfortheimpactofsub-samplingasanapproximation,
weintroducedthefactorisedmodellingoftaskweightswhichallowssharingofinformation
betweenauxiliarytasksthatmightthemselvesberelated.
C DATASET DETAILS
Table4: Specificationsofdatasetsusedtoevaluateourmethods.
Domain Task LabelType TrainSize DevSize TestSize Classes Metric
BIOMED CHEMPROTKringelumetal.(2016) relationclassification 4169 2427 3469 13 Accuracy
CS SCIERCLuanetal.(2018) relationclassification 3219 455 974 7 F1
STANCE SE-2016-6Mohammadetal.(2016) stancedetection 2497 417 1249 3 Accuracy
CS ACL-ARCJurgensetal.(2018) citationintent 1688 114 139 6 F1
NEWS H.PARTISANKieseletal.(2019) partisanship 515 65 65 2 Accuracy
D MORE TRAINING DETAILS
Weruneachhyper-parameterconfigurationacross3seeds 0, 1, 2. Weuseabatchsizeof128
{ }
forallend-taskstasksexceptH.PARTISANwhereweuseabatchsizeof64. Theauxiliarytask
batch-size,aux bsz,issharedacrossallthensub-sampledauxiliaryobjectivesaccordingtothe
objectiveâ€™sweight.
We use the AdamW optimizer (Loshchilov & Hutter, 2017), with weight decay of 0.01