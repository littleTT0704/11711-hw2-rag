(Ribeiroetal.,2016;Shwartz-ZivandTishby, hasshownthatnaturallanguagecontributestoper-
2017; Fong and Vedaldi, 2017; Kim et al., 2018; formanceimprovementsincomplexmultistepinfer-
Lipton,2018;Wiegreffeetal.,2022). Manysuch ence(Weietal.,2022;Wangetal.,2022b;Zhang
explainabilitytechniquesrequiresignificantexper- et al., 2022). Step-by-step reasoning in CoT re-
tise in deep learning to use effectively, requiring liessolelyonthesystemtomakepredictionswith-
consumersoftheexplanationstoanalyzethedata, out human involvement. There is also work that
internalstates,andoutputtrendsofthesystemof allows users to ask questions about the systemâ€™s
interest(Ribeiroetal.,2016;Kanekoetal.,2022d; predictionsandtasks(Slacketal.,2022)inacon-
KanekoandOkazaki,2023). However, manypo- versationalformat. Comparedtothemorestandard
tential system users lack this expertise, such as learningandexplanationparadigms,thisapproach
medical or legal professionals who want to use allows humans to understand and teach the sys-
machinelearningmodelsandneedtoconfirmthe temintuitively. However,intheseworks,thecom-
veracityofthegeneratedresultsorrectifyanymis- municationtendstobeone-sided,fromhuman-to-
takenpredictions. systemorsystem-to-human,whichstillfallsshort
Toaddressthisissue,researchersareworkingto ofthefullinteractiveproblemsolvingprocessex-
findwaystobothexplainsystempredictionsinnat- periencedbyhumaninterlocutors(Lakkarajuetal.,
2022).
1Ourdatasetispubliclyavailableat:https://github.
com/kanekomasahiro/discussion_nlp Inthisstudy,wetakethefirststepstowardses-
4202
naJ
03
]LC.sc[
3v98711.5032:viXra