 introduced in ยง 6, report model per-
io 15 32.67 argparse 1 100.00
json 15 35.33 aspose 1 10.00 formance with each (ยง D.2), and visualize their
subprocess 13 30.77 bisect 1 0.00
requests 10 37.00 cgi 1 80.00 correlationswiththeexecutionaccuracy(ยงD.3).
bs4 9 38.89 configparser 1 60.00
itertools 9 27.78 ctypes 1 60.00
operator 9 64.44 dateutil 1 30.00
D.1 MetricDescription
time 9 20.00 difflib 1 0.00
math 8 61.43 docxtpl 1 10.00
builtins 6 76.67 filecmp 1 40.00 BLEU BLEU(Papinenietal.,2002)isalexical-
selenium 6 50.00 ftplib 1 60.00
tensorflow 6 6.67 hashlib 1 0.00 based evaluation metric, which calculates the n-
django 5 20.00 heapq 1 0.00
sqlite3 5 38.00 imp 1 40.00 gram overlap between text prediction and (multi-
PIL 4 35.00 inspect 1 0.00
ple)references. Mostdefaultcalculationprocesses
codecs 4 72.50 locale 1 0.10
cv2 4 22.50 lxml 1 0.00 calculate up to 4-grams and adopt the smoothing
scipy 4 5.00 mechanize 1 0.00
sklearn 4 0.00 mpl_toolkits 1 0.00 functionintroducedinLinandOch(2004).
base64 3 6.67 multidict 1 90.00
csv 3 36.67 pprint 1 20.00
flask 3 50.00 queue 1 0.00 ROUGE ROUGE (Lin, 2004) is another more
glob 3 43.33 regex 1 100.00
shutil 3 60.00 rsa 1 10.00 recall-orientedlexical-basedevaluationmetric. It
socket 3 40.00 ssl 1 0.00
struct 3 16.67 texttable 1 60.00 was originally designed for measuring text sum-
sympy 3 0.00 unicodedata 1 90.00
marization, mainly by counting the number of
