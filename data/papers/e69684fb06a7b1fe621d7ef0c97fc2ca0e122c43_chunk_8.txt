 al., 2021), we utilize 3.4 ModelRetriever
DataFinder’s trained bi-encoder retriever to rank Weneedtoselectanappropriatemodeltofinetune.
themostrelevantdatasets. Oncearelevantdataset To support many tasks with a unified model
is identified, the next step is to determine which interface,wepresentlylimitourselvestoencoder-
columnsofthedatasetcorrespondtotheinputand decoder architectures on Hugging Face (Wolf
the desired output specified by the user. As au- etal.,2020),followingrecentworkthatshowsthat
tomatically inducing the correct schema for any encoder-decodermodelsaremoredata-efficientfor
datasetcanbechallenging,weadoptahuman-in- modeldistillation(Calderonetal.,2023). Thisre-
the-loopapproach. Wepresentthetop-k datasets, strictionstillleavesalargesetofpretrainedmodels
where k = 25 by default, to the user and allow to choose from, e.g. Salesforce/codet5-base
themtoeitherselectthemostrelevantdatasetorto for coding-related tasks (Wang et al., 2021b) or
statethatnoneareagoodfitfortheirtask. Wethen MaryaAI/opus-mt-ar-en-finetuned-ar-to-en
asktheusertoidentifytheappropriatecolumnsfor forArabic-to-Englishtranslation(Tiedemannand
inputandoutputfromthedataset’sschema. Thottingal,2020). Weframetheproblemofselect-
ingapretrainedmodelasasearchproblem. Using
3.3 DatasetGenerator
theuser’sinstructionasaquery,wesearchagainst
We carefully engineered our dataset generator to alltextualdescriptionsofmodelsonHuggingFace.
enable speed-optimized generation at a low-cost This search task is challenging because Hug-
whilecreatingdiverseandhigh-qualityexamples. gingFacemodeldescriptionsaresparseandcon-
Ourstrategycomprisesthefollowingcomponents: tain lots of templatic text, often with only a few
words that signify the