 Processing (Vol- E∗ i t | − t | ¬i
ume 1: Long Papers), pages 788–801, Online. As- (cid:16) (cid:17)
q(y xe,xd) q(y xe,xd )
sociationforComputationalLinguistics. − f | − f | ¬i
(cid:16) (cid:17)
RuiqiZhong,StevenShao,andKathleenR.McKeown.
2019. Fine-grainedsentimentanalysiswithfaithful A.2 QualitativeResults
attention. CoRR,abs/1908.06870.
InTable6,weprovideexamplesofnon-contrastive
and contrastive explanations for NMT decisions.
A ContrastiveExplanationsforNeural
WeuseMarianMT(Junczys-Dowmuntetal.,2018)
MachineTranslation(NMT)Models
with pre-trained weights from the model trained
A.1 ExtendingContrastiveExplanationsto totranslatefromEnglishtoRomancelanguages4
NMT to extract explanations. Each example reflects a
Machinetranslationcanbethoughtofasaspecific decision associated with one of the five types of
typeoflanguagemodelswherethemodeliscondi- linguisticambiguitiesduringtranslationidentified
tionedonboththesourcesentenceandthepartial inYinetal.(2021a).
translation. It has similar complexities as mono-
4https://github.com/Helsinki-NLP/Tatoeba-Challenge/
linguallanguagemodelingthatmakeinterpreting blob/master/models/eng-roa/README.md
194
In the first example, the model must translate
the gender neutral English pronoun “it” into the
masculine French pronoun “il”. In both non-
contrastive and contrastive explanations, the En-
glish antecedent “vase” influences the model to
predict“il”,howevertodisambiguate“il”fromthe
femininepronoun“elle”,themodelalsorelieson
thefrenchant