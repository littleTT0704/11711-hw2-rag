Learning to Scaffold:
Optimizing Model Explanations for Teaching
PatrickFernandes∗,Ψ,Ω,(cid:60) MarcosTreviso∗,Ω,(cid:60) DanishPruthi†,Λ
AndréF.T.MartinsΩ,(cid:60),Γ GrahamNeubigΨ
ΨLanguageTechnologiesInstitute,CarnegieMellonUniversity,Pittsburgh,PA
ΩInstitutoSuperiorTécnico&LUMLIS(LisbonELLISUnit),Lisbon,Portugal
(cid:60)InstitutodeTelecomunicações,Lisbon,Portugal
ΛAmazonWebServices ΓUnbabel,Lisbon,Portugal
Abstract
Modernmachinelearningmodelsareopaque,andasaresultthereisaburgeoning
academicsubfieldonmethodsthatexplainthesemodels’behavior. However,what
istheprecisegoalofprovidingsuchexplanations,andhowcanwedemonstrate
thatexplanationsachievethisgoal? Someresearcharguesthatexplanationsshould
help teach a student (either human or machine) to simulate the model being
explained,andthatthequalityofexplanationscanbemeasuredbythesimulation
accuracy of students on unexplained examples. In this work, leveraging meta-
learningtechniques,weextendthisideatoimprovethequalityoftheexplanations
themselves,specificallybyoptimizingexplanationssuchthatstudentmodelsmore
effectivelylearntosimulatetheoriginalmodel. Wetrainmodelsonthreenatural
language processing and computer vision tasks, and find that students trained
withexplanationsextractedwithourframeworkareabletosimulatetheteacher
significantlymoreeffectivelythanonesproducedwithpreviousmethods. Through
humanannotationsandauserstudy,wefurtherfindthattheselearnedexplanations
morecloselyalignwithhowhumanswouldexplaintherequireddecisionsinthese
tasks. Ourcodeisavailableathttps://github.com/coderpat/learning-scaffold.
1 Introduction
Whiledeeplearning’sperformancehasledittobec