tasks. Informa-
tionandMediaTechnologies,6(3):680–700.
FanYangandPaulVozila.2014. Semi-supervisedChi-
nesewordsegmentationusingpartial-labellearning
withconditionalrandomfields. InProceedingsofthe
2014ConferenceonEmpiricalMethodsinNatural
LanguageProcessing(EMNLP),pages90–98,Doha,
Qatar.AssociationforComputationalLinguistics.
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-
bonell,RussRSalakhutdinov,andQuocVLe.2019.
A MoreDetailsofTaskSettings layersasthesharedencodingmodulewhoseout-
put representations are used for both sub-tasks.
A.1 DPAR
Each sub-task further adopts a private encoder
• Model. Similar to NER, we utilize a BERT- thatisinitializedwiththeremainingpre-trained
based module to provide contextualized repre- layers and is trained with task-specific signals.
sentations. We further stack a standard first- WesimplysetN to6,whiletheresultsaregen-
order non-projective graph-based parsing mod- erallynotsensitivetothishyper-parameter. Final
ule based on a biaffine scorer (Dozat and Man- task-specificpredictorsarefurtherstackedupon
ning, 2017). The marginals for each token’s thecorrespondingprivateencoders. Weadopta
headdecisioncanbefeasiblycalculatedbythe CRFlayerformentionextractionandapairwise
Matrix-Treealgorithm(Kooetal.,2007;Smith localpredictorwithabiaffinescorerforrelation
andSmith,2007;McDonaldandSatta,2007). orargumentextraction.
• QueryandSelection. Followingpreviousworks
• Sentenceselection. Foranunlabeledsentence,
(Flannery and Mori, 2015; Li et al., 2016), we
there is an uncertainty score for each sub-task.
viewDPARasahead-wordfindingproblemand
Formentions,theuncertaintyistheaveragemar-
regard each token and its head decision as the