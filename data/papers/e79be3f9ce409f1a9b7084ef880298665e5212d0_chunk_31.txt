ieZhou. Coin:
[30] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays, Alarge-scaledatasetforcomprehensiveinstructionalvideo
PietroPerona,DevaRamanan,PiotrDolla´r,andCLawrence analysis. InProceedingsoftheIEEEConferenceonCom-
Zitnick. Microsoft coco: Common objects in context. In puter Vision and Pattern Recognition, pages 1207–1216,
European conference on computer vision, pages 740–755. 2019. 1,2,5
Springer,2014. 2 [44] Makarand Tapaswi, Yukun Zhu, Rainer Stiefelhagen,
[31] Yang Liu, Samuel Albanie, Arsha Nagrani, and Andrew Antonio Torralba, Raquel Urtasun, and Sanja Fidler.
Zisserman. Use what you have: Video retrieval using Movieqa:Understandingstoriesinmoviesthroughquestion-
representations from collaborative experts. arXiv preprint answering. In Proceedings of the IEEE conference on
arXiv:1907.13487,2019. 2,5,7 computervisionandpatternrecognition,pages4631–4640,
2016. 1
[32] JiasenLu,DhruvBatra,DeviParikh,andStefanLee. ViL-
[45] Atousa Torabi, Niket Tandon, and Leonid Sigal. Learning
BERT:PretrainingTask-AgnosticVisiolinguisticRepresen-
tationsforVision-and-LanguageTasks. In11pages, 5fig- language-visual embedding for movie understanding with
ures,082019. 2 natural-language. arXiv preprint arXiv:1609.08124, 2016.
2
[33] Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan
[46] DuTran,HengWang,LorenzoTorresani,JamieRay,Yann
Duan, Tianrui Li, Xilin Chen, and Ming Zhou. Univilm:
LeCun,andManoharPaluri.Acloserlookatspatiotemporal
A unified