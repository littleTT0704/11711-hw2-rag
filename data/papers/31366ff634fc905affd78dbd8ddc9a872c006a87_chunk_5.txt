ated Code
maths qrt x
Reference Code Encode
x CodeBERTScore
x ** 0.5 Precision
CodeBERT
** CodeBERTScore
Generated Code Recall
math.sqrt(x) CodeBERT 0.5 CodeBERTScore
F-score
Figure2: AdiagramillustratingCodeBERTScore: Weusealanguage-specificCodeBERTmodeltoencodeeach
of⟨natural_language, reference_code⟩and⟨natural_language, generated_code⟩. Wethencomputethepairwise
cosine similarity between every encoded token in the reference and every encoded token in the generated code,
ignoringtheencodednaturallanguagecontexttokensandencodedpunctuationtokens; finally, wetakethemax
acrosstherowsoftheresultingmatrixtocomputePrecisionandacrosscolumnstocomputeRecall.
fortoken-matchingapproachessuchasBLEUand didates is more important than the absolute value
CrystalBLEU to compare the reference with the of f(yˆ,y∗). That is, ideally, if a prediction yˆ
1
candidates, while CodeBERTScore can trivially is more functionally equivalent to y∗ and more
match variable names according to their semantic preferable by human programmers over a predic-
similarityandtheirfunctionalroleinthecode. tionyˆ,wewishthatagoodmetricwouldrankyˆ
2 1
higherthanyˆ. Thatis,weseekanf functionsuch
2
Contributions In summary, our main contribu-
thatf(yˆ,y∗) > f(yˆ,y∗).
1 2
tions are: (a) CodeBERTScore: a self-supervised
metric for NL→Code evaluation, based on
BERTScore, which leverages the benefits of pre-
trained models, while not requiring labeling or 2.2 Background: BERTScore
manually annotated data. (b) An extensive em-
pirical evaluation across four programming lan- BERTScore (Zhang et al., 2020) was proposed as
guages, showing that CodeBERTScore is more a method for evaluating mainly machine transla-
correlated