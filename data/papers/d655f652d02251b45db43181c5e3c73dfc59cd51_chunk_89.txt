 dataset (Sections
befoundin7.
4.1 and E). Crowdworkers agree the data is high-quality
Arerelationshipsbetweeninstancesmadeexplicitinthe 91% of the time, and have trouble surfacing values, rights,
data? or duties that are missed, providing suggestions less than
There are no relationships between instances beyond the 1%ofthetime.Additionally,inanattempttounderstandif
factthateachsituationhasseveralseq2seqtasks,whichcan thedatasetalignsbestwithanydemographicgroups,were-
betriviallyreconstructed. cruit613crowdworkerstomarkpersonalagreementwiththe
data,anddonotfindsignificanttakeawaysforwhichgroups usingFlan-T5(Chungetal.2022).Wetake95%ofoursitu-
arerepresentedbestinthedata. ationsdeterminnisticallyfromthosethathavelesstoxic/NS-
FW/explicit content, and sample the other 5% uniformly
N.3 DataCollectionProcess from the rest of the data so as to include the entire spec-
How was the data collected? (e.g., hardware appara- trum of inputs. We find that this succeeds in increasing the
tus/sensor, manual human curation, software program, diversityofthedataset,asmeasuredbyuniquen-gramsdi-
softwareinterface/API;howweretheseconstructs/mea- vided by the length of the dataset (dist-2:.23→.36, dist-3:
sures/methodsvalidated?).54→.67).
The situations were provided by volunteer users of the
Isthereinformationmissingfromthedatasetandwhy?
Delphi user demo, and the candidate values, rights, duties
(thisdoesnotincludeintentionallydroppedinstances;it
andtheircorrespondingrelationsweregeneratedbyalarge
might include, e.g., redacted text, withheld documents)
languagemodel,GPT-4.
Isthisdatamissingbecauseitwasunavailable?
Who was involved in the data collection process? (e.g., No, there is no known data missing from the dataset, al-
students, crowdworkers) How were they compensated? though