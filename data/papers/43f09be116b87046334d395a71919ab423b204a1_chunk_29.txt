domaindata.Wevarytheamountofannotated
datawithrespecttothenumberofmentions.Whentransfer-
ure6fortransferbetweenOntoNotesgenreswith
ringON→i2b2(bottomrow), ourmodel(CL,MD )has
S T
an equivalent amount of annotated data (unequal thelargestimprovementoverthebaseline(CL,CL )with
S T
amountofannotatortime). verylittletrainingdataorannotatortime.Forthei2b2→CN
(toprow),however,theperformanceimprovementincreases
Forourtimedannotationexperimentdescribed
withmoreannotateddata.
in§3,wereportmoredetailedannotatoragreement
metricsforthetwoannotationtasksinTable6. We
expectthatagreementscoresforbothtasksarelow,
sincei2b2/VAdatasetishighlytechnical,andanno-
tatorshavenodomainexpertise. Theincreasedtask
complexityofcoreferenceresolutionmayfurther
worsenagreementforthetaskrelativetomention
detection. We do not use this annotated data be-
yondtimingannotationtasks.
B ReproducibilityDetails
ImplementationDetails Forallmodels,webe-
gan first with a pretrained SpanBERT (base) en-
Figure 6: Heatmap represents performance improvements
coder(Joshietal.,2020)andrandomlyinitialized
fromourmodelSpanBERT+high-precc2f(CL,MD )over
S T
parametersfortheremainingmentiondetectorand thebaselineSpanBERT+c2f(CL,CL )wheresingletons
S T
antecedentlinking. Weuse512formaximumseg- aredroppedfromthesystemoutput.Thebaselinehasaccessto
100%oftargetdomaincoreferenceexamples,andourmodel
mentlengthwithbatchsizeofonedocumentsim-
hasaccessto100%mentionannotations.
ilar to Lee et al. (2018). We first train the model
withacoreferenceobjectiveoverthesourcedomain
CL,andthenwetrainoverthetargetdomainwith domain mentions, our baseline model performed
S