SpringerBerlinHeidelberg. ISBN978-3-540-49195-8.
YaoFu,HaoPeng,LituOu,AshishSabharwal,andTusharKhot. Specializingsmallerlanguage
modelstowardsmulti-stepreasoning,2023.
HiroakiHayashi,YusukeOda,AlexandraBirch,IoannisKonstas,AndrewFinch,Minh-ThangLuong,
Graham Neubig, and Katsuhito Sudoh. Findings of the third workshop on neural generation
andtranslation. InProceedingsofthe3rdWorkshoponNeuralGenerationandTranslation,pp.
1–14,HongKong,November2019.AssociationforComputationalLinguistics. doi: 10.18653/v1/
D19-5601. URLhttps://aclanthology.org/D19-5601.
10
KennethHeafield,HiroakiHayashi,YusukeOda,IoannisKonstas,AndrewFinch,GrahamNeubig,
XianLi,andAlexandraBirch.Findingsofthefourthworkshoponneuralgenerationandtranslation.
InProceedingsoftheFourthWorkshoponNeuralGenerationandTranslation,pp.1–9,Online,
July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.ngt-1.1. URL
https://aclanthology.org/2020.ngt-1.1.
Peter Henderson, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan Jurafsky, and Joelle Pineau.
Towardsthesystematicreportingoftheenergyandcarbonfootprintsofmachinelearning. Journal
ofMachineLearningResearch,21(1),2020.
JungoKasai,HaoPeng,YizheZhang,DaniYogatama,GabrielIlharco,NikolaosPappas,YiMao,
WeizhuChen,andNoahA.Smith. FinetuningpretrainedtransformersintoRNNs. InProceedings
ofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pp.10630–10643,
OnlineandPunta