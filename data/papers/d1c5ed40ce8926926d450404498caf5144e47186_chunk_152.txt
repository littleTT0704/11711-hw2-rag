 often irrelevant despite containing a
surface form of the topic, and an additional relevance estimation step is required to
remove noise and reduce the pseudo-documents to a manageable size.
Relevance Estimation
We adapted the source expansion pipeline in Chapter 4 to apply the statistical rele-
vancemodeltocontentextractedfromalocalsource. Insteadofretrievingdocuments
about a given topic from an external source (step 1) and splitting the documents into
text nuggets (step 2), the previously generated pseudo-document for that topic is
fetched. The nuggets in the pseudo-document are then scored (step 3) and the most
relevant nuggets are merged into a new document (step 4), similarly to the search-
basedapproach. Lexicallyredundanttextisagainfilteredout, usingthetokenoverlap
with the seed and previously selected nuggets as a measure of redundancy. The statis-
tical model for estimating the relevance of text nuggets extracted from local sources
can be very similar to the model used to score nuggets from search results, with the
exception that search-related features are not available. For instance, our relevance
model for source expansion based on Yahoo! searches uses the retrieval rank of the
source document of a nugget and the overlap of the nugget with the abstract gen-
erated by the search engine for that document as features. In the experiments with
the local web crawl, we fitted a new model without these two features to the same
annotated dataset.
However, the relevance model should ideally be adapted to the characteristics
of the local source, and additional features that were previously not necessary or
unavailable may be included in the statistical model. For example, the ClueWeb09
corpus contains much more irrelevant information and low-quality text than the top
results returned by a web search engine. To better recognize and avoid this noise, pre-
computed spam probabilities, page ranks or readability estimates for the documents
in the crawl could be leveraged as features. If different surface forms of a topic are
used when extracting text nuggets that mention it from a corpus, we can also give
less weight to nuggets that contain a more generic and possibly ambiguous variant.
This could be accomplished by including a feature that is based on the idf score of
the surface form that appears in a nugget. In Section 8.1 we demonstrate that