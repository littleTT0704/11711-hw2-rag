Selection
5 In-contextLearningforMathematical
Early chain-of-thought work randomly or heuris-
Reasoning
tically selects in-context examples. However, re-
Large language models (LLMs), such as GPT- centstudieshaveshownthatthistypeoffew-shot
3(Brownetal.,2020),haverecentlyrevolutionized learning can be highly unstable across different
thefieldofnaturallanguageprocessing(NLP),es- selections of in-context examples (Rubin et al.,
peciallyonaccountoftheirpowerfulfew-shotin- 2022; Liu et al., 2022a). Therefore, which in-
contextlearningcapabilities(Brownetal.,2020). contextreasoningexamplesmakethemosteffec-
In-context Learning (ICL) enables LLMs to per- tive prompts is still an unknown problem in the
formtargettasksbyprovidingsometaskexamples literature. To address the limitation, recent work
asconditionsatinferencetime,withoutupdating has investigated various methods to optimize the
model parameters (Radford et al., 2020; Brown in-contextexamplesselectionprocess(Rubinetal.,
et al., 2020). ICL allows users to quickly build 2022;Zhangetal.,2023;Luetal.,2022b;Yuetal.,
modelsfornewusecaseswithoutworryingabout 2023; Fu et al., 2023). For example, Rubin et al.
fine-tuningandstoringalargeamountofnewpa- (2022) attempt to address this issue by retrieving
rametersforeachtask,soitiswidelyusedinfew- semantically similar examples. In addition, Fu
shotsettingsnowadays(Minetal.,2022). etal.(2023)proposecomplexity-basedprompting,
An in-context example typically contains an whichchoosesexampleswithcomplexreasoning
input-output pair with some prompt words, e.g., chains, i.e., chains with more reasoning steps, as
Pleaseselectthelargestnumberfromthelist. In- theprompt. PromptPG(Luetal.,2022b)learnsto
put: [2,4,1,5,8]. Output: 8,andfew-shotworks select optimal in-context examples via