both 52.4 71.0 -
Accuratelylabelingastepasunlinkableisnon-
+unlinkable 50.4 71.6 -
trivial–itrequiresexaminingwhetherthestepcan +λ=0 51.9 71.4 -
be linked to any goal in G. Instead, we train the
Table1: Therecall@nfordifferentmodelsonthetest
model to perform this classification by assigning
set. Thetophalfarewithparaphraseretrievalonlyand
unlinkable to steps that have a ground-truth
the bottom half are with taking the top-30 candidate
goalbutthisgoaldoesnotappearinthetop-k can-
goalsgeneratedbythebestmodel(SP)andaddingthe
didategoallist. ThelossfollowsEquation2. rerankingmodel. Thebestperformancerecallisbold.
“surr”denotesthesurroundingstepsofthequerystep.5
4 AutomaticStepPredictionEvaluation
To train our models and evaluate how well our Reranking Weselectthetop-30candidategoals
hierarchydiscoverymodelcanlinkstepstogoals, predicted by the SP model as the input to the
weleverageexistingannotatedstep-goallinks. reranking stage. The recall@30 of the SP model
is 72.5%, which bounds the performance of any
4.1 LabeledStep-goalConstruction
reranker.6 As seen in the bottom half of Ta-
InwikiHow,therearearound21kstepsthatalready ble 1, reranking is highly effective, as the best
haveahyperlinkredirectingittoanotherwikiHow configuration brings a 19.6% improvement on
article, populated by editors. We treat the title recall@1, and the recall@10 almost reaches the
of the linked article as the ground-truth goal for upperboundofthisstage. Wefindthatunderthe
the step. For example, as in B5 of Figure 1, the sameconfiguration,DEBERTA-largefinetunedon
ground-truth goal of the step Create a channel is MNLI(Heetal.,2020)outperformsBERTby1.7%
Make a Youtube Channel. We build the training, on recall@1, matching the reported trends from
