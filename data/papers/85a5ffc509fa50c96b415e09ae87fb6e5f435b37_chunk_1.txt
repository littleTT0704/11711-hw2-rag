BIASX: “Thinking Slow” in Toxic Content Moderation
with Explanations of Implied Social Biases
Warning:contentinthispapermaybeupsettingoroffensive.
YimingZhang♢ SravaniNanduri♠ LiweiJiang♠ TongshuangWu♡ MaartenSap♡
♢UniversityofChicago ♠UniversityofWashington ♡CarnegieMellonUniversity
yimingz0@uchicago.edu, maartensap@cmu.edu
Abstract
No, can you get one of the boys to carry that out?
It’s too heavy for you.
Toxicityannotatorsandcontentmoderatorsof-
ten default to mental shortcuts when making
"Thinking fast" Targeted group: women
decisions.Thiscanleadtosubtletoxicitybeing
- no explanations Implies women are physically weak
missed,andseeminglytoxicbutharmlesscon-
tentbeingover-detected. WeintroduceBIASX, : Allow ❌ "Thinking slow" (BiasX) : Moderate
a framework that enhances content modera-
tionsetupswithfree-textexplanationsofstate- Figure1: Tocombat“thinkingfast”inonlinecontent
ments’impliedsocialbiases,andexploreitsef- moderation,weproposetheBIASXframeworktohelp
fectivenessthroughalarge-scalecrowdsourced moderatorsthinkthroughthebiasedorprejudicedim-
userstudy. Weshowthatindeed,participants plicationsofstatementswithfree-textexplanations,in
substantiallybenefitfromexplanationsforcor- contrasttomostexistingmoderationparadigmswhich
rectly identifying subtly (non-)toxic content. providelittletonoexplanations.
Thequalityofexplanationsiscritical: imper-
fect machine-generated explanations (+2.4% sionmakingwithfree-textexplanationsofapoten-
on hard toxic examples) help less compared tiallytoxicstatement’stargetedgroupandsubtle
toexpert-writtenhumanexplanations(+7.2%). biased or prejudiced implication (Figure 1). In-
Ourresultsshowcasethepromise