Generateoneanswerperquestionandusethis
(Lourie et al., 2021), which is the current SOTA, tomeasuretheperformanceofthefew-shotGPT-3
followingthesetupinTalmoretal.(2021). inference model; (2) Generate M = 20 answers
QASC (Khot et al., 2020) is an 8-way multiple- perquestion,andusetheseanswerstopromptthe
choiceQAdatasetaboutgradeschoolscience. This SOTAinferencemodels.
dataset also includes two pieces of background
4 ExperimentalResults
knowledgeperquestion,whosecompositionfully
answersthequestion. Wedoinferencewithzero- Aswewillshow,ourgeneratedknowledgeprompt-
shot T5 and finetuned T5 (including UnifiedQA ingmethodsetsnewstate-of-the-artresultsonmost
whichisSOTA),usingthesamesetupsasCSQA. datasetsweevaluateon,andworkswellunderboth
zero-shotandfinetunedsettings. Inparticular,our
3.2 KnowledgeGenerationBaselines
knowledgegenerationoutperformsnaivebaselines
Westudytheimpactofourknowledgegeneration as well as template-based knowledge generation,
method(shorthandedasK)bycomparingwiththe andison-parwithretrieval-basedsystems.
followingbaselines:
Noknowledge(âˆ…) Werefertoinferencewithout 4.1 OverallPerformance
anyknowledgestatementsasthevanillabaseline. Table3showstheresultsonzero-shotandfinetuned
Random sentences (R) Sampling random sen- modelsfollowingourtasksetups.
tencesfromthelanguagemodelwithoutcondition- New state-of-the-art. We apply our method on
ingonthequestion. Weusethesameimplementa- topofthesameinferencemodelusedintheprevi-
tionsetupasourknowledgegenerationmethod(i.e. ousstate-of-the-art. OnNumerSense,weachievea
3157
A B B C D D
1 2 1 2
Dataset NumerSense CSQA CSQA CSQA2 QASC QASC
InferenceModel T5-11b T5-11b UQ