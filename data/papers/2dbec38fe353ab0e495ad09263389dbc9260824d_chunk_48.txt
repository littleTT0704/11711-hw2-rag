ad Rubin, Jonathan Herzig, and Jonathan Berant.
2022. Learning to retrieve prompts for in-context
Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie learning. NorthAmericanChapteroftheAssociation
Millican, Jordan Hoffmann, Francis Song, John forComputationalLinguistics(NAACL).
Aslanides, Sarah Henderson, Roman Ring, Susan-
nah Young, et al. 2021. Scaling language models: MrinmayaSachan,KumarDubey,andEricXing.2017.
Methods,analysis&insightsfromtraininggopher. Fromtextbookstoknowledge: Acasestudyinhar-
arXivpreprintarXiv:2112.11446. vestingaxiomaticknowledgefromtextbookstosolve
geometry problems. In Proceedings of Empirical
ColinRaffel,NoamShazeer,AdamRoberts,Katherine MethodsinNaturalLanguageProcessing(EMNLP),
Lee,SharanNarang,MichaelMatena,YanqiZhou, pages773–784.
Wei Li, and Peter J Liu. 2020. Exploring the lim-
its of transfer learning with a unified text-to-text Mrinmaya Sachan and Eric Xing. 2017. Learning
transformer. JournalofMachineLearningResearch tosolvegeometryproblemsfromnaturallanguage
(JMLR),21:1–67. demonstrationsintextbooks. InProceedingsofthe
6thJointConferenceonLexicalandComputational
AbhilashaRavichander,AakankshaNaik,CarolynRose, Semantics,pages251–261.
andEduardHovy.2019. Equate:Abenchmarkevalu-
ationframeworkforquantitativereasoninginnatural David Saxton, Edward Grefenstette, Felix Hill, and
languageinference. InProceedingsofthe23rdCon- PushmeetKohli.2020. Analysingmathematicalrea-
ferenceonComputationalNaturalLanguageLearn- soningabilitiesof neuralmodels. In International
ing(CoNLL),pages349–361. ConferenceonLearningRepresentations(ICLR).
YasamanRazeghi, RobertLLoganIV,MattGardner, Tal Schuster, Ashwin K