 task. For
example, (Deng et al., 2022) used both supervised data instances and task reward to learn the target prompt-
generation models.
Figure 6 Left: prompt as the learnable component θ to steer pretrained models (such as GPT-
3) to perform the downstream task of interest (e.g., generating a story of a certain topic).
Right: The novel learned knowledge tuples by treating the symbolic knowledge graph as the
target model.
Symbolic knowledge graphs. The target model can even be a symbolic system such as a knowledge graph
(KG) or a rule set. Here θ denotes the KG structure to be learned, and p θ(t) can be seen as a distribution
assigning a (non-)uniform nonzero probability to any knowledge tuple t in the KG and zero to all other tuples.
(Hao et al., 2022) presents a concrete instance of the learning system that incrementally learns (extracts) a
commonsense relational KG (Figure 6, right), using the pretrained language models such as BERT (Devlin et
al., 2019) as the experience.
Probabilistic graphical models and composite models. The target model p θ(t) can also be probabilistic
graphical models (Jordan, 2003; Koller & Friedman, 2009), a rich family of models characterizing the
conditional dependence structure between random variables with a directed/undirected graph (Figure 5, right).
Graphical models may also be composed with the neural modules to form more complex composite models,
typically with the neural modules extracting features from the raw inputs and the graphical modules capturing
the high-level structures (Johnson et al., 2016; Wilson et al., 2016a; Zheng et al., 2015). As discussed in the
earlier sections, the common learning and inference approaches for probabilistic graphic models, such as the
(variational) EM algorithm, are special instances of SE and its teacher-student mechanism. The SE framework
offers a generalized formulation for learning graphical and composite models.
9. Panoramic Learning with All Experience
The preceding sections have presented a standardized formalism of machine learning, on the basis of the
standard equation of objective function, that provides a succinct, structured formulation of a broad design
42
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model'