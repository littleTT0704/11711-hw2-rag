ructure,itsgoals,andthecasestudies.
Background(20min) Ahigh-speedrecapofes- terminewhetheracaptionistrueorfalseabouta
tablishedcrowdsourcingconceptsandterms. We paired image. The data was collected to require
referbacktothecontentofthissectioninthecase reasoningaboutobjectquantities,comparisonsbe-
studies. This section includes the basic structure tween object properties, and spatial relations be-
of a Mechanical Turk task (HIT), typical incen- tweenobjects. NLVR2isusedasevaluationdata
tive mechanisms, typical communication mecha- for numerous language-and-vision systems (e.g.,
nisms,typicalworkerqualificationandscreening Tan and Bansal, 2019; Chen et al., 2019c). Both
mechanisms,aswellasrelevantresultsaboutthe datasetswerecrowdsourcedwithacontrastivecap-
demographicsandexpressedpreferencesofcrowd- tioning designed to elicit linguistically complex
workersandthecrowdworkercommunity. sentencesandtonaturallybalancethedatasetsbe-
tweentrueandfalseexamples. NLVR2alsouses
Case Study I: MultiNLI (45 min) We discuss
a tiered system during crowdsourcing including
theMultiNLI(Williamsetal.,2018)corpus,with
distinctpoolsofannotationtasksforexperienced
primaryfocusonexperimentsfromsubsequentpa-
workersandnewworkers.
persthatextendorevaluatethedatacollectionpro-
tocolusedtocreatethisdataset. MultiNLIisbuilt Case Study III: CerealBar (25 min) Cereal-
aroundthetaskofnaturallanguageinference(a.k.a. Bar (Suhr et al., 2019a) is a game designed for
textualentailment;Daganetal.,2006;MacCartney, studying collaborative natural language interac-
2009): giventwosentences,thetaskistoidentify tions,releasedalongsideadatasetofinteractions
(roughly)whetherthefirstsentenceentailsthesec- between human players.2 CerealBar emphasizes
ond. Westartwiththiscasestudynot