. 30; 6000–6010. Curran Associates Inc.
https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
↩
Wainwright, M. J., & Jordan, M. I. (2006). A variational principle for graphical models. In S. Haykin, J. C.
Principe, T. J. Sejnowski, & J. McWhirter (Eds.), New directions in statistical signal processing (pp. 155–
201). https://doi.org/10.7551/mitpress/4977.003.0009
↩
Wainwright, M. J., & Jordan, M. I. (2008). Graphical models, exponential families, and variational
inference. Foundations and Trends in Machine Learning, 1(1–3), 1–305. http://doi.org/10.1561/2200000001
↩
Welling, M., & Teh, Y. W. (2011). Bayesian learning via stochastic gradient Langevin dynamics. In L.
Getoor & T. Scheffer (Eds.), Proceedings of the 28th International Conference on Machine Learning (pp.
681–688). https://icml.cc/2011/papers/398_icmlpaper.pdf
71
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
↩
Wilson, A. G., Hu, Z., Salakhutdinov, R. R., & Xing, E. P. (2016a). Deep kernel learning. In A. Gretton & C.
C. Robert (Eds.), Proceedings of the 19th International Conference on Artificial Intelligence and Statistics
(Vol. 51; 370–378). https://proceedings.mlr.press/v51/wilson16.html
↩
Wilson, A. G., Hu, Z., Salakhutdinov, R. R., & Xing, E. P. (2016b). Stochastic variational deep kernel
learning. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, & R. Garnett (Eds.), Proceedings of the 30th