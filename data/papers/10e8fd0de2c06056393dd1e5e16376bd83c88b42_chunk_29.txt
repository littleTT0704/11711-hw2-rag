, Robin Jia, Minjoon Seo, of the Association for Computational Linguistics,
Eunsol Choi, and Danqi Chen. 2019. Mrqa 2019 7:453–466.
shared task: Evaluating generalization in reading
comprehension. arXivpreprintarXiv:1910.09753. KentonLee,Ming-WeiChang,andKristinaToutanova.
2019. Latent retrieval for weakly supervised
KartikGoyal,ChrisDyer,andTaylorBerg-Kirkpatrick. open domain question answering. arXiv preprint
2019. Anempiricalinvestigationofglobalandlocal arXiv:1906.00300.
Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Sandeep Subramanian, Tong Wang, Xingdi Yuan,
Ryan McDonald. 2020. Zero-shot neural passage Saizheng Zhang, Yoshua Bengio, and Adam
retrievalviadomain-targetedsyntheticquestiongen- Trischler. 2017. Neural models for key phrase de-
eration. arXivpreprintarXiv:2004.14503. tection and question generation. arXiv preprint
arXiv:1706.04560.
FabioPetroni, AleksandraPiktus, AngelaFan, Patrick
Lewis, Majid Yazdani, Nicola De Cao, James Simon Šuster and Walter Daelemans. 2018. Clicr: A
Thorne, Yacine Jernite, Vladimir Karpukhin, Jean dataset of clinical case reports for machine reading
Maillard, et al. 2020. Kilt: a benchmark for comprehension. arXivpreprintarXiv:1803.09720.
knowledgeintensivelanguagetasks. arXivpreprint
arXiv:2009.02252. Wilson L Taylor. 1953. “cloze procedure”: A new
toolformeasuringreadability. Journalismquarterly,
JulianoRabelo,RandyGoebel,Mi-YoungKim,Yoshi- 30(4):415–433.
nobu Kano, Masaharu Yoshioka, and Ken Satoh.
Nandan Thakur, Nils Reimers, Andreas Rücklé, Ab-