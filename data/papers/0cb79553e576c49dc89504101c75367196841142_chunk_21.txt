softhe59thAnnualMeet-
base and licensed under the Apache License 2.0,
ingoftheAssociationforComputationalLinguistics
andthe11thInternationalJointConferenceonNatu- with the non-toxic and toxic corpus respectively.
ralLanguageProcessing(Volume1: LongPapers), Weusethesamepretrainingprocedureusedtofur-
pages1667–1682,Online.AssociationforComputa-
ther fintune BART (Lewis et al., 2020), and ran-
tionalLinguistics.
domly corrupt sequences during training, which
alignswithBART’sintendeduse.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond,ClementDelangue,AnthonyMoi,Pier-
ricCistac,TimRault,RemiLouf,MorganFuntow- TrainingCorpus WeusetheJigsawUnintended
icz,JoeDavison,SamShleifer,PatrickvonPlaten, BiasinToxicityClassification(Do,2019)dataset
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, forfinetuningourexpertandantiexpert,acorpusof
Teven Le Scao, Sylvain Gugger, Mariama Drame,
forumcommentsonnewsarticles. Eachcomment
QuentinLhoest,andAlexanderRush.2020. Trans-
hasfivebinaryannotationsonifitistoxicornot.
formers:State-of-the-artnaturallanguageprocessing.
InProceedingsofthe2020ConferenceonEmpirical Wemarkallsequenceswithnotoxicannotationsas
Methods in Natural Language Processing: System non-toxic,andallsequenceswithmorethan50%
Demonstrations,pages38–45,Online.Association
toxic annotations as toxic. The intended use of
forComputationalLinguistics.
thisdatasetistohelpminimizeunintendedmodel
XingWu,TaoZhang,LiangjunZang,JizhongHan,and bias, which we follow in this work. Finally, we
SonglinHu.2019. Maskandinfill:Applyingmasked sample100instancesfromthevalidationset