 of the
zsRE SGD 1e-1 10
Wikidata5m SGD 1e-1 10 claims are true and half are false. When training
thelearnedoptimizer,wetreatthethefactsasthe
Table12: Finalhyperparametersofthebaselineupdate
Main Input when training the learned optimizer
methodforeachtask.
and claims as entailed data. When training the
True/Falseclassifier,wefittotheclaims,forwhich
sameaswithlearnedoptimizers,arawaverageof
test accuracy is 83.65 ( 1.05). This seems to
UpdateSuccessRate(averagedovereachkindof ±
generalizewelltothefacts,astestaccuracyhereis
data),RetainRate(LocalNeutral)and∆-Acc. The
93.66( 0.87),althoughasthelowcontrapositive
gridsearchisoverthefollowingparameters: The ±
accuracysuggests(Table3),themodelseemstobe
off-the-shelfoptimizersarefromtorch.optim
toopronetopredictingtrueforthisdata.
andinclude{AdamW,SGD,andRMSProp}with
SinceveryfewoftheMainInputsarepredicted
default arguments (except for the learning rate).
as false, we run into a small dilemma when fit-
We consider a number of maximum steps in {5,
ting the learned optimizer with the use of the en-
10, 100}. The learning rates we consider depend
taileddataobjectiveterm. Theentailmentbetween
ontheoptimizer: {1e-4,1e-5,1e-6}forAdamW,
factandclaimonlyholdswhenthefactistrue,so
{1e-4,1e-5,1e-6}forRMSProp,and{1e-1,1e-2,
we can only compute the objective when updat-
1e-3} for SGD. The LR ranges were selected af-
ingapointfromfalsetotrue. Thisendsupbeing
ter some initial manual exploration of the space.
lessthan10%ofthetrainingdata. Weultimately
OurfinalhyperparametervaluesareshowninTa-
choose