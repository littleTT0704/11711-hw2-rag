, it is also possible to incrementally run
test
predictiont,whichcontainsboththeintermediatesteps thePLsegmentsandfeedtheexecutionresultsbacktothe
test
andtheircorrespondingprogrammaticstatements. LLMtogeneratethefollowingblocks. Forsimplicity, in
ourexperiments,weusedasingle,post-hoc,execution.
This work focuses on COT-style reasoning chain, but in
A: Roger started with 5 tennis balls.
Appendix I we show that PAL also improves Least-to-
tennis_balls = 5
Most (Zhou et al., 2022) prompts, which introduce rea-
2 cans of 3 tennis balls each is
soningchainsthatdecomposeaquestionintosub-questions.
bought_balls = 2 * 3
tennis balls. The answer is
4.ExperimentalSetup
answer = tennis_balls + bought_balls
Dataandin-contextexamples Weexperimentwiththree
broad classes of reasoning tasks: (1) mathematical prob-
Figure 2: A close-up of a single example from lems (ยง4.1) from a wide range of datasets including
a PAL prompt. Chain-of-thought reasoning is GSM8K (Cobbe et al., 2021), SVAMP (Patel et al., 2021),
highlightedinblue, and PAL programmatic steps ASDIV(Miaoetal.,2020),andMAWPS(Koncel-Kedziorski
are highlighted in gray and pink. etal.,2016);(2)symbolicreasoning(ยง4.2)fromBIG-Bench
Hard(Suzgunetal.,2022);(3)andalgorithmicproblems
(ยง4.3)fromBIG-BenchHardaswell. Detailsofalldatasets
Example A close-up of the example from Figure 1 is areshowninAppendixH. Foralloftheexperimentsfor
shown in Figure 2. While chain-of-thought only de- which COT prompts were available, we use the same in-
composes the solution in the prompt into natural lan- contextexamplesasusedbypreviouswork. Otherwise,we
guage steps such as Rogerstartedwith5tennisballs and randomlysampledafixedset