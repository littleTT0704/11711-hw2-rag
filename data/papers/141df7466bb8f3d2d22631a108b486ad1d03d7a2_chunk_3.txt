ulatedandareal-worldenvironment.
InHomeRobot,weprovidebothachallengingsimulated“northstar”task,whereinamobilemanipulatorrobotmustfindand
graspmultipleseenandunseenobjects,andacorrespondingreal-worldroboticsstacktoallowotherstoreproducethisresearch
andevaluationtoproduceusefulhomerobotassistants.
bylanguage.Webelievethisisastrong“buildingblock”for basis for shared, mobile manipulation research in human
futurecapabilities,andcanbeimplementedinmanydiffer- homeenvironments.
entways:usingmotionplanningandsimpleheuristicsoran
LLM-basedplannertodeterminegoals,asperSayCan/Say- Open-VocabularyMobileManipulation
Plan (Ahn et al. 2022; Rana et al. 2023), built on a task-
OurHomeRobotcodeisreleasedwithmodulesforOpenVo-
and-motion-planningstack(Garrettetal.2020;Curtisetal.
cabularyMobileManipulation(OVMM)(Yenamandraetal.
2022),reinforcementlearning(Yenamandraetal.2023b),or
2023b), where a robot must find any object and place it in
usingimplicitrepresentationsandpretrainedmodels(Bolte
any location in an ordinary home. We chose this task be-
etal.2023).Havingacommontaskwhichdoesnotpreclude
cause it represents a foundational capability for robots to
any of these options allows us to share useful components
be useful assistants: they must perceive a wide variety of
acrossprojects(e.g.detection,mapping,andgrasping).
objects, grasp and manipulate them, and understand large,
Our proposal and software stack are based around the
complexscenesthatmaynotbewellmappedtobeginwith.
Hello Robot Stretch, a low-cost mobile manipulation plat-
Formally, the HomeRobot OVMM task is set up as
form already in use at over 40 universities. By leveraging
instructions of the form: “Move (object) from the
existing and accessible infrastructure increases the odds of
(start recept