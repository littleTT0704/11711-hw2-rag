.ThefirsttermistheGAN
loss that jointly approximates conditional and unconditional distributions [45].
At the ith stage, the generator G has a corresponding discriminator D. The
i i
adversarial loss for G is defined as:
i
L =−1 E (cid:2) log(D (yˆ))(cid:3) −1 E (cid:2) log(D (yˆ,s))(cid:3), (2)
Gi 2 yˆi∼PGi i i 2 yˆi∼PGi i i
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
unconditionalloss conditionalloss
Title Suppressed Due to Excessive Length 5
Fig.2. The architecture of the proposed CAGAN with word, SE, and local attention.
Whenomittinglocalattention,localattentionisremovedfromtheFattn networks.In
n
the upsampling blocks it is replaced by SE attention.
where yˆ are the generated images. The unconditional loss determines whether
i
theimageisrealorfakewhiletheconditionallossdetermineswhethertheimage
andthesentencematchornot.AlternatelytothetrainingofG,eachdiscrimina-
i
torD istrainedtoclassifytheinputintotheclassofrealorfakebyminimizing
i
the cross-entropy loss.
Thesecond termofEquation1, L,is afine-grainedword-level image-
DAMSM
text matching loss computed by the DAMSM [42]. The DAMSM learns two
neural networks that map subregions of the image and words of the sentence to
acommonsemanticspace,thusmeasuringtheimage-textsimilarityattheword
level to compute a fine-grained loss for image generation. The image encoder
prior to the DAMSM is built upon a pretrained Inception-v3 model [36] with
added perceptron layers to extract visual feature vectors for each subregion of
the image and a global image vector.
3.2 Attention models
Local self-attention Similartoaconv