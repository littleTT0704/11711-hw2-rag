reviews. ative and positive prompts adversarial settings,
ForeaseofnotationweconsiderthepositiveLM wherethetaskistosteertowardtheoppositesenti-
our expert and negative LM our anti-expert, and mentoftheprompt.
useα “ ˘3.2forsteeringineachdirection. The
tradeoffbetweenfluencyandsentimentcontrolfor 4.2.2 Baselines
manyvaluesofαisshownin§4.3.
Weconsiderthesamebaselinesasin§3,alongwith
anewbaseline(CTRL;Keskaretal.,2019).
4.2 Evaluation
4.2.1 GenerationPrompts
DAPT CorrespondingtoourDAPTbaselinein
Inordertotestourmethod’sabilitytocontrolsen- §3,wescorealldocumentsinOpenWebTextwith
timent beyond the domain that the sentiment ex- theHuggingFacesentimentclassifier,andkeepthe
pertsaretrainedon(moviereviews),wecollecta mostpositive2%andmostnegative2%(according
datasetof100Knaturallyoccurringpromptsfrom totheprobabilityofthepredictedlabel)toobtain
theOpenWebTextCorpus(OWT)(Gokaslanand thepositiveandnegativecorpora. Weperforman-
Cohen,2019). DetailsareoutlinedinAppendixB. otherroundofpretrainingoneachcorpustoobtain
Wegenerate25continuationsforeachpromptfrom apositiveLMandnegativeLM.
PPLM Aswithtoxicity§3,weretrainthesenti- data is limited to the domain of that data; train-
mentclassifierforPPLMwithalargerembedding ing on Amazon reviews does not allow general-
sizecompatiblewithourbasemodel. Thetraining ization outside of the reviews domain. In a sim-
datausedisSST-5. Again,weevaluatePPLMon ilar vein, while the positive and negative experts
only10%ofthepromptscomparedtoothermodels, achievedecentperformance(evenperformingthe
whicharerandomlyselected: 500neutralprompts, bestonnegativeprompts),theydosoatt