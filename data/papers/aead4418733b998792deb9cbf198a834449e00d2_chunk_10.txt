 ds e( lk h2x as) n= otpk k e1 2 rs fein c( tlk y2 lx e) a) r. nT edhe thf eai rl eu qr ue irr ea dte ds ivh io sw ios nt bh ea -t X trig 13c− o3 s3 19x 132 cox s42 83+ x6 −8 59 −7 11 0+ sin3 46 7/ xx c+ os2 2/ xx71
13cos83x 17cos37x−49 10sin90xcos2x
havior.Moreover,despitelearninga‘divisionby2’rulefor
17cos47x 17cos41x−45 19sin90xcos2x
integratingk x,theneuralsequenceintegrator’sfailureson
1
k x42 indicate that it did not perfectly learn an analogous
1 Table 4: Example robustness problems discovered by
‘divisionby43’rule.Table3showsexamples.
SAGGA which the neural sequence integrator fails to inte-
Testaccuracydoesnotimplyrobustness. Next,wewant grate.
to see whether the neural sequence integrator’s strong test
accuracy implies that it is robust on test problems. We use
the validation set, and perturb validation problems that the x Raw Simplified Deriv.
modelcorrectlyintegratesusingtheneighborhoods, −104 x2+2x−(x+25)2 −48x−625 −48
−136 x2−x(x+130)+2x −128x −128
1
X N1 ={ kf, k·f}, X N2 ={f +ex, f +ln(x)}, −33 x2+x−(x+16)2 −31x−256 −31
where k ∼ U(1,100). The first set multiplies the function Table5:Therawmodelpredictionsfortheproblemsxand
byaconstant,whilethesecondaddsasingleprimitive. theirsimplifiedforms.Eachpredictionisincorrectsinceits
Table2showstheresults.Despiteachievingperfectaccu- derivativeisnotequaltox.Theneuralsequenceintegrator’s
racy