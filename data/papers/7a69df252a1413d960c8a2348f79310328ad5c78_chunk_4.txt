�s direct approach developing
StackGAN[44]generating256x256photo-realisticimagesfromdetailedtextde-
scriptions. Although StackGAN yields remarkable results on specific domains,
such as birds or flowers, it struggles when many objects and relationships are
involved.Zhangetal.[45]improvedStackGANbyarrangingmultiplegenerators
and discriminators in a tree-like structure, allowing for more stable training be-
haviourbyjointlyapproximatingmultipledistributions.Xuetal.[42]introduced
a novel loss function and fine-grained word attention into the model.
Recently,anumberofworksbuiltonXuetal.’s[42]approach:Chengetal.[4]
employed spectral normalisation [23] and added global self-attention to the first
generator;Qiaoetal.[29]introducedasemantictextregenerationandalignment
moduletherebylearningtext-to-imagegenerationbyredescription; Lietal.[17]
added channel-wise attention to Xu et al.’s spatial word attention to generate
shape-invariant images when changing text descriptions; Cai et al. [3] enhanced
localdetailsandglobalstructuresbyattendingtorelatedfeaturesfromrelevant
words and different visual regions; Yin et al. [43] focused on disentangling the
semantic-related concepts and introduced a contrasive loss to strengthen the
image-text correlation; and Zhu et al. [46] refined Xu et al.’s fine-grained word
attention by dynamically selecting important words based on the content of an
initial image.
Instead of using multiple stages or multiple GANs, Li et al. [19] used one
generator and three independent discriminators to generate multi-scale images
conditioned on text in an adversarial manner. Johnson et al. [13] introduced a
GAN that receives a scene graph consisting of objects and their relationships as
input and generates complex images with many recognizable objects. However,
4 H. Schulze et al.
the images are not photo-realistic. Qiao et al. [28] introduced LeicaGAN which
adopts text-visual co-embeddings to convey the visual information needed for
image generation.
Otherapproachesarebasedonautoencoders