 (Freitag
to produce a score, as the MQM framework pro-
et al., 2022): en→de, zh→en, and en→ru. The
videsanalgorithmicproceduretoobtainonefrom
ground-truthtranslationqualityscoresarederived
identifiederrors: thetotalscoreisthesumofpenal-
from MQM ratings in which expert annotators
tiesforallerrorsidentified,where(roughly)major
markederrorspansinthetranslationswithdifferent
errorsgetpenalizedwith−5andminorswith−1
severitylevelswhichareautomaticallyconverted
(seeAppendixAforamoredetaileddescriptionof
toanumericscore(see§2). Thefourlow-resource
thescoringalgorithm).3 Figure3showsthemain
language pairs come from the WMT’19 Metrics
AUTOMQM promptusedinthispaper.
SharedTask(Maetal.,2019): en↔guanden↔kk.
Importantly,obtainingmeaningfulAUTOMQM
SinceMQMratingsarenotavailableforthelow-
resultsinazero-shotsettingisasubstantiallymore
resourcepairs,thegroundtruthqualityscoresare
challengingtaskcomparedtoscoreprediction: we
directassessment(DA)scores. DAscoresarequal-
foundthat,withoutanyin-contextexamples,LLMs
ityassessmentsassignedbynon-expertratersona
tendtoproduceoutputsthatareeitheruninforma-
scalefrom0-100,thennormalizedperrater. SeeTa-
3Thisissimilartomethodsthatleverageexternalexecutors ble1forstatisticsaboutthenumberofMTsystems
toimprovetheperformanceofLLMs(Gaoetal.,2022) andsegmentsforeverylanguagepair.
Additionally,inourexperiments, AUTOMQM unabletoobtainthespan-levelpredictionsforthe
required in-context examples with MQM anno- MATESEsubmission,wealsocompareagainstthe
tations to work, so we restrict our evaluation of topsubmissiontotheWMT’22Word-LevelQual