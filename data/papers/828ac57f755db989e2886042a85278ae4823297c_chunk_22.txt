e9b%etter 79.775%3 69.9%
700 Resultsofourmodelonpastandfuturemodelingare resultforfuturepredictionthanpastinferring.Wegiveour 754
andasmultiple-choiceque70s1tionsh-oawnnsownTeabrlien5g.Itisshorwesqouuriernecdodetroissceap-ableofrea- hypothesisherebutesxpplloitre1inthe7fu2tu.4re%.Forfut4u7re.0pr%edic- 75.975%5 47.1%
MPII-MD split2 72.0% 47.0% 73.3% 48.8%
lectananswerfromcandidatesattestingtime,rankingloss
7 split3 72.0% 46.9% 71.7% 48.1%
ismoresuitableformodelingtheproblem.
Evaluation of dual-channel learning. We then show the Table4.ResultsofourGRUmodelsoninferringpastandpredict-
effectiveness of using two channels for learning. The re- ingthefuture.
sult of how integrating two representations influences the
performanceisshowninFigure6. Aswecansee,itisben-
sametransformationlayerandsamehyper-parametersdur-
eficialtointegratewordrepresentationsduringtraining,and
ingtraining. ThisresultisshowninTable5. Detailedanal-
sentencesareweightedmorethanwords. Itisbecauseour
ysiswillbediscussedinnextSection.
visualfeaturesrepresentmoreofglobalabstraction,which
iscorrespondingtothesentencerepresentation, whilespe-
5.2.EvaluationofInferringthePastandPredicting
cific object features corresponding to the word representa-
Future
tionhavenâ€™tbeenconsideredinthiswork. Wewillexplore
thisdirectionindetailsinthefutureworks. WefirstshowtheresultsofourGRUmodelsinalltasks.
Comparison between our GRU model and ConvNet The results of describing the present is in Table 3, while
model. To show the effectiveness of our encoder-decoder results of inferring the past and predicting the future are
approachinmodelingthepresent,wecompare