 and S.
Vishwanathan and R. Garnett (Eds.), Proceedings of the 31st International Conference on Neural
Information Processing Systems (Vol. 30; 6833–6844). Curran Associates Inc.
https://papers.nips.cc/paper/2017/file/2d2c8394e31101a261abf1784302bf75-Paper.pdf
↩
Singh, S., Lewis, R. L., Barto, A. G., & Sorg, J. (2010). Intrinsically motivated reinforcement learning: An
evolutionary perspective. IEEE Transactions on Autonomous Mental Development, 2(2), 70–82.
https://doi.org/10.1109/TAMD.2010.2051031
↩
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-based
generative modeling through stochastic differential equations [Conference session]. International
Conference on Learning Representations 2021, virtual. https://iclr.cc/virtual/2021/poster/3177
↩
Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction (2nd ed.) MIT Press.
↩
Sutton, R. S., McAllester, D. A., Singh, S. P., & Mansour, Y. (2000). Policy gradient methods for
reinforcement learning with function approximation. In S. Solla, T. Leen, & K. Müller (Eds.), Proceedings
of the 12th International Conference on Neural Information Processing Systems (Vol. 12; 1057–1063). MIT
Press. https://papers.nips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf
↩
Tan, B., Hu, Z., ZichaoYang, R., & Xing, E. (2018). Connecting the dots between MLE and RL for sequence
generation. arXiv. https://doi.org/10.48550/arXiv.1811.09740 ↩
70
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a