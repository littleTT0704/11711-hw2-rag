 as
i i=1
only the learned internal representation but also downstream input and reconstructs it to {xÂ¯}T. The decoder consists
i i=1
sound event detection and localisation performance. Inorder of CNN based network for combining the intermediate time-
to achieve that we choose auxiliary task as reconstruction of frequency representations obtained for each audio event to an
extracted time-frequency features for audio. By having time- audio level time-frequency representation. The architecture
frequencyreconstructionauxiliarytaskwehypothesisethenet- closely follows the common encoder structure in reverse or-
workwilllearnrepresentationswhichretainaudioeventinfor- derconsistingof8blocksof2DConvolution,BatchNormand
mation better [25, 26]. We use an auto-encoder structure for ReLUwithAveragePoolaftereverytwoblockswithadecreas-
reconstruction where the encoder is shared with the primary ingnumberoffilters.
Table1:WeaklysupervisedsoundeventdetectionperformanceacrossdifferentSNR
Network SNR20dB SNR10dB SNR0dB
encoder pooling aux. micro-p macro-p AUC micro-p macro-p AUC micro-P macro-p AUC
VGGish GAP (cid:55) 0.5067 0.6127 0.9338 0.4291 0.5390 0.9144 0.3295 0.4093 0.8694
VGGish GMP (cid:55) 0.5390 0.5186 0.8497 0.5263 0.5023 0.8422 0.4640 0.4441 0.8189
VGGish GWRP (cid:55) 0.7018 0.7522 0.9362 0.6538 0.7129 0.9265 0.5285 0.6084 0.8985
VGGish(dil.) AP (cid:55) 0.7391 0.7586 0.9279 0.6740 0.7404 0.9211 0.5714 0.6341 0.9014
VGGish 2AP (cid:51) 0.7829 0.7645 0.9390 0.7603 0.7486 0.9343 0.69