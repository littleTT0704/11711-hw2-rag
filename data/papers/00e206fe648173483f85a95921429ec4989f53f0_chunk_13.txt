
ON i2b2 20.8% 5.3 AugmentedSilverMentions
ONGenrei ONGenrej (8.1%,47.9%) X
Tofurtherreduceannotationburden,weaugment
Table3:Summaryofsource-targetconfigurationsinourex-
periments. We experiment with transfer between domains the set of annotated mentions over the target do-
withcommonordifferingannotationstyle,whereannotation
main. Wetrainamentiondetectoroverasubsetof
stylecandictatewhetherornottherearesingletonsannotated
goldannotatedtarget-domain. Then, weuseitto
ordomain-specificmentionstoannotateforexample.
tagsilvermentionsovertheremainingunlabeled
documents,andusethesesilvermentionlabelsin
domain with coreference annotations optimizing
computingMDT.
onlythecoreferencelossCLS. Then,wecontinue
trainingwithCLT ontargetdomainexamples. 5.4 CoreferenceEvaluationConfiguration
We additionally experiment with an alterna-
Inadditiontothemostcommoncoreferencemet-
tivebaseline(high-prec. c2fCLS,CLT,MDT)in rics MUC,B3,CEAF, we average across link-
whichcoreferenceannotationsarereusedtoopti-
φ4
based metric LEA in our score. We also evalu-
mizeourMDoverthetargetdomain. Thisallows
ateeachmodelwithandwithoutsingletons,since
forfullutilizationthetargetdomainannotations.
including singletons in the system output can ar-
tificially inflate coreference metrics (Kübler and
Proposed: high-prec. c2f (CLS,MDT,MLMT)
Zhekova,2011). Whenevaluatingwithsingletons,
Weusethesamemodelarchitectureandpre-trained
we keep singletons (if they exist) in both the sys-
encoder as the baseline, but also incorporate the
temandGOLDclusters. Whenevaluatingwithout
joint training objective CL+MD. We optimize
singletons,wedropsingletonsfromboth.
CL with core