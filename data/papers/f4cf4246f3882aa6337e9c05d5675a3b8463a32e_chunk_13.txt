attentiondistributionα t require a pixelwise mask to denote the object of interest.1
conditioned on the hidden state of the decoder h t−1 from Finally,theagentpredictsaStopactiontoendtheepisode.
thelasttimestep: We concatenate the hidden state h with the input features
t
z =(W h )(cid:62)x, u tandtraintwoseparatenetworkstopredictthenextaction
t x t−1
α
t
=Softmax(z t), (1) 1ThefinalobjectchosenbytheinteractionAPIisbasedontheIntersection-
over-Union(IoU)scorebetweenthepredictedmaskandtheground-truth
xˆ =α(cid:62)x objectmaskfromthesimulator.
t t
5
a andinteractionmaskm : 5.Experiments
t t
a =argmax(W [h ;u ]), WeevaluatethebaselinemodelsintheAI2-THORsim-
t a t t
(3) ulator. Whenevaluatingontestfolds, werunmodelswith
m
t
=σ(deconv[h t;u t])
thelowestvalidationloss. Episodesthatexceed1000steps
where W are learnable parameters of a fully connected orcausemorethan10failedactionsareterminated. Failed
a
layer,deconvisathree-layerdeconvolutionnetwork,andσ actions arise from bumping into walls or predicting action
isasigmoidactivationfunction. Actionselectionistrained interactionmasksforincompatibleobjects,suchasattempt-
using softmax cross entropy with the expert action. The ingtoPickupacountertop. Theselimitationsencourage
interaction masks are learned end-to-end in a supervised efficiencyand reliability. We assesstheoveralland partial
manner based on ground-truth object segmentations using successofmodels’taskexecutionsacrossepisodes.
binary cross-entropy loss. The mask loss is rebalanced to
5.1.EvaluationMetrics
account for sparsity in these dense masks in which target
objectscantakeupasmallportionofthevisualframe. ALFRED allows us to