neucom.2006.01.034. URL https://www.sciencedirect.com/science/
article/pii/S092523120600508X. Selected papers from the 3rd International Confer-
enceonDevelopmentandLearning(ICDL2004)Timeseriespredictioncompetition: theCATS
benchmark.
11
PublishedasaconferencepaperatICLR2023
Chen Yu and Linda B. Smith. Embodied attention and word learning by toddlers. Cog-
nition, 125(2):244–262, 2012. ISSN 0010-0277. doi: https://doi.org/10.1016/j.cognition.
2012.06.016. URL https://www.sciencedirect.com/science/article/pii/
S0010027712001369.
MertYuksekgonul,FedericoBianchi,PratyushaKalluri,DanJurafsky,andJamesZou. Whenand
why vision-language models behave like bags-of-words, and what to do about it?, 2022. URL
https://arxiv.org/abs/2210.01936.
HaoZhu,GrahamNeubig,andYonatanBisk. Few-shotlanguagecoordinationbymodelingtheory
ofmind. InInternationalConferenceonMachineLearning,pp.12901–12911.PMLR,2021.
HaoZhu,YonatanBisk,andGrahamNeubig. Simulatedlanguagelearningthroughcommunicative
goalsandlinguisticinput. ProceedingsoftheAnnualMeetingoftheCognitiveScienceSociety,
44:1351–1358,2022.
A APPENDIX
A.1 FULLEFFECTSOFDISTRACTORDIFFICULTY
InTable2,weselectthecaptionandhybriddistractorsinvolvedinthetrainingofthemostperfor-
mant models to be reported. Here, as promised, we report the results of experiments over a fuller
rangeofdistractorvariants.
Table3: Performanceandlanguagefeaturesofspeakerstrainedonalldistractorvariants.
Model Performance POSF1 Average
Distractors Acc Fluency ADJ ADP NOUN VERB Length
Base 0.81 1.