ousticenergyin
3202
luJ
62
]VC.sc[
1v35931.7032:viXra
Figure1: Illustrationofourframework. Weconvertphonemeclipsintomelspectrogramsanddevelopestimatorsforeachphoneme-
acousticmodel(AM)pair.HypothesistestingisusedtodeterminethepredictabilityofAMsfromphonemes.Greendenotespredictable
AMsandredotherwise,wherethecolorshadeindicatesthedegreeofpredictability.
theformofsoundwaves, producingvoice. Theshapeanddi- 3.3. AMEstimator
mensions of the resonant chambers change as the movements
WeleverageanAMestimatorE topredictthej-thAMfrom
ofthevocaltractmodifytheacousticsignal,resultingindiffer- ij
the i-th phonemem(i) = E (p(j) as anestimator that maps
entpatterns[19,20]. Toproduceaspecificpattern,themouth ij
thej-thphonemetothei-thAM.Tobegin,wetransformeach
andnosemustformacorrespondingshape.Eachpatterncorre-
phonemeintoalogmelspectrum,whichisessentiallyanimage.
spondstoauniquecompositionalunitofspeech,oraphoneme.
Thisisaclassicregressionproblem, andtherefore, weneeda
Whenaspeakerenunciatesdifferentphonemes,thevocaltract,
modelwithstrongfeatureextractioncapabilitiestoextractin-
mouse,nose, andotherrelatedfacialstructuresactinconcert.
formation from the image. We develop a modified version of
Andeachphoneme,therefore,carriessomeinformationabout
theclassicalMNasNetmodeldevelopedbyGoogleAI.Itisde-
alltheserelatedfeatures.
signedtobeefficient,lightweight,andhighlyaccuratefortasks
such as image classification and object detection. [21]. Our
3. Methods modificationretainstheoriginalstructure,butwithafewmodi-
ficationstotheinputandoutputlayers.Specifically