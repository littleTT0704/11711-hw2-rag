. The results also indicate that it is more effective to rank the longer markup-
basedtextnuggets, eventhoughtheyareoftenonlypartiallyrelevant. Thisisbecause
someofthefeatures, suchasthelikelihoodratiosandthecoverageofthesearchengine
abstract, are less reliable for short text nuggets. The advantage of more fine-grained
nugget selection when using sentence-level nuggets does not seem to compensate for
the difficulties in estimating their relevance.
Figure 5.1 illustrates the ranking performance of the baselines and logistic re-
gression models in terms of precision-recall curves. We omitted the independent LR
models for ease of presentation. In rankings generated by the LR model with adjacent
features for markup-based nuggets, relevant text nuggets are highly concentrated at
the top ranks. For example, precision exceeds 80% up to a recall level of over 60%.
Thus when using this model, it is feasible to expand a seed document with mostly
relevant text by selecting nuggets from the top of the ranking.
We used the one-sided Wilcoxon signed-rank test [Wilcoxon, 1945, Siegel, 1956]
58 CHAPTER 5. INTRINSIC EVALUATION
1.0
LR Adjacent
(Markup)
0.9
LR Adjacent
(Sentence)
0.8
Cosine Sim
0.7 (Markup)
n
o Cosine Sim
is
(Sentence)
ic 0.6
e Search
r
P Rank
0.5
Round Robin
(Markup)
0.4
Round Robin (Sentence)
0.3
Random
0.2
0.0 0.2 0.4 0.6 0.8 1.0
Recall
Figure 5.1: Precision-recall curves for baselines and linear relevance models.
to determine whether the performance differences between the baselines and linear
relevance models are statistically significant. The Wilcoxon test is a non-parametric
method that makes few assumptions about the distribution of the data. It is a better
choice for this task than the paired Studentâ€™s t-test because it does not require the
data to be normally distributed. For each ranking strategy, we computed the average
precision of the rankings generated for all of the topics used