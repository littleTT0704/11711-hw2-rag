, both
OI
Table 1: Lexical associations between toxicity and approaches also hurt in-distribution test perfor-
TOXTRIG mentions in the original dataset (Founta mance, indicating that ONI and other TOXTRIG
et al., 2018) and various filtered counterparts. Ran- features are essential for good performance.11 In
dom, AFLite, and DataMaps all contain only 33% of
contrast, the models trained on hard and am-
theoriginaldataafterfiltering. LowerPearsonR cor-
biguoussubsetsfromDataMapsbothpreservein-
relation value indicates less superficial patterns in the
distribution performance, even though they are
dataset, i.e., less bias. Takeaway: The hard and am-
biguoussubsetsgivenbyDataMapscontainthelowest trainedonlyathirdoftheoriginaldata. Theyalso
amountoflexicalassociations,indicatedinboldface. reducetherateoffalselypredictingNOImentions
as toxic (FPR ), while not showing much im-
NOI
provementfor ONI andmaintainingFPR
OI
ofthe
less the model infers lexical associations for toxi-
originalbaseline.
city,andhenceislessbiased.
Surprisingly,themodeltrainedontheeasysub-
Evaluation for Filtered Datasets We addition- set from DataMaps shows good bias reduction on
allyconsidermetricsbasedonspuriouslexicalas- the NOI and ONI categories, while matching the
sociationsfordatafilteringapproaches. Thismea- random selection baseline for OI. This is despite
suresprevalenceofspurioussurfacepatternsinthe DataMaps-Easyshowinganincreasedassociation
filtered datasets, which might propagate to mod- between TOXTRIG mentions and toxicity (Table
elstrainedonthedata. Specifically, wereportthe 1). Notably, the F 1 for all categories suffers un-
Pearsonâ€™s correlation between the gold standard derthismodel,indicatingthatitislesscompetent
toxicity label and whether or not it contains NOI, than the baseline. These results suggest that re-
OI, or ONI mentions. These correlations are de- ducedass