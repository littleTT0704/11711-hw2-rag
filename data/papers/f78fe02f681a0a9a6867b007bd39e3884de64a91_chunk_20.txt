
HumanjudgesevaluateChatGPT’sresponsesto
GPT-3.5 50% 46% 31% 47%
bemuchmorespecific,butsignificantlylessnatural COSMO-11B 50% 54% 69% 53%
compared to COSMO. We hypothesize this is be-
ChatGPT 39% 49% 70% 50%
causeChatGPTisspeciallytrainedtogivehelpful COSMO-11B 61% 51% 30% 50%
andinformativeresponsestouserrequests. Future
work would be well-suited to compare the non- Table7: Head-to-headhumanevaluationbetweenmod-
equivalenceofsimulatingnaturalconversationsvs. elsonresponsegenerationforSODA(§5.3). Thediffer-
ences in the Specific from the top row, and the differ-
producingusefulresponsesforusers.
encesintheNaturalandSpecificfromthebottomrow
6 RelatedWork arestatisticallysignificantwith|z|>7.6andp<0.05.
Building Dialogue Datasets with Large Lan-
2022)ortask-specificlabels(Kulháneketal.,2021;
guage Models Several studies have used large
Chenetal.,2022). Comparedtoexistingworks,we
languagemodelstoaugmentorsynthesizedialogue
arethefirsttocontextualizecommonsenseknowl-
datasets. Zhengetal.(2023)andChenetal.(2022)
edge graphs for generating narratives and derive
useGPT-J(Wang,2021)toaugmentresponsesfor
full conversations from scratch in a significantly
emotionalsupportconversationsandunderstanding
large-scale. Thisallowsustoencompassanexcep-
tasks, respectively. Chen and Yu (2021) trains a
tionallybroadspectrumofsocialinteractions.
pseudo-labelertoincreasetheout-of-domaingen-
eralization of dialogue models. Ou et al. (2022)
7 Conclusion
uses counterfactual reasoning to alter the seman-
ticsofresponsesandcollectnewones. Kimetal.
Wepresented SODA,thefirstmillion-