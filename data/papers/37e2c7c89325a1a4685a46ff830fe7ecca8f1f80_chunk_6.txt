,T)=E (x,y)∼Dtest[1{S θ∗(x)=T(x)}]. (1)
Next,thetrainingofthestudentisaugmentedwithexplanationsproducedbytheexplainerE. We
introduceastudentexplainerE :S×X →E,(theS-explainer)toextractexplanationsfromthe
S
student,andregularizingtheseexplanationsontheexplanationsofteacher(theT-explainer),usinga
lossL thattakesexplanationsforbothmodels:
expl
(cid:20) (cid:21)
θ∗ =argminE L (S (x),T(x))+βL (E (S,x),E (T,x)). (2)
E
θ
(x,y)∼Dˆ
train
(cid:124)sim θ
(cid:123)(cid:122) (cid:125)
(cid:124)expl S θ
(cid:123)(cid:122)
T
(cid:125)
simulabilityloss explainerregularizer
Forexample,Pruthietal.[2020]consideredasateacherexplainerE variousmethodssuchasLIME
T
[Ribeiroetal.,2016],IntegratedGradients[Sundararajanetal.,2017],andattentionmechanisms,and
exploredbothattentionregularization(usingKullback-Leiblerdivergence)andmulti-tasklearningto
regularizethestudent.
The key assumption surrounding this evaluation framework is that a student trained with good
explanations should learn to simulate the teacher better than a student trained with bad or no
(cid:0) (cid:1)
explanations,thatis,SIM S θ∗,T > SIM(S θ∗,T).Forclarity,wewillrefertothesimulabilityofa
E
modelS
θ∗
trainedusingexplanationsasscaffoldedsimulability.
E
3 OptimizingExplainersforTeaching
As a first contribution of this work, we extend the previously described framework to