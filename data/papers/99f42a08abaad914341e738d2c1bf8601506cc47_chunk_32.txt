(data-dependent)waytocontrolthe and (ii) adjustable magnitude augmentation. As a concrete
featuremagnitude.Moreover,thereexistmanyotherstrate- example,wecoulduseg((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))=(cid:107)x 1(cid:107)t·(cid:107)x 2(cid:107)t where
gies that can dynamically control the feature magnitude to t adjusts the augmentation strength of feature magnitude.
improvetheempiricalperformance,suchas[36]. g((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))=1reducestothecosinesimilarityscore.In
general,howtodesignagoodg isnotclearandremainsto
4.3 DiscussionsandOpenProblems beexploredinfutureendeavours.
Optimal design of characteristic function. It is clear that
thecharacteristicfunctionisthekeytolargeangularmargin, 5 A UNIFIED CHARACTERIZATION OF LOSS FUNC-
but is there an optimal characteristic function? The answer TIONS IN HYPERSPHERICAL FACE RECOGNITION
to this question remains open. We argue that the optimal
design of characteristic function should be dynamic and In this section, we take a closer look at what characterizes
depends on the specific dataset, the network architecture, hyperspherical face recognition. As our unified framework
the optimizer, the stage of training (i.e., the weights of the in Section 3 discusses, a feature normalization strategy, a
network), etc. Current studies on hyperspherical FR still (non-)target angular function and a characteristic function
focuses on a static characteristic function. [70], [71] explore can fully determine the loss function of a hyperspherical
an automatic way to learn a characteristic function from FR method. Particularly, the characteristic function ∆(·)
data,butthoselearnedcharacteristicfunctionsarestillstatic controls the property of the induced angular margin (e.g.,
onesanddonotleadtoasignificantperformancegain.[45] size,trainingstability).Itdoesnotconsiderthefeaturemag-
combines the sample quality to hyperspherical FR