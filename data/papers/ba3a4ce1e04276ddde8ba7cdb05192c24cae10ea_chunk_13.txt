 proposed architectures have pervisedSEDbyusingtheauxiliarytaskreconstructionoutput.
the best precision scores against GMP, GAP, GWRP, Atrous
acrossallSNR=0, 10, 20. Particularly, foraudioeventslike 6. Conclusions
‘Bass drum’, ‘bus’, ‘double bass’, ‘cowbell’ the architecture
outperformsothermodelsbyalargemarginasshownintable This paper proposes assisted self-supervised task for improv-
3. However,theproposedmodelstrugglesinaudioeventslike ing sound event detection in limited data and noisy settings.
‘gong’,‘chime’and‘meow’wheretheattentionpoolingwithdi- The architecture consists of sound event detection as a pri-
latedconvolutionencoderperformsbetter[14]. Thisindicates marytaskwithtwo-stepattentionpoolingasaprimarydecoder
using atrous or dilated convolutions helps in detecting audio and time-frequency representation reconstruction as an auxil-
events whose energy is spread wide in the temporal domain. iary task. We empirically evaluate the proposed framework
This can be incorporated into our current architecture by re- formulti-label weaklysupervised soundeventdetection, ona
placing the linear convolutions in the shared encoder with di- remix DCASE 2019 and 2018 dataset under 0, 10 and 20 dB
lated convolutions. Further analysis and event-specific results SNR. The proposed self-supervised auxiliary task framework
areavailableinthelongversionofpaper3 andskippeddueto withtwo-stepattentionoutperformsexistingbenchmarkmod-
spaceconstraints. elsby22.3%,12.8%,5.9%on0,10and20dBSNRrespec-
tively. Theablationstudycarriedoutindicatesthemajorityof
5.4. Interpretablevisualisationofaudioevents performanceimprovementisassociatedwithtwostepattention
pooling with secondary performance improvement from self-
Apart from improved performance, using two step attention
supervised auxiliary task. Furthermore, by using two step at-
pooling provides a way to localise each audio event present
tention,wecaneasilyvisualisethesound