itoutperformedeveryotherprojectionwetried(see§6foramoredetaileddiscussion). Figure2
illustrateseachstepofourparameterizedattentionexplainer.
5 Experiments
Toevaluateourframework,weattempttolearnexplainersfortransformermodelstrainedonthree
different tasks: text classification (§ 5.1), image classification (§ 5.2), and machine translation
qualityestimation(atext-basedregressiontask, detailedin§5.3). WeuseJAX[Bradburyetal.,
2018]toimplementthehigher-orderdifferentiation,andusepretrainedtransformermodelsfromthe
HuggingfaceTransformerslibrary[Wolfetal.,2020],togetherwithFlax[Heeketal.,2020]. For
eachtask,wetrainateachermodelwithAdamW[LoshchilovandHutter,2019]but,asexplainedin
§3,weuseSGDforthestudentmodel(innerloop). Wealsousescalarmixing[Petersetal.,2018]to
poolrepresentationsfromdifferentlayersautomatically.3 Wetrainstudentswithateacherexplainer
inthreesettings:
• NoExplainer: Noexplanationsareprovided,andnoexplanationregularizationisusedfortraining
thestudent(i.e.β =0inEquation3). Werefertostudentsinthissettingasbaselinestudents.
• Static Explainer: Explanations for the teacher model are extracted with five commonly-used
saliency-basedexplainers: (1)L2normofgradients;(2)agradient×inputexplainer[Deniletal.,
2014];(3)anintegratedgradientsexplainer[Sundararajanetal.,2017];andattentionexplainers
thatusesthemeanpoolingoverattentionfrom(4)allheadsinthemodeland(5)fromtheheadsof
thelastlayer[Fomichevaetal.,2021b,Vafaetal.,2021]. MoredetailscanbefoundinAppendixA.
• LearnedExplainer(SMaT):Explanationsareextractedwiththeexplainerdescribedin§4,with
coefficientsforeachheadthataretrainedwithSMaTjointlywiththe