ensaresetto48and30,respectively. For
videoretrievalonthe“val1”split.
paragraph-videoretrievalonActivityNet,wesetthemboth
•Howto100M[35]. Wecomparewithpreviousworkunder to 256. The 2D R-152 feature is extracted for one frame
thepretrainingprotocolonHowto100M[35,34,60,33]. It per second, and then globally pooled to 2048-d. For 3D
was collected from YouTube and contains over 1.2M nar- CNNfeatures,wefollow[35]tosamplevideoframesat24
rated videos associated with automatically generated tran- fpsandextractanI3D-X101featureevery16frames. This
scripts. Eachvideocontainsover100clipsonaverage. results in 1.5 2048-d feature per second. For Eq. 3 and 4,
Tofurtherverifythetransferrabilityorourlearnedmulti- wesetthetemperaturesτ andτ bothequalto1.
1 2
modal representation from Howto100M, we also evalu- Training on separate datasets. In this setting, we train
atetheactionsteplocalizationandactionsegmentationon models from scratch using the training set provided in
CrossTask[61]andCOIN[43],respectively. YouCook2,MSR-VTTandActivityNetseparately.Wetrain
5
YouCook2 MSR-VTT(split1) YouCook2 MSR-VTT(split1)
VideoRepresentation R1↑R5↑R10↑MR↓ R1↑ R5↑ R10↑MR↓ Losses Cascade R1↑ R5↑R10↑MR↓ R1↑ R5↑R10↑MR↓
R-152,Baseline 4.1 13.2 19.4 81.0 16.4 42.6 55.8 8.0 L n/a 14.135.7 48.8 11.0 22.949.7 61.7 6.0
1
R-152,Ours 4.6 14.1 20.4 71.0 18.9 46.2 58.8 7.0
L n/a 13.335.8 48.9 11.0