2020). We also annotate stance toward each of
ments, we further annotate target groups from a
the previous comments in the thread. Using our predefined list comprising identity-based groups
annotatedcorpus,weshowthat42%ofhumanre- ofpeople(e.g.,peopleofvarioussexuality/sexual-
sponses in offensive contexts exhibit agreement
orientation/gender,peoplewithdisabilities,people
stance, whereas only 13% agree with safe com-
fromaspecificrace,politicalideologies,etc.) and
ments. Analysis of 5 million Reddit comment specific individuals e.g., (public figures, Reddit
threadsacrosssixmonths,similarlyfindsusersare
users, etc.) We present the list of selected target
threetimesmorelikelytoagreewithoffensivecom-
groupsinFigure7intheAppendix.
ments. Furthermore,wefindthatneuralchatbots 2)Stance-Weannotatethe stanceofu towards
i
learn to mimic this behavior - DialoGPT, GPT-3, each previous comment, u,∀j < i. Stance is
j
andFacebook’sBlenderchatbotareallmorelikely
viewedasalinguisticallyarticulatedformofsocial
toagreewithoffensivecomments.
action, in the context of the entire thread and so-
Finally,wepresentinitialexperimentswithtwo cioculturalsetting(DuBois,2007;Kieslingetal.,
controllable text generation (CTG) methods that 2018). Stance alignment between a pair of utter-
aimtocontrolthestanceofautomaticallygenerated ancesisannotatedasAgree,DisagreeorNeutral.
replies. Ourexperimentssuggestthatdomainadap- Our primary interest is in analyzing the stance
tivepretraining(Gururanganetal.,2020)reduces taken towards offensive statements. We assume
the number of contextually offensive responses, that a user or a chatbot can become offensive by
although this does not completely eliminate the aligning themselves with an offensive statement
problem,suggestingtheneedforfurtherresearch madebyanotheruser(seeFigure1).4
oncontrollablestanceinneuraltextgeneration. Additionally,fordialoguemodelresponsesu,
k
