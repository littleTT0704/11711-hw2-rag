andthemodelscomputetheCTC theBLEUscoresforthe2022modelunreliable.
policyaftereachtokenratherthanword). However,
Lang Model AL AL BLEU
westillobserveasignificantreductionincomputa- ↓ CA↓ ↑
2022 1991 3138 31.8
tionallatency,namelyby45and34%relativeRTF En-De
2023 1955 3072 31.4
forEn DeandEn Zh,respectively.
→ → 2022 1906 3000 15.5
En-Ja
2023 1982 3489 15.3
Lang Decoding AL AL RTF BLEU
↓ CA↓ ↓ ↑
BWBS 1922 3121 0.46 30.6 2022 1984 3289 26.8
En-Zh
En-De IBWBS 1977 3277 0.52 31.7 2023 1987 3508 26.6
CTC 1946 2518 0.21 30.6
Table3: Submittedonlinizedlargeofflinemodels.
BWBS 1948 2855 0.41 26.5
En-Zh IBWBS 1945 3031 0.48 26.5
CTC 1981 2515 0.28 25.8
We also submit the system based on the large
model onlinized using the CTC policy. The sys-
Table2: Comparisonofonlinizationofthelargeoffline
modelusingchunkingwiththelocalagreementpolicy temsaresummarizedinTable4. Unfortunately,we
(LA-2)andwiththeproposedCTCpolicy. werenotawareofthetrainingandtestdataoverlap
duringtheevaluationperiod,sowedecidedtouse
our2022modelalsothisyear.
4 Submission
In this section, we summarize our submission to Lang Model AL ↓ AL CA↓ BLEU ↑
the Simultaneous track at IWSLT 2023. In total, En-De 2022 1959 2721 31.4
En-Zh 2022 1990 2466 26.3
wesubmit10systemsforallthreelanguagepairs.
Table4: Submittedlargeofflinemodelsonlinizedusing
4.1 OnlinizedOfflineModels
theproposedCTCpolicy.
Followingourlastyear’ssubmission,