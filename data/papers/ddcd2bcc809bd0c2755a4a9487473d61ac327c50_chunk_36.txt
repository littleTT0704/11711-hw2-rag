ichnikandyouwillsaywhatthedifferencesare.”
Inthestorydidsomeonesaysomethingthattheyshouldnothavesaid?
Answerwith“Yes”or“No”only,withoutexplanations.
Incaseofdoubt,answeraccordingtothemostprobableanswer.
Answer:
Table6: Anexamplepromptusedforeachtask.
8.3.2 DecodingParameters google/flan-t5-xl, google/flan-t5-xxl; tempera-
ture=0.0001
Asinglesample(thefirst)wasselectedfromeach
modelfortheanalysisofthestories. Weusedthe
hyperparametersdetailedbelow. Wechosehyper-
FlanUl2 (Tay et al., 2022). Python
parametersthatminimizerandomnessandpredict package transformers implementation
the most probable answer (i.e., low temperature,
(T5ForConditionalGeneration, AutoTok-
samplingmethod),andallowforsufficientnumber enizer); torch; Generation by generate function;
oftokens.
do_sample=True; max_length=50; tempera-
ture=0.0001
FlanT5 (Chung et al., 2022). Python pack-
age transformers implementation (AutoMod-
elForSeq2SeqLM, AutoTokenizer); torch; Gen- GPT (Brown et al., 2020). Python package
eration by generate function; do_sample=True; openaimodel=text-davinci-002,text-davinci-003;
max_length=50, from_pretrained:google/flan-t5- GenerationbyCompletion.createfunction;temper-
small, google/flan-t5-base, google/flan-t5-large, ature=0,max_tokens=50
14
ChatGPT.11 Pythonpackageopenaimodel=gpt-
3.5-turbo-0301,gpt-4-0314;GenerationbyChat-
Completion.createfunction;temperature=0
AI21.12 Pythonpackageai21model=j2-jumbo-
instruct, j2-grande-in