. Yamanishi, and Y. Ya-
[6] A. Kumar and B. Raj, “Audio event detection using weakly
mashita, “Jointanalysisofacousticeventsandscenesbasedon
labeled data,” in Proceedings of the 24th ACM International
multitasklearning,”2019IEEEWorkshoponApplicationsofSig-
ConferenceonMultimedia,ser.MM’16. NewYork,NY,USA:
nalProcessingtoAudioandAcoustics(WASPAA),pp.338–342,
Association for Computing Machinery, 2016, p. 1038–1047.
2019.
[Online].Available:https://doi.org/10.1145/2964284.2964310
[23] H. L. Bear, I. Nolasco, and E. Benetos, “Towards joint sound
[7] S.-Y. Tseng, J. Li, Y. Wang, F. Metze, J. Szurley, and scene and polyphonic sound event recognition,” in INTER-
S.Das, “Multipleinstancedeeplearningforweaklysupervised SPEECH,2019.
small-footprintaudioeventdetection,”inProc.Interspeech2018,
2018, pp. 3279–3283. [Online]. Available: http://dx.doi.org/10. [24] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Lib-
21437/Interspeech.2018-1120 rispeech: Anasrcorpusbasedonpublicdomainaudiobooks,”
in2015IEEEInternationalConferenceonAcoustics,Speechand
[8] A. Kumar and B. Raj, “Deep cnn framework for audio event SignalProcessing(ICASSP),2015,pp.5206–5210.
recognitionusingweaklylabeledwebdata,”2017,arXivpreprint,
https://arxiv.org/abs/1707.02530. [25] E.M.GraisandM.D.Plumbley,“Singlechannelaudiosource
separationusingconvolution