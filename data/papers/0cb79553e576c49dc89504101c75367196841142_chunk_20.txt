psy- arXiv.
chological well-being of content moderators: The
emotionallaborofcommercialmoderationandav- Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
enuesforimprovingsupport. InProceedingsofthe Weinberger, and Yoav Artzi. 2019. Bertscore:
2021CHIConferenceonHumanFactorsinComput- Evaluating text generation with BERT. CoRR,
ingSystems,CHI’21,NewYork,NY,USA.Associa- abs/1904.09675.
tionforComputingMachinery.
A ModelingDetails
EmmaStrubell,AnanyaGanesh,andAndrewMcCal-
lum. 2019. Energy and policy considerations for A.1 Out-of-the-BoxModeling
deeplearninginnlp.
We use the HuggingFace Transformers library
KurtThomas,DevdattaAkhawe,MichaelBailey,Dan (Wolf et al., 2020) version 4.10.2 for out-of-the-
Boneh,ElieBursztein,SunnyConsolvo,NicolaDell,
box, pretrained BART models and for finetuning
ZakirDurumeric,PatrickGageKelley,DeepakKu-
using the Trainer class. It is licensed under the
mar,DamonMcCoy,SarahMeiklejohn,ThomasRis-
tenpart,andGianlucaStringhini.2021. Sok: Hate, Apache License 2.0., and the code is available at
harassment, and the changing landscape of online https://github.com/huggingface/transformers.
abuse. In 2021 IEEE Symposium on Security and
Privacy(SP),pages247–267.
A.2 FinetuningtheExperts
Bertie Vidgen, Tristan Thrush, Zeerak Waseem, and Fortheexpertandanti-expertmodels,wefurther
DouweKiela.2021. Learningfromtheworst: Dy- finetunethebaseBARTmodelwith139Mparame-
namicallygenerateddatasetstoimproveonlinehate
ters,foundathttps://huggingface.co/facebook/bart-
detection. InProceeding