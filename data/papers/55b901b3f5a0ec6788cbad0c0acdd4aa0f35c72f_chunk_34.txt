al(θ t+1(w)) β(cid:0) (cid:1)T(cid:0) val(θ )(cid:1) (4)
∂w ≈− ∇LTi ∇LE t
i
Topreventtheaboverelaxationfromfindingthetrivialsolutionofjustupweigtingsolelytheend-task,
Deryetal.(2021b)introduceaspecialdev-headwhichtheyuseforestimatingthemeta-gradient:
∂ Lv Ta ∗l(θ∗(w)) β(cid:0) (cid:1)T(cid:0) val([θ ;φ∗] )(cid:1) (5)
∂w ≈− ∇θ LTi ∇θ LE body t
i
Whereφ∗ isthespecialdev-headandθ isthebodyofthemodel. Forevenmoredetailsabout
t body
META-TARTAN,pleaseseeSection3ofDeryetal.(2021b).
Though we leverage MET-TARTAN, compared to Dery et al. (2021b), we make three distinct
contributionstothefieldofauxiliarylearning. Welistthembelow
1. Novel Problem Formulation: As far as we are aware of, we are the first to formulate
theproblemofautomatedauxiliarylearning. Specifically,wepresentedanapproachfor
automaticallyconstructingasuiteofauxiliaryobjectivesbasedonexistingobjectives.Please
notethatDeryetal.(2021b)performauxiliarylearningwithonlytheDAPT/TAPTvariants
oftheBERTobjective. Theyeffectivelyassumethatthesearchspaceofobjectives(the2
theyexplore)isgivenbefore-hand. Ourapproachautomaticallycreatesthesearchspace.
2. Theoretical Novelty: To the best of our knowledge, we are the first work to provide an
explorationofwhyauxiliarylearningimprovesprimarytaskperformanceviaalgorithmic
stability. Dery et al. (2021b) in introducing META-TARTAN do not attempt to give a
theoreticalcharacter