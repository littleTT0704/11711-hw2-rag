25 0.50 0.75 1.00
Ratio to Full Datastore Size
Figure4:ThedifferencesbetweenusingapproximateandaccuratekNNsearchonvaryingsizeofthedatastore.
5.2 AddingSoftmaxTemperaturetokNNDistribution
Becausethenumberofretrievednearestneighbors,k isusuallymuchsmallerthanthevocabularysizeV,
intuitively,thekNNdistributionP usedforinterpolationtendstobemorepeakythanthestandardLM
kNN
output distribution. When k = 1024 and V = 33000, as in our experiments, P will only have a few
kNN
vocabularyitemswithanon-zeroprobability. Furthermore,manyoftheretrievedneighborssharethesame
targettokenandthusmakethekNNdistributionevenpeakier. Onewaytocontroltheentropy,orpeakinessof
thedistributionistoaddtemperaturetothelogitsthatgointothesoftmaxfunction(Holtzmanetal.,2019).
Wecalculatetheprobabilityofnon-parametriccomponentP withthefollowingequationwheretisthe
kNN
softmaxtemperature:
P =Msoftmax(mask-to-k(W ⊗h )/t) (6)
kNN ds ds
Ingeneral,thehigherthetemperature,theless“peaky”thedistributionwouldbecome. Weexperimentwith
boththe5%aswellasthefulldatastoreusingdifferenttemperaturesrangingfrom0to3at0.1intervals. The
resultsareshowninFigure5aandFigure5brespectively.
(a)On5%subsampleddatastore. (b)Onfulldatastore.
Figure5: Theinterpolatedperplexityvarieswithdifferentsoftmaxtemperaturevalues.
Wecanseethatthedefaulttemperaturet=1doesnotalwaysresultinthebest-interpolatedperplexityand
tuningsoftmaxtemperatureisdesirableforallsizesofdatastore. Thelessonlearnedhereisthattuningthe
9
ytixelpreP
detalopretnI
softmaxtemperatureforthek