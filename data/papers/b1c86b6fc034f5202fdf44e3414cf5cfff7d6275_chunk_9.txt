
embeddingvectorsz,z producesubclassprobabilitiesafterasigmoidactivation,whichisusedfor
1 2
thepredictionofmulti-labeleddata.
The ontological layer, M, then relates the class probabilities of level 1 to those in level 2 of the
ontologythroughthefollowingrelation:
p(y |x)=M·p(y |x)
2 1
Wemodifytheontologicallayerproposedin[1]inordertofitthemulti-labeldatascenario,whereM
isconstructedsuchthatitaveragestheprobabilitiesofthesubclasseswithinasinglesuperclass. Note
thatthislayerisfixedandnottrainable,itdependsstrictlyontheontologyofthetrainingdata.
Thefinallossfunctionincorporatesthebinarycrossentropylossofthelevel1classes,L,andthe
1
level2classes,L,withtheembeddingloss,D =(||z −z || −d)2whered∈{0,1,2}according
2 w 1 2 2
tothetypeofinputpair.
L=λ (L1+L2)+λ (L1+L2)+λ D
1 1 1 2 2 2 3 w
Thebasenetworktakesaninputfeatureofdimension128beforetheoutputlayertothe42classesin
thefirstontologylevelandthenthroughtheontologylayertothe7classesinthesecondlevel. The
baselinepaperdoesnotactuallyreportevaluationmetricsfortheAudiosetdata,astheyfocusedon
otheraudiodatasets: UrbanSounds-US8KanddatafromtheMakingSenseofSoundsChallenge.
Thesearebothsinglelabeleddatasets.
3.5 GraphConvolutionalNetwork
Tomodelboththeco-occurrenceinformationintroducedfromweaklabelsandthedomainknowledge
from ontology, we seek to utilize graph embedding approaches to extend the Siamese network
architecture.In[8]and[9],aGraphConvolutionNetwork(GCN)isshowntobeeffectiveforlearning
usefulnoderepresentationsthroughtheinformationinacorrelationgraph. Theessentialideaisto
updatethenoderepresentationsbyaggregating