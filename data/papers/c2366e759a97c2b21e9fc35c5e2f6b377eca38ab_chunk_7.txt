 propose
t=T−1 t=T
1Terminologyborrowedfromnaturallanguageprocessingwheretokensarewords;here,theyareinstances.
2Similarto<CLS >tokensusedforsentenceclassification.
3
a prompt-situation architecture (Fig. 3). The prompt encoder receives one demonstration trajec-
tory as input, and outputs a learned representation of the preference. These output prompt tokens
are input to a situation decoder, which also receives the current state as input. The decoder π is
trained to predict the action chosen by the expert for the situation, given a prompt demonstration.
The left half is prompt encoder ψ and the right half
is the situation decoder or policy π acting on given
state. The prompt encoder ψ : f ◦f ◦f con-
slot te e
sists of an instance encoder f, transformer encoder
e Slot Attention
f, andaslot-attentionlayerf [27]. ψ takesthe
te slot
whole demonstration trajectory τ as input and
prompt Transformer Decoder
returns a fixed and reduced preference embedding
Transformer Encoder
γ =ψ(τ )ofsequencelengthH.Slotattentionis
prompt
aninformationbottleneck,whichlearnssemantically
meaningfulrepresentationsoftheprompt.
Instance Encoder Instance Encoder
The situation decoder is a policy π : f ◦ f that
td e
receivesasinputN instancetokensfromthecurrent Prompt Situation
sceneS, consistingofobjects, aswellas, placement
Figure 3: Prompt-Situation Architecture.
instances separated by <ACT> tokens (Fig. 2b).
The left is the prompt encoder which takes
Thepolicyarchitectureisatransformerdecoder[18]
as input a prompt demonstration and out-
with self-attention layers over the N input tokens.
puts a learned preference embedding. The
Thisisfollowedbyacross-attentionlayerwithpref-
right half is the situation decoder, which
erenceembeddingγ (H tokens)fromtheprompten-
conditionedonpreferenceembeddingfrom
coder.Weselecttheoutputofthesituationdecoderat
