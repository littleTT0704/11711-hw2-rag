thebaselinemethodswithtwo
metrics: themeanabsoluteerror(MAE)andtherootmean
4.1.Data squarederror(RMSE).
Fordemonstrationpurpose,wesynthesizea3-linesdataset On the synthetic 3-lines data, Figure 3 shows the fitting
(as shown in Figure 1a). For further evaluation, we se- resultsonthetestsetforourmethodsandbaselinemethods.
lect five other standard datasets that are commonly used WeobservethatourHRMEmodelsprovideamoreaccurate
in regression tasks. Four of these datasets are from the predictionthanthebaselines. Specifically,thelinearmodel
UCImachinelearningrepository(Dheeru&KarraTaniski- isjustpredictingthemeanofthethreedifferentdistributions;
dou,2017): theCCPPdataset(TuÂ¨fekci,2014;Kayaetal., thedecisiontreeandrandomforestprovideabetterfitthan
2012), the concrete dataset (Yeh, 1998), the Boston linear regression, but discontinuities and higher variance
housing dataset (Belsley et al., 2005) and the energy occurduetothepiece-wiselinearnatureofthesetwomod-
dataset (Candanedo et al., 2017), and one kin40k els. MLPachievessmallerpredictionerrorthanDTandRF,
dataset(Seegeretal.,2003;Deisenroth&Ng,2015). The butitalsoshowsdiscontinuitiesandfailuretocapturethe
datasetsrangefromsmall-sizedtolarge-sizedandfromlow- datamodality. Incomparison,ourHRMEmodelsprovide
dimensionaltohigh-dimensional. Thestatisticsareshown much smoother fitting with lower bias and variance than
inTable1.Thedivisionoftrainandtestsetsareeitherusing thebaselines. Notethatevenwithlinearleafexperts,the
thedefaultsplitorusing0.7:0.3split. HRME-LRmodelisabletocapturethenonlinearmodality
ofthedataandmakeregionalpredictionsbysoft-switching
4.2.Models its experts among the three distributions. Further, by us-
ingnon-