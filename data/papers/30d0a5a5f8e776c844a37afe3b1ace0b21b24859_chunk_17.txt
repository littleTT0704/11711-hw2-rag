objectstobeinsertedbetweenthestartandthe
that the locations are on the same floor and a navi- goal, maintaining a minimum pairwise geodesic dis-
gable path exists between them. Next, five goal ob- tancebetweenthemtoavoidcluttering. Furthermore,
jects are randomly sampled from the set of Cylinder tomakethetaskevenmorerealisticandchallenging,
8
three distractor objects (which are not goals) are in- of 55%. This model is an evolution of Proj-Neural,
sertedineachepisode.Thepresenceofdistractorswill where three auxiliary tasks were used to inject infor-
encouragenewagentstodistinguishbetweengoalob- mationaboutthemapandobjectsintotheagentâ€™sin-
jectsandotherobjectsintheenvironment.Anepisode ternalrepresentation.
is considered successful if the agent is able to reach In the 2022 challenge, instead, we noticed some
within1meterofeverygoalinthespecifiedorderand similarities between the Baseline method, Mem-
generatetheFOUNDactionateachgoalobject. Apart SLAM, and the winning entry in the 2022 MultiON
from the standard evaluation metrics used in Object- challenge, Exploration and Semantic Mapping for
Nav,suchasSuccessRate(SR)andSuccessweighted Multi Object-Goal Navigation (EXP-MAP). Both the
bypathlength(SPL)[9],weadditionallyuseProgress methods are modular, consisting of detection (iden-
and Progress weighted by path length (PPL) to mea- tifying objects from raw RGB images), Mapping (in-
sureagentperformance. Theleaderboardforthechal- crementallybuildingatop-downmapoftheenviron-
lengeisbasedonthePPLmetric. MultiONchallenge ment using Depth observations and relative poses),
was hosted on evalAI, an open-source platform for andPlanning(navigatingtoadetectedgoalobjectby
evaluatingandcomparingartificialintelligencemeth- generatinglow-levelactions)modules.Allthesemod-
ods. The participants implemented their methods in els record previously seen objects in some memory
docker images and submitted them to evalAI. The (e.g., semantic map of the environment). The EXP-
docker