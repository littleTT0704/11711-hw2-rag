leduetothelargeractionandstate
2LanguageTechnologiesInstitute@CarnegieMellonUniversity
3AllenInstituteforAI 4NVIDIA spaces,longhorizon,andinabilitytoundocertainactions.
1
0202
raM
13
]VC.sc[
2v43710.2191:viXra
—Language— —VirtualEnvironment— —Inference—
#Human Visual Movable State
Granularity Vis.Obs. Navigation Interaction
Annotations Quality Objects Changes
TACoS[43] 17k+ High&Low Photos (cid:55) (cid:55) – – –
R2R[3];Touchdown[14] 21k+;9.3k+ Low Photos (cid:55) (cid:55) Ego Graph (cid:55)
EQA[15] (cid:55) High Low (cid:55) (cid:55) Ego Discrete (cid:55)
MatterportEQA[55] (cid:55) High Photos (cid:55) (cid:55) Ego Discrete (cid:55)
IQA[20] (cid:55) High High (cid:55) (cid:51) Ego Discrete Discrete
VirtualHome[42] 2.7k+ High&Low High (cid:51) (cid:51) 3rdPerson (cid:55) Discrete
VSP[58] (cid:55) High High (cid:51) (cid:51) Ego (cid:55) Discrete
Discrete
ALFRED 25k+ High&Low High (cid:51) (cid:51) Ego Discrete
+Mask
Table 1: Dataset comparison. ALFRED is the first interactive visual dataset to include high-level goal and low-level
naturallanguageinstructionsforobjectandenvironmentinteractions. TACoS[43]providesdetailedhigh-andlow-leveltext
descriptions of cooking videos, but does not facilitate task execution. For navigation, ALFRED enables discretized, grid-
basedmovement,whileotherdatasetsusetopologicalgraphnavigationoravoidnavig