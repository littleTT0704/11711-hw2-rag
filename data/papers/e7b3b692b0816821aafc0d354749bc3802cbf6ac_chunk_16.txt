ternallistener. Modelswith
learnedlistenersandRSAmodelswiththepretrainedlistenerperformcomparablyinaccuracyand
fluency. BecausetheRSAmodelsrepresenttheupperboundofhowgoodaspeakerâ€™slistenermodel
canbe,thissuggeststhatourlearnedlistenersareverybeneficialtothespeakers. Thisisalsoshown
through the high ToM accuracies reported, especially in the most performant models, those with
highlistenerweight. Thesequalitativeandquantitativeresultsprovidecomputationalevidencethat
ToM can play an important role in simulated language acquisition, similarly to how it has been
hypothesizedtoplayacriticalroleinhumanlanguageacquisition.
6.3 EFFECTSOFDISTRACTORDIFFICULTY
As shown in Table 2, we generally find significant improvements in language quality in models
trained on more difficult distractors. The largest gains are those seen in the fluency score, where
difficult distractors achieve gains ranging between 25% to 46%. We also find that models trained
onmoredifficultdistractorsusemoresimilarvocabularytotheground-truthcaptions,asmeasured
byF1scoreintheground-truthcaptionsandutterancesproduced. Thisissignificantlyhigherover
adpositions,nouns,andverbsonmodelstrainedwithmoredifficultdistractors. Finally,allspeakers
trainedondifficultdistractorsgeneratemorecomplexutterancescomparedtothebasespeaker,with
utterances that are at least one word longer on average. This supports our hypothesis that when
confronted with increased environmental pressure, the speaker adapts by becoming more precise,
fluent,andcomplexwithitslanguage.Thesecanbeseenqualitativelyinonerepresentativeexample
in Fig. 3, which shows that a speaker trained on hard distractors is able to generate more fluent
utterancesthatmorepreciselydescribetheimage(inthisexample,correctlyidentifyinganobjectin
theimageasabaseballbat,asopposedtoanumbrella).
Wefindsmallerdifferencesbetweenthelanguageofmodelstrainedwithvarioustypesofharddis-
tractors. Speaker models trained with visually similar distractors achieve the highest fluency, at
2.09