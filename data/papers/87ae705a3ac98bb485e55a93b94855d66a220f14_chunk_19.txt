atasetsusedintheseexperimentsare(1)alarge
aggressivethepruningis.Thesearchisperformedoverthe
corpuscollectedforspokenlanguageunderstanding(SLU)
combinationofpropertiesandtypescreatedbycombining
and (2) a smaller corpus of linearized AMRL parses. The
thepropertycandidateswithallthepossiblematchingtypes.
SLU corpus is composed by a total of ∼2.8m unique sen-
tences.Thesesentencesspanontheorderof20domains,200
Optimization Weoptimizedtheparametersintwoways.
intents,and200slots.Thevocabularyofthisdatasetamounts
Inthefirstwefine-tunedpretrainedembeddingsfordomain
to∼150kdistinctwords.Therepresentationforthiscorpusis
andslots.Inthesecond,weperformedjointtraining,learning
showninFigure2.TheAMRLcorpusissignificantlysmaller
theSLUembeddinglayersatthesametimeastheAMRL
thentheSLUcorpusandcontainsonlyaround350kunique
ones. Each model is trained until it fully converges on the
sentencesinthelinearizedrepresentation.Thisdataconsists
trainingset,typicallythistakesaround60epochs.Weuse
ofintents,typesandproperties.Figure4showsanexample
a fixed learning rate of 0.0005 with an L2 penalty of 1e-
oftheannotationforthesamesentenceshowninFigure1.
8, and a batch size of 128 sentences each. The output of
TheAMRLcorpusspansover60linearizedintents,200prop-
each bi-LSTM layer is a vector of size 256 that is created
ertiesand200types.Thetotalvocabularyofthiscorpusis
byconcatenatingthehiddenrepresentationofforwardand
around42kwords,oneorderofmagnitudesmallerthenthe
backwardLSTMs(eachofsize128).
SLUone.Thedevelopmentsetandtestsetcontainaround
Topreventoverfittingtoourtrainingsetwetaketwomea-
48ksentencesannotatedusingAMRL.Acc