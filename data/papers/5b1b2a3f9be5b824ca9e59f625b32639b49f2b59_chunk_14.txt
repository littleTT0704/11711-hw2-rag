 {ci(cid:54)=âˆ…} Ïƒ(i) i Ïƒ(i) i
references frames, thus are more discriminative and generate where 1 is an indicator function and Dice indicates the Dice
morerepresentativeattention.Thereference-to-targetattention
loss [43]. The best assignment ÏƒË† is solved by the Hungarian
is visualized in Figure 4 (c), where the compressed version
algorithm[28].GiventhebestassignmentÏƒË†,thelossbetween
looks more informative. According to the above two factors,
ground-truth and predictions can be computed as
our robust token compression can generate a better segmenta-
tion mask. (cid:88)N
L= âˆ’logpË† (c )+1 Dice(mË†,m ), (4)
We underline that the goal of our online method is dif- ÏƒË†(i) i {ci(cid:54)=âˆ…} ÏƒË†(i) i
ferent from the offline methods [60], [23], and the network i=0
designs should be different accordingly. The offline methods Following [13], we only consider the mask loss when the
tackle sequence-to-sequence prediction. The importance of all class prediction is not the empty class.
framesisequivalent,andcompressingreferencecontextisnot 4) Instance Identity Matching
mercenary.Fortheonlinesetting,thetargetforeachprediction Unlikepreviousonlinemethods[68],[7],[66]croppingout
is only the current frame, and importance-aware compression instances and using multiple cues (e.g., class, position and
could benefit as discussed above. appearance) for matching instances across frames, we directly
2) Decoder leverage the constraint that non-empty predictions from the
same slot of the instance code have the same identity.
(Order-preserving) Order-preservinginstancecode.Oursimpleinstanceidentity
Instance codeğ‘’ matching approach takes advantage of the Lipchitz continuity
!
of our network (Appendix A) on the condition of bounded
Transformer inputs. Given the Lipchitz continuity of our network Î˜(Â·)
decoder
on the normalized image space I, the relation of input and
prediction can be represented as
Learnableinstance query
