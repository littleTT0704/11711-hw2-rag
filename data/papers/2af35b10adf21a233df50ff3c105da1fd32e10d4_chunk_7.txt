hedif-
therecording. Togetthetranscription,therecordingispassed
ferencesinthecontentofthetwodatasets. Toensurethatthe
throughASR.WeusedGoogleAPI[17]toextractthetranscrip-
differenceincontentisnotaconfoundingfactor,westudythe
tion. EachwordinthetranscriptisrepresentedasaBERT[18]
phonemedistributionsofthetwodatasets.Figure3presentsthe
contextualizedwordembedding. Theseembeddingsarepassed
phonemedistributionsofbothdatasets.Todetermineifthedif-
throughanLSTMlayer(showninblue).Fortheattentionlayer
ferencebetweenthedistributionsisstatisticallysignificant,we
werepresentthekeysastheoutputoftheconvolutionallayer;a
runaWilcoxonranktest[25].TheWilcoxonranktestisanon-
3-dimensionaloutput. Thequeryisthelasthiddenstateofthe
parametric test, used to compare two related samples. In this
LSTMpassedthroughalinearprojection.
case,thenullhypothesisH isthatthereisnodifferenceinthe
The network is optimized using the Cross-Entropy loss, 0
distributions of the phonemes under the two datasets, and the
withweightsforindividuallabelsduetotheclassimbalancein
alternativehypothesisH isthatthereisadifferencebetween
thedatasets. TheASRbasedtranscriptoftheutteranceisseg- 1
thedistributionsofthetwodatasets. Weobtainap-valueof.3,
mentedintodifferentphonemesusinganHMMbasedphoneme
thereforewithÎ± =.05,wefailtorejecttheH. Thisensures
segmentor [19]. Once the model is trained, the attended- 0
thatthedifferenceinthephonemiccontentofthetwodatasets
phonemeoutputsareinspected.
isunlikelytoaffectthedistributionoftheattended-phonemes.
4. Experiment
4.1. Dataset
We use two types of datasets; acted and natural