.ImplementationDetails
arenotcomputedintheHRPNloss. ThedefinitionofRPN
lossfollows[25]. L cls,L box,andL mask followthedefini- We compare our model with two recent state-of-the-art
tionsin[13]. L mcl iscomputedusingEquation4.3. instance segmentation models, PolarMask [32] and Mask
Thefinalmulti-tasklossofourproposedapproachiscal- R-CNN [13]. All models use ResNet-50 based FPN as
culatedusing: a backbone network. We train all the networks for 100
epochs, with a starting learning rate of 0.003 then we de-
L=L hrpn+L cls+L box+L mask+L mcl. (7) crease it to 0.001 after 10 epochs. Mini-batch SGD is
used as the optimizer with batch size equals 8. We initial-
TheHRPNandMaskR-CNNHeadcanbetrainedend- izeallthebackbonenetworkswiththeweightspre-trained
to-endtogetherwithSRN.However,inthatcase,themodel on COCO [20]. The input images are resized to have the
trainingandinferencewouldbeheavyduetothemulti-scale shorter side being 800 and the longer side less or equal to
featuresimilaritycalculation. Therefore,weonlycalibrate 1333. For testing, an NMS with threshold 0.5 is used and
confidencescoresofthemodelwhichhasthebestinstance top100detectionsareretainedforeachimage.
segmentationperformance. Forthescorerefinementprocedure,SRNistrainedusing
hard negative mining. We firstly generate 1,000 (X, X+)
4.5.Inference pairsfromdifferentvideos,andrandomlyextract5negative
samplesforeach(X,X+)pairasdescribedinSection4.3.
In test time, we use HRPN to generate building region
Wecalculatethelossof5negativesamples,andchoosethe
proposals. Thenthebuildingproposalsareusedassupervi-
top K ones with the highest losses as in [31] to optimize.
sionfordamageanchorsamplingandpro