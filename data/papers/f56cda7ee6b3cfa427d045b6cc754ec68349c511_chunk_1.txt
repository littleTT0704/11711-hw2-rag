Just Say No: Analyzing the Stance of Neural Dialogue Generation in
Offensive Contexts
AshutoshBahetiâ™¦ MaartenSapâ™£ AlanRitterâ™¦ MarkRiedlâ™¦
â™¦ GeorgiaInstituteofTechnology,Atlanta,GA,USA
abaheti95@gatech.edu,alan.ritter@cc.gatech.edu,riedl@cc.gatech.edu,
â™£ UniversityofWashington,Seattle,WA,USA
msap@cs.washington.edu
Abstract
Reddit comment from r/atheism Offensive Labels
Dialogue models trained on human conversa- USER: B he ac va eu s lie c er ne sli eg io fru os m p Geo op dl e to w dh oo wth hi an tk e t vh ee r y RO elf if ge ion usi sv e fo t lo k s
tions inadvertently learn to generate toxic re- they want are f***ingpsychotics
sponses. Inadditiontoproducingexplicitlyof-
ðŸ¤–BOT 1: Thank you for saying what I was Agree Offensive
fensive utterances, these models can also im- thinking!
plicitly insult a group or individual by align-
that's wrong, no one said they
ðŸ¤–BOT 2: Disagree Safe
ing themselves with an offensive statement. can do whatever they want.
To better understand the dynamics of contex-
ðŸ¤–BOT 3:Everyone in the world's the same Neither Safe
tually offensive language, we investigate the
stance of dialogue model responses in offen- Stance Labels
siveRedditconversations.Specifically,wecre-
Figure1: ExampleofanoffensivecommentbyaRed-
ate TOXICHAT, a crowd-annotated dataset of
dituserfollowedbythreeDialoguemodelâ€™sresponses.
2,000 Reddit threads and model responses la-
We also show the stance labels for the responses with
beledwithoffensivelanguageandstance. Our
respecttotheprecedingoffensivecomment.
analysisrevealsthat42%ofhumanresponses
agreewithtoxiccomments,whereasonly13%
agree with safe comments. This undesirable
researchhasshownthatdialoguemodelscanpro-
behavior is learned by neural dialogue