.
ALwithPAofhowtodecidewhichsub-structures
Algorithm 1 illustrates the overall AL process.
to select. Most previous work uses a pre-defined
Wefocusonsentence-leveltasks. InFA,eachsen-
fixedselectioncriterion,suchasathresholdorra-
tenceisannotatedwithafullstructuredobject(for
tio,whichmaybehardtodecideinpractice. Inthis
example,alabelsequenceorasyntaxtree). InPA,
work,weadoptaperformancepredictortoestimate
annotationgranularityisatthesub-structurelevel
the error rate of the queried instances and decide
(forexample,asub-sequenceoflabelsorapartial
the ratio of partial selection accordingly. In this
tree). Weadoptatwo-stepselectionapproachfor
way,ourapproachcanautomaticallyandadaptively
all the strategies by first choosing a batch of sen-
adjust the amount of partial selection throughout
tencesandthenannotatingwithinthisbatch. This
theALprocess.
approach is natural for FA since the original aim
Another interesting question for AL is how
istolabelfullsentences,anditisalsocommonly
to better leverage unlabeled data. In this work,
adopted in previous PA work (Mirroshandel and
we investigate a simple semi-supervised method,
Nasr, 2011; Flannery and Mori, 2015; Li et al.,
self-training(Yarowsky,1995),whichadoptsthe
2016). Moreover,thisapproachmakesiteasierto
model’s automatic predictions on the unlabeled
control the reading context size for fair compar-
data as extra training signals. Self-training natu-
isonsofdifferentstrategiesasdescribedin§3.2.
rally complements AL in the typical pool-based
Without loss of generality, we take sequence
settingwhereweassumeaccesstoapoolofunla-
labeling as an example and illustrate several key
beleddata(Settles,2009). Itisparticularlycompat-
pointsintheALprocess. Othertasksfollowsimilar
iblewithPA-basedALsincetheun-selectedsub-
treatment,with