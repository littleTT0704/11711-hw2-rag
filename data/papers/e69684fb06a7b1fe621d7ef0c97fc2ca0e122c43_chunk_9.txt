 content of the model. To
High-Diversity Few-Shot Prompting We use addressthis,wefollowtheHyDEframework(Gao
automatedpromptengineeringtogenerateadiverse etal.,2023)andfirstusegpt-3.5-turbotocreate
dataset. Weaugmenttheuser-provideddemonstra- ahypotheticalmodeldescriptiongiventheuser’s
tionexampleswitharandomsampleofpreviously instructions. Weshowanexampleofahypotheti-
generatedexamplestopromotediversityandavoid caldocumentgeneratedforaquestion-answering
generatingduplicateexamples. Withoutthisstrat- instruction in Figure 3. Using this description as
egy,120outof200generatedQAexampleswere an expanded query, we then apply the BM25 al-
duplicates;withit,only25wereduplicates. gorithmtocomputequery-modelsimilarityscores
(Robertsonetal.,1995). Toensuretheeaseofde-
TemperatureAnnealing Weadjustthesampling
ploymentoftheresultingmodel,wefilteroutmod-
temperaturefromlow(favoringdeterministicout-
elswhosesize(inbytes)exceedsauser-specified
puts)tohigh(encouragingdiverseexploration)pro-
threshold (set to 3GB by default). Using the in-
portionallytothenumberofexamplesalreadygen-
tuition that highly-downloaded models are more
erated. Thismodulationhelpspreserveoutputqual-
likelytobehighinquality,wechoosethetopmodel
itywhilegraduallyencouragingdiversity.
afterrankingby:
2https://www.deepl.com/en/docs-api BM25(query,model)·log(#ofDownloads+1).
Your task is to generate an answer to a natural themodeloutputandreferenceintheembedding
question. In this task, the input is a string that
space. We use XLM-R (Conneau et al., 2020) as
consists of both a question and a context passage.
theencoderforBERTScoretosupportmultilingual
evaluation.
LLM