2019. Parameter-efficient transfer learning for nlp.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and In International Conference on Machine Learning,
KristinaToutanova.2018. Bert:Pre-trainingofdeep pages2790–2799.
bidirectional transformers for language understand-
Daniel P Huttenlocher, Gregory A. Klanderman, and
ing. arXivpreprintarXiv:1810.04805.
William J Rucklidge. 1993. Comparing images
using the hausdorff distance. IEEE Transac-
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
tions on pattern analysis and machine intelligence,
Kristina Toutanova. 2019. BERT: Pre-training of
15(9):850–863.
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference
Ganesh Jawahar, Benoît Sagot, and Djamé Seddah.
of the North American Chapter of the Association
2019. What does bert learn about the structure of
for Computational Linguistics: Human Language
language? InProceedingsofthe57thAnnualMeet-
Technologies, Volume 1 (Long and Short Papers),
ingoftheAssociationforComputationalLinguistics,
pages4171–4186,Minneapolis,Minnesota.Associ-
pages3651–3657.
ationforComputationalLinguistics.
Phillip Keung, Yichao Lu, György Szarvas, and
Zi-Yi Dou, Keyi Yu, and Antonios Anastasopoulos. Noah A. Smith. 2020. The multilingual Amazon
2019. Investigating meta-learning algorithms for reviews corpus. In Proceedings of the 2020 Con-
low-resource natural language understanding tasks. ferenceonEmpiricalMethodsinNaturalLanguage
InProceedingsofthe2019ConferenceonEmpirical Processing(EMNLP),pages4563–4568,Online.As-
Methods in Natural Language Processing and the sociationforComputationalLinguistics.
Yu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li, Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping
Yuyan Zhang, Mengzhou