ner
Reddits: threadsfromtoxicSubRedditsidentified et al., 2020) and later finetuned on Blended Skill
in previous studies (Breitfeller et al., 2019) and Talk(BST)dataset(Smithetal.,2020). TheBST
Redditcommunity-reports.6 (AppendixB). datasetcontains5Kpoliteconversationsbetween
We are most interested in responses generated crowdworkers which aims to blend 3 conversa-
by dialogue models in offensive contexts. How- tionalskillsintoonedataset1)engagingpersonal-
ever, offensive language is rare in a random sam- ity (Zhang et al., 2018b; Dinan et al., 2020b), 2)
ple (Davidson et al., 2017; Founta et al., 2018). empatheticdialogue(Rashkinetal.,2019)and3)
Hence,weimplementatwo-stagesamplingstrat- knowledgeincorporation(Dinanetal.,2019b).
egy: (1) Random sample - From both sources, Weonlyincludethefirsttwomodelsduringan-
randomlysample500threads(total1000). (2)Of- notation but compare our controlled text genera-
fensivesample-Fromremainingthreadsinboth tion models against all three dialogue models in
sources,sampleadditional500threads(total1000), §6.1. ResponsesforDGPTandGPT-3aregener-
whose last comment is predicted as offensive by ated on the comments part of the threads7 using
a classifier. Specifically, we used high-precision nucleussampling(p = 0.9)(Holtzmanetal.,2019).
predictions(probability≥ 0.7)fromaBERT-based Blenderbotusesbeamsearchwithbeamsize= 10
offensivecommentclassifier(Devlinetal.,2019) andmin. beamsequencelength= 20togenerate
that was fine-tuned on the Social Bias Inference responses.
Corpus(Sapetal.,2020). Thisclassifierachieves
≈ 85.4OffendlabelF1ontheSBICdevset. 3.2 TOXICHATCorpusStatistics
Werecruitedcrowd-workersfromtheAmazonMe