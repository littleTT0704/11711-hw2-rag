
,cipot
hcae
roF
.tesatad
noitamitse
ecnaveler
fo
egasu
dna
sliateD
:1.5
elbaT
.stnemirepxe
ruo
ni
desu
si
cipot
eht
woh
dna
,ot
dengissa
saw
cipot
eht
rotatonna
eht
,steggun
tnaveler
fo
rebmun
eht
,steggun
54 CHAPTER 5. INTRINSIC EVALUATION
Markup Sentence Token
Rel. B Irrel. B Rel. B Irrel. B Rel. B Irrel. B
Rel. A 1347 198 3715 323 89277 5612
Irrel. A 36 9926 157 13491 4085 159545
Cohen’s κ 0.9085 0.9218 0.9190
Table 5.2: Inter-annotator agreement on the topic Mother Teresa. The agreement be-
tween annotators A and B was evaluated at the level of markup-based text nuggets,
sentence-level nuggets and nuggets consisting of individual tokens. For each granular-
ity, the table shows the number of instances that were labeled as relevant or irrelevant
by the annotators, and Cohen’s κ coefficient.
Markup Sentence Token
Rel. C Irrel. C Rel. C Irrel. C Rel. C Irrel. C
Rel. A 1739 99 6237 158 164950 3253
Irrel. A 190 13165 428 16656 13015 179269
Cohen’s κ 0.9124 0.9379 0.9097
Table 5.3: Inter-annotator agreement on the topic Iran-Iraq War. The agreement be-
tween annotators A and C was evaluated at the level of markup-based text nuggets,
sentence-level nuggets and nuggets consisting of individual tokens. For each granular-
ity, the table shows the number of instances that were labeled as relevant or irrelevant
by the annotators, and Cohen’s κ coefficient.
if they appear in long passages of otherwise irrelevant text. Here the annotation in-
terface helps by highlighting topic