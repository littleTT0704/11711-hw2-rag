torunthefourLMbaselinesonthecomplete
dataset. Weusedan8-coreCPUIntel(R)Core(TM)i7-10510U@1.80GHz. Andwespend600USD
ontheusageoftheOpenAIAPI.
Evaluation Metrics For most standard metrics in our experiments, we use the
classification_reportfunctionbythesklearnlibrary(Pedregosaetal.,2011).6
OtherSettings Inadditiontothezeroshotresultsreportedinthemainpaper,wealsoexperiment
withthefew-shotsetting. Previousworkperformsfew-shotpromptingwithGPT,asithasdemon-
stratedstrongperformanceacrossawiderangeofNLPtasks(Brownetal.,2020;Zellersetal.,2020;
SchickandSch√ºtze,2020;Malkinetal.,2021;LucyandBamman,2021). Wetryrandomlyselecting
someexamplestoshowtoGPTbeforequestioningthetargetscenario,buttheperformanceisaffected
alotbytherandomnesssuchastheorderofexamples(e.g.,thesimilarityofthelastexampleandthe
scenariowhichwequestionabout),andalsolimitedbythesmallsizeofourchallengeset. Hence,
inthescopeofthispaper,wedidnotadoptthefew-shotsetting,butonlyusetheentiresetasthe
challengeset.
B.2 PromptTemplates
WelistthepromptsweuseinTable6. Wealsoopen-sourceanexamplepromptathttps://beta.
openai.com/playground/p/UPUm3zmtLbuoUleX87GqCoJx?model=text-davinci-002.
B.3 ParaphrasesofthePrompt
GPT-3andInstruct-GPT:
5https://beta.openai.com/overview
6https://scikit-learn.org/stable/modules/generated/sklearn.metrics.
classification_report.html
24
Model ContentofPrompt
BERT-base, Readthesituationandanswerthequestion.
BERT-large, Situation:[Scenario]
RoBERTa-