 Wereportthequalityofknowledge
morehelpfulknowledge. Wealsoanalyzedthenon-
statements along four axes: (1) Grammaticality:
selectedknowledgeandfoundthatthesestatements
whetheritisgrammatical;(2)Relevance: whether
haveslightlylowerfactualityandhelpfulnessthan
itisrelevanttothetopicorconceptsmentionedon
theselectedknowledge.
thequestion;(3)Factuality: whetheritis(mostly)
factuallycorrect; and(4)Helpfulness: whetherit
helpsansweringthequestioninaneitherdirector
indirectway,andmayfallintooneofthethreecat-
4.5 QualitativeExamples
egories: helpful(i.e. supportsthecorrectanswer),
harmful(i.e. negatesthecorrectanswerorsupports
anincorrectanswer),orneutral(neitherhelpfulnor Table 5 shows a few examples where the gener-
harmful). ThesemetricsareadaptedfromShwartz atedknowledgerectifiesmodelprediction. Dueto
etal.(2020)andaredefinedinAppendixA.3. spaceconstraintsweonlyshowtheselectedknowl-
edge (§2.2) for each question. In all examples,
Fromeachdataset,wesampleupto50selected
themodelwithoutpromptedknowledgeassignsa
knowledge (§2.2) that change the correctness of
higher score to an incorrect answer than the cor-
T5-11b’sprediction(i.e. rectifiesmodelprediction
rectanswer,whilewithknowledgeprompting,the
fromwrongtoright,ormisleadsmodelprediction
correct answer is assigned a much higher score.
fromrighttowrong). Theknowledgearelabeled
Prompting with generated knowledge can trans-
bytwoNLPexpertsandamoderatelevelofagree-
formcommonsensereasoningintoexplicitreason-
mentwasreached(FleissKappaκ = 0.57(Landis
ing procedures such as paraphrasing, induction,
and Koch, 1977)). To ensure objectivity, it is not
deduction, analogy, abductive reasoning, logical
revealedtotheannotatorswhethertheknowledge
elimination,negation,andnumericalreasoning.
rectifiesorm