A-11b-ft Unicorn-ft T5-11b UQA-11b-ft
dev test test dev dev dev test dev test dev test
core all
(∅)Vanillabaseline 67.5 70.23 64.05 39.89 85.18 69.9 70.2† 48.16 44.89 81.75 76.74
(R)Randomsentences 68.5 – – 21.79 85.42 70.37 – 49.35 – 82.18 –
(C)Contextsentences 70.5 – – 42.51 85.34 70.92 – 55.83 – 82.61 –
(T)Template-based – – – 45.37 – – – – – – –
(IR)Retrieval-based – 70.41 65.10∗∗ – – 74.0 73.3†† 76.89 – 90.06 –
(A)Answers 73.0 – – 51.84 84.93 69.22 – 52.48 – 81.53 –
(K)Ours 78.0 79.24 72.47 47.26 85.34 72.37 73.03 58.32 55.00 84.02 80.33
prev.SOTA(noIR) – 72.61 66.18∗ – 79.1(test)# 69.9 70.2† – – 81.75 76.74‡
Few-shotGPT-3Infer. 60.5 – – – 71.58 53.80 – – – 66.09 –
Table3: Experimentalresultsofapplyingdifferentknowledgegenerationmethodsonvarioustasksandinference
models. T5-11bisthezero-shotinferencemodel,whereasotherinferencemodelsarefinetunedbasedonT5-11b.
We bold the best and underline the second best numbers. Previous SOTA and retrieval-based methods are also
basedontheinferencemodelintheircorrespondingcolumn: *T5-11b1.1+digits(SubmissionbyISIWaltham);
** T5-11b + IR (Yan, 2021); # UQA-11b-ft (Khashabi et al., 2020) (SOTA of single-model methods without
referencingConceptNet);†Unicorn-ft