etafixed-sizedencodingvectore. Finally,we
fortrainingismulti-labelbinarycross-entropy: l
obtaintheeventualembeddingc = e jjg ofcodel bycon-
l l l
XL catenating e l with g l which is the embedding of l produced
L (y;y^)=(cid:0) [y log(y^)+(1(cid:0)y )log(1(cid:0)y^)] (4) by the graph encoding network. c contains both the latent
BCE l l l l l
semanticsofthedescription(ine )aswellastheICDhierar-
l=1 l
chyinformation(ing ).
l
As mentioned above, the distribution of ICD codes is ex-
tremelylong-tailed. Tocounterthelabelimbalanceissue,we Keywords reconstruction loss. To ensure the generated
adopt label-distribution-aware margin (LDAM) [Cao et al., feature vector f~ captures the semantic meaning of code l,
l
4020
ProceedingsoftheTwenty-NinthInternationalJointConferenceonArtificialIntelligence(IJCAI-20)
we encourage f~ to reconstruct the keywords extracted from approximately58,000hospitaladmissionsof47,000patients
l
theclinicalnotesassociatedwithcodel. whostayedintheICUoftheBethIsraelDeaconessMedical
For each input text x labeled with code l, we extract the Center between 2001 and 2012. Each admission record has
label-specifickeywordsetK = fw ;w ;:::;w gastheset a discharge summary that includes medical history, diagno-
l 1 2 k
ofmostsimilarwordsinxtol, wherethesimilarityismea- sisoutcomes,surgicalprocedures,dischargeinstructions,etc.
suredbycosinesimilaritybetweenwordembeddinginxand Eachadmissionrecordisassignedwithasetofmostrelevant
label embedding v. Let Q be a projection matrix, K be the ICD-9codesbymedicalcoders. Thedatasetispreprocessed
l
setofallkeywordsfromallinputsand(cid:25)((cid:1);(cid:1))