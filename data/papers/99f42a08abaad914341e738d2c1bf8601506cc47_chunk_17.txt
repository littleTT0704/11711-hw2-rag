 is n, m m− +1 1θ12 mm +−1 1θ12
W1 W2 W1 W2
deep metric learning. From Fig. 2(b), one can observe that
largersputsmorefocusonthehardsamples,sincetheloss
ratio between hard and easy samples increases. Finding a
goodsessentiallycanbeviewedassearchingforasuitable
balance between easy and hard samples in hyperspherical mθ1=θ2 θ1=mθ2 θ1=θ2/m θ1/m=θ2
FRmethods,e.g.,[3],[4],[5],[9]. SphereFace, SphereFace-R v1 SphereFace-R v2
Tosummarize,Eq.(6)essentiallythrowsawaytheinfor-
(c) Multiplicative Angular Margin
mationencodedinthefeaturemagnitudex.Despitethetwo
major advantages that ease the training of hyperspherical Fig. 3. An intuitive comparison among no angular margin (e.g., [9],
FR methods, it remains an open problem whether it is [30]), additive angular margin (CosFace [3], [4] and ArcFace [5])
andmultiplicativeangularmargin(SphereFace,SphereFace-Rv1and
beneficialtocombinefeaturemagnitudetotraining.Feature
SphereFace-Rv2).
magnitude is closely related to image quality and semantic
ambiguity [8], [72], and such information intuitively seems
useful to distinguish different faces. However, training activation function. SphereFace adopts the same paradigm
hyperspherical FR methods without feature normalization byconstructingthefollowingtargetangularfunctionψ(θ):
generallyyieldsinferiortrainingstabilityandgeneralization (cid:20)kπ (k+1)π(cid:21)
performanceinpractice.Inordertoexplorewhetherfeature ψ(θ)=(−1)kcos(mθ)−2k, θ ∈, (9)
m m
magnitudeisindeedhelpfulornot,weconsidertoconstrain
thefeaturemagnitudeviaasoftregularizationinSection4.2. where