) withMGS-SBLEU.Fortrainingfromscratch,weselect(cid:11)1.0
tradesperplexityfortasklossminimizationinPGandMRT, andnoise1.0.AllmodelsareselectedbyvalidationBLEU
while MGS finds solutions that are much more stable in usingbeamsearchwithwidth5.
terms of perplexity, as shown in Figure 3. Our conclusion
isthatMGSisanattractivealternativetomixingminimum
Results. Resultsforthebaseline,MGSfine-tunedmodels,
risktrainingandpolicygradientwithmaximumlikelihood
andmodelstrainedfromscratchwithMGSareinTable4,
trainingfortheproblemoftextgeneration.
along with prior work that fine-tuned with minimum risk
traininginTable5.
MGS candidate analysis. First, we perform an ablation Thefine-tunedMGS-SBLEUmodelimprovesBLEUover
oftheproposaldistributionq,whichisamixtureoftwo thebaselineMLEmodel(+0.32test)atacomparablelevel
MGS
components.Wecompareagainstonlyusingthezero-mean totheimprovementfromfine-tuningwithMRT(+0.24and
(q zero)orMLE-mean(q MLE)componentsasproposals,and +0.50test),withMGS-METEORshowingasimilargain.All
findthatthetraininglossonlydecreaseswhenbothcompo- ofthefine-tunedMGSmodelsimprovethesequence-level
nentsintheq MGSmixtureareincluded.Thetasklossonthe tasklossesthatarecomputedwithgreedydecoding(SBLEU,
validationset(seeAppendix)isanalogous. METEOR,EDIT),witheachmodelachievingthebestscore
Next,weinspecthowthepooledtasklossvariesbetween on its associated task loss. MGS-EDIT shows the largest
thesampledcandidates.Thestandarddeviationincandidate difference,underperformingonBLEUyetoutperformingthe
weightsw((cid:1) k)duringtrainingfallwithin0.35-0.45,imply- baselinebyafullpointonEDIT.
ingthateachpro