ER-PRESERVINGPROPERTY.
IMPACTOFNUMBEROFINSTANCEQUERIESONYOUTUBE-VIS-2019
VALIDATIONSET.
WeightW AP AP50 AP75 AR1 AR10
(cid:37) 40.1 63.2 42.1 40.3 46.3
(cid:33) 40.8 63.4 43.5 42.4 46.7
TABLEVIII
IMPACTOFPIXEL-WISEWEIGHTW ONTHETOKENFUSION.
As the videos in Youtube-VIS dataset is of 6 FPS, the latency
of our method is 0.171 s, while the latency of the offline Fig. 9. Illustration of fired slots and class correlation of instance code.
Theheatmapisnormalizedbyeachclass.
method IFC with a clip containing N = 36 frames is 6.4
f
s (FPS =89.4 reported in [13]).
model
As shown in Table I, we compare both FPS and latency of
transformer decoder respectively. To directly fuse features in
our method and previous methods. Our method achieves the
transformer encoder, we compute reference tokens similarly
best trade-off of accuracy and latency among online methods.
to the target token. To fuse features in transformer decoder,
Analysisoffiredslotandclasscorrelationofinstancecode. we extract reference tokens O(cid:48) by separate transformer
ref
We consider the slot is fired it has a class probability larger encodersandconcatenatethembeforethetransformerdecoder.
than0.4andonlykeeppredictionsinfiredslotsasfinaloutput. As shown in Table IV, both baseline settings will result
As shown in Figure 9, we visualize the correlation of fired in a plummet in performance. Two reasons may account
slots in instance code and each class. We noticed that most for the decrease. First, the instance position and appearance
of objects are predicted from the same slot while, for several in the target frame differ from those in reference frames,
classes, e.g., person, duck and earless seal, they are predicted which can mislead the network if giving reference frames the
in stand-alone slots. Those classes are either most commonly same importance as the target frame. Second, in transformer
appearedorchallengingclassesinthedat