 generative, discriminative, and energy-based models. Ma et al. (2022)
presented parsimony and self-consistency as the guiding principles for learning from data. Those unified
treatments shed new light on the sets of originally specialized methods and foster new progress in the
respective fields. LeCun (2022) presented a modeling architecture to construct autonomous intelligent agents
that combines concepts such as world model and hierarchical joint embedding. Our standardized formalism of
48
Harvard Data Science Review â€¢ Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
the learning objective is complementary and offers a general framework for training the relevant model
architectures. The framework also covers the key learning ingredients mentioned in LeCun (2022), including
the self-supervised learning (Section 4.1.2) and intrinsic motivation (Section 4.3.2).
Integrating diverse sources of information in training has been explored in previous work, which is often
dedicated to specific tasks. Roth (2017) presented different ways of deriving supervision signals in different
scenarios. Zhu et al. (2020) discussed the integration of physical and other knowledge in solving vision
problems. The distant or weak supervision approaches (Mintz et al., 2009; Ratner et al., 2017) automatically
create (noisy) instance labels from heuristics, which are then used in the supervised training procedure. The
panoramic learning we discussed here makes use of broader forms of experience not necessarily amenable to
be converted into supervised labels, such as reward, discriminator-like models, and many structured
constraints. The experience function f(y) offers such flexibility for expressing all those experiences.
11. Future Directions
We have presented a standardized machine learning formalism, materialized as the standard equation of the
objective function, that formulates a vast algorithmic space governed by a few components regarding the
experience, model fitness measured with divergence, and uncertainty. The formalism gives a holistic view of
the diverse landscape of learning paradigms, allows a mechanical way of designing ML approaches to new
problems, and provides a vehicle toward panoramic learning that integrates all available experience in building
an AI agent. The work shapes a range of exciting open questions and opportunities for future study. We discuss
a few of these directions below.
Continual learning in complex dynamic environments.