pled segmentation map be S
t
∈ RCo×Ho×Wo
where C, H and W are the dimension, height and width
o o o
of the upsampled segmentation map. After that, we leverage
dynamic convolution [25] to obtain instance masks M from
t
instance code. In particular, dynamic filters θ
t
∈ RCo×N are
learned from instance code by two fully connected layers.
(c) Attention map (d) Predicted mask
The mask prediction M
t
∈ RN×Ho×Wo can be computed as
Fig.4. VisualizationofintermediatecomponentsinRCF.Giventhehard M t =θ tTS t.
cases(a)withconfusingbackground,ourdesignwithtokencompressioncan 3) Loss Function
generatemorerepresentativeattentionmaps(c)andgetbetterresult(d).
We assign each prediction with a ground-truth label then
applyasetoflossfunctionsbetweenthem.Givenasetofpre-
token set (with size |C(cid:48) ×K ×K|) of references, the target dictions {pˆ i(c),mˆ i}N
i=0
and a set of ground-truth {c i,m i}N
i=0
tokens(|C(cid:48)×H×W|)dominatetheattentioninthetransformer (padded with ∅), we search for an assignment σ ∈ S
N
encoder. We thus get larger weights for target values of the with highest similarity, where p i(c) is the probability of class
compressed tokens than the uncompressed counterpart. The c (including ∅) and m i is the mask of the i-th instance
target-to-target attention map in Figure 4 (c) shows that target respectively. S N is a set of permutations of N elements. The
tokens in the transformer play more important roles than that similarity can be computed as
withoutcompression.Besides,thecompressedtokensfilterout Sim=1 (cid:2) Dice(m,mˆ )+pˆ (c )(cid:3), (3)
irrelevant or noisy pixels and contain global information of