-connected layer. During train-
ing, asetofT observationsfromtheexpertdemonstration u t =[v t;xˆ t;a t−1],
(2)
isencodedasV = (cid:104)v,v,...,v (cid:105), wherev isthevisual
1 2 T t h =LSTM(u,h )
t t t−1
featurevectorattime-stept.
where[;]denotesconcatenation.Thehiddenstateh isused
Language encoding. Given a natural language goal t
toobtaintheattentionweightedlanguagefeaturexˆ.
G = (cid:104)g,g,...g (cid:105) of L words, and step-by- t+1
1 2 Lg g
step instructions S = (cid:104)s,s...s (cid:105) of L words,
1 2 Ls s
we append them into a single input sequence X = Action and mask prediction. The agent interacts with
(cid:104)g 1,g 2,...g Lg,<SEP>,s 1,s 2...s Ls(cid:105) with the <SEP> to- theenvironmentbychoosinganactionandproducingapix-
ken indicating the separation between the high-level goal elwisebinarymaskindicatingaspecificobjectintheframe.
and low-level instructions. This sequence is fed into a bi- AlthoughAI2-THORsupportscontinuouscontrolforagent
directional LSTM encoder to produce an encoding x = navigationandobjectmanipulation,wediscretizetheaction
{x 1,x 2,...,x Lg+Ls}foreachwordinX. space. The agent chooses from among 13 actions. There
are 5 navigation actions: MoveAhead, RotateRight,
Attention over language. The agent’s action at each RotateLeft, LookUp, and LookDown together with
timestepisbasedonanattentionmechanismweightingto- 7 interaction actions: Pickup, Put, Open, Close,
kens in the instruction. We perform soft-attention on the ToggleOn,ToggleOff,andSlice.Interactionactions
languagefeaturesxtocomputethe