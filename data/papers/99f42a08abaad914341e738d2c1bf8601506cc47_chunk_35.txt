 only critical difference lies in the
TABLE3
weighting factor ρ i = 1+(cid:80)e ix (cid:54)=p y(Q ex( pθ (y Q,θ (i θ, ys,,m θi),s),m)) in Eq. (20), VaryingmfornofeaturenormalizationonVGGFace2(%).
where Q(θ y,θ i,s,m) varies for different loss functions in m SphereFace SphereFace-Rv1 SphereFace-Rv2
the forward pass. This finding suggests that once CGD is
1.1 53.09 55.18 52.71
applied, the gradient of every loss function in hyperspher-
1.2 55.36 55.97 56.08
ical FR can be viewed as a particular weighting strategy
1.3 55.32 51.11 50.19
to combine Q(cid:48)(θ y,θ i,s,m) of different i (cid:54)= y. In other
1.4 44.95 43.04 37.78
words,onlytheweightingfactorsρ i,∀iinthegradientL(cid:48)
s
=
1.5 34.23 31.54 30.94
(cid:80) i(cid:54)=yρ i ·Q(cid:48)(θ y,θ i,s,m) will differ for different loss func-
tions. Therefore, the design space for loss functions can be
areenabledwhenNFNandSFNareused.WeuseSFNet-20
switchedfromfindingQ(θ y,θ i,s,m)tofindingaweighting
andSFNet-64intheablationandexploration,whileSFNet-
strategyforcombiningthegradientsQ(cid:48)(θ y,θ i,s,m),∀i(cid:54)=y.
64 and IResNet-100 are adopted in large-scale benchmarks
Such a gradient weighting perspective reveals that search-
toachievestate-of-the-artperformance.
ingforsuitablemandmisequivalenttodesigningagood
Training