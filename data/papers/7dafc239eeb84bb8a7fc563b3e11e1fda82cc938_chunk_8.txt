 2 RN(cid:2)dc. Thenthelabel-wiseattentionfea- tion on the code description, we use a label encoder func-
turea l 2Rdforlabelliscomputedby: tion C : L 7! C that maps the code description to a low-
dimension vector c. We denote c = C(l). The generator,
s l =softmax(tanh(H (cid:1)W a>+b a)(cid:1)v l); a l =s> l (cid:1)H (1) G : Z(cid:2)C 7! F, takes in a randl om Gaussian noise vector
where s is the attention scores for all rows in H and a is z 2Zandanencodingvectorc2Cofacodedescriptionto
l l
the attended output of H for label l. Intuitively, a l extracts generatealatentfeaturef~ l = G(z;c)forthiscode. Thedis-
the most relevant information in H about the code l by us- criminatororcritic,D :F(cid:2)C7!R,takesinalatentfeature
ingattention. EachinputthenhasintotalLattentionfeature vector f (either generated by WGAN-GP or extracted from
vectorsforeachICDcode. realdataexamples)andtheencodedlabelvectorctoproduce
a real-valued score D(f;c) representing how realistic f is.
Multi-labelclassification. Foreachcodel,thebinarypre-
TheWGAN-GPlossis:
dictiony^ isgeneratedby:
l
L =E [D(f;c))](cid:0)E [D(f~;c))]+
f
l
=recti(cid:12)er(W o(cid:1)a l+b o); y^
l
=(cid:27)(g l>(cid:1)f l) (2) WGAN (f;c)(cid:24)P Sf;c (f~;c)(cid:24)P Sf~;c
(cid:21)(cid:1)E [(jjrD(f^;c