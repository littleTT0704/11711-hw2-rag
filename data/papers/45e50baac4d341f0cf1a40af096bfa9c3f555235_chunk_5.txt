,RACE,andRELIGION. Whilethe
(Kuduguntaetal.,2021),andadaptivecomputation
setofidentitiescoveredbythisdatasetisfarfrom
(Elbayadetal.,2020)tofuturework.
complete, it serves as a useful indicator as these
modelsareencodingcommonsocialbiases;how- Sincemodelcompressionaffectsmodelsize,we
ever,thelackofbiasindicatedbythisbenchmark are particularly interested in understanding how
doesnotimplyanoveralllackofinappropriatebias pretrainedmodelsizeimpactsmeasuresofsocial
in the model, for example with respect to other bias, and how that changes as a function of how
groups. We briefly describe each dataset below; well the model fits the data. We are also inter-
refertotheoriginalworksformoredetail. ested in investigating how the number of tokens
observedduringtrainingimpactsalloftheabove.
CrowS-Pairs iscomposedofpairsofminimally We experiment with three different base LLMs:
distantsentencesthathavebeencrowdsourced. A BERT(Devlinetal.,2019),RoBERTa(Liuetal.,
minimally distant sentence is defined as a small 2019), and Pythia (Biderman et al., 2023), with
number of token swaps in a sentence, that carry uncompressedmodelsizesrangingfrom70Mpa-
differentsocialbiasinterpretations. Anunbiased rametersto6.9Bparameters. BERTandRoBERTa
2664
Model Params Size(MB) GENDER RACE RELIGION
BERTBase 110M 438 57.25 62.33 62.86
+ DYNAMIC PTQ int8 110M 181 57.25 0.19 62.14 9.53 46.67
↓ ↓
+ CDA (Websteretal.,2020) 110M 1.14 56.11 5.63 56.70 2.86 60.00
↓ ↓ ↓
+ DROPOUT(Websteretal.,2020) 110M 1.91 55.34 3.30 59.03 7.62 55.24
↓ ↓ ↓
+ INLP (Ravfogeletal.,2020) 110