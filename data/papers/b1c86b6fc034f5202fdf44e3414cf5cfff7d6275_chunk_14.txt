pairsthatarenotreallythe"same"subclass. Thiscanexplainwhyweseesuch
poorperformancemetricscomparedtotheMLPwithnoontologyinformation.
7
WeightedAP WeightedAUC
Model SubclassLevel SuperclassLevel SubclassLevel SuperclassLevel
MLP 0.4509 0.7056 0.8706 0.8556
Siamese+Ontology 0.3653 0.3876 0.8055 0.6505
Siamese+GCN 0.4285 0.6790 0.8460 0.8280
MLP+GCN 0.4590 0.7117 0.8751 0.8602
Table1: mAPandAUCResultsofdifferentmodels
Figure5: mAPacrossdifferentlowlevellabels
4.4 PerformanceofSiamese-GCNModel
TheextensionoftheSiamesemodelreplacestheOntologylayerwithaGraphConvolutionnetwork
toembedontologyinformation. WetrainedthemodelbyAdamoptimizerforabout30epochs. We
use2LinearLayerasthenodeembeddingofGCNandapply2LayerGCN.Theperformanceis
sensitivetothehyper-parameters位, 位 and位 ofthelossfunctionbecauseitwouldamplifyor
1 2 3
reducelearningratefordifferentlossterms. TheTable3showshowdifferenthyper-parameterscould
affecttheperformance. Oneinterestingobservationisthatthegreater位isnotnecessaryequaltothe
greaterlearningrate.
Inthisexperiment,wealsocanseethattheSiamesenetworkwithGCNcouldtoleratethenoisesin-
troducedfromweaklylabelleddatabetterthanthebaselineSiamesewithanun-trainableOntological
Layer. ThissuggeststhattheGCNcanbettercapturetheontologyhierarchyinthemodelandthatit
canevenovercomethenoiseintroducedbyattemptingtofindpairsfortheSiamesenet. Overall,the
evaluationmetricsforthismodelareclosetothebaselineMLPwithnoontologyinformation.
4.5 PerformanceofMLP-GCNModel
To study the utility of the Siamese net we also