hebestperformanceonthistestset. OnthePM85
and PM85. We generated outputs with our model, MGM,
dataset, our proposed model outperforms all methods and
and MODNet without additional inputs. However, BGM-
gets the SOTA result. In the D646 benchmark, we again
V2methodneedsthesamebackgroundoftheinputimage
outperformtheMODNet, MGM,andBGM-V2. TheFBA
and FBA requires trimap for the corresponding input data.
reachesthebestperformance. However,itisslightlybetter
For BGM-V2, we provided the background image that we
thanourmethodandourresultsarequiteacceptablewhen
used during the preparation of the test data. Since D646,
compare with the FBA. Please note that since each study
PM85, and PPM-100 datasets do not include trimaps, we
createsthetestsetupwithadifferentsetofbackgroundim-
created different trimaps by using erosion and dilation op-
ages,thepresentedscoresmayshowdifferences.
erations to evaluate FBA and present the best scores. Ac-
cordingtothefigure,ourresultsarealmostthesameasthe
As previously stated, while our approach does not take
groundtruthdata, especiallyforthechallengingpart, such
anyinputinadditiontotheoriginalimage,theFBAmethod
as hair. Besides, although all models perform quite well,
takestrimapandtheBGM-V2methodtakesthebackground
thedifferencesbetweenthemareinthedetails,particularly
of the original input image that does not contain the sub-
aroundthebordersofthesubjects. Moreover,werandomly
ject itself. However, they are too sensitive to these addi-
collectedimagesfromthewebandwerunourmodelover
tionalinputs. Forinstance,ifthereareanydissimilaritiesin
themtopresenttheperformanceofthesystemonthereal-
thebackgroundimagesuchastranslation,BGM-V2cannot
worldimages. Thecorrespondingoutputsarepresentedin
produce a proper output and generates a completely cor-
Figure 3. The Alpha column contains the predicted alpha
ruptedpredictioninstead. Similarly,FBAissensitivet