 different types of language that occur when asking humans to describe the action
versus using templated language.
Before After Template Human
place yellow block on the red stackwarmcolors
block
Unknownconcepts
stack the red block on the moveredrighttosamexandyaxisas
greenone green
CoordinateSystem
placegreenontheyellowone move the green box forward three
spaces
Spatiallanguage
stacktheblueoneonyellow take the blue block in your hand and
raiseitabovethetable.movetheblock
backandtotherightuntilitisdirectly
abovetheyellowblock.lowertheblue
blockdownontotheyellowblockand
releaseit
Latentdetailsabouthandmovement
put the yellow one on the movetheyellowcubetotherightuntil
greenblock itisontopofthegreencubewiththe
front half of the yellow cube touching
thefarhalfofthetopofthegreencube
Denotesspecificnuance
TABLEA1:Abovearetheinitialandfinalvisualframesforeachtask,nexttothetemplatelanguageandhumandescriptions
forexamplesfromourtrainingset.Theseexamplesillustratewhyitcanbesodifficultforamodeltopredictspecificmotions
that correspond to a particular natural language command, and further justify our approach for visualizing robot actions
before execution. Specific reasons why each description is difficult to ground are indicated in bold
A-II. PREDICTIONRESULTS
OneadvantageofproposedDREAMCELLsystemisthatitallowsustogeneratemultiplehallucinationsofpossiblefutures.
Here, we show example plans generated from four unseen test environments, given a natural-language prompt. We show
predictions for the first four high level actions: align, grasp, lift, and move to. Environments and trials were chosen
at random, and should be indicative of performance on the prospection problem.
Prompt: “put red on blue”
1.
2.
3.
4.
Fig. A1: Example showing predicted plans given straightforward language.
Prompt: “put blue on the other one”
1.
2.
3.
4.
Fig. A2: Example showing predicted plans given underspecified language. The system always picks up the blue block, and
