Statistical Source Expansion for Question Answering
Nico Schlaefer
CMU-LTI-11-019
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
5000 Forbes Ave., Pittsburgh, PA 15213
www.lti.cs.cmu.edu
Thesis Committee:
Eric Nyberg (Chair)
Jamie Callan
Jaime Carbonell
Jennifer Chu-Carroll (IBM T.J. Watson Research Center)
Submitted in partial fulfillment of the requirements
for the degree of Doctor of Philosophy
In Language and Information Technologies
Â© 2011 Nico Schlaefer
ii
Abstract
A source expansion algorithm automatically extends a given text corpus with re-
lated information from large, unstructured sources. While the expanded corpus is not
intended for human consumption, it can be leveraged in question answering (QA) and
other information retrieval or extraction tasks to find more relevant knowledge and
to gather additional evidence for evaluating hypotheses. In this thesis, we propose a
novel algorithm that expands a collection of seed documents by (1) retrieving related
content from the Web or other large external sources, (2) extracting self-contained
text nuggets from the related content, (3) estimating the relevance of the text nuggets
withregardtothetopicsoftheseeddocumentsusingastatisticalmodel, and(4)com-
pilingnewpseudo-documentsfromnuggetsthatarerelevantandcomplementexisting
information.
In an intrinsic evaluation on a dataset comprising 1,500 hand-labeled web pages,
the most effective statistical relevance model ranked text nuggets by relevance with
81% MAP, compared to 43% when relying on rankings generated by a web search en-
gine, and 75% when using a multi-document summarization algorithm. These differ-
ences are statistically significant and result in noticeable gains in search performance
in a task-based evaluation on QA datasets. The statistical models use a compre-
hensive set of features to predict the topicality and quality of text nuggets based on
topic models built from seed content, search engine rankings and surface characteris-
tics of the retrieved text. Linear models that evaluate text nuggets individually are
compared to a sequential model that estimates their relevance given the surrounding
nuggets. The sequential model leverages features derived from text segmentation al-
gorithms to dynamically