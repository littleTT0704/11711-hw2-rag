 We vary m an optimal margin hyperparameter m that leads to the
from1.1to1.5andreportthecorrespondingAUC-0.0005in best performance for each scale s. If m is smaller than
Table3.Itcanbeobservedthatsmallmargin(e.g.,1.1)results the optimal value, the performance is usually improved as
ininferiorperformance,becausethelearnedfeaturesarenot m increases. If m is greater than the optimal value, the
sufficientlydiscriminative.Ontheotherhand,incorporating performance is usually decreased as m increases. Second,
a margin that is too large can not produce good results as for larger s, the corresponding optimal m will also tend to
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 12
TABLE10
EvaluationonMegaFace,IJB-BandIJB-C.WeuseSFNet-20asthebackbonearchitectureandVGGFace2asthetrainingsetforallthecompared
methods.Resultsarein%andhighernumberindicatesbetterperformance.
MegaFace IJB-B IJB-C
(refined) 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR
Method FN m s t Iden. Veri. 1e-6 1e-5 1e-4 top1 1e-2 1e-1 1e-6 1e-5 1e-4 top1 1e-2 1e-1
NormFace[9] HFN 0.35 40 - 76.81 82.18 32.53 68.20 82.24 91.17 58.85 78.99 65.64 76.31 86.15 92.09 70.60 81.43
CosFace[3],[4] HFN 0.35 40 - 81.38 85.73 40.77 73.66 85.51 91.96 67.97 82.77 70.43 80.21 88.75 93.09 75.36 84.90
ArcFace[5] HFN 0.4 40 - 83.80 87.98 40.15 76.52 87.50 92.26 70.