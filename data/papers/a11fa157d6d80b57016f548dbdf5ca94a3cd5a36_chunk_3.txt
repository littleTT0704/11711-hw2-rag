 Romero et al., 2019; Zhang et al., 2020b;
tionaccess(Google,2012),decisionmaking(Yang
Nguyenetal.,2021),yettheextractedrelationsare
et al., 2021; Santos et al., 2022), and improving
limitedtothoseexplicitlystatedinthetext,miss-
machinelearningingeneral(Lietal.,2019;Wang
ingallothersthatarenotmentionedordonothave
etal.,2019;Tanetal.,2020;Xiongetal.,2017).
exactmatchwiththetextinthecorpus. Similarly,
∗Equalcontribution.Codeavailableathttps://github.
KG completion approaches (Bordes et al., 2013;
com/tanyuqian/knowledge-harvest-from-lms. Demo
availableathttps://lmnet.io Bosselutetal.,2019;Yaoetal.,2019)isrestricted
3202
nuJ
2
]LC.sc[
3v86241.6022:viXra
Method Module(s) Outcome Arbitraryrelation
Textmining(Zhangetal.,2020a;Nguyenetal.,2021) NER,CR,RE,etc.1 KG ✗
LAMA(Petronietal.,2019),LPAQA(Jiangetal.,2020) LMs tailentity ✓
COMET(Bosselutetal.,2019) FinetunedGPT-2 tailentity ✗
SymbolicKnowledgeDistillation(Westetal.,2022) GPT-3 KG ✓2
BertNet(ours) LMs KG ✓
Table1:Categorizationofworksonautomaticknowledgeextraction.Comparedtoothercategoriesofapproaches,ourmethod
extractsfullexplicitKGsofarbitrarynewrelationsfromanyLMs.
tothepreexistingrelations(Figure1). 2020;Newmanetal.,2021)andenhancewithour
Ontheotherhand,largelanguagemodels(LMs) newrescorestrategyforpromptweighting,leading
pretrained on massive text corpus, such as BERT toconsistentandaccurateoutcomeknowledge.
(Devlin et al., 2019) and GPT-3 (Brown et al.,