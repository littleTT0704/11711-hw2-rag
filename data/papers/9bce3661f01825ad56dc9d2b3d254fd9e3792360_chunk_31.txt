azeer, Niki Parmar, Jakob Ireland.AssociationforComputationalLinguistics.
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser,andIlliaPolosukhin.2017. Attentionisall
youneed. Advancesinneuralinformationprocessing
systems,30.
BoshiWang,SewonMin,XiangDeng,JiamingShen,
You Wu, Luke Zettlemoyer, and Huan Sun. 2022a.
Towardsunderstandingchain-of-thoughtprompting:
Anempiricalstudyofwhatmatters. arXivpreprint
arXiv:2212.10001.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc
Le,EdChi,SharanNarang,AakankshaChowdhery,
andDennyZhou.2022b. Self-consistencyimproves
chainofthoughtreasoninginlanguagemodels. arXiv
preprintarXiv:2203.11171.
ZiruiWang,AdamsWeiYu,OrhanFirat,andYuanCao.
2021. Towardszero-labellanguagelearning. arXiv
preprintarXiv:2109.09193.
Albert Webson and Ellie Pavlick. 2022. Do prompt-
basedmodelsreallyunderstandthemeaningoftheir
prompts? InProceedingsofthe2022Conferenceof
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
nologies, pages 2300–2344, Seattle, United States.
AssociationforComputationalLinguistics.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.
Chainofthoughtpromptingelicitsreasoninginlarge
languagemodels. arXivpreprintarXiv:2201.11903.
Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta,
Mark Riedl, and Yejin Choi. 2022. Reframing
human-AIcollaborationforgeneratingfree