(PoE),anequationthatstatesgivennexperts:
ricis6.3GPUhours.
(cid:81)
Meaning Preservation We use BERTScore
p(d|θ,...,θ ) =
mp m(d|θ m)
(1)
1 n (cid:80) (cid:81)
(Zhang et al., 2019), which outputs the co-
c
mp m(c|θ m)
sine distance between model sentence embed-
whereθ denotestheparametersofmodelm,dis
dings,tomeasurethemeaningsimilaritybetween m
somedatavector,p (d|θ )denotestheprobability
the original sentence and the rewrite. We use m m
ofdundermodelm,andciteratesoverallpossible
RoBERTa-large (Liu et al., 2019) as our model,
datavectors.
which has 354M parameters. We use the code
ApplyingthePoEtoautoregressivegeneration
locatedathttps://huggingface.co/spaces/evaluate-
equation, d represents a single token, p (d|θ )
metric/bertscore under the MIT License and its m m
representsthenexttoken-probabilityofdundera
intendeduse.
specificmodel,andciteratesoveralltokensinthe
We run this evaluation with a single NVIDIA
vocabularyV.
RTX6000 GPU, which takes approximately 15
Givenavectorx,thesoftmaxequationis:
seconds per 100 examples. With an estimate of
450,000textsprocessed,ourusageforthismetric exi
softmax(x )= fori=1,2,...,K
is18.7GPUhours. i (cid:80)K exj
j=1
B.4 TotalComputationalBudget
In the replacing step of MARCO, we perform
Summing up our computational usage from the the following ensembling of unnormalized log-
above sections, including finetuning the experts, probabilities(i.e.,logits)z,z+,andz− fromthe
i i i
ourtotalcomputationalbudgetis106.1GPUhours