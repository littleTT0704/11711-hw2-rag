alearningrateof10−5
and8batchsizeinallexperiments. NotethatSpears(1998)refersto WAE asWhite
language varieties, and deals with English preva-
A.4 PredictionCombiningwithBias-only
lentintheUnitedStates.
Model
Weprependtheformattedexamplepairstoeach
To prevent the possibility that our LMIXIN- AAE tweet in our training data, and generate the
TOXTRIG/ONI is not well trained, thus resulting translation from GPT-3 using top-0.95 nucleus
in the decrease of models’ in-distribution perfor- samplingwithatemperatureof0.5. Prompts,for-
mance, we use the joint-prediction from the main matting, and generation parameters were chosen
andbias-onlymodeltoinferthein-distributiontest basedonmanualinspectionoftheoutput.
3154
ToxicRatio R ↓ R ↓ R ↓ R ↓
NOI OI ONI AAE
Original† 0.8308 0.0287 0.4320 0.2610 0.4061
Random 0.8312 0.0288 0.4312 0.2621 0.4011
AFLite 0.7669 0.0342 0.4708 0.2835 0.4236
DataMaps-Ambig. 0.6736 0.0493 0.4683 0.3230 0.4445
DataMaps-Hard 0.6645 0.0521 0.4533 0.3190 0.4426
DataMaps-Easy 0.9972 0.0135 0.0771 0.0396 0.0928
Table 7: Lexical and dialectal associations between toxicity in the original dataset (Davidson et al., 2017) and
various filtered counterparts. Random, AFLite, and DataMaps all contain only 50% of the original data after
filtering. (Wecouldnotperformdownsamplingonthesedatasetsduetotheirheavilyskewedlabeldistribution.)
LowerPearsonRcorrelationvalueindicateslesssuperficialpatternsinthedataset,thusarelessbiased. Theeasy
subsetgivesthebestresultshereareduetoitssevere