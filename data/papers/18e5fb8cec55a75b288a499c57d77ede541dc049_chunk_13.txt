asitspossiblereferences.
plates and scoring functions. To train the model, given the
scores computed for each answer candidate S 1;S 2;:::S m, ExperimentalSetup
weusethemarginalranking(MR)lossdefinedas:
Baselines
1 Xm We compare our results with the following baselines. Ma-
L=
m
max(0;(cid:17)(cid:0)S y+S i) (3) jority answers each question with the most frequent op-
i=1 tionintheentiredataset.‘Vanilla’versionsofthelanguage
i6=y
13510
Model KG aNLI CSQA PIQA SIQA WG
Majority - 50.8 20.9 50.5 33.6 50.4
GPT2-L - 56.5 41.4 68.9 44.6 53.2
RoBERTa-L - 65.5 45.0 67.6 47.3 57.5
Self-talk (Shwartzetal.2020) - - 32.4 70.2 46.2 54.7
COMET-DynaGen(BosselutandChoi2019) ATOMIC - - - 50.1 -
SMLM (BanerjeeandBaral2020) * 65.3 38.8 - 48.5 -
GPT2-L(MR) ATOMIC 59:2((cid:6)0:3) 48:0((cid:6)0:9) 67:5((cid:6)0:7) 53:5((cid:6)0:4) 54:7((cid:6)0:6)
GPT2-L(MR) CWWV 58:3((cid:6)0:4) 46:2((cid:6)1:0) 68:6((cid:6)0:7) 48:0((cid:6)0:7) 52:8((cid:6)0:9)
GPT2-L(MR) CSKG 59:0((cid:6)0:5) 48:6((cid:6)1:0) 68:6((cid:6)0:9)