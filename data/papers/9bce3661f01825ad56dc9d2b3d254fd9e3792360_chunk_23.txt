ornAnantaprayoon,MasahiroKaneko,and 2017. Revolt: Collaborativecrowdsourcingforlabel-
Naoaki Okazaki. 2023. Evaluating gender bias ingmachinelearningdatasets. InProceedingsofthe
of pre-trained language models in natural lan- 2017CHIConferenceonHumanFactorsinComput-
guage inference by considering all labels. ArXiv, ingSystems,CHI’17,pages2334–2346,NewYork,
abs/2309.09697. NY,USA.AssociationforComputingMachinery.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Masahiro Kaneko and Danushka Bollegala. 2021c.
Kristina Toutanova. 2019. BERT: Pre-training of Unmasking the mask - evaluating social biases in
deepbidirectionaltransformersforlanguageunder- masked language models. In AAAI Conference on
standing. InProceedingsofthe2019Conferenceof ArtificialIntelligence.
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech- MasahiroKaneko, DanushkaBollegala, andTimothy
nologies,Volume1(LongandShortPapers),pages Baldwin. 2024. The gaps between pre-train and
4171–4186,Minneapolis,Minnesota.Associationfor downstreamsettingsinbiasevaluationanddebiasing.
ComputationalLinguistics.
Masahiro Kaneko, Danushka Bollegala, and Naoaki
YilunDu,ShuangLi,AntonioTorralba,JoshuaBTenen- Okazaki.2022a. Debiasingisn’tenough! –onthe
baum,andIgorMordatch.2023. Improvingfactual- effectiveness of debiasing MLMs and their social
ityandreasoninginlanguagemodelsthroughmultia- biasesindownstreamtasks. InProceedingsofthe
gentdebate. arXivpreprintarXiv:2305.14325. 29thInternationalConferenceonComputationalLin-
guistics,pages1299–1310,Gyeongju,Republicof
RuthCFongandAndreaVedaldi