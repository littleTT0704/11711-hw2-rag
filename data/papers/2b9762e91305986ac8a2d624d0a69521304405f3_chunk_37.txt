 Schwenk, 2019), which consists of
XTREME leaderboard broken down by language upto1,000English-alignedsentencepairscover-
familyontheremaining XTREME tasksinFigure ing 122 languages. We find the nearest neighbor
2.
usingcosinesimilarity. Tomakethesettingmore
realistic, we move away from zero-shot retrieval
C XTREME tasksretainedin XTREME-R
andfine-tunemodelsonSQuADv1.1.
XNLI The Cross-lingual Natural Language In-
D Languages
ference corpus (Conneau et al., 2018) requires a
model to determine whether a premise sentence Language characteristics We show a detailed
entails,contradicts,orisneutralwithrespecttoa overview of languages in XTREME-R including
hypothesis sentence. We use the crowd-sourced interesting typological differences in Table 7.
Englishdatathatwasprofessionallytranslatedto Wikipedia information is taken from Wikipedia8
14otherlanguagesforevaluationandtheMultiNLI and linguistic information from WALS Online9.
(Williamsetal.,2018)trainsetfortraining.
8https://meta.wikimedia.org/wiki/List_
7WearenotawareofthetechnicaldetailsofPolyglotand of_Wikipedias
theanonymoussubmission. 9https://wals.info/languoid
(a)PerformanceonXNLI (b)PerformanceonPAWS-X
(d)PerformanceonXQuAD
(c)PerformanceonWikiANN-NER
(e)PerformanceonTyDiQA-GoldP (f)PerformanceonBUCC
Figure2: PerformanceofallmodelsontheXTREMEleaderboardon(a)XNLI,(b)PAWS-X,(c)WikiANN-NER,
(d)XQuAD,(e)TyDiQA-GoldP,and(f)BUCCacrosslanguagefamilies.
XTREME-R includesmembersoftheAfro-Asiatic, features from URIEL (Littell et al., 2017) across
Austro-Asiatic, Austronesian, Dravidian, Indo- the languages while the family index consists of
European, Japonic, Kartvelian, Kra-Dai, Niger- the