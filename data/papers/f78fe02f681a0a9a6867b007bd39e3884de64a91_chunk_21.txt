scaledia-
(2022a)proposesahuman-machinecollaborative
loguedatasetcoveringanexceptionallywiderange
framework,whereaworkerandGPT-3taketurns.
ofsocialinteractionstoalleviatethedatascarcity
Kimetal.(2022b)buildsBlendedSkillBotsTalk
issue. SODAisnotonlyordersofmagnitudelarger
bylettingmultipleagentsgroundedintargetskills
thanpopulardialoguedatasets;itisalsoperceived
engageformulti-skilldialogues. Chenetal.(2023)
tobesignificantlybetterthanthemacrossmultiple
generatedyadicandmulti-partyconversationswith
aspects(e.g.,naturalness,specificity,consistency).
topicwordsandshowtheyhavecomparablequal-
ity to human-authored conversations. GPT-3 has
Formaking SODA,wealsointroduced CO 3,a
frameworkfordistillingconversationsfromalarge
also been used to help simulate task-oriented di-
languagemodelbycontextualizingcommonsense
alogues (Li et al., 2022) on a small scale. Oth-
knowledge. With SODA,wetrainedaconversation
ersalsoaugmentdialogueswithadditionalannota-
tionsâ€“e.g.,commonsenseinferences(Zhouetal., model COSMOthatcangeneralizesignificantly
better than existing models to unseen dialogues;
12Evaluation was run on the 2022 Dec 15 ver-
andgenerateresponsesthatareevenmorepreferred
sion: https://help.openai.com/en/articles/6825453-
chatgpt-release-notes thanground-truthresponsesofanexistingdataset.
8 Limitations hopefutureworkwillextendhumanevaluationto
havepotentiallymoreannotatordiversity.
PrecautionstakenduringDatasetConstruction
Also, since SODA mainly focuses on social
Miningcontentfromlargelanguagemodelsmight
chitchatgroundedonsocialcommonsense,itlacks
surface or even amplify harmful content within
conversationsgroundedinscientifick