okeninthelastfourlayers. Thesec-
evaluation data, bitext, and paraphrase data. For
ondwayistoconcatenatethehiddenstatesofall
bitextandparaphrasedata,weprovidesupportfor
wordtokensinthelastfourlayersandmeanpool
trainingusingeithertextfilesorHDF5files.
these representations. Both methods result in a
4096dimensionembedding. Wealsocompareto
Lastly, this paper contains new experiments
a more recently released model called Sentence-
showcasing the limits of these scaled-up models
BERT(ReimersandGurevych,2019). Thismodel
and detailed comparisons with prior work on a
issimilartoInferSentinthatitistrainedonnatu-
suite of semantic similarity tasks in a variety of
rallanguageinferencedata(SNLI;Bowmanetal.,
languages. We release our code and models to
2015). However,insteadofusingpretrainedword
thecommunityinthehopethattheywillbefound
embeddings, they fine-tune BERT in a way to in-
usefulforresearchandapplications,aswellasus-
duce sentence embeddings. Lastly, we also com-
ingthemasabasetobuildstronger,fastermodels
paretotheunsupervisedversionofSimCSE(Gao
coveringmoreofthelanguagesoftheworld.
etal.,2021),whichfine-tunesapretrainedencoder
on contrastive pairs, where positive pairs are ob-
tainedbyusingdropoutonasingleinputsentence.
2OurEnglishmodelisP-SP,andthecross-lingualmodels
areP-SP-AR,P-SP-DE,P-SP-ES,P-SP-FR,P-SP-RU,P-SP- 3Note that in all experiments using BERT, including
TR,andP-SP-ZH. Sentence-BERT,thelarge,uncasedversionisused.
380
2.2 Cross-LingualSemanticSimilarityand we choose the most similar sentence in some set
SemanticSimilarityinNon-English accordingtothecurrentmodelparameters,i.e.,the
Languages onewith