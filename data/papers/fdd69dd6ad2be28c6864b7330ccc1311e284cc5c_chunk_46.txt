B,usingUDA[29],FixMatch[20],FlexMatch[21],CoMatch[60],andSimMatch
[47]. We train these algorithms using 10 labels per class and 100 labels per-class, i.e., a total of
10,000labelsand100,000labelsrespectively,correspondingtoroughly1%and10%ofthetotal
labeleddatainImageNet. Forlearningrateandweightdecay,wefollowthefine-tuningprotocolin
MAE[33],whereweuseAdamWwithalearningrateof1e-3andweightdecayof0.05. Weuse16
A100totraineachalgorithmandsetthebatchsizeto256forbothlabeledandunlabeleddata. Other
algorithmichyper-parametersstaythesameastheiroriginalimplementations.
WepresenttheresultsonImageNetinTable11. UDAandFixmatcharenearthebottom,similarto
USB.SimMatchisstillmarkedasoneofthetops. Surprisingly,CoMatchdoessowellonImageNet
whenitrankedonly9thontheUSBbenchmark. Also,whileFlexMatchisthebestonUSB,it’spretty
firmlybehindCoMatchandSimMatchonImageNet.
18
LSShcroT
no
setar
rorre
naem
Table11: ImageNetaccuracyresults. WeuseMAEpre-trainedViT-B.
Method 1wLabels 10wLabels Rank
UDA 38.62 62.37 5
FixMatch 37.93 62.88 4
FlexMatch 39.13 63.09 3
CoMatch 44.32 65.80 2
SimMatch 46.48 67.61 1
Table12: Swin-TransformerresultsonEuroSATandSemi-AVES.
Dataset EuroSAT Semi-Aves
#Label 20 40 5,959
Supervised 44.32±1.10 34.40±1.44 38.76±0.21
Fully-Supervised 1.86±0.10 -
Π-Model 42.49±3.21 30.54±1.37 38.74±0.60
Pseudo-Labeling 42.49±3.21 30.54±