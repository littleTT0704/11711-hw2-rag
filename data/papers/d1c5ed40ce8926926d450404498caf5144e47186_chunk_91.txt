-level
features, we also show the MAP score if the previous or next feature value is used.
80%
70% Previous Current Next
60%
50%
P
A40%
M
30%
20%
10%
0%
Figure 5.3: MAP of individual features on markup-based text nuggets. We ranked
nuggets by feature values in descending (+) or ascending (-) order. For nugget-level
features, we also show the MAP score if the previous or next feature value is used.
62 CHAPTER 5. INTRINSIC EVALUATION
80%
75%
70%
65%
60%
55%
P
A 50%
M
45%
40%
35%
30%
25%
20%
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
λ (Novelty-Relevance Tradeoff)
Figure 5.4: MAP of the MMR algorithm for different tradeoffs between novelty and
relevance. The solid line is for markup-based nuggets, the dashed line for sentence-
level nuggets.
of the MMR algorithm for sentence-length and markup-based text nuggets when
using varying λ values. Since in this evaluation we do not penalize redundancy in
the rankings, our initial choice of λ = 1 performs best. We also tried inverting the
sign of the novelty component in the MMR algorithm, turning it into an estimate of
the similarity of text nuggets to already selected nuggets. This modified algorithm
selects text that is related to both the seed document and higher ranking nuggets.
Again we experimented with different λ values and found that the optimum is near
λ = 1, i.e. we should select the most relevant text regardless of its redundancy.
However, depending on the application that leverages the expanded content, different
parameter settings could be more effective. For instance, QA systems benefit from
new information that is not covered in a seed corpus in addition to paraphrases of
already available information, and thus a configuration of the MMR algorithm that
rewards novelty may yield better results. We leave the evaluation of the impact of
different relevance–novelty tradeoffs on QA performance as a possible direction for
future work.
