CODEX,
overNLandMULTIvariants(Nijkampetal.,2022). whichwhenscalinguptoDAVINCI-002,thesegaps
Thepassrateincreasesas CODEGEN growsfrom continuetoincreaseby4.9pointsonaverage,indi-
350M to 2.7B, and continues to increase in non- catingthatscalingupCODEGENmoreeffectively
English languages when further scaling to 6.1B. catchesuponopen-domainperformance.
CODEGEN exhibits multilingual capacity, as its
5.3 DomainVariance
resultsonnon-Englishsubsetsareclosetothaton
English,andconsistentlyincreaseduringscaling. Wenowdivedeeperintotheresultswithinindivid-
Although CODEX and CODEGEN havecompa- ualdomains. WefocusontheCODE-DAVINCI-002
rableperformanceonexistingdatasetssuchasHu- modelasithasthebestperformanceacrossallmod-
manEval,ODEXeffectivelyunveilstheefficacyof els. InFigure8,weplotaccuracywithrespectto
CODEGEN on open-domain coding queries even thedomainfrequency,asapproximatedin§3.1.
withmanyfewerparameters,i.e.,CODEGEN 6.1B Execution accuracy is not low on all open do-
yieldssimilarpass1tothe176B CODEX DAVINCI- mains. Forexample,CODE-DAVINCI-002achieves
001modelonsomelanguages. Morefine-grained 50% pass@1 for several common libraries such
results (pass@k at 1 ≤ k ≤ 10) for both models as random and math. But high domain frequency
80 en / 1 80 en / id
en / n en / const
65 es / 1 en / intent
es / n es / id
ja / 1 65 es / const
50
ja / n es / intent
ru / 1 ja / id
35 p@1 p@2 p@3 p@4 p@5 p@6 p@7 p@8 p@9 p@10 ru / n 50 ja / const
ja / intent
ru / id
ru /