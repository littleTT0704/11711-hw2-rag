
1.4B 92.6 129K 66.6/63.2/66.2 1.4B 91.4 29K 66.1/59.7/63.3
2.8B 92.9 114K 67.1/63.7/66.8 2.8B 91.6 50K 64.1/60.2/61.9
6.9B 92.7 129K 69.0/64.0/68.4 6.9B 91.4 21K 67.3/60.1/67.3
Table2: BiasmeasuredusingSSforthefull-precision Table 3: Bias measured using SS for int8 quantized
PythiamodelshavingthebestLMscorepermodelsize. PythiamodelshavingthebestLMscorepermodelsize.
’he/she’. TheSelf-Debiasbaselinewasproposedby afunctionofthepretrainingofthePythiamodelsin
Schicketal.(2021),andusespromptstoencourage Figures2to7,9,10and11. TheBERT/RoBERTa
modelstogeneratetoxictextandlearnstogiveless BaseandLargeversionsareroughlycomparable
weight to the generate toxic tokens. Self-Debias withthe160Mand410MPythiamodels. Forthe
doesnotchangethemodel’sinternalrepresentation, SS dataset, the 160M model is consistently less
thusitcannotbeevaluatedontheSEATdataset. biased than the 410M model. However, this is
Notable trends in Table 1 are the reduction of not the case for the other two datasets where the
socialbiaseswhenapplyingdynamicPTQanddis- 160Mstrugglesinthe RACEcategorywhileassess-
tillation, which can compete on average with the ingthedistanceofsentenceembeddings(SEAT);
specificallydesigneddebiasmethods. Additional andintheRELIGIONcategorywhileswappingmin-
resultsininAppendixBalsodisplaysimilartrends. imally distant pairs (CrowS). This illustrates the
On the SS dataset in Table 4 we are also able to difficulty of distinguishing between semantically
observethattheapplicationofdistillationprovides closewords,andshowst