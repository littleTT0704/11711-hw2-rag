 Ineachcase,weuseAdamWfrom i
tuning them. Main refers to the first term in Eq.
torch.optimwithaLRof1e-5andweightde-
1, plus the KL term with random data. We use
cay of 1e-4. We select the best model according
K 5 for all experiments. For results across
to the best dev set accuracy, checkpointing after train â‰¤
K valuesonzsRE,seeFig. 8.
each training epoch. The learned optimizers are
optimized with AdamW, using a learning rate of Baselineupdatemethod. Wetuneabaselineoff-
3e-4andweightdecayof0. Wetrainthelearned the-shelfoptimizerseparatelyforeachdataset,us-
optimizerfor5epochsoneachdatasetexceptfor ing r = 1. Our performance criterion is the
test
2725
Relation %TestData tailsremain. Somerelationsareone-to-many,and
thereforeweaccumulatevalidcompletingentities
PlaceofBirth 11.00
AwardReceived 11.00 from the data as possible answers; later we com-
CauseofDeath 5.66
puteaccuracyasanexactmatchwithanypossible
PlaceofDeath 11.00
PlaceofBurial 8.33 answer. All10relationsappearineachsplitofthe
EducatedAt 11.00 data. Only 33.80% and 37.18% of the entities in
Child 11.00
thedevandtestsplitsareseeninthetrainingdata,
Occupation 11.00
Spouse 11.00 thoughwedonotfindthatmodelsperformbetter
Sibling 9.01 onentitiesseenintraining.
Table11: Wikidatarelationsandtheirproportionofthe
B.4 LeapOfThoughtAdditionalDetails
testdata.
TheLeapOfThoughtdatasetconsistsofafactanda
Dataset Optimizer LR Num.Steps
claimforeachdatapoint,wherethetruthofthefact
FEVER AdamW 1e-6 100 impliesthattheclaimhaslabely (True/False). All
i
LeapOfThought SGD 1e-2 100
of the facts in the data are true, while half