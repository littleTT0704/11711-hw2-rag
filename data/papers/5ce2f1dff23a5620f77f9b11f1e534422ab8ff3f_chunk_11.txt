like
instances ({tasktype, object, receptacle, room}), 140
“pointing”modelcouldbeusedtoselectanactionfrom
in-distribution evaluation task instances (seen split -
the list of permissible actions.
tasksthemselvesarenovelbuttakeplaceinroomsseen
during training) and 134 out-of-distribution evaluation
task instances (unseen split - tasks take place in novels
Action Attention We are interested in learning a
rooms). An example of the task could be: “Rinse the
policy π that outputs the optimal action among per-
egg to put it in the microwave.” Each training instance
missible actions. We eschew the long rollout/ large
in AlfWorld comes with an expert, from which we
action space problems by (1) representing observations
collected our training demonstration.
by averaging over history, and (2) individually encod-
ing actions (Fig 5). In our proposed action attention
HumanGoalSpecification Thecrowd-sourcedhu-
framework, we first represent historical observations
mangoalspecificationsforevaluationcontain66unseen
Ht as the average of embeddings of all individual ob-
verbs and 189 unseen nouns (Shridhar et al., 2020b).
servations through history (Eq. 1), and HA as the list
In comparison, the template goals use only 12 ways of
of embeddings of all the current permissible actions
goal specification. In addition, the sentence structure
(Eq. 2). Then, in Eq. 3, we compute the query Q
for human goal specification is more diverse compared
usingatransformerwitha“query”head(M )ontask
Q to the template goals. Therefore, human goal experi-
embedding (Ht), the current observation embedding
ments are good for testing the generalization of models
(Ot), and the list of action embeddings (HA). In Eq.
to out-of-distribution scenarios.
4 we compute the key K for each action a using the
i i
same transformer with a “key” head (M ) on task
K Pre-trained LMs. For the Plan module (sub-task
embedding (Ht), the current observation embedding
generation), we experimented with the open-source
