 fi
rr y d soa e t an mgs
u
ehs t
iu
rs er ra
l
(a a nt t’
tl
asa ak lg sn g i hbt ht t t tf
g t
tn n ne h hh e
e
ey e oo.o t
e
ee ad g d d o
d
d
de e ae s- r
r
rr r tt
0 5000 10000 15000 20000 25000 30000 thus should go to more workers), just okay, or especially
Number of images
boring (and hard to ask even one good question for). We
Figure9: Distributionofmoviesinthe trainingsetby
VCR
used this to train a deeper model for this task. The model
numberofimages.BluebarsaremoviesfromLSMDC(46k
uses a ResNet 50 backbone over the entire image [30] as
images);redareMovieClips(33kimages).TheMovieClips
wellasamultilayerperceptronovertheobjectcounts. The
images are spread over a wider range of movies: due to
entire model is trained end-to-end: 2048 dimensional fea-
spacerestrictions,mostareunder‘otherMovieClips.’
turesfromResnetareconcatenatedwitha512dimensional
projetion of the object counts, and used to predict the la-
11
deksa snoitseuq n htiw segami fo rebmuN
a)Boringimage.
b)Interestingimage.
Figure12: Screenshotofourannotationinterface. Workers
Figure 11: Two example images that come from the raw
aregivenanimage,aswellascontextfromthevideo(here,
video pipeline. Image a) is flagged by our initial filter as
captionsfromLSMDC[67]),andareaskedtowriteoneto
‘boring’,becausethereareonlytwopeoplewithoutanyad-
three questions, answers, and rationales. For each answer,
ditionalobjects,whereasimageb)isflaggedasbeinginter-
they must mark it as likely, possible, or unlikely. Workers
estingduetothenumberofpeopleandobjectsdetected.
also