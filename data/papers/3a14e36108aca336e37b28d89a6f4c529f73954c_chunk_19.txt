(0.049)
Pearson 0.107(0.003) 0.125(0.001) 0.108(0.003) 0.203(1e-04) 0.120(0.191)
METEOR
Spearman 0.098(0.008) 0.114(0.002) 0.122(0.001) 0.164(0.002) 0.121(0.187)
Table5:PearsonandSpearmancorrelationsbetweenautomaticandhumanevaluationmetrics,withp-valuesinbrackets.TOF
metricsexcludedastheyaremainlyforvalidation.Boldcorrespondstohighestcorrelationperhumanevaluationmetric.
5.4 OverallTakeaways corpus (Huang et al. 2016), ii) M, an in-domain model
iid
onfirst20%ofROCStories’trainsplit.Wetesteachoni)
Humansmodifytextgreatlywhilesuccessfullyperforming
Controlset{s }i=n,inputstoriesfromtestSup,ii)Challenge
NAREOR.BARTandT5modelsperformdecentlywithmin- i i=1
set{s′}i=n,reorderedstoriesfromtestSup.Table7shows
imalbuteffectiveedits.GPT-2modelstendtorepeat,halluci- i i=1
drastic drops across metrics (higher is better - see Prabhu-
nate,andreducetextqualityandplotpreservation.Basedon
moye,Salakhutdinov,andBlack(2020))forbothM and
human(§5.1)andautomatic(§5.2)evaluation,BART-d-2S ext
M fromcontroltochallengeset,confirmingourhypothe-
and T5-d-2S are the best models overall. BART-d-2S out- iid
sis.Systemswithabilitytomanipulatenarrativevariableslike
doesitsreordervariant,possiblyduetoBART’spretraining
ordercouldbeimportantforautomatingpedagogicalsetups,
as a denoising autoencoder, closer to our denoise training
especiallyforfine-grainedl