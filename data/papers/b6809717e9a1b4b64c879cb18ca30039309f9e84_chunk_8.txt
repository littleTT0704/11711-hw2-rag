otheGRUinthreefeatureencodingmodes: SEQUENTIAL(showninModel
Overview),ALLTOCURRENTandPREVIOUSONLY.
We train an Atomic relation classifier using a Dim-2: Emotion/humandrivethatmotivates
RoBERTa-base model (Liu et al., 2019) and the Dim-3: Changeinlocationthatenables
Atomicdatasettoclassifyevent-pairsintooneof Dim-4: Stateofpossessionthatenables
the nine possible relationship labels as well as a Dim-5: Otherattributethatenables
None label (to introduce negative samples). We Glucose relation classifier was trained on a
achievedavalidationF1of77.15%,whichishigh RoBERTa-basemodeltoclassifyevent-pairsfrom
fora10-wayclassificationtask. Wedescribetrain- theGlucosedatasetintooneoftenpossiblerelation
ingandotherexperimentaldetailsintheAppendix. labelsaswellasaNonelabel. Weusedthespecific
When making inferences on the Event-annotated version of Glucose events represented in natural
dataset,wepredictthelikelihoodthatapreceding language. As a result, we achieved a validation
sentenceinastorywillberelatedtothecurrentsen- F1 of 80.94%. Training and other experimental
tenceviaeachoftheninerelationshiplabels. Be- details are in the Appendix. During inference on
causeAtomicrelationsaredirectedrelations(e.g., the Event-annotated dataset, we predict and use
I ate some cake xEffect I am full is different asfeaturesthelikelihoodthatthecurrentsentence
fromIamfullxEffectIatesomecake),wealso will be related to a preceding sentence via each
madethereverseinferenceincasecommonsense relationlabel.
relations between sentences exist in the reverse
Realis eventsarewordsthatserveastriggers(i.e.,
direction. Together,9forwardatomicrelationfea-
head words) for structured event representations
turesand9reversefeatures(markedwith’-r’)are
(Sims et al., 2019). Realis event words denote
used.
concrete events that actually happened,