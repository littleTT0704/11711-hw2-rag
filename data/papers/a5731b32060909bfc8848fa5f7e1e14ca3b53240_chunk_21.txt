NLP
6https://ajc.org/translatehate/kike systems(unintentionally)perpetuateharmsagainst
erocS
IPA
evitcepsreP
marginalizedgroups. Thisfindingisnotsurprising, usingNLPtoadvancedogwhistleresearch. Even
as prior work shows that toxicity detection often though LLMs’ performance is likely due to vast
failsonsubtlelanguage(HanandTsvetkov,2020; trainingdata,andeventhen,theiroutputsrequire
Hartvigsenetal.,2022),butunderscorestheneed manualverification,ourexperimentswithGPT-3
for toxicity and hate speech detection models to demonstrate that LLMs have some ability to sur-
be able to flag hateful dogwhistles. One poten- facedogwhistlesandexplaintheircovertmeanings.
tialapproachtoimprovesuchmodelscouldbeto Thisisparticularlyvaluableasdogwhistlesarein-
train them to recognize dogwhistles in naturally- tentionally hidden from out-group members, and
occurringin-groupcontexts(startingwithmodel- out-group researchers may have no other way to
ing contextual factors; Zhou et al., 2023). More accessthisinformation. Thereisthusauniqueop-
broadly,contentmoderationpipelinesshouldtake portunityforLLMstoassistdogwhistleresearch,
contextintoaccountandconsidermechanismsto andpoliticalcontentanalysismorebroadly.
identifywhenadogwhistlehaspotentiallynegative
consequences. Beyond toxicity detection, future
Bridginglarge-scaleanalysisandmathematical
workoughttoconsidertheimpactofdogwhistles
models Our work builds foundations for large-
inabroaderrangeofNLPtasks,suchasbiasmiti-
scalecomputationalanalysisofdogwhistlesinreal-
gationorstorygeneration.
world political discourse. We diverge from prior
HowdoLLMsknowaboutdogwhistles? Our quantitative dogwhistle research, which focuses
findings regarding GPT-3’s ability to surface and onmathematicallymodelingtheprocessunderly-
identifydogwhistles’co