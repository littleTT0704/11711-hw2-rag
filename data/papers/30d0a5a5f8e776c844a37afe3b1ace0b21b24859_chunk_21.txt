 movement being de-
its surroundings. While current navigation mod-
fined by users with a minimum distance of 0.01 m
els tightly integrate seeing and moving, they are
and a minimum angle of 1Â°. BenchBot provides the
deaf to the world around them, motivated by these
robotagentaccesstoRGB-Dcamera,laser,andeither
factors, the audio-visual navigation task was intro-
ground-truth or estimated pose information for the
duced [38, 66], where an embodied agent is tasked
robotimmediatelyaftercompletinganygivenaction.
to navigate to a sounding object in an unknown un-
Theprogressionofpassivecontrolwithground-truth
mapped environment with its egocentric visual and
pose data, through to active control with estimated
audio perception (Figure 8). This audio-visual navi-
posedataisdesignedtograduallybridgethegapfrom
gationtaskcanfindapplicationsinassistiveandmo-
passive to active semantic SLAM. The final cuboid
bilerobotics, e.g., robotsforsearchandrescueopera-
mapcreatedbytheagentwithinthechallengeiseval-
tionsandassistivehomerobots. Alongwiththetask,
uatedusingthenewobjectmapquality(OMQ)mea-
theSoundSpacesplatformwasalsointroduced,afirst-
sure outlined in [82]. This evaluation measure con-
of-its-kindaudio-visualsimulatorwhereanembodied
sidersthequalityofeveryprovidedobjectcuboid, in
agent could move around in the simulated environ-
termsofbothgeometricandsemanticaccuracy,when
mentwhileseeingandhearing.
compared to its best match in the ground-truth map,
Audio-visual navigation is a challenging task be-
as well as the number of provided cuboids with no
cause the agent not only needs to perceive the sur-
matchingground-truthequivalentandviceverse.The
rounding environment, but also to reason about the
final OMQ score is between 0 and 1 with 1 being the
spatial location of the sound emitter in the environ-
9https://developer.nvidia.com/isaac-sim ment via the received sound. This