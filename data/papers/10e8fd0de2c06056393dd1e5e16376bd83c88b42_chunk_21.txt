.56
as“StandardQGen"intable4and 5. Oursecond
Quasar-S 10.24 21.79 17.47
approach,whichhasbeenlessexploredpreviously, Quasar-T 34.92 41.99 44.73
NewsQA 18.57 21.20 12.71
converts a sentence in the target corpus to a fill-
SearchQA 34.60 38.80 37.27
in-the-blankstyleclozequestion(Taylor,1953)by COLIEE 46.79 54.17 62.38
maskingaplausibleanswerspan(entitymention)
inthesentence. Werefertothismethodas“Cloze Table5: Readerperformance: Comparingtwotypesof
QA". questionformatsforaugmentation
Few-shotDataGeneration Zero-shotinterven- Baseline DataGen
tionslikequestiongenerationmodelsaretrainedon
CliCR 23.87 29.06
thesourcedomainandinevitablydonotproduce BioASQ 50.41 51.36
Quasar-S 50.37 71.93
generationsthatarefullycompatiblewiththetar-
Quasar-T 54.77 55.47
getdomain,leadingtodegradationwhenthesource NewsQA 12.54 22.69
andtargetdomainsdifferdrastically. Analternative SearchQA 63.03 63.35
COLIEE 73.39 82.23
approachwouldbetotrainaquestiongeneration
modelwithafewexamplesfromthetargetdomain.
Table 6: Retriever Acc@100 with target specific few
However,inpracticeitisdifficulttoadaptorfine-
shotaugmentations(DataGen).
tune a question generation and answering model
(for validating QA pair correctness) with only a
handfulofexamples. erate data, one could alternatively use the same
Toalleviatethisproblem,weproposeafewshot modelandexamplestoanswerquestionsdirectly.
techniquethatpromptsaLLM(Chowdheryetal., WenexttesttowhatextenttheLLMcanperform
2022)togenerateasentencegivenapassage. We closed-bookQA