 and the generated
data. A lower FID implies a closer distance between the generated image dis-
tribution and the real image distribution. The FID is consistent with human
judgment and more consistent to noise than the IS [10] although it has a slight
bias [22]. Please note that there is some inconsistency in how the FID is cal-
culated in prior work, originating from different pre-processing techniques that
significantly impact the score. We use the official implementation1 of the FID.
To ensure a consistent calculation of all of our evaluation metrics, we replace
the generic Inception v3 network with the pre-trained Inception v3 network we
usedforcomputingtheISofthecorrespondingdataset.Were-calculatetheFID
scores of papers with an official model to provide a fair comparison.
Implementation detail We employ spectral normalisation [23], a weight nor-
malisation technique to stabilise the training of the discriminator, during train-
ing. To compute the semantic embedding for text descriptions, we employ a
pre-trainedbi-directionLSTMencoderbyXuetal.[42]withadimensionof256
for the word embedding. The sentence length was 18 for the CUB dataset and
12 for the COCO dataset.
All networks are trained using the Adam optimiser [14] with a batch size
of 20, a learning rate of 0.0002, and β = 0.5 and β = 0.999. We train for
1 2
600 epochs on the CUB and for 200 epochs on the COCO dataset. For the
model utilising squeeze-and-excitation attention we use r = 1, and λ = 0.1
and λ = 50.0, respectively for the CUB and the COCO dataset. For the model
utilising local self-attention as well we use r =4, and λ=5.0 and λ=50.0.
4.1 Results
Quantitative Results As Table 1 and Figure 3 show, our model utilising
squeeze-and-excitationattentionoutperformsthebaselineAttnGAN[42]inboth
metrics on both datasets. The IS is improved by 9.6% ± 2.4% and 25.9% ±
5.3% and