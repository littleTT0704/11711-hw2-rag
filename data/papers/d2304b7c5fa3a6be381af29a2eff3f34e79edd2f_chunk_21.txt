pre-trainingdata,leadingtomodelbias.22 Sub-
cinating) may be deemed more malicious than jectivity in annotation is a point of discussion in
false headlines with more benign consequences many pragmatic-oriented tasks, e.g. social norm
(e.g. someexamplesofsatire). Futureworkmay prediction(Jiangetal.,2021)andtoxicitydetection
explorecategorizingseverityofheadlinesbasedon (Halevyetal.,2021;Sapetal.,2021). Weencour-
potentialharmsresultingfromimplications. age conscious efforts to recruit diverse pools of
annotatorssomultipleperspectivesareconsidered,
Perceivedlabelscanhelpusunderstandwhich
andfutureworkonmodelingreactionframescan
headlines may fool readers. We can use these
considerlearningalgorithmsthatmitigateharmful
labelstodeterminewhichtypesofmisinformation
effects of biases, depending on use case (Khalifa
headlinesappearmostlikerealnewstogenerally
etal.,2021;Gordonetal.,2022).
knowledgeable readers. These may also help in
Lastly,weonlyconsiderEnglish-languagenews
designingmisinformationcounteringsystemsand
andannotatewithworkersbasedintheUS.Itmay
betteradversarialexamplestoimproverobustness
bethatnewsheadlineswouldbeinterpreteddiffer-
ofmisinformationdetectionmodels.
entlyinotherlanguagesandcultures.
We can generate counter-narratives to misin-
7 Conclusion
formation. Ourresultsindicateitispossibleto
generate effective explanations for the intent of
We introduced Misinfo Reaction Frames, a prag-
headlinesthatdiscouragetrustinmisinformation
maticformalismforunderstandingreaderpercep-
(Section5.3),seeAppendixA.5forexamples. We
tion of news reliability. We show that machine-
encourage future work that further improves per-
generatedreactionframescanchangeperceptions
formanceofthesemodels(e.g. throughintegration
ofreaders,andwhilelarge-scalelanguagemodels
ofdomainknowledge).
are able to discern between real news and misin-
