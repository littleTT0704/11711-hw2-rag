if-
todataintheselow-resourcelanguages. ferencefromthebest-performingsets. Allthissug-
geststhatLLMevaluatorsaremuchmorerobustto
6.3.1 AUTOMQM
thechoiceofin-contextexampleswhenprompted
Figure 8 shows the mean and interquartile range for AUTOMQM rather than for score prediction.
(IQR)oftheperformanceofPaLM-2BISONwith Wealsofindthatthebehaviorofin-contextlearn-
AUTOMQM, as we increase the number of in- ing is quite similar for both reference-based and
contextexamples(again,with100examplesetsper reference-lessevaluationtasks. Finally,weobserve
)ED-NE(
nosraeP
nosraeP
)ed-ne(
secnerrucco
#
)ed-ne(
secnerrucco
#
PaLM-2 (Bison) 0.35 PaLM-2 (Bison)
0.30 PaLM-2 (Bison) ref-free PaLM-2 (Bison) ref-free
0.30
0.25
0.25
0.20
0.20
0.15
0.15
0.10 0.10
0.05 0.05
0.00 0.00
0 1 2 3 4 5 6 0 1 2 3 4 5 6
# of in-context examples # of in-context examples
Figure8: MeanPearsonanditsinterquartilerange(IQR),asweincreasethenumberofin-contextexamples
inthe AUTOMQM prompt,forEN-DE(left)andZH-EN(right).
System-Level Segment-Level
All(2LPs) EN-DE ZH-EN
Model Ref? Accuracy ρ acc⋆ ρ acc⋆
Baselines
MetricX-XXL ✓ 81.1% 0.549 61.1% 0.581 54.6%
MATESE ✓ 79.9% 0.391 58.8% 0.528 51.5%
COMET-QE ✗ 76.9% 0.419 56.3% 0.505 48.8