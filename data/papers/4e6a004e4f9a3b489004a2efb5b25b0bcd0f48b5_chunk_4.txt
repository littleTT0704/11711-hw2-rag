odety,KhudaBukhsh,andCarbonell2020)demon-
worksandLongformermodelsforthesame.Thekeydiffer- strates the ability of BERT and similar LM’s to track com-
enceliesinthedataextractionandmethodology. munityperception,aggregateopinionsandcomparethepop-
(Khadilkar, KhudaBukhsh, and Mitchell 2022) goes in ularityofpoliticalpartiesandcandidates.Thisisdemonstra-
depthtowardsfindinggenderandracialbiasinalargesam- tiveofourworkasweintendtouseBERTforthepurpose
pleofBollywood(andHollywood)movies.Theauthorhas of sentiment analysis. The authors conclude by stating that
amalgamated several known NLP models while he tries to theLMcanbeusedasapipelineforextractingDatainthe
createareasonablyrobustmodelofhisown.Theportionsin future.
whichthisparticularstudydiffersfromthosebeforeisthat In (Hamilton, Leskovec, and Jurafsky 2016) the authors
thesamplesizeisfairlylarge.Itthendivergesfurtherwithits try to counter the problem of word meaning changing se-
ratherinnovativeuseofdiachronic-wordembeddingassoci- mantically with context. They propose a robust method by
ationtests(WEAT).Othertechniquesthatareimplemented using embeddings. These are then evaluated with the ’Law
include count-based statistics dependent on a highly popu- ofConformity’and’TheLawofInnovation’.Thesedisplay
larlexiconclozetestusingBERTasabasemodel(anidea the role of frequency and polysemy in the building struc-
wecouldconsiderafterdataattention)andbiasrecognition tural blocks of language. These blocks will be crucial for
usingWEAT.Thefinalmodelisacombinationoftheabove 2 reasons, (1) The meaning changes may adversely affect
three.Thispaperishighlyrelevanttoourprojectasituses sentiment analysis and thus affect results. Thus frequency
a similar idea of our own. It uses aforementioned models and polysemy must be duly curtailed. (2) The embed