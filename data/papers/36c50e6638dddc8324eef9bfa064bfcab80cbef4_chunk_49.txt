resultsforotherbaselinemodelsand
up to four multi GPUs to train larger dialogue
thebestperformingPushShiftTransformermodel
agentssuchasourProst,PushShiftTransformer,
(Rolleretal.,2021). WealsoreportthoseofProst
andBlenderBot(Rolleretal.,2021).
forcomparison.
Averageruntime. WhenwetrainProstonour
Additional human evaluation details and re-
setting,ittakes2.3secondsperbatchand70hours
sults. For GPT-3 and Instruct GPT-3, we use the
for full training. For Canary, it takes 1.0 second
following prompt to make them into a dialogue
perbatch,andwetraineditfor23hours.
agent: The following is a conversation between
Speaker 1 and Speaker 2.\n\n {input context}\n
C DetailsofExperiments
Speaker2:.
C.1 DialogueSafetyClassification WealsoreporttheresultsforDialoGPT(Zhang
etal.,2020)finetunedonthesametrainingsetas
Details of baselines. The BAD classifier is
ProstinTable9.
a BERT-based classifier pre-trained on the bot-
adversarial dialogue safety (BAD) dataset (Xu D Detailsofzero-shotexperiments
et al., 2021). This dataset is composed of hand-
D.1 GeneralizingtoReal-worldToxic
craftedadversarialsamplestofoolthesafetyclassi-
PhrasesviaProst
fier. ForGPT-2(Radfordetal.,2019)andT5-large
(Raffeletal.,2020),wetrainthemtogeneratethe Dataset. ToxiChat(Bahetietal.,2021)isacrowd-
safetylabelsbytreatingthemasspecialtokens. sourcedEnglishcorpusforinvestigatingthestance
ofhumanandmachineresponsesinoffensivecon-
C.2 Rule-of-thumbGeneration
versations, with 2,000 Reddit conversations and
Details of baselines. We fine-tune off-the-shelf correspondingannotationsoftargetedoffensivelan-
GPT-2 (Radford et