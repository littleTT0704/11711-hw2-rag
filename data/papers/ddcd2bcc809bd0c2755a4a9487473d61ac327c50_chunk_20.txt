 shows the SocialIQa accuracies for
objective to follow natural language instructions
questionsfocusingonthemaincharactervs. others.
and generate helpful answers. This might make
WhileGPT-4(thebest-performingmodel)achieves
themcooperativeandleadtoLLMsassumingthat
atotalof79%accuracyscore,onthesubsetques-
alldetailsareimportant,ratherthanthattheinput
tionsof“others”,itachievesonly74.5%.
is adversarial. For example, they might pay too
much attention to the mention of the false label
6 SummaryofFindingsandInsights
intheunexpectedcontentstask,failingtoseethat
We investigated whether modern LLMs robustly the label doesn’t matter if the person can’t read
displayN-ToMabilities. Byquantifyingtheirper- it or if the container is transparent. The fact that
formanceon6N-ToMbenchmarks,wefoundthat LLMsperformreasonablywellontruebeliefexam-
while some datasets have been nearly “solved” ples(Figure3)mightbeattributedtorecencybias
(e.g., TriangleCOPA with 96% accuracy by (O’ConnorandAndreas,2021), sincethecorrect
flan-t5-xxl), others remain challenging for contentistypicallythelastonetobementioned.
LLMswithconsiderablylowerperformance(e.g., Finally, we reassess the finding of Sap et al.
FauxPas-EAIwith27%accuracybyGPT-4,which (2022) that LLMs perform better on predicting
8
the mental states of the main character vs. oth- thattheyhaveToM).Instead,weneedtoconsider
ers(SIQA,§5.1);Sapetal.(2022)suggestedthat other explanations (e.g., that they are relying on
thismightbeduetocenteringtheory(Groszetal., heuristics). Thesameholdsintheotherdirection,
1995),accordingtowhichtextstendstofocuson whenanalyzinghowmodelsworkinordertolearn
describingasingleprotagonist. aboutthehuman