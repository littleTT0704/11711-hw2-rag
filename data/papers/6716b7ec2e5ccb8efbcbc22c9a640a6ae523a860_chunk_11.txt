metrics.
Model R@10 R@100 6.2 Readerimprovement
DPR-PT 33.9 69.4
Ouranalysis,inTable1,indicatesthattheFiD(T5-
ANCE-PT 53.8 80.7
based)modeloutperformsthecurrentBART-based
TAS-B-PT 53.9 85.0
baseline modelon all the evaluation metrics. We
SPLADE-max-PT 58.5 85.9
DistilSPLADE-PT 61.6 86.9 observed an improvement of around 10 points in
BLEU score in the FiD setting compared to the
DPR-FT(Baseline) 73.2 92.8
RAGmodel. FiDextractsrelevantevidencefrom
SPLADE-max-FT 75.1 93.9
concatenatedpassagesdisregardingtheirretrieval
DistilSPLADE-FT 77.0 94.8
DistilSPLADE-FT+DPR-FT(Neg) 78.6 94.9 scores,unlikeRAGwhichusesthemformarginal-
DistilSPLADE-FT+DPR-FT(Neg) 85.7 94.9 ization. Reinforcingsignalsfromtheretrieverfor
+Reranker the reader component might be the cause of the
dipinperformanceofRAGcomparedtoFiD.We
Table2:Performanceoftheretrieverfordifferentmodel
alsoobservedthatincreasingthenumberofinput
configurations at Recall@10 and Recall@100. X-PT
tokenstothereadermodelhelpscapturedialogue
refers to the pretrained X model while X-FT implies
andpassagecontextrelevanttotheinputquery.
thatXwasfinetunedonMultiDoc2dial. DPR-FTwas
theretrieveremployedfortheMultiDoc2Dialbaseline.
7 Conclusion
2. Itisevidentthatthepretrainedsparseretrieval
frameworks, Splade and DistilSPLADE, achieve We introduced our submission (CMU-QA) for the
betterretrievalperformanceincomparisontothe Multidoc2Dial shared task. Our approach (R3)
pretrainedDPRmodel. Thissuggeststhattheexact focuses on