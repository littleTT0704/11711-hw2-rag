man, Pierric Cis- Texas.AssociationforComputationalLinguistics.
tac, Thibault Goehringer, Victor Mustar, François
Lagunas,AlexanderRush,andThomasWolf.2021. LariaReynoldsandKyleMcDonell.2021. Promptpro-
Datasets: Acommunitylibraryfornaturallanguage gramming for large language models: Beyond the
processing. InProceedingsofthe2021Conference few-shot paradigm. In Extended Abstracts of the
onEmpiricalMethodsinNaturalLanguageProcess- 2021 CHI Conference on Human Factors in Com-
ing: SystemDemonstrations,pages175–184,Online putingSystems,CHIEA’21,NewYork,NY,USA.
andPuntaCana,DominicanRepublic.Association AssociationforComputingMachinery.
forComputationalLinguistics.
Stephen E. Robertson, Steve Walker, Micheline
NelsonF.Liu,TonyLee,RobinJia,andPercyLiang. Hancock-Beaulieu, Mike Gatford, and A. Payne.
2023a. Do question answering modeling improve- 1995. Okapiattrec-4. InTextRetrievalConference.
ments hold across benchmarks? In Proceedings
of the 61st Annual Meeting of the Association for Anna Rogers, Niranjan Balasubramanian, Leon Der-
ComputationalLinguistics(Volume1: LongPapers), czynski,JesseDodge,AlexanderKoller,SashaLuc-
pages13186–13218,Toronto,Canada.Association cioni, MaartenSap, RoySchwartz, NoahASmith,
forComputationalLinguistics. andEmmaStrubell.2023. Closedaimodelsmake
badbaselines.
PengfeiLiu,WeizheYuan,JinlanFu,ZhengbaoJiang,
HiroakiHayashi,andGrahamNeubig.2023b. Pre- EmreSezgin,JosephSirrianni,andSimonL.Linwood.
train, prompt, and predict: A systematic survey of 2022. Operationalizingandimplementingpretrained
largeailinguisticmodelsintheunitedstateshealth- SherryWu,HuaShen,DanielSWeld,