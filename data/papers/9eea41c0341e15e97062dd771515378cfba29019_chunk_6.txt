Note toandincludingutteranceu,andtheoutputis
t
that the simplest heuristic would increase each theperspectiveshiftedversion,y. A[SEP]
t
utterance’s word count by 1, as the colon next to tokendelimitstheleftcontext,u,...,u,
1 t−1
the speaker name is swapped out with the word fromtheutteranceu.
t
“says”).
3. left and right context: The input is the full
The average word-wise edit distance between conversation,with[SEP]tokensaroundthe
original and perspective-shifted utterances is 8.5 utteranceu,andtheoutputistheperspective
t
words. This is partially due to the insertion of a shiftedversion,y.
t
dialogue tag (e.g. “says”) in each utterance, the
4. conversation-level: The input is a complete
removalofemojis(average0.1perutterance),and
dialogueu,...,u,andtheoutputisacom-
theresolvingoffirstandsecondpersonpronouns 1 T
(average 0.9 per utterance). The part of speech3 pleteperspectiveshifty 1,...,y T.
distributionoftheconversationsalsochanges,with
For each formulation, we finetune a BART-large
a strong (65.8%) decrease in interjections and a
(Devlin et al., 2019) model for 15 epochs, using
slight (5.1%) decrease in adjectives and adverbs.
earlystopping,aneffectivebatchsizeof8,anda
However, in utterances that contain at least one
learningrateof5e-5.
emoji,thenumberofadjectivesandadverbspresent
increases 12.8%. This is consistent with the an-
Results ROUGE 1/2/L scores and BARTScore
notation guidelines, which instruct annotators to
foreachmodelarelistedinTable2.
capturethemeaningofinformalmarkerssuchas
The no context model treats this as a purely
emojiwithdescriptors.
utterance-level task, but fully precludes the addi-
tionofcontext