 Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
Peyré, G., & Cuturi, M. (2019). Computational optimal transport: With applications to data science.
Foundations and Trends in Machine Learning, 11(5–6), 355–607. https://doi.org/10.1561/2200000073
↩
Ranganath, R., Gerrish, S., & Blei, D. (2014). Black box variational inference. In P. Langley (Ed.),
Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics (Vol. 33;
814–822). https://proceedings.mlr.press/v33/ranganath14.html
↩
Ratner, A., Bach, S. H., Ehrenberg, H., Fries, J., Wu, S., & Ré, C. (2017). Snorkel: Rapid training data
creation with weak supervision. Proceedings of the VLDB Endowment. International Conference on Very
Large Data Bases, 11(3), 269–282. https://doi.org/10.14778/3157794.3157797 ↩
Rawlik, K., Toussaint, M., & Vijayakumar, S. (2012). On stochastic optimal control and reinforcement
learning by approximate inference. In Proceedings of Robotics: Science and Systems VIII.
http://doi.org/10.15607/RSS.2012.VIII.045
↩
Real, E., Liang, C., So, D., & Le, Q. (2020). AutoML-zero: Evolving machine learning algorithms from
scratch. In H. Daumé III & A. Singh (Eds.), Proceedings of the 37th International Conference on Machine
Learning (Vol. 119; 8007–8019). https://proceedings.mlr.press/v119/real20a.html
↩
Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine Learning, 62(1–2), 107–136.
https://doi.org/10.1007/s10994-006-5833-1 ↩
Roth, D. (2017). Incidental supervision: Moving beyond supervised learning. Proceedings of the AAAI
Con