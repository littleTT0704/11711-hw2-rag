anicalTurk. Italsoachievedstate-
Our workshop has held 2 ObjectNav challenges: of-the-artintheHabitat2021Challenge, withanSPL
the RoboTHOR ObjectNav Challenge [51] and the of0.146andasuccessrateof34%.
Habitat ObjectNav Challenge [166, 214]. Both chal-
lenges use the mentioned action and observation
space, as well as a simulated LoCoBot robotic agent.
3.1.4 Multi-ObjectNav
Incomparison:
InMulti-ObjectNav(MultiON)[198], theagentisini-
• Scenes. The RoboTHOR Challenge6 includes tialized at a random starting location in an environ-
89 room-sized dorm-like scenes. The Habi- ment and asked to navigate to an ordered sequence
tat 2021 Challenge7 90 houses from the Matter- of objects placed within realistic 3D interiors (Fig-
port3D dataset [27] and the Habitat 2022 Chal- ures 6a, 6b). The agent must navigate to each target
lenge8uses120housesfromtheHM3DSemantics
objectinthegivensequenceandcalltheFoundaction
dataset[151]. BothiterationsoftheHabitatChal- to signal the object’s discovery. This task is a gener-
lengeusescenescollectedfromreal-worldscans. alized variant of ObjectNav, whereby the agent must
In contrast, RoboTHOR scenes were hand-built navigate to a sequence of objects rather than a sin-
by 3D artists to be accessible in AI2-THOR [99] gle object. MultiON explicitly tests the agent’s navi-
gationcapabilityinlocatingpreviouslyobservedgoal
4https://www.youtube.com/watch?v=0BvUSjcc0jw
objectsandis,therefore,asuitabletestbedforevalu-
5https://www.youtube.com/watch?v=1uSsds7HSrQ
atingmemory-basedarchitecturesforEmbodiedAI.
6https://ai2thor.allenai.org/robothor/challenge
7https://aihabitat.org/challenge/2021/ Theagentisequippedwithan