across languages and was also trained on mono-
11NotethatmUSEandLaBSEreportresultsusingtheangle
lingual text using a masked language modelling
asthemetricinsteadofitscosineforsemanticsimilaritytasks,
but as they do not evaluate on these specific datasets, we
include the results from Reimers and Gurevych (2020) for 12The average performance for VMSST is 84.3, versus
comparisonwhichusescosinesimilarity. 82.6forLaBSE,and79.3forXLM-R(Para.)
Model Sem.Sim. BitextMining Quest.Retrieval Score
Eng. XL XL(s.) XL(d.) Tatoeba BUCC(c.) BUCC(m.) NQ MKQA
RandomInit.(24Layer)
VMSST 71.1 71.7 77.7 67.7 61.4 78.7 89.0 38.3 22.3 58.1
VMSST(fact.) 67.3 69.9 76.3 65.7 63.0 77.9 90.4 37.3 21.5 57.2
VMSST(4enc.) 71.2 70.2 76.6 66.0 60.8 77.7 88.5 38.4 22.0 57.6
VMSST(12Ldec.) 71.1 70.9 77.4 66.7 61.2 78.4 88.8 38.0 22.2 57.8
VMSST(1Ldec.) 71.0 71.2 77.0 67.4 63.0 79.4 89.1 38.7 22.8 58.5
VMSST(noKL) 70.7 68.7 76.2 63.7 56.9 70.8 86.6 37.8 21.5 55.7
VMSST(1enc.) 70.6 69.4 76.7 64.6 60.0 77.0 87.8 38.4 21.4 57.0
VMSST(noenc.l.e.) 71.2 69.8 76.1 65.5 61.2 78.7 88.9 38.2 22.0 57.7
VMSST(nodec.l.e.) 70.8 70.7 76.7 66