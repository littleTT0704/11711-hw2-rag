(EMNLP),9087–9105.
2019. Online:AssociationforComputationalLinguistics.
Beltagy, I.; Lo, K.; and Cohan, A. 2019. SciBERT: A Pre- Lake, B.; and Baroni, M. 2018. Still Not Systematic After
trained Language Model for Scientific Text. In Proceed- AllTheseYears:OntheCompositionalSkillsofSequence-
ingsofthe2019ConferenceonEmpiricalMethodsinNat- To-SequenceRecurrentNetworks. Iclr2018.
ural Language Processing and the 9th International Joint
Lake, B. M. 2019. Compositional generalization through
Conference on Natural Language Processing (EMNLP-
metasequence-to-sequencelearning. InAdvancesinNeural
IJCNLP), 3615–3620. Hong Kong, China: Association for
InformationProcessingSystems.
ComputationalLinguistics.
Lample, G.;and Charton, F. 2019. Deep learning for sym-
Charton, F.; Hayat, A.; and Lample, G. 2021. Learn-
bolicmathematics. arXivpreprintarXiv:1912.01412.
ing advanced mathematical computations from examples.
arXiv:2006.06462. Michel,P.;Li,X.;Neubig,G.;andPino,J.2019.OnEvalua-
tionofAdversarialPerturbationsforSequence-to-Sequence
Davis, E. 2019. The Use of Deep Learning for Sym-
Models. In Proceedings of the 2019 Conference of the
bolicIntegration:AReviewof(LampleandCharton,2019).
North American Chapter of the Association for Computa-
arXiv:1912.05752.
tional Linguistics: Human Language Technologies, Volume
Gardner, M.; Artzi, Y.; Basmov, V.; Berant, J.; Bogin, B.; 1(LongandShortPapers),3103–3114.Minneapolis,Min-
Chen,S.;Dasigi,P.;Dua,D.;Elazar,Y.;Gottumukkala,A.; nesota:AssociationforComputationalLinguistics.
