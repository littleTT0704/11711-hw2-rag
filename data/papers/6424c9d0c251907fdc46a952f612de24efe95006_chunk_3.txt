shipatGoogle.
1Codeandmodelsarereleasedathttps://next.cs.cmu.edu/ blecontinuationsoftherealtrajectoriestowardseachsuch
multiverse goal. In this way, our dataset is “anchored” in reality, and
1
0202
raM
82
]VC.sc[
3v54460.2191:viXra
yetcontainsplausiblevariationsinhigh-levelhumanbehav- motionsbyconsideringthemaspointsinthescene. These
ior,whichisimpossibletosimulateautomatically. research works [21, 60, 33, 30] have attempted to predict
Wecallthisdatasetthe“ForkingPaths”dataset,arefer- personpathsbyutilizingvisualfeatures. RecentlyLianget
encetotheshortstorybyJorgeLuisBorges.2 Asshownin al. [30] proposed a joint future activity and trajectory pre-
Fig.1,differenthumanannotationshavecreatedforkingsof dictionframeworkthatutilizedmultiplevisualfeaturesus-
futuretrajectoriesfortheidenticalhistoricalpast.Sofar,we ingfocalattention[29,28]. Manyworks[23,50,4,18,64]
havecollected750sequences,witheachcoveringabout15 invehicletrajectorypredictionhavebeenproposed. CAR-
seconds,from10annotators,controlling127agentsin7dif- Net [50] proposed attention networks on top of scene se-
ferentscenes. Eachagentcontains5.9futuretrajectorieson mantic CNN to predict vehicle trajectories. Chauffeur-
average. We render each sequence from 4 different views, net[4]utilizedimitationlearningfortrajectoryprediction.
and automatically generate dense labels, as illustrated in Multi-future trajectory prediction. Many works have
Fig. 1 and 3. In total, this amounts to 3.2 hours of trajec- triedtomodeltheuncertaintyoftrajectoryprediction. Var-
tory sequences, which is comparable to the largest person ious papers (e.g. [20, 43, 44] use Inverse Reinforcement
trajectorybenchmarkVIRAT/ActEV[3,36