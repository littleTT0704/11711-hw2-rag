examineourproposedapproach,wecompareit
bel},andweassignvalue-dependentlabelstoeach withmultiplebaselines,includingarandombase-
sample. Forinstance,ifcontentC wasoriginally line, prompt-based few-shot learning with OPT-
labelledasRole-stereotyping(RS),weconvertinto 175B, and fine-tuning transformer-based models.
three testing samples, {C, value, Sexist}, {C, For the fine-tuning setting, we fine-tune on dif-
RS
counter-value, Non-Sexist}, and {C, random ferentdatasetups–onlywithhuman-labeleddata
RS
value/counter-value,NA}. NotethatvaluesforNA (withoutgenerateddata)andwithsemanticallyaug-
labelsaretotallyunrelatedtothecontentcategory. menteddata.
In this way, we can inspect the model’s perfor-
Random Baseline We randomly select the pre-
manceinmakingavaluejudgementonthesame
dicted label for each test sample with the same
content with different values. In total, there are
labelprobabilitydistributionasinthetrainingdata.
17,720testsamples,withalabelratioof1:1:1.
OPT-175B (few-shot) This baseline uses OPT-
5.2 Models
175B with a prompt-based few-shot learning for
5.2.1 VA-MODELs(Ours) labelprediction.2 Weprovide20few-shotsamples
Generatingvalue-alignedtrainingdata Using inthecontext.
the method explained in Section 4.1, we get 100
Human-Labeled(HL)-Models Weonlyusethe
contentpiecesfromeachofthevalueandcounter-
smallsubsetofhuman-labeledsamplesastraining
valueprompts. Insum,thereare200uniquepieces
data to fine-tune smaller transformer-based LMs
of content per category.1 Then, all content per
with a linear layer trained on top. We choose the
categoryispairedwithavalueandcountervalue
base versions of ALBERT, RoBERTa and BART
andcorrespondinglabels{content,value,‘