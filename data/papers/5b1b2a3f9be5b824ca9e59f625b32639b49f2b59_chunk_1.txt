1
Online Video Instance Segmentation via Robust Context Fusion
Xiang Li, Jinglu Wang, Xiaohao Xu, Bhiksha Raj, Fellow, IEEE Yan Lu, Senior Member, IEEE
Video instance segmentation (VIS) aims at classifying, segmenting and tracking object instances in video sequences. Recent
transformer-based neural networks have demonstrated their powerful capability of modeling spatio-temporal correlations for the
VIS task. Relying on video- or clip-level input, they suffer from high latency and computational cost. We propose a robust context
fusion network to tackle VIS in an online fashion, which predicts instance segmentation frame-by-frame with a few preceding
frames. To acquire the precise and temporal-consistent prediction for each frame efficiently, the key idea is to fuse effective and
compact context from reference frames into the target frame. Considering the different effects of reference and target frames on
the target prediction, we first summarize contextual features through importance-aware compression. A transformer encoder is
adopted to fuse the compressed context. Then, we leverage an order-preserving instance embedding to convey the identity-aware
information and correspond the identities to predicted instance masks. We demonstrate that our robust fusion network achieves
the best performance among existing online VIS methods and is even better than previously published clip-level methods on the
Youtube-VIS 2019 and 2021 benchmarks.
In addition, visual objects often have acoustic signatures that are naturally synchronized with them in audio-bearing video
recordings. By leveraging the flexibility of our context fusion network on multi-modal data, we further investigate the influence of
audios on the video-dense prediction task, which has never been discussed in existing works. We build up an Audio-Visual Instance
Segmentation dataset, and demonstrate that acoustic signals in the wild scenarios could benefit the VIS task.
Index Termsâ€”video instance segmentation, multimodal learning
I. INTRODUCTION acrossframes.Severalsubsequentmethods[29],[2],[18],[48]
The recently introduced video instance segmentation (VIS) fuse inter-frame features in the encoding stage. In particular,
problem receives increasing attention because of growing some methods [18], [29], [48] crop out ROI features to fuse
interest among researchers in the multimedia community. VIS context within local regions, but cropped features are isolated
aims at simultaneously classifying, segmenting and tracking from the