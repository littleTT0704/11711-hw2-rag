 in passage P. For additional information about lnn term weighting
and other weighting schemes that are commonly used in information retrieval, we
18 CHAPTER 2. RELATED WORK
refer the reader to Manning et al. [2008]. In our implementation of MMR, individual
characters and tokens that appear on a list of about 250 function words are removed,
the Porter stemmer [Porter, 1980] is applied to the remaining tokens, and the same
term weighting scheme is used.
The choice of query Q is crucial to the performance of the MMR algorithm. Car-
bonell and Goldstein achieve strong results using topic descriptions that consist of
about 100–150 tokens as queries. These descriptions were compiled manually and are
ofhighquality, andtheytendtorepeatimportantinformation. WhenapplyingMMR
to select text that is related to the topic of a seed document for source expansion,
we found that the approach is most effective if the entire seed is used as a query. If
instead only the seed title is used, or if the seeds are artificially degraded by removing
text or adding noise, performance degrades substantially (cf. Sections 5.3 and 5.4).
Thus the algorithm appears to work best if the queries are long, and redundancy in
the queries may help reinforce important information and give more weight to key
terms in the cosine similarity calculations.
The MMR algorithm terminates once a given number of passages has been se-
lected, or when the compression ratio reaches a threshold. The compression ratio is
defined as |S|/|R|, where |·| could e.g. be the total character length or the number
of text passages in a set. However, it can be difficult to choose a threshold when eval-
uating the algorithm because the ideal summary length is subjective and should be
determined based on the application and user preferences. Depending on the cutoff
point, precision and recall of the generated summaries can differ widely. In addition,
it may not be effective to use a fixed threshold because different summary lengths
may be optimal depending on the topic and the amount of relevant content in the
set of candidate passages. For these reasons, we do not set a threshold in our experi-
ments, butinsteadwegenerateacompleterankingofallcandidatepassages. Ranking
performance is evaluated using mean average precision (MAP) as a single aggregate
measure that takes into