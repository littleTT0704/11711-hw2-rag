Tactical Rewind: Self-Correction via Backtracking
in Vision-and-Language Navigation
LiyimingKe1∗ XiujunLi1,2 YonatanBisk1 AriHoltzman1 ZheGan2
JingjingLiu2 JianfengGao2 YejinChoi1,3 SiddharthaSrinivasa1
1PaulG.AllenSchoolofComputerScience&Engineering,UniversityofWashington
2MicrosoftResearchAI 3AllenInstituteforArtificialIntelligence
{kayke, xiujun, ybisk, ahai, yejin, siddh}@cs.washington.edu
{xiul, zhgan, jingjl, jfgao}@microsoft.com
Abstract
We present the Frontier Aware Search with backTrack-
ing (FAST) Navigator, a general framework for action de-
coding, that achieves state-of-the-art results on the Room-
to-Room(R2R)Vision-and-Languagenavigationchallenge
of Anderson et. al. (2018). Given a natural language in-
struction and photo-realistic image views of a previously
unseen environment, the agent was tasked with navigating
fromsourcetotargetlocationasquicklyaspossible. While
allcurrentapproachesmakelocalactiondecisionsorscore
entire trajectories using beam search, ours balances local
andglobalsignalswhenexploringanunobservedenviron-
ment. Importantly, this lets us act greedily but use global
signalstobacktrackwhennecessary.ApplyingFASTframe-
worktoexistingstate-of-the-artmodelsachieveda17%rel- (a) SoTABeamSearch (b) FASTNAVIGATOR
ative gain, an absolute 6% gain on Success rate weighted Figure1. Top-downviewofthetrajectorygraphsforbeamsearch
byPathLength(SPL).1 andFAST.BlueStaristhestartandRedStopisthetarget.
1.Introduction decoded as output. Several subsequent architectures also
use this framing; however, they augment it with impor-
When reading an instruction (e.g. “Exit the bathroom, tantadvancesinattentionmechanisms,globalscoring,and
tak