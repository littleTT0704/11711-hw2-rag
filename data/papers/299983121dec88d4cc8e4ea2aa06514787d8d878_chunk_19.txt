generation.Ex.4’shu-
allexamples.See§5.2andAppendixDforfurtherdetails.
manreferenceiscreative,whichisanareawhereVisCTG
still lacks in comparison. For ex. 5, while VisCTG edits
Model Aspect O1 O2 O3 “someone”to“man”,itisunabletomergethetwoinstances
Overall 0.44 0.24 0.32 of“man”oradjustthesentencetobemorecoherent.These
BART-large Commonsense 0.32 0 0.68 weaknessesarelikelybecausecaptionstendtobesimplis-
Fluency 0.56 0.12 0.32
tic (due to the captioning model’s training data), limiting
VisCTG’sabilitytomakeheavieredits.VisCTG,unsurpris-
Table 10: Avg. expert linguist eval results on test for
CG ingly,appearstodependquiteheavilyonthecaptions,and
BART-large.O1:VisCTGwins,O2:baselinewins,O3:in-
hencethequalityoftheimagesandcaptioningmodel.
distinguishable.See§5.2andAppendixDforfurtherdetails.
7 RelatedWork
gethertheinputconceptsintoaformofEnglishsyntax,often Constrained Text Generation: There have been several
failing to do so effectively. VisCTG models can produce works on constrained text generation. Miao et al. (2019)
moregrammatical,fluent,andlogicaltextbyexploitingthe useMetropolis-HastingssamplingtodetermineLevenshtein
syntacticanddependencystructuresofthecaptions.Further, edits per generation step. Feng, Li, and Hoey (2019) pro-
10623
Method Text
Conceptset {sit,chair,toy,hand}(example1)
Captions alittlegirlsittingonachairwithateddybear<s>asmallchildsittingonachairwithateddybear<s>a
youngboysittingonachairwithaskateboard<s>amansittingonachairwitharemote
BART-base-BL