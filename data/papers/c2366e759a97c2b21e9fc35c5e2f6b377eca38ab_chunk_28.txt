achhigh-levelstep,wemeasurethestateusingthreeRealSenseRGBD
cameras[34], whicharecalibratedtotherobotframeofreferenceusingARTags[35]. Thecamera
output, extrinsics, and intrinsics are combined using Open3D [36] to generate a combined point-
cloud. This pointcloud is segmented and clustered to give objects’ pose and category using the
algorithmfrom[37]andDBScan. Foreachobjectpointcloudcluster, weidentifytheobjectpose
basedonthemean ofthepointcloud. For categoryinformationweusemedianRGBvalue ofthe
pointcloud, and map it to apriori known set of objects. In the future this can be replaced by more
advanced techniques like MaskRCNN [69]. Placement poses are approximated as a fixed, known
location,astheplaceactiononhardwareisafixed‘drop’positionandorientation.Theperstepstate
of the objects is used to create the input prompt tokens used to condition the policy rollout in the
real-world,asdescribedinSection3.2.
Figure8: Humandemonstrationofreal-worldrearrangementofhouseholddishes.
A.2 Hardwarepolicyrollout
We zero-shot transfer our policy π trained in simulation to robotic hardware, by assuming low-
levelcontrollers. WeuseaFrankaPandaequippedwithaRobotiq2F-85gripper,controlledusing
the Polymetis control framework [33]. Our hardware setup mirrors our simulation, with different
categoriesofdishware(bowls,cups,plates)onatable,a“dishwasher”(cabinetwithtwodrawers).
Theobjectiveistoselectanobjecttopickandplaceitintoadrawer(rack)(seeFig. 8).
Oncewecollectthehumanpromptdemonstrationtokens,wecanusethemtoconditionthelearned
policy π from simulation. Converting the hardware state to tokens input to π follows the same
pipelineastheonesusedforcollectinghumandemonstrations. Ateachstep,thesceneiscaptured
using3Realsensecameras,andthecombinedpointcoundissegmentedandclusteredtogetobject
poses