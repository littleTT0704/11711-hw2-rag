 100.0 100.0 92.4
Avg 47.3 90.9 64.8 26.7 51.6 32.8 Avg 95.8 100.0 95.3 55.1 87.0 64.1
Table 10: Error rate of XLM-R fine-tuned on English Table 11: Error rate of mBERT fine-tuned on English
SQuADv1.1on6 CHECKLIST QAtestsacrossall50 SQuADv1.1on6 CHECKLIST QAtestsacrossall50
languages. languages.
Table12: ExamplefailurecasesofXLM-Ronasubsetoflanguages. Eachfailurecaseconsistsofacontext(C),a
question(Q),ananswer(A),andXLM-Râ€™sprediction(P).
Numberofparameters Pre-trainingdata
Model
(inmillions) Monolingualdata Paralleldata
mBERT 178 85GB N/A
XLM-R(large) 559 6.3Ttokens N/A
MMTE 190 N/A 25Bpairs
mT5 13,000 1Ttokens N/A
RemBERT 575 1.8Ttokens N/A
X-STILTS 559 6.3Ttokens N/A
FILTER 559 6.3Ttokens N/A
VECO 559 1.3TB 6.4Mpairs
T-URLv2+StableTune 559 2.1TB 42GB
ERNIE-M 559 1.5TB 69GB
Table13: MetadataforthecurrentsubmissionstoXTREME.Notethatmonolingualpre-trainingdataisreported
ineithernumberoftokensorsizeofthedata(inGB/TB).Theamountofparalleldataisreportedineithernumber
ofpairsorsizeofthedata(inGB/TB).
Mewsli-X LAReQA
Subset\Model mBERT XLM-RLarge mBERT XLM-RLarge
All 40.2 47.1 16.3 31.3
Samelanguage 85.7 83.6 58.2 57.1
Differentlanguages 25.8 35.5 12.1 28.7
Table14