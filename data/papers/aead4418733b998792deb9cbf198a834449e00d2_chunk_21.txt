ainthedata;thusasparsetrainingsetyields
anunderconstrainedhypothesisspace,withhypothesesthat
do not strongly generalize (e.g. Table 5), causing behavior
7 RelatedWork
thatbreakssimplerules(e.g.adheringtoatemplateorfol-
Inthiswork,westudysystematicgeneralizationinsequence lowingthesumrule).Wesuspectthatinductivebiases–e.g.
models applied to symbolic integration, in terms of robust- encodedthroughthetrainingdistribution,architecturalcom-
ness,compositionality,andextrapolation,anddevelopage- ponents,orlearningalgorithm–areneededtonarrowthehy-
neticalgorithmforbuildingadversarialproblemsets. pothesestothosethatstronglygeneralize.
8635
References Hill, F.; Lampinen, A.; Schneider, R.; Clark, S.; Botvinick,
M.;McClelland,J.L.;andSantoro,A.2020. Environmen-
Agarwal,V.;Aditya,S.;andGoyal,N.2021. Analyzingthe
tal drivers of systematicity and generalization in a situated
NuancesofTransformers’PolynomialSimplificationAbili-
agent. In International Conference on Learning Represen-
ties. arXiv:2104.14095.
tations.
Agrawal,A.;Batra,D.;andParikh,D.2016. Analyzingthe
Behavior of Visual Question Answering Models. In Pro- Holtzman, A.; Buys, J.; Du, L.; Forbes, M.; and Choi, Y.
ceedings of the 2016 Conference on Empirical Methods in 2020. The Curious Case of Neural Text Degeneration. In
Natural Language Processing, 1955–1960. Austin, Texas: InternationalConferenceonLearningRepresentations.
AssociationforComputationalLinguistics. Hupkes,D.;Dankers,V.;Mul,M.;andBruni,E.2020.Com-
Alzantot, M.; Sharma, Y.; Elgohary, A.; Ho, B.-J.; Srivas- positionality Decomposed: How do Neural Networks Gen-
tava,M.;