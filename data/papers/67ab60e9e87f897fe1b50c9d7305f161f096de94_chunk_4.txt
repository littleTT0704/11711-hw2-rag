 good representation should (1) transfer to a wide
range of different tasks and (2) transfer with limited supervision (Goyal et al., 2019, 2022).
In the following paragraphs, we describe trends from the natural language processing
(NLP) and vision literature on representation learning, some of which have been applied
to audio. Vision work is particularly relevant (Amiriparian et al., 2017), as 2-D transfor-
mations of audio, such as the widely used log-Mel spectrogram (Davis and Mermelstein,
1980), lend themselves well to methods designed to process 2-D input data. For this rea-
son, a common thread in the literature on audio representations is that vision models are
applied to 2-D audio representations. With that said, many of the insights from text-based
language modeling, such as autoregressive neural modeling (Bengio et al., 2001), predict-
ing tokens masking as an unsupervised pretext task (Collobert et al., 2011), and bidirec-
tional transformers (Devlin et al., 2019), have found their way into the audio literature,
e.g., WaveNet (van den Oord et al., 2016), wav2vec (Schneider et al., 2019), and HuBERT
(Hsu et al., 2021), respectively. Textless NLP like Generative Spoken Language Modeling
(GSLM, Lakhotia et al. (2021)), applies an NLP lens to spoken audio instead of written
text.
Inducing representations The shallowest representation for audio is the raw digital
audio signal itself. However, its extremely high dimensionality means it is rarely useful for
discriminative tasks without additional processing, whether via manually crafted DSP en-
gineering or transformations learned by training a neural network (Trigeorgis et al., 2016).
Better representations might be obtained by applying a hand-crafted transformation based
upon domain-expertise, such as the log-scaled Mel spectrogram (Davis and Mermelstein,
1980), Mel Frequency Cepstral Coefficients (MFCC, Logan (2000)), constant Q-transform
(Scho¨rkhuber and Klapuri, 2010), or scattering transform (And´en and Mallat, 2014). Au-
dio filterbanks can also be learned (Zeghidour et