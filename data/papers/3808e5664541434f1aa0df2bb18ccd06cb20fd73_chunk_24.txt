
Amodei. 2020. Language models are few-shot Levy, Roy Schwartz, Samuel R. Bowman, and
learners. InProc.ofNeurIPS. Noah A. Smith. 2018. Annotation artifacts in nat-
urallanguageinferencedata. InProc.ofNAACL.
Christopher Clark, Mark Yatskar, and Luke Zettle-
moyer.2019. Donâ€™ttaketheeasywayout: Ensem- Jessica Guynn. 2020. What civil rights groups want
ble based methods for avoiding known dataset bi- from facebook boycott: Stop hate speech and ha-
ases. InProc.ofEMNLP. rassmentofblackusers.
Adam M Croom. 2013. How to do things with slurs:
Moritz Hardt, Eric Price, and Nati Srebro. 2016.
Studies in the way of derogatory words. In Lan-
Equality of opportunity in supervised learning. In
guage&communication.
Proc.ofNeurIPS.
Thomas Davidson, Debasmita Bhattacharya, and Ing-
HeHe,ShengZha,andHaohanWang.2019. Unlearn
mar Weber. 2019. Racial bias in hate speech and
dataset bias in natural language inference by fitting
abusive language detection datasets. In Abusive
theresidual. InEMNLPWorkshoponDeepLearn-
LanguageWorkshop(atACL).
ingApproachesforLow-ResourceNLP.
Thomas Davidson, Dana Warmsley, Michael Macy,
and Ingmar Weber. 2017. Automated hate speech Eun Seo Jo and Timnit Gebru. 2020. Lessons from
detectionandtheproblemofoffensivelanguage. In archives: strategiesforcollectingsocioculturaldata
Proceedings of the International AAAI Conference inmachinelearning. InProc.ofFAT.
onWebandSocialMedia.
Rabeeh Karimi Mahabadi, Yonatan Belinkov, and
Thiago Dias Oliva, Dennys Marcelo Antonialli, and JamesHenderson.2020. End-to-endbiasmitigation
AlessandraGomes.2020. Fightinghatespeech, si- bymodellingbiasesincorpora. InProc.ofACL.
lencing drag queens? artificial intelligence in con-