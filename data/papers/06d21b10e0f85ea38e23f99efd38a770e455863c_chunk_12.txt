Place - 75.4 71.3 85.0 81.3 74.2
2017STS3rdPlace - 74.6 70.0 84.9 79.1 73.6
P-SP 1024 76.2\76.7 78.3\78.4 85.8\85.6 78.4\77.8 79.2\79.5
Table 3: Comparison of our models with those in the literature on non-English and cross-lingual STS. We also
includethetop3systemsforeachdatasetfromtheSemEval2017STSsharedtask. Performanceismeasuredin
Pearson’sr 100. WealsoincluderesultsinSpearmans’sρ 100afteraslashforLASER,LaBSE,andP-SP.
× ×
sentence pairs by their trigram overlap (Wieting Oneexception,though,iswedonotincludetrain-
et al., 2017), which is calculated by counting tri- ingdatafromTatoeba13 (Tiedemann,2012)asthey
gramsinthetwosentences,andthendividingthe do, since this domain is also in the bitext mining
numberofsharedtrigramsbythetotalnumberin evaluation set. The amount of data used to train
the sentence with fewer tokens. We only include eachofourmodelsisshowninTable1.
sentencepairswherethetrigramoverlapscoreis
0.7. Theparaphrasescoreiscalculatedbyaver- Hyperparameters. For all models, we fix the
≤
aging PARAGRAM-PHRASE embeddings(Wieting batch size to 128, margin δ to 0.4, and the an-
etal.,2016b)forthetwosentencesineachpairand nealing rate to 150.14 We set the size of the
thencomputingtheircosinesimilarity. Thepurpose sentencepiece vocabulary to 50,000, using a
ofthelowerthresholdistoremovenoisewhilethe sharedvocabularyforthemodelstrainedonbitext.
higher threshold is meant to remove paraphrases Ifawordisnotinvocabulary,wesimplyexcludeit,
thataretoosimilar. unlessthetextonlyconsistsofunknownwordsin