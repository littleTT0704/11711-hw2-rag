SNLIandANLI.InSNLI,the
few-shot-discussion system performs worse than et al., 2021; Honovich et al., 2022; Wang et al.,
the few-shot system, but in the three datasets of 2022b). Therefore,weproposetouseGPT-3.5and
ANLI, we find that the performance is the best. ChatGPTtogeneratediscussiondatainazero-shot
This is because ANLI is more difficult data com- andusethemasdiscussionexamplesforafew-shot
pared to SNLI, and we hypothesize that through toinvestigateifitispossibletoachievethesame
discussion,systemsgetamoredetailedunderstand- levelofimprovementasfromusingmanuallycre-
ingofproblems,whichinturncontributestoper- ated data. If a system can automatically produce
formanceimprovement. high-qualitydata, itcanproduceenoughdatafor
From the results of previous experiments, we fine-tuningatalowcost. Therefore,wealsoinves-
foundthatdiscussionbetweenhumansandsystems tigatetheeffectivenessofpseudo-discussiondata
is beneficial for improving performance.9 There- infine-tuning.
fore, the few-shot-discussion system, in which a Ingeneratinghumandiscussions,thesystemis
discussion example is also given as a prompt, is givenpromptsintheformofthepremise,hypoth-
expectedtoachieveadeeperunderstandingofNLI esis, gold label, and the labels from each human.
problems and improve performance through the The human labels are randomly chosen to be the
discussionexampleintheprompt. gold label or the other incorrect label. For exam-
ple, given the premise “A nun is taking a picture
6 Analysis
outside.” andhypothesis“Anunistakingaselfie.”
with the gold label of neutral, the prompt would
6.1 Pseudo-DiscussionData
be“Reproduceamulti-turninteractivediscussion
Onedrawbackofusingdiscussiondataisthatitcan
inwhichthefollowingpremiseandhypothesisare
becostlytocreatecomparedtodatasetsthatonly