BjörnRoss, MichaelRist, GuillermoCarbonell, Ben- soning about effects and harms of offensive state-
jaminCabrera,NilsKurowsky,andMichaelWojatzki. ments. InFindingsofACL.
2016. MeasuringtheReliabilityofHateSpeechAn-
notations: TheCaseoftheEuropeanRefugeeCrisis.
PaulRottger,BertieVidgen,DirkHovy,andJanetPier-
rehumbert. 2022. Two contrasting data annotation
paradigmsforsubjectiveNLPtasks. InProceedings
ofthe2022ConferenceoftheNorthAmericanChap-
ter of the Association for Computational Linguis-
tics:HumanLanguageTechnologies,pages175–190,
Seattle,UnitedStates.AssociationforComputational
Linguistics.
RWJF.2017. Discriminationinamerica: experiences
andviews.
MaartenSap,DallasCard,SaadiaGabriel,YejinChoi,
andNoahASmith.2019. Theriskofracialbiasin
hatespeechdetection. InACL.
MaartenSap,SaadiaGabriel,LianhuiQin,DanJuraf-
sky, Noah A Smith, and Yejin Choi. 2020. Social
biasframes: Reasoningaboutsocialandpowerim-
plicationsoflanguage. InACL.
Maarten Sap, Swabha Swayamdipta, Laura Vianna,
XuhuiZhou,YejinChoi,andNoahA.Smith.2022.
Annotatorswithattitudes: Howannotatorbeliefsand
identitiesbiastoxiclanguagedetection. InNAACL.
7
A ImplementationDetails • Lenient: thepostmightbeaggressive,angry,or
useprofanity/swearwords,butisnotoffensive
A.1 ExplanationGenerationwithLLMs
or prejudiced and does not use slurs in hateful
Weuselargelanguagemodels(Ouyangetal.,2022) ways.
to generate free-text explanations. Given a state-
• Moderate: the post is offensive, prejudiced,
ments,weuseapatternF toencodeoffens