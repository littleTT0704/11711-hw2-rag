chesthetop100
relevantpassagesfromthepassageindex,followedbyaRoBERTA-basedcross-encoderforreranking. Thetop10
passagesarepassedtoFiDwithT5tooutputthefinalresponse. Thismodelisalsousedtoperformcurriculum
learningasdiscussedinSection4.
sitions between segments, which we refer to as anddialoguecontext(previousturns)asthequery.
topic shifts, are not marked. As a result, models The query is then passed to the retriever which
are required not only to determine the grounding selectsthetop-npassageswhicharefurtherpassed
passagesforeachturnbutalsotodeterminewhich to a reranker. The top-k (out of top-n) reranked
parts of the dialogue context continue to be rele- passagesarethenfedtothereaderalongwiththe
vantacrosstopicshifts. Theoriginaldatasetalso querytofinallygeneratetheagent’sresponse.
presentsseveraldistinctdomainsofgroundingdoc- Inourexperiments,weuseDistilSPLADE(For-
umentsfromdifferentpublic-facingwebsitesthat maletal.,2021)asourretriever,whichaugments
exhibit different writing styles. Each dialogue is the query and passages, subsequently projecting
groundedindocumentsdrawnfromthesamedo- them to a sparse vector in the vocabulary space.
main. Eachcoordinateintheprojectedvectorrepresents
Thesharedtaskdefinestwosettings: onewhere the semantic importance of a term (also called
all of the dialogues are grounded in documents “termimpact”(Malliaetal.,2021))formatching.
fromdomainsseenduringtraining(MDD-SEEN), Theinputsareaugmentedbyapplyingasparsity-
and another where the grounding domain is un- inducing activation function on the logits of a
seen (MDD-UNSEEN). Due to the open domain Masked Language Model such as BERT (Devlin
evidence retrieval and natural language response et al., 2019), which selects the important words
generationsettingofthetask,itlendsitselfwellto presentinthepassageandaddsadditionalexpan-
aretri