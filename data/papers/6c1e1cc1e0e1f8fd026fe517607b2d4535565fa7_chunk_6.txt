textexam- 2cansof3tennisballseachis6, in PAL we also aug-
plewithchainofthought(COT)intermediatesteps. Specifi- ment each such NL step with its corresponding pro-
cally,eachin-contextexampleintheCOTsetupisatriplet grammaticstatementsuchas tennis balls = 5 and
(cid:104)x,t,y (cid:105),wherex andy areinput-outputpairasbefore, bought balls = 2 * 3. Thisway,themodellearns
i i i i i
andt isanaturallanguagedescriptionofthestepsthatare togenerateaprogramthatwillprovidetheanswerforthe
i
neededtoarriveattheoutputy fromtheinputx. SeeFig- test question, instead of relying on LLM to perform the
i i
ure1foranexample. Withtheadditional“thoughts”t,the calculationcorrectly.
i
promptissettop≡(cid:104)x ·t ·y (cid:105)(cid:107)(cid:104)x ·t ·y (cid:105)(cid:107)...(cid:107)(cid:104)x ·t ·y (cid:105).
1 1 1 2 2 2 k k k WepromptthelanguagemodeltogenerateNLintermediate
During inference, the new question x is appended to steps using comment syntax (e.g. “#...” in Python)
test
thepromptasbeforeandsuppliedtotheLLM.Crucially, suchtheywillbeignoredbytheinterpreter. Wepassthe
themodelistaskedwithgeneratingboththethoughtt generatedprogramt toitscorrespondingsolver,werun
test test
andthefinalanswery. Thisapproachofpromptingthe it,andobtainthefinalrunresulty. Inthisworkweuse
test test
modeltofirstgenerateareasoningprocesst improves a standard Python interpreter, but this can be any solver,
test
the accuracy of the answer y across a wide range of interpreteroracompiler.
test
tasks (Wang et al., 2022a; Wei et al