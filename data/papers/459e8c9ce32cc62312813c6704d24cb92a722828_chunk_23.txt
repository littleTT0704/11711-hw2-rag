research.
and weights them according to their improvement in task
loss.Keytoourmethodisaproposaldistributionwhichei- References
therperformsrandomsearcharoundthecurrentparameteror
Baevski, A.; and Auli, M. 2019. Adaptive Input Rep-
aroundthemaximum-likelihoodgradient.
resentations for Neural Language Modeling. In Interna-
MGS substantially reduced non-termination and repe-
tionalConferenceonLearningRepresentations. URLhttps:
tition in a text completion task, and outperformed maxi-
//openreview.net/forum?id=ByxZX20qFQ.
mumlikelihoodonmachinetranslation,withfine-tuningand
whentrainedfromscratch.MGSincorporatesthemaximum- Bahdanau,D.;Brakel,P.;Xu,K.;Goyal,A.;Courville,A.;
14038
Pineau,R.L.J.;andBengio,Y.2017. Anactor-criticalgo- matters. In32ndAAAIConferenceonArtificialIntelligence,
rithmforsequenceprediction. In5thInternationalConfer- AAAI2018. ISBN9781577358008.
enceonLearningRepresentations,ICLR2017-Conference
Holtzman,A.;Buys,J.;Forbes,M.;andChoi,Y.2019. The
TrackProceedings.
curious case of neural text degeneration. arXiv preprint
Bahdanau,D.;Cho,K.;andBengio,Y.2015.NeuralMachine arXiv:1904.09751.
TranslationbyJointlyLearningtoAlignandTranslate. In
Koehn,P.;andKnowles,R.2017. SixChallengesforNeural
3rdInternationalConferenceonLearningRepresentations,
MachineTranslation. doi:10.18653/v1/w17-3204.
ICLR2015,SanDiego,CA,USA,May7-9,2015,Conference
TrackProceedings. URLhttp://arxiv.org/abs/1409.0473. Lafferty,J.;McCallum,A.;andPereira,F.C.N.2001. Con-
Ban