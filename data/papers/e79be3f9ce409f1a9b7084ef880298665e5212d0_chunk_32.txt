 video and language pre-training model for mul-
convolutions for action recognition. In Proceedings of the
timodal understanding and generation. arXiv:2002.06353,
IEEEconferenceonComputerVisionandPatternRecogni-
2020. 1,2,3,5,6,7,8,12
tion,pages6450–6459,2018. 5
[34] A.Miech,J.B.Alayrac,L.Smaira,I.Laptev,J.Sivic,and
[47] AshishVaswani,NoamShazeer,NikiParmar,JakobUszko-
A.Zisserman. End-to-endlearningofvisualrepresentations
reit,LlionJones,AidanNGomez,LukaszKaiser,andIllia
from uncurated instructional videos. In 2020 IEEE/CVF
Polosukhin. Attentionisallyouneed. 062017. 3
Conference on Computer Vision and Pattern Recognition
[48] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chau-
(CVPR),pages9876–9886,June2020. 1,2,3,5,8
mond,ClementDelangue,AnthonyMoi,PierricCistac,Tim
[35] Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac,
Rault, Re´mi Louf, Morgan Funtowicz, Joe Davison, Sam
Makarand Tapaswi, Ivan Laptev, and Josef Sivic.
Shleifer,PatrickvonPlaten,ClaraMa,YacineJernite,Julien
HowTo100M: Learning a Text-Video Embedding by
Plu,CanwenXu,TevenLeScao,SylvainGugger,Mariama
WatchingHundredMillionNarratedVideoClips. InICCV,
Drame,QuentinLhoest,andAlexanderM.Rush. Hugging-
062019. 1,2,5,6,7,8
face’s transformers: State-of-the-art natural language pro-
[36] Tomas Mikolov, Kai Chen, Greg S. Corrado,