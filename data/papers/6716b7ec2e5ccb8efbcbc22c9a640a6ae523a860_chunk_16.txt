, and Luke Zettlemoyer. 2020a. SivaReddy,DanqiChen,andChristopherD.Manning.
Bart: Denoisingsequence-to-sequencepre-training 2019b. CoQA: A conversational question answer-
fornaturallanguagegeneration,translation,andcom- ing challenge. Transactions of the Association for
prehension. InProceedingsofthe58thAnnualMeet- ComputationalLinguistics,7:249–266.
ingoftheAssociationforComputationalLinguistics,
pages7871–7880. Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer
Singh,TimRockta¨schel,MikeSheldon,Guillaume
PatrickLewis,EthanPerez,AleksandraPiktus,Fabio Bouchard, and Sebastian Riedel. Interpretation of
Petroni,VladimirKarpukhin,NamanGoyal,Hein- natural language rules in conversational machine
rich Ku¨ttler, Mike Lewis, Wen-tau Yih, Tim reading.
Rockta¨schel,etal.2020b. Retrieval-augmentedgen-
LeeXiong,ChenyanXiong,YeLi,Kwok-FungTang,
erationforknowledge-intensivenlptasks. Advances
Jialin Liu, Paul N. Bennett, Junaid Ahmed, and
inNeuralInformationProcessingSystems,33:9459–
ArnoldOverwijk.2020. Approximatenearestneigh-
9474.
bor negative contrastive learning for dense text re-
Chin-YewLin.2004. Lookingforafewgoodmetrics: trieval. CoRR,abs/2007.00808.
Rougeanditsevaluation.
Benfeng Xu, Licheng Zhang, Zhendong Mao, Quan
Wang, Hongtao Xie, and Yongdong Zhang. 2020.
YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
Curriculumlearningfornaturallanguageunderstand-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
ing. InProceedingsofthe58thAnnualMeeting