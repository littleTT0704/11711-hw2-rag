,SoftMatchachievesanerrorrate
7
PublishedasaconferencepaperatICLR2023
FixMatch 1.0 1.0 1.0 0.8 FlexMatch
SoftMatch 0.8 0.8 0.8
0.6
0.6 0.6 Fix.BestCls.
0.6
0.4 0.4 0.4 F Sole ftx.. BB ee ss tt CC ll ss..
0.2 0.2 F Fi lx exM Ma atc th ch 0.4 F Fi lx exM Ma atc th ch 0.2 F Fi lx ex..W Wo ors rt stC Cls l. s.
SoftMatch SoftMatch Soft.WorstCls.
0.00k 50k 100k 150k 0.00k 50k 100k 150k 0.20k 50k 100k 150k 0.00k 50k 100k 150k
Iter. Iter. Iter. Iter.
(a) Eval.Error (b) Quantity (c) Quality (d) Cls.Quality
Figure2: QualitativeanalysisofFixMatch, FlexMatch, andSoftMatchonCIFAR-10with250la-
bels. (a)Evaluationerror;(b)QuantityofPseudo-Labels;(c)QualityofPseudo-Labels;(d)Quality
ofPseudo-Labelsfromthebestandworstlearnedclass. Qualityiscomputedaccordingtotheun-
derlyinggroundtruthlabels. SoftMatchachievessignificantlybetterperformance.
of12.68%onAGnewswithonly40labelsand1.68%onDBpediawith70labels, surpassingthe
secondbestbyamarginof2.81%and0.5%respectively. Onsentimenttasks,SoftMatchalsoshows
thebestresultsonAmazon-5andIMDb,andcomparableresultstoitscounterpartonYelp-5.
4.4 QUALITATIVEANALYSIS
In this section, we provide a qualitative comparison on CIFAR-10 with 250 labels of FixMatch
(Sohnetal.,2020),FlexMatch(Zhangetal.,2021),andSoftMatchfromdifferentaspects,asshown
in Fig. 2. We compute the