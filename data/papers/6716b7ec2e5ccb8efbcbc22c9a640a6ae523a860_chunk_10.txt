to-sequenceBART sawadecreaseinmetricsfortheRRandRR+CL
(Lewis et al., 2020a) to generate the response by settings.
marginalizingitaccordingtodocumentscores.
6.1 Retrievalimprovement
Weusestructure-basedsegmentation,withthe
Wepresenttheresultsfordifferentretrieverconfig-
original and reranking original scoring functions.
urations at Recall@10 and Recall@100 in Table
WeuseDPRencoderfinetunedonMultiDoc2Dial
forretrieval,andapretrainedBART-largemodel. 2https://github.com/facebookresearch/FiD
151
Model Reader EM F1 BLEU RougeL
Baseline BART 3.6 33.8 19.2 31.4
DistilSPLADE+RAG BART 4.8 38.5 23.7 36.2
DistilSPLADE+FiD T5 5.1 42.3 29.7 40.2
DistilSPLADE+FiD+RR T5 5.5 43.1 30.1 41.1
DistilSPLADE+FiD+RR+CL(M1) T5 5.3 43.3 31.1 41.4
DistilSPLADE+FiD+Gold T5 5.3 42.4 30.5 40.6
DistilSPLADE+FiD+Gold+RR T5 5.5 42.5 30.4 40.7
DistilSPLADE+FiD+Gold+RR+CL(M2) T5 5.6 43.0 30.5 41.0
M1(onSharedTaskMDD-SEENtest) T5 - 46.2 31.8 44.2
M2(onSharedTaskMDD-UNSEENtest) T5 - 33.0 25.0 32.0
Table1:ModelperformanceonthevalidationsplitforEM,F1,BLEUandRougeL.Weseeaconsistentimprovement
acrossallmetricswithDistilSPLADEastheretrieverandFiDasthereader. Goldmeanstheground-truthpassage
waspassedduringtraining. Reranking(RR)andcurriculumlearning(CL)furtherboostperformanceonall