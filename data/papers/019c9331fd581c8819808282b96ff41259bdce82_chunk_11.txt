the task as a simple pair-wise classification. Our
framingallowsnon-expertannotatorstomakede- 4.3 CollectingCDECannotations
cisions without concern for complex granularity WecrowdsourceannotationsforCDECusingAma-
issues. Ourfollow-upquestionregardinginclusion zon Mechanical Turk (MTurk). Each Human In-
facilitatesaposthocanalysisoftheeventgranular- telligenceTask(HIT)constitutesannotatingcross-
itiesinourdataset. document links for one pair of documents. We
To ensure completeness of our CDEC dataset, obtainedIRBapprovalandsetourHITpricebased
wecollectannotationsforeachpairofdocuments onpreliminarystudies.12 OnMTurk,werestricted
in a given subtopic (ยง3). As highlighted earlier, ourHITstocrowdworkersfromtheUSandsetour
thequasi-identityofeventsmayormaynotallow qualificationthresholdsfor%HITs,andtotalHITs
fortheapplicationoftransitivityproperty. There- approvedas95%and1000respectively. Wepaida
fore,inourdataset,wecannotexpandcoreference faircompensationof$10.9/houronaverage.13 Our
linksusingtransitivity. Socollectingannotations annotationtaskrequiresproficiencyinEnglish,as
betweeneachpairinagivensubtopicisnecessary. wellasagoodunderstandingofeventcoreference.
Tothisend,weattachaqualificationtestwitheight
Annotation Guidelines: Events are common-
yes/noquestionsregardingeventcoreference,with
place in the newswire; therefore, it is feasible to
aqualificationthresholdof75%.14
explaintheconceptofeventsandtheircoreference
For each document pair, we collected annota-
viasimpleexample-basedguidelines. Inourguide-
tionsfromthreedifferentcrowdworkers. Ineach
lines,wefirstdefineeventsandthenprovidenumer-
task,crowdworkersgothroughthetwodocuments
ousexamplesofidenticalandnon-identicalevent
anddevelopahigh-levelunderstandingofthenews
mentions, with detailed explanations. Following
story. They then