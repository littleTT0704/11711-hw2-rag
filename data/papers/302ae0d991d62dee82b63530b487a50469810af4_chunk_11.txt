ourmodelstartsbyapply-
Once we have produced a representation for arguments ing the operation vector vop at every location of the map,
ha and operations ho, we multiply each by their own feed- weighted by each location’s attention score. This creates a
forward layers, then softmax to produce a distribution over worldrepresentationofsizeB×D×H ×W ×|vop|.We
20blocksand32operationsfordaanddop,respectively. thenpassthisworldthroughtwoconvolutionallayersusing
tanhorrelunonlinearities.
da =softmax(Waha+ba) Inordertopredictthefinallocationfortheblock-to-move,
(3)
dop =softmax(Woho+bo) weapplyafinal1×1×1convolutionallayertopredictoff-
setsandtheirrespectiveconfidencesforeachlocationrela-
tivetoacoordinategrid(8valuestotal).Thecoordinategrid
ArgumentSoftmax Thefirstoutputofourmodelisanat-
is a constant 3D tensor generated by uniformly sampling
tention over the block IDs. The input world is represented
pointsacrosseachcoordinateaxistoachievethedesiredres-
bya3DtensorofIDs.2Wecanconvertthistoaone-hotrep-
olution. Given the coordinate grid, the goal of the learned
resentation and multiply it by the distribution to get an at-
convolutional model is to, at every sampled point, predict
tentionper“pixel”(herebyreferredtoasargumentattention
offsets for x, y, z, θ, as well as a confidence for each pre-
map)equaltothemodel’sconfidence.Inpracticewefound
dicted offset. This formulation was similarly used for key-
that the model was better able to learn when the attention
pointlocalizationin(Singh,Hoiem,andForsyth2016).Let
map was multiplied by 10. This may be due to parameter gx(i,j,k)bethexcoordinatesforallsampledgridpointsat
initialization.Additionally,wedonotallowthemodeltoat- gridlocation(i,j,k)andletdx(i,j