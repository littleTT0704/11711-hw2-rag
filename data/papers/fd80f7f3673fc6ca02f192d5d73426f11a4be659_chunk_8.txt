stopredictmajorandminorerrorsand,sim- and quality estimation as textual templates (with
ilarly to AUTOMQM, used the identified errors a general description of the problem and “slots”
for the inputs and outputs), we can use general- 4.2 Finetuning
purposeLLMstoperformthesetasksatinference-
IthaspreviouslybeenshownthatLLMsarecapa-
time,withoutanyparameterupdates.
bleofzero-shotevaluation(KocmiandFedermann,
Throughoutthepaper,wechoosetouseKocmi
2023),buttheextenttowhichfinetuningonhuman
and Federmann (2023)’s GEMBA-SQM prompt
judgmentdatacanfurtherboosttheperformanceof
(Figure2),whichasksmodelstogenerate(astring
LLMshasnotbeenstudied. IntheWMT’22Met-
representationof)ascorefrom0-100. Wechoose
ricsSharedTask(Freitagetal.,2022),alltopsub-
this prompt for two reasons: firstly, early explo-
missionswerelearnedmetrics;thatis,pretrained
rationswiththeirsandotherpromptsshowedthat modelsfinetunedonhumanjudgmentdata2.
this generally performed well. Secondly, using a
Thus, we investigate whether LLMs are
singlepromptensuresafairercomparisonbetween
amenable to finetuning on human judgment data.
thecapabilitiesofdifferentmodels.1
LLMs used in top-performing metrics are gener-
allymuchlargerthanthepretrainedlanguagemod-
Score the following translation from elsleveragedbypreviouslearnedmetrics(which
{src_lang} to {tgt_lang} with respect
generally have fewer than 1 billion parameters).
to the human reference on a continuous
Moreover,mostlearnedmetricsleveragepretrained
scale from 0 to 100 that starts with
"No meaning preserved", goes through encoder-onlyratherthan(decoder-only)prefixlan-
"Some meaning preserved", then "Most guage models. We experiment with finetuning
meaning preserved and few grammar mistakes",
LLMsusingtwoobjectives