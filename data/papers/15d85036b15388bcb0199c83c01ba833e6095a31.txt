Title: Towards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models
Venue: Workshop on Innovative Use of NLP for Building Educational Applications
Year: 2023
Abstract: By aligning the functional components derived from the activations of transformer models trained for AES with external knowledge such as human-understandable feature groups, the proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems. The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models’ decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.
CMU authors: C. Rosé
Other authors: James Fiacco, David Adamson
tldr: The proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems.
