toadaptivelyweighttheobjectivesin
basedonmeasuringeachobjective’sinfluenceonE’svalidationsetloss.
A
3. We make our algorithm scalable by sub-sampling the tasks. By exploiting the underlying
A
structureoftheobjectivesin viaafactoredapproachtomodelingtaskweights,wereducethe
A
impactoftheinexactsub-sampling.
6 EXPERIMENTAL SETTING
Ourexplorationofauxiliarylearninghasmadethefollowingtransitionsfromthestatus-quo: manual
toautomated,singletasktomultitask,end-taskagnostictoend-taskaware. Inthissection,wesetup
experimentstovalidatethesedeviationsfromthestandard.
We focus on continued pre-training (Gururangan et al., 2020; Aghajanyan et al., 2021). In this
setting,weperformfurtherauxiliarylearningonanalreadypre-trainedmodel. Wefavorthissetting
overpre-trainingfromscratch(Liuetal.,2019b;Yangetal.,2019)notonlybecauseitisamore
computationallyfeasiblearenaforexperimentationbutalsobecauseitismorerelevanttomodern
MLsystemswherebuildinguponpre-trainedmodelsisthenorm(Qiuetal.,2020;Duetal.,2020).
ModelDetailsandDatasets: Weuseapre-trainedRoBERTa (Liuetal.,2019b)astheshared
base
modelbase. Weimplementeachauxiliaryobjectiveasaseparateheadontopofthissharedbase.
For classification based objectives, the output head is a 2-layer multi-layer perceptron (MLP)
thatreceivesrepresentationsforthespecialclassificationtoken[CLS](Devlinetal.,2018)from
RoBERTa. Forsequencegenerationobjectives,wemakeacopyofthepre-trainedoutputlayer
base
of RoBERTa for each task. Table 4 in Appendix C provides details of the 5 datasets used.
base
6
PublishedasaconferencepaperatICLR2023
All datasets are low-resource classification tasks. Not only are these datasets more amenable to
meta-learningfromacomputational