tokenizer as is, due to the extremely small scale
SentiraamaastargetlanguagedatasetsandMARC
of target language data. We conjecture that the
as the source language dataset. To unify the la-
subwordvocabularythatXLM-Rlearnsisalsoben-
belspace,wecurateMARCbyassigningnegative
eficialtoencodelanguagesonwhichitisnoteven
labels to reviews rated with 1 or 2 and positive
labels to those rated with 4 or 5. We leave out
2Details of data splits can be found at github.com/
neutral reviews rated with 3. For SentiPers, we microsoft/MetaXL.
assignnegativelabelstoreviewsratedwith-1and 3XLM-Rasabasemodelleadstosignificantlybetterre-
sultsforbothbaselinesandMetaXLthanmBERT,thuswe
-2andpositivelabelstothoseratedwith1or2. For
mainlypresentresultswithXLM-Rinthemaintext.Detailed
SentiPers,thoughthedatasetisrelativelylarge,we resultsonmBERTcanbefoundinAppendixC
Source Method qu cdo ilo xmf mhr mi tk gn average
(1) - target 57.14 37.72 61.32 59.07 55.17 76.27 55.56 48.89 56.39
JT 66.10 55.83 80.77 69.32 71.11 82.29 61.61 65.44 69.06
(2) English
MetaXL 68.67 55.97 77.57 73.73 68.16 88.56 66.99 69.37 71.13
JT 79.65 53.91 78.87 79.67 66.96 87.86 64.49 70.54 72.74
(3) Related
MetaXL 77.06 57.26 75.93 78.37 69.33 86.46 73.15 71.96 73.69
Table2: F1forNERacrossthreesettingswherewe,(1)onlyusethetargetlanguagedata;(2)usetargetlanguage
data along with 5k examples of English; (3) use the target language data along with 5k examples of a related
language. JTstandsforj