
Jiang, W. and Tanner, M. A. Hierarchical mixtures-of-
experts for generalized linear models: some results on
Avnimelech,R.andIntrator,N. Boostedmixtureofexperts:
densenessandconsistency. InAISTATS.Citeseer,1999b.
anensemblelearningscheme. Neuralcomputation,11
(2):483–497,1999.
Jiang, W. and Tanner, M. A. On the identifiability of
Bailey,T.L.,Elkan,C.,etal. Fittingamixturemodelbyex- mixtures-of-experts. NeuralNetworks,12(9):1253–1258,
pectationmaximizationtodiscovermotifsinbipolymers. 1999c.
1994.
Jiang,W.andTanner,M.A. Ontheasymptoticnormality
Belsley, D. A., Kuh, E., and Welsch, R. E. Regression ofhierarchicalmixtures-of-expertsforgeneralizedlinear
diagnostics: Identifyinginfluentialdataandsourcesof models. IEEETransactionsonInformationTheory,46
collinearity,volume571. JohnWiley&Sons,2005. (3):1005–1013,2000.
Bishop,C.M.andSvenskn,M. Bayesianhierarchicalmix- Jordan, M.I.andJacobs, R.A. Hierarchicalmixturesof
turesofexperts. InProceedingsoftheNineteenthconfer- expertsandtheemalgorithm. Neuralcomputation,6(2):
enceonUncertaintyinArtificialIntelligence,pp.57–64. 181–214,1994.
MorganKaufmannPublishersInc.,2002.
Kanaujia, A. and Metaxas, D. Learning ambiguities us-
Breiman, L. Random forests. Machine learning, 45(1): ingbayesianmixtureofexperts. InToolswithArtificial
5–32,2001. Intelligence, 2006. ICTAI’06. 18th IEEE International
Conferenceon,pp.436–440.IEEE,2006.