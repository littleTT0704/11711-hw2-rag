ynoldsandMcDonell,2021). Practitioners
gpt-3.5-turbo,byanaverageof20%while can now write a prompt specifying the intended
beingupto700timessmaller. Wealsoshow systembehavior(optionallywithafewdemonstra-
that this data can be used to obtain reliable tions),andaskanLLMtogenerateadesiredout-
performanceestimatesofmodelperformance,
put via text completion. This makes it possible
enablingmodeldeveloperstoassessmodelre-
toprototypeNLPsystemsrapidlyforavarietyof
liability before deployment. Prompt2Model
applicationswithoutwritingasinglelineofcode
is available open-source at https://github.
com/neulab/prompt2model.1 (FloridiandChiriatti,2020).
However, there is still a gap between proof-
1 Introduction of-conceptprototyping—showingLLMscanbe
promptedforaparticulartask—andpracticalde-
Traditionally,buildinganNLPmodelfromscratch
ployment. Prompting LLMs can be expensive as
hasbeenasubstantialundertaking. AnNLPpracti-
they require either a significant amount of com-
tionerseekingtosolveanewproblemwouldneed
putingoraccesstocommercialAPIs,andtheirre-
to define their task scope, find or create data that
lianceontheinputpromptqualitymakesthemun-
specifies the intended system behavior, choose a
stablecomparedtotrainedmodels(Minetal.,2022;
suitablemodelarchitecture,trainthemodel,assess
Bubecketal.,2023). Becausepractitionersusually
its performance through evaluation, and then de-
do not have enough annotated validation data to
ployitforreal-worldusage(Paleyesetal.,2022).
measuretheirsystemperformance,itisalsomore
∗equalcontribution. challenging for them to debug their systems be-
1Ourdemovideoispostedatyoutu.be/LYYQ_EhGd-Q. foredeployment(Jiangetal.,2022). Additionally,
3202
guA
32
]LC.