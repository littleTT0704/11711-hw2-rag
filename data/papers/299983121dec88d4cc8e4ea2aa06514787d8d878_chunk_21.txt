puttingapplesinabagandpickingthemupfromthetree.
BART-base-VisCTG Amanputsabagofapplesonatree.
Humanreference Ipickedanapplefromthetreeandputitinmybag.
Table11:Qualitativeexamplesfortest.BLstandsforbaseline.ConceptsetreferstotheinputkeywordsandCaptionsrefers
CG
tothecaptions(separatedby<s>)usedbytheVisCTGmodelforthatparticularexampletoproduceitsfinalgeneration.
poseSemanticTextExchangetoadjusttopic-leveltextse- ViLBERT(Luetal.2019):mainlyencodersthatjointlyrep-
mantics.Gangaletal.(2021)introducenarrativereordering resentimagesandtextratherthanseq2seqmodels.Further,
(NAREOR)toeditthetemporalityofnarratives. unlikethesemodelswhicharepretrained,VisCTGexploits
per-examplevisualinfotofixspecificissuesperconceptset.
Data-to-text NLG: E2E-NLG (DusË‡ek, Novikova, and
Rieser 2018) and WebNLG (Gardent et al. 2017) are two
8 ConclusionandFutureWork
popularNLGbenchmarkswithstructuredinputs-meaning
representation(MR)andtriplesequences,respectively.
In conclusion, we motivated and explored the use of vi-
sual grounding for improving the commonsense of Trans-
CommonsenseInjectionandIncorporation: Onecom-
formermodelsfortextgeneration.Weinvestigatedthisfor
monsenseknowledgegraph(KG)isCOMET,trainedonKG
concept-to-textgeneration,callingourmethodVisCTG:Visu-
edges. EKI-BART (Fan et al. 2020) and KG-BART (Liu
allyGroundedConcept-to-TextGeneration.Extensiveexper-
etal.2021)useexternalknowledgetoimproveCommonGen
imentsonBARTandT5showeditsefficacyontheCommon-
performance.Distinctly,VisCTGusesvisualgroundingand
Gen task. Comprehensive evaluation and