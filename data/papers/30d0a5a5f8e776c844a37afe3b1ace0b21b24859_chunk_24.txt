oundon
Right, and Done. At each episode step, the agent re-
thechallengewebsite.
ceives egocentric (noiseless) RGB-D images captured
with a 90â—¦ field-of-view (FoV) camera, the binaural OneofthelimitationsoftheSoundSpacesplatform
is that it provides pre-rendered RIRs for fixed grid
audio received by the agent. The episode terminates
pointsanddoesnotallowuserstorendersoundsfor
whentheagentexecutestheDoneaction,oritrunsout
arbitrarylocationsorenvironments. Totacklethisis-
ofapre-specifiedtimebudget. Theagentisevaluated
sue,wehaveintroducedSoundSpaces2.0[40](Fig.9,
usingstandardembodiednavigationmetrics,suchas
a continuous, configurable and generalizable simu-
SuccessRate(SR)andSPL[9]. WeuseSPLasthemet-
lator. This new simulator has enabled continuous
ricforrankingchallengeparticipants.
audio-visualnavigationaswellasmanyotherembod-
10https://soundspaces.org/challenge iedaudio-visualtasks. Webelievethissimulatorwill
11
Gypsum
Visual
Reflection
HRTF Render
Reverb Direct sound RGB
Transmission
Carpet
Acoustic Left Ear
Render
Hardwood
Right Ear
Figure9. SoundSpaces2.0,acontinuous,configurable,and
generalizable audio-visual simulation platform. It models
variousacousticphenomenaandrendersvisualandaudio
observationswithspatialandacousticcorrespondence.
taketheaudio-visualnavigationtasktothenextstep.
Anotherimportantdirectionforfutureresearchisfor
the agent to reason about the semantics between the Figure10.Exampleofthescenechangedetectionchallenge.
soundandobjects(e.g.semanticaudio-visualnaviga- Between two scenes some objects are added (blue) and re-
tion [37] and finding fallen objects [64]). If the agent moved(orange)andtheseneedtobeidentifiedandmapped
could leverage the semantics of sounding objects, it out.
couldnavigatefasterbyreasoningwherethe