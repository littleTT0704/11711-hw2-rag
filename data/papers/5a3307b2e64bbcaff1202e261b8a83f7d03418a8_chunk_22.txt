ations.Sincethephonatorymodulerequiresa
malesubsets.Foreachsubset,weadopt7/1/1/1splittingforD𝑡/D𝑣1 longtrainingprocedure,wefirsttrainitwiththevoicecodeencoder
/D𝑣2/D𝑒.Intraining,thevoicerecordingsarerandomlytrimmed Efor60kstepsonourtrainingsetD𝑡.Wefollowthetrainingsetting
tosegmentsof6to8seconds,whileweusetheentirerecordings in[18]totrainthephonatorymodule.Theotherparametersetting
intesting.ThegroundtruthAMsarenormalizedtozeromeanand follows[18].Wedirectlynormalizedthevoicesignalasinputtothe
unitvariance.Forvoicefeatures,weextract64-dimensionallogMel- networkinsteadoffirstconvertingittoLog-Melspectrum.Toensure
spectrogramsusingananalysiswindowof25ms,withthehopof statisticalsignificance,weperformN=100repeatedexperimentsto
10msbetweenframes.Weperformmeanandvariancenormalization computethe𝐶𝐼 𝑢.Fortheexperimentsatphonemelevel,weleverage
ofeachMel-frequencybin. Wav2Vec[2]tocutthelongvoicerecordingsintophonemes.
decnalaB
)c(
tesbus
elaM
)a(
tesbus
elameF
)b(
tesbus
elameF
RethinkingVoice-FaceCorrelation:AGeometryView Conference’23,July2023,Ottawa,Canada
PhonationModule 100%𝑤ˆ 75%𝑤ˆ 50%𝑤ˆ PhonatoryModule Predictable Unpredictable
(cid:33) 0.953±0.009 0.909±0.024 0.842±0.030 (cid:33) 0.628±0.021 0.990±0.032
(cid:37) 0.952±0.014 0.927±0.030 0.879±0.041 (cid:37) 0.730±0.