ations.Sincethephonatorymodulerequiresa
malesubsets.Foreachsubset,weadopt7/1/1/1splittingforDğ‘¡/Dğ‘£1 longtrainingprocedure,wefirsttrainitwiththevoicecodeencoder
/Dğ‘£2/Dğ‘’.Intraining,thevoicerecordingsarerandomlytrimmed Efor60kstepsonourtrainingsetDğ‘¡.Wefollowthetrainingsetting
tosegmentsof6to8seconds,whileweusetheentirerecordings in[18]totrainthephonatorymodule.Theotherparametersetting
intesting.ThegroundtruthAMsarenormalizedtozeromeanand follows[18].Wedirectlynormalizedthevoicesignalasinputtothe
unitvariance.Forvoicefeatures,weextract64-dimensionallogMel- networkinsteadoffirstconvertingittoLog-Melspectrum.Toensure
spectrogramsusingananalysiswindowof25ms,withthehopof statisticalsignificance,weperformN=100repeatedexperimentsto
10msbetweenframes.Weperformmeanandvariancenormalization computetheğ¶ğ¼ ğ‘¢.Fortheexperimentsatphonemelevel,weleverage
ofeachMel-frequencybin. Wav2Vec[2]tocutthelongvoicerecordingsintophonemes.
decnalaB
)c(
tesbus
elaM
)a(
tesbus
elameF
)b(
tesbus
elameF
RethinkingVoice-FaceCorrelation:AGeometryView Conferenceâ€™23,July2023,Ottawa,Canada
PhonationModule 100%ğ‘¤Ë† 75%ğ‘¤Ë† 50%ğ‘¤Ë† PhonatoryModule Predictable Unpredictable
(cid:33) 0.953Â±0.009 0.909Â±0.024 0.842Â±0.030 (cid:33) 0.628Â±0.021 0.990Â±0.032
(cid:37) 0.952Â±0.014 0.927Â±0.030 0.879Â±0.041 (cid:37) 0.730Â±0.