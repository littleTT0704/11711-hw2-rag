commonreadermetricof
suchasheuristicdataaugmentationsandlanguage
exact-matchtoreducetheoccurrencesofminordatasetanno-
modelgeneratedpseudo-data,withoutrelyingon tationguidelinesleadingtoa0scoreforareasonableanswer.
(NQ)(Kwiatkowskietal.,2019)andBoolQ(Clark PassageRetriever(DPR) (Karpukhinetal.,2020)
et al., 2019). We treat this domain as our source andthestate-of-the-artmodel4)Spider(Rametal.,
as it used for the vast majority of current work 2021)(supervisedwithNaturalQuestions).
in ODQA (and many other areas of language re- Reader: Weusethestate-of-the-artT5-largebased
search). fusion-in-decoder(FiD)model(IzacardandGrave,
Inadditiontothesupervisedtrainingdatafrom 2020)whichencodestop100documentsinparal-
NQandBoolQ,weaddadditionalclozestyleques- lel. Therepresentationareconcatenatedandthen
tionsderivedfromtheQApairsinNQ.Foreachqa decodedtogeneratethefinalanswer.
pair, we retrieve a sentence from Wikipeida with
3 CategorizingDataShiftTypes
thehighestBM25similarityscore. Wethenconvert
the retrieved sentence into a cloze-style question
There are many aspects that determine in what
byreplacingtheanswerstringinthesentencewith
waysandtowhatextentonedatadistributiondif-
sentinelmarkers(Raffeletal.,2020)3.
fersfromanother. Havingabetterunderstanding
Target Domains: We consider five vastly dif-
ofthisspectrumofpossibilitieswouldenableusto
ferent domains (Stackoverflow, Reddit, Pubmed,
predictwhetheranewdatasetwouldbecompatible
JapaneseStatuteLawcodes,CNN/Dailymailand
with an existing model and, if not, what types of
Wikipedia) as our target corpora and re-purpose
interventionswouldberequiredinordertoenable
seven open-domain QA and/or reading compre-
themod