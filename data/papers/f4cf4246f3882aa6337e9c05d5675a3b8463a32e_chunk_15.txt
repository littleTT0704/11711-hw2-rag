stepval- amodelistheratioofgoal-conditionscompletedattheend
uest/T,wheretisthecurrenttime-step,andT isthetotal ofanepisodetothosenecessarytohavefinishedatask. For
lengthoftheexpertdemonstration(trainedviaL2loss). example, inthepreviousHeat&Placeexample, thereare
We also train the agent to predict the number of sub- four goal-conditions. First, a potato must be sliced. Sec-
goals completed so far, c t. These sub-goals represent seg- ond, a potato slice should become heated. Third, a potato
ments in the demonstration corresponding to sequences of sliceshouldcometorestonacountertop. Fourth,thesame
actionslikenavigation,pickup,andheatingasidentifiedin potatoslicethatisheated shouldbeonthecountertop. If
the PDDL plan, discussed in Section 3.2. Each segment theagentslicesapotato, thenmovesaslicetothecounter
hasacorrespondinglanguageinstruction,butthealignment topwithoutheatingit,thenthegoal-conditionsuccessscore
must be learned. This sub-goal prediction encourages the is 2/4 = 50%. On average, tasks in ALFRED have 2.55
agenttocoarselytrackitsprogressthroughthelanguagedi- goalconditions. Thefinalscoreiscalculatedastheaverage
rective. Thispredictionisalsoconditionedonthedecoder goal-condition success of each episode. Task success is 1
hiddenstateh tandtheconcatenatedinputu t: onlyifgoal-conditionsuccessis1.
c =Ïƒ(W [h ;u ]). (5)
t c t t
Path Weighted Metrics. We include a Path Weighted
Wetrainc inasupervisedfashionbyusingthenormalized versionofbothmetricsthatconsidersthelengthoftheex-
t
number of sub-goals accomplished in the expert trajectory pertdemonstration[2]. Expertdemonstrationsfoundviaa
ateachtimestep,c /C,astheground-truthlabelforatask PDDLsolveronglobalinformationarenotguaranteedtobe
t
withC sub