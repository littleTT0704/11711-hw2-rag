bar
onimageclassificationanddetectiontasks[11,14,34],Re- (Video QA) in temporal domain, which has been largely
currentNeuralNetworks(RNNs),particularlyLongShort- unaddressed. OurVideoQAconsistsofthreesubtasks. As
Term Memory (LSTM) [12], play a key role in visual de- shown in Figure 1, if we see a man slicing cucumbers on
scriptiontasks,suchasimagecaptioning[7,41,44].Asone a cutting board, we can infer that he took out a knife pre-
stepbeyondimagecaptioning, ImageQuestionAnswering viously, and predict that he will put them on a plate after-
(ImageQA),whichrequiresanextralayerofinteractionbe- wards. The same as image QA, video QA requires finer
tweenhumanandcomputers,havestartedtoattractresearch understandingofvideosandsentencesthanvideocaption-
attentionveryrecently[2,10,23]. ing. Despite the success of these methods for video cap-
In the area of video analysis, there are a few very re- tioning[40,46],thereareafewresearchchallengesremain
centsystemsproposedforvideocaptioning[40,46]. These unsolved,whichmakesthemnotreadilyapplicabletoVideo
methods have demonstrated promising performance in de- QA.
scribingavideobyasingleshortsentence.Similarasimage First, a Video QA system should explore more knowl-
captioning,videocaptioningmaynotbeasintelligentasde- edgebeyondjustvisualinformationandthecoarsesentence
sired, especiallywhenweonlycareaboutaparticularpart annotationsbecauseitrequiresfinerunderstandingofvideo
orobjectinthevideo[2].Inaddition,itlackstheinteraction contentandquestions. Forthesakeofvideocaptioning,ex-
betweencomputersandtheusers[10]. isting systems [40, 46] train LSTM models merely based
In this paper, we focus on Video Question Answering onvideocontentandtheassociatedcoarsesentenceannota-
1
5102
voN
51