.3 67.2 18.3 43.1
learningratesandhiddenstatesizes).
Revisited 39.4 57.5 34.0 63.5 13.5 36.8
BottomUp 42.8 62.3 25.1 63.0 10.7 39.6
MLB 45.5 61.8 36.1 65.4 17.0 40.6
MUTAN 44.4 61.0 32.0 64.4 14.1 39.3
• Ourprojectionofimagefeaturesmapsa2176dimen- Table 6: VQA baselines evaluated with GloVe or BERT,
sional hidden size (2048 from ResNet50 and 128 di- evaluatedonthe evaluationsetwithR2Cascompari-
VCR
mensional class embeddings) to a 512 dimensional son. WhileBERThelpstheperformanceofthesebaselines,
vector. ourmodelstillperformsthebestineverysetting.
• Our grounding LSTM is a single-layer bidirectional
LSTM with a 1280-dimensional input size (768 from
F.VQAbaselineswithBERT
BERTand512fromimagefeatures)anduses256di-
mensionalhiddenstates.
We present additional results where baselines for VQA
• Our reasoning LSTM is a two-layer bidirectional
[5]areaugmentedwithBERTembeddingsinTable6. We
LSTM with a 1536-dimensional input size (512 from
didn’t include these results in the main paper, because to
image features, and 256 for each direction in the at-
the best of our knowledge prior work hasn’t used contex-
tended, groundedqueryandthegroundedanswer). It
tualized representations for VQA. (Contextualized repre-
alsouses256-dimensionalhiddenstates.
sentationsmightbeoverkill,particularlyasVQAquestions
• The representation from the reasoning LSTM,
are short and often simple). From the results, we find that
groundedanswer,andattendedquestionismaxpooled
whileBERTalsohelpsthebaselines,ourmodelR2Cben-
and projected to a 1024-dimensional vector. That
efits even more, with a 2.5% overall boost in