ecantransfer dle panoramic videos. In addition, audio is introduced in
thespatialinformationencodedinthevisualobjectstosu- panoramicsaliencyprediction(Chaoetal.2020)givenits
perviseacousticmodality.Inparticular,toreflectthetrue3D strongabilitytoinfluencehumanattention.
locationofobjectsandmitigatetheinfluenceofdistortionsin
ERframes,wemapthe2Dcoordinatesofpixelsbacktothe VideoObjectSegmentation
3Dsphereandencodetheminthepositionalencodingduring
Video object segmentation (VOS) can be categorized as
thefusion.Inthisway,themodelcancapturethetruespatial
unsupervised (Wang et al. 2019; Ren et al. 2021a), semi-
positionofeachpixel.Ourcontributionsaresummarizedas:
supervised(Wangetal.2021)andreferring(Wuetal.2022;
• Weproposeanaudio-visualvideosalientobjectdetection Li et al. 2022c) VOS. The most relevant type to this work
framework for panoramic scenarios. To the best of our is the unsupervised VOS (UVOS) which aims to segment
knowledge,wearethefirsttotacklethisproblem. primaryobjectregionsfromthebackgroundinvideos.Early
methodstackletheUVOSproblembyobjectproposal(Kim
• We introduce a label-guided audio-visual fusion mod-
andHwang2002),temporaltrajectory(Fragkiadaki,Zhang,
ule to effectively utilize the rich spatial and semantic
andShi2012)andsaliencyprior(Wangetal.2015;Wang,
informationencodedintheambisonicaudiorecordings
Shen,andPorikli2015).Morerecently,deeplearning-based
synchronizedwithpanoramicvideos.
methodsareproposedformodelingthespatio-temporalinfor-
• Our model achieves state-of-the-art results on the
mation.MATNet(Zhouetal.2020)usesamotion-attentive
ASOD60Kdataset.Extensiveexperimentsareconduct