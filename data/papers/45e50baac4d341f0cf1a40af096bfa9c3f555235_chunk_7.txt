.47 0.20 63.37 0.95 60.00
↓ ↓ ↓
DistilRoBERTa 82M 329 7.28 52.87 3.49 60.08 2.86 63.81
↓ ↓ ↑
Table 1: CrowS-Pairs stereotype scores for GENDER, RACE, and RELIGION for BERT and RoBERTa models.
Stereotypescorescloserto50%indicatelessbiasedmodelbehavior. Boldvaluesindicatethebestmethodperbias
category. ResultsontheotherdatasetsdisplayedsimilartrendsandwereincludedinAppendixBforspace.
representtwosimilarsetsofwidelyusedandstud- theteachermodel(soft-targets)andthetruelabels
ied pretrained architectures, trained on different (hard-targets)tobettergeneralizetounseendata.
data with a small overlap. RoBERTa pretraining
Quantization compresses models by reducing
wasdoneover161GBoftext,whichcontainedthe
theprecisionoftheirweightsandactivationsduring
16GBusedtotrainBERT,approximatelyaten-fold
inference. WeusethestandardPyTorchimplemen-
increase. RoBERTa also trained for longer, with
tation3toapplydynamicPTQoverthelinearlayers
larger batch sizes which have shown to decrease
ofthetransformerstack,fromfp32full-precision
theperplexityoftheLLM(Liuetal.,2019).
to quantized int8 precision. This work analyzes
The set of checkpoints released for the Pythia
quantizedBERT,RoBERTa,andPythiamodelsof
model family allows us to assess an even wider
acomprehensiverangeofsizes.
variety of model sizes and number of training to-
kens,includingintermediatecheckpointssaveddur-
3 Results
ing pretraining, so that we can observe how bias
varies throughout pretraining. We used the mod- DynamicPTQanddistillationlowersocialbias.
elspretrainedonthededuplicatedversionofThe InTable1weanalyzetheeffectsofdynamicPTQ
Pile(Gaoetal.,2021)containing768GBoftext. and