 we will estimate the probability P(L = 1|N...N )
t 1 T
as opposed to P(L = 1|N ) when using an independent logistic regression model.
t t
The directed graphical model in Figure 8.7 illustrates our independence assump-
tionsaboutthenuggets, labelsandboundaries. Inparticular, weassumethefollowing
for t ∈ {2,...,T}:
P(N |N...N,L...L,B...B ) = P(N |L ), (8.1)
t 1 t−1 1 t 2 t t t
P(L |N...N,L...L,B...B ) = P(L |L,B ). (8.2)
t 1 t−1 1 t−1 2 t t t−1 t
These are reasonable assumptions since the distributions of text nuggets and their
labelscanbeexpectedtodependprimarily,thoughnotexclusively,ontheirimmediate
neighbors. The model can be regarded as a generalization of a hidden Markov model
[Rabiner, 1989] since the probability of a transition to a label L does not only depend
t
on the previous label L but also on the current nugget boundary B described by
t−1 t
the transition features from Section 8.2.1.
Theemission probability of nugget N givenits labelL can beestimated as follows
t t
according to Bayes’ rule:
P(L |N )P(N ) P(L |N )
t t t t t
P(N |L ) = ∼.
t t
P(L ) P(L )
t t
138 CHAPTER 8. EXTENSIONS FOR RELEVANCE ESTIMATION
The prior probability P(N ) can be ignored since it is a constant that does not depend
t
on the label, and the marginal probability P(L ) can be estimated by maximum
t
likelihood estimation (i.e. relative frequency estimation) from a training set of labeled
text nuggets as follows:
Number of relevant nuggets
P(L = 1) =,
t
Total number of nuggets
P(L = 0) = 1−P(L = 1).
t t
The conditional probability P(L |N ) can be