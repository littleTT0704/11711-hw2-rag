istics.
Massively multilingual transfer for NER. In Pro-
ceedings of the 57th Conference of the Association
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-
forComputationalLinguistics,ACL2019,Florence,
ham Neubig, Orhan Firat, and Melvin Johnson.
Italy, July 28- August 2, 2019, Volume 1: Long Pa-
2020. XTREME: A massively multilingual multi-
pers,pages151–164.AssociationforComputational
task benchmark for evaluating cross-lingual gener-
Linguistics.
alisation. In Proceedings of the 37th International
Conference on Machine Learning, volume 119 of
Phillip Rust, Jonas Pfeiffer, Ivan Vulic´, Sebastian
Proceedings of Machine Learning Research, pages
Ruder, and Iryna Gurevych. 2021. How good is
4411–4421.PMLR.
yourtokenizer? onthemonolingualperformanceof
TakuKudo.2018. Subwordregularization: Improving multilinguallanguagemodels. InProceedingsofthe
neuralnetworktranslationmodelswithmultiplesub- 59thAnnualMeetingoftheAssociationforCompu-
wordcandidates. InProceedingsofthe56thAnnual tationalLinguisticsandthe11thInternationalJoint
Meeting of the Association for Computational Lin- Conference on Natural Language Processing (Vol-
guistics(Volume1:LongPapers),pages66–75,Mel- ume1:LongPapers),pages3118–3135,Online.As-
bourne, Australia. Association for Computational sociationforComputationalLinguistics.
Linguistics.
Shoetsu Sato, Jin Sakuma, Naoki Yoshinaga, Masashi
Guillaume Lample and Alexis Conneau. 2019. Cross- Toyoda,andMasaruKitsuregawa.2020. Vocabulary
linguallanguagemodelpretraining. InNeurIPS. adaptationfordomainadaptationinneuralmachine
translation. InFindingsoftheAssociationforCom- A Tasks
putational Linguistics: EMNLP 2020, pages 4269–
4279, Online. Association for Computational Lin- For all tasks