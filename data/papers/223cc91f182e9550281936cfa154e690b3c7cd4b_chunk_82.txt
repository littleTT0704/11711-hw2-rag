. S., & Barto, A. G. (2018). Reinforcement learning: An introduction (2nd ed.) MIT Press.
Sutton, R. S., McAllester, D. A., Singh, S. P., & Mansour, Y. (2000). Policy gradient methods for reinforcement
learning with function approximation. In S. Solla, T. Leen, & K. Müller (Eds.), Proceedings of the 12th
58
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
International Conference on Neural Information Processing Systems (Vol. 12; 1057–1063). MIT Press.
https://papers.nips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf
Tan, B., Hu, Z., ZichaoYang, R., & Xing, E. (2018). Connecting the dots between mle and rl for sequence
generation. arXiv. https://doi.org/10.48550/arXiv.1811.09740
Tan, B., Qin, L., Xing, E., & Hu, Z. (2020). Summarizing text on any aspects: A knowledge-informed weakly-
supervised approach. In B. Webber, T. Cohn, Y. He, & Y. Liu (Eds.), Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing (EMNLP), (pp. 6301–6309).
http://doi.org/10.18653/v1/2020.emnlp-main.510
Taskar, B., Guestrin, C., & Koller, D. (2004). Max-margin Markov networks. In S. Thrun, L. Saul, & B.
Schölkopf (Eds.), Proceedings of the 16th International Conference on Neural Information Processing Systems
(Vol. 16; 25–32). MIT Press. https://papers.nips.cc/paper/2003/file/878d5691c824ee2aaf770f7d36c151d6-
Paper.pdf
Thrun, S. (1998). Lifelong learning algorithms. In S. Thrun & L. Pratt (Eds.), Learning to