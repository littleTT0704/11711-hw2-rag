sconsiderimportant. SeeappendixBforde-
something”(3). Participantsarguedthat,giventhis tailsonhowwehandleambiguityinmentions.
outsideattention,thebenchmarkfocusofNLPis
toonarrow,thatbenchmarksfailtocaptureno- simpler to manage, simpler to train” (17). Previ-
tionsoflanguageunderstandingthattranslate ously, participants described spending “like 90%
towideraudiences,andthatweshouldmoveon
ofourtimere-implementingpapers”(12);asmore
frombenchmarksnotwhentheyaresaturatedbut papersbeganreleasingcodeimplementedinpop-
when“itwouldn’treallyimprovetheworldtoim- ularframeworks,thecostofusingthosemethods
provethisperformanceanymore”(9). Thisechoed asbaselinesdecreased. Oneparticipantstatedthat
“thingsthatsoftwaremakeseasy,peoplearegoing
a common refrain: many participants, especially
early-andmid-careerresearchers,sawpositiveso- to do” (18); this further compounds centraliza-
cialchangeasagoalofprogressinNLP. tionontothemostpopularlibraries,withlittle
incentive to stray from the mainstream: “ev-
5 Softwarelotteries erybodyusesPyTorch,sonowIusePyTorchtoo”
(8);“wejustuseHuggingFaceforprettymuchev-
Hooker (2021) argues that machine learning re-
erything” (18).4 Figure 3 visualizes mentions of
search has been shaped by a hardware lottery:
frameworksacrosspapersintheACLAnthology,
anidea’ssuccessispartiallytiedtoitssuitability
showing both the rise and fall in their popularity.
foravailablehardware. Severalparticipantsspoke
The rising peaks of popularity reflect the central-
aboutsoftwareinwaysthatindicateananalogous
izationovertime. Whilesomecommunitieswithin
softwarelotteryinNLPresearch: asthecommunity
NLP had previously seen some centralization on
centralizesinitssoftwareuse,italsocentralizesin
tool