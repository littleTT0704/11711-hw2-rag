negativeexamples A.6 Follow-upQuestions
toillustrateeventcoreferencetothecrowdwork-
Table 14 lists the four follow-up questions. We
ers(seeA.2inAppendix). Ourdatasetislimited
present these questions for each coreference link
totheEnglishlanguage, specificallyfortextdoc-
annotatedbythecrowdworker.
umentsrelatingtoDisastersandaccidents. While
wehavetakenspecificstepstoimprovethequality
ofourdataset,theremightbeincorrectormissing
coreferencelinks. However,webelievethatsuch
incorrect/missing links will not create additional
riskstothemodelstrainedonourdataset.
A.2 AnnotationGuidelines
Toexplainthetaskofcross-documenteventcoref-
erencetocrowdworkersonMechanicalTurk,we
presentdetailedexample-basedguidelines(Table6,
Table7). Additionally,weprovidecrowdworkers
with detailed instructions to our annotation inter-
face(Table4,Table5). Workersviewtheseinstruc-
tions before the start of each task and optionally
during the task. In our HIT, we also link to a 1-
minutevideotourofourannotationinterface.
Inourguidelines,weonlypresentexamplesof
fullandnullcoreference. Whileweconsidermem-
bership a form of coreference (partial), we donâ€™t
trainthecrowdworkersonfullandpartialidentity.
A.3 MTurkConsentForm
AconsentformisattachedtothestartofeachHIT.
Crowdworkersarerequiredtogothroughtheform
andprovidetheirconsentbeforestartingthetask.
Anonymized version of the consent form is pre-
sentedinTable8andTable9. Weanonymizethe
documentfortheconferencereviewprocess.
A.4 MTurkQualificationTest
Toidentifyhigh-qualitycrowdworkers,wedesign
a qualification test and add it as an additional re-
Instructionsforusingthetool
Thistoolcanbeusedtoselecteventsthatarethesameacrossthetwogivendocuments.
Howtoopeninstructions
<embedded