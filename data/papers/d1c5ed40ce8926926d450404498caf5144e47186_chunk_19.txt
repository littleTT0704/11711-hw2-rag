 statistical
models consistently outperform the baselines, and they yield statistically significant
improvements in average precision. We also show that active learning can reduce the
amount of labeled data needed to fit statistical models by two orders of magnitude
with only a small loss in relevance estimation performance.
Source expansion is also applied to the question answering task, using Watson and
the OpenEphyra QA system as testbeds. Its impact is evaluated on questions from
the Jeopardy! TV show and factoid questions from TREC evaluations [Dang et al.,
2007]. In these experiments, we expand about 500,000 seed documents from encyclo-
pedias and a dictionary with related text from web search results. For each QA task,
search performance and end-to-end results are evaluated on datasets of over 3,000
questions. Our approach yields consistent and statistically significant improvements
over baselines without source expansion, improving QA accuracy by 7.6%–12.9%.
We also demonstrate that seed documents can be expanded with related information
extractedfromalocallystoredtextcorpuswithoutrequiringasearchengine. Theim-
pact of this extraction-based method on QA performance is comparable to the source
expansion approach that uses web searches. When combining the two methods, QA
accuracy increases by 9.4%–19.8% on Jeopardy! and TREC datasets.
6 CHAPTER 1. INTRODUCTION
1.4 Outline
This thesis is organized as follows. In Chapter 2 we give an overview of established
research areas and existing algorithms that are related to our work on statistical
source expansion. Chapter 3 introduces a canonical QA pipeline and describes QA
tasks, performance metrics and systems that served as the basis for a task-based
evaluation of SE. In Chapter 4 we discuss our SE method in detail, give examples
of expanded documents generated with our approach, and illustrate how they help
improve QA performance. In Chapter 5 we present intrinsic evaluation results for
our relevance models and baselines, and in Chapter 6 we apply statistical SE to the
question answering task. Chapter 7 describes how the SE approach can be extended
to leverage unstructured document collections as seed corpora or as sources of related
content for SE. In Chapter 8 we discuss how active learning can reduce the need for
labeled training data when fitting statistical models for relevance