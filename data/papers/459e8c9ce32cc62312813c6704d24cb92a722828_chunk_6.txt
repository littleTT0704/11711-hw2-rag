 to an output Y = (y ;:::;y ). N((cid:1)jr L ;I(cid:27)2)(cid:1)(1(cid:0)(cid:25));
1 jYj (cid:18) MLE
Inoursettingofneuralsequencegeneration,thismapping
where(cid:25) 2[0;1]isamixtureparameterthatwesetto0.5in
isadeterministicdecodingalgorithmF((cid:18);X),whichuses
practice.Givenabatchofexamples,wecomputethegradient
anautoregressivemodelp (cid:18)(YjX)=Qj tY =j 1p (cid:18)(y tjy <t;X)to ofthemaximumlikelihoodloss,samplecandidatedirections
produceanoutputY^ givenaninputX.Thisincludesgreedy from the proposal distribution (5), then evaluate the task
and beam search decoding, and stochastic decoding algo- loss of each candidate and form the update direction (3).
rithmswithanoiseinput,F((cid:18);X;(cid:15)).Thegoalofsequence Algorithm 1 summarizes the procedure, called maximum-
generationistofindamodelwhosegenerationshaveminimal likelihoodguidedparametersearch(MGS).
tasklossonasetD =f(X;Y)gofinput-outputpairs,
3 OtherTaskLossMinimizationMethods
X
C((cid:18);D)= c(F((cid:18);X);Y); (1)
Comparisonwithpolicygradient. Policygradient(PG)
X;Y2D methodssuchasREINFORCE(Williams1992)consistof
theobjectiveandgradientestimator:
whereweassumec(Y^;Y)2Risanarbitrarysequence-level
h i
loss(e.g.sentence-BLEU).Themostwidelyusedapproach C ((cid:18))= E E c(Y^;Y) ; (6)
to training such a model is minimizing the negative log-
PG
(X;Y)(cid:24)D
Y^(cid:24)p(