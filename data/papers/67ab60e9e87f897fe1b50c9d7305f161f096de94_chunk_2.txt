 spirit of shared
exchange,eachparticipantsubmitted anaudioembedding modelfollowing acommonAPI
that is general-purpose, open-source, and freely available to use. Twenty-nine models
by thirteen external teams were evaluated on nineteen diverse downstream tasks derived
from sixteen datasets. Open evaluation code, submitted models and datasets are key
contributions, enabling comprehensive and reproducible evaluation, as well as previously
impossiblelongitudinalstudies. Itstillremainsanopenquestionwhetheronesinglegeneral-
purpose audio representation can perform as holistically as the human ear.
Keywords: audio representations,representationlearning,embeddings, transferlearning,
multi-task learning, multi-modal learning, classification, tagging
Â©... J.Turianet al.
2202
yaM
92
]DS.sc[
3v22030.3022:viXra
Turian et al.
1. Introduction
The codification of strong general-purpose representations in natural language and com-
puter vision has led to a renaissance in multimodal modeling and increased cross-discipline
collaboration. Audio is an equally rich source of information about the world, but outside
of speech recognition it has not achieved the same degree of attention from the machine
learningcommunity. Thisisakeychallengeforthecommunity,asgoodrepresentationssup-
port good machine learning. And robust evaluation enables general representations. Broad
evaluation suites help prevent overfitting to common test sets (Recht et al., 2018) and have
improved the state-of-the-art on language and vision representation learning (Wang et al.,
2019b,a; Goyal et al., 2019; Zhai et al., 2019; DeYoung et al., 2020). In general practice,
audio representations are not evaluated on a broad range of audio problems, and as a re-
sult, it is difficult to know which audio representation to use for a novel audio learning
task.
The Holistic Evaluation of Audio Representations (HEAR) benchmark was created to
encourage the development of flexible audio representations, to give greater insight into
how audio representations will generalize, and to enable fast development cycles both for
researchers developing new models and researchers applying existing models. HEAR was
launched as a NeurIPS 2021 shared challenge, and participants submitted audio representa-
tion models that are