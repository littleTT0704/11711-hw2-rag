 duringtrainingandinference. Here, westudyhow
3
entvideorepresentationsasdescribedaboveandcompareit they perform separately and contribute to the final perfor-
withthebaselinemodelwhichhasidenticalarchitecturebut mance. In Table 2, we use R-152+S3D-HM as the video
merely trained with L as depicted in Eq. 5. The baseline feature and report the results with different loss combina-
3
6
YouCook2
Model Lang. Video
R1↑ R5↑ R10↑ MR↓
Random – – 0.0 0.2 0.3 1675
TVJE[35] w2v R-152+I3D-X101 4.2 13.7 21.5 65
UniVL(v1)[33] BERT R-152+I3D-X101 3.4 10.8 17.8 76
TACo(Ours) BERT R-152+I3D-X101 4.9 14.7 21.7 63
UniVL(v3)[33] BERT S3D-HM 7.7 23.9 34.7 21
TACo(Ours) BERT S3D-HM 16.6 40.3 53.1 9.0
Table5: Comparingtext-videoretrievalonYouCook2.
MSR-VTT
Model Lang. Video
R1↑ R5↑ R10↑ MR↓
Random – – 0.1 0.5 1.0 500.0
JSFusion[53] BiLSTM R-152 10.2 31.2 43.2 13.0
JPoSE[49] w2v TSN+Flow 14.3 38.1 53.0 9.0
TVJE[35] w2v R-152+I-101 12.1 35.0 48.0 12.0
UniVL(v1)∗[33] BERT R-152+I-101 14.6 39.0 52.6 10.0
TACo(Ours) BERT R-152+I-101 19.2 44.7 57.2 7.0
CE[31] GPT CollaborativeExperts 20.9 48.8 62.4 6