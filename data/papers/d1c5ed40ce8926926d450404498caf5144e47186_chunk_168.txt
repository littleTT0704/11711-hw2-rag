:
(cid:26) (cid:26) ˆ
P(y = 1|x) if yˆ= 0 P(y = 1|x) if P(y = 1|x) < 0.5
P (x) = =
err P(y = 0|x) if yˆ= 1 P(y = 0|x) if Pˆ (y = 1|x) ≥ 0.5
124 CHAPTER 8. EXTENSIONS FOR RELEVANCE ESTIMATION
Here y is the true label of the instance x, and yˆ is the label estimated by the current
logisticregressionmodel. Thesecondequalityholdsifwepredictwhicheverclasslabel
ˆ
is more likely based on the probability estimate P(y = 1|x) from the LR model. We
do not know the true posterior probability P(y = 1|x) but can use the LR estimate
instead to obtain the following uncertainty term:
(cid:26) ˆ ˆ
P(y = 1|x) if P(y = 1|x) < 0.5
ˆ
Uncertainty(x) = P (x) =
err ˆ ˆ
1−P(y = 1|x) if P(y = 1|x) ≥ 0.5
ˆ
= 0.5−|P(y = 1|x)−0.5|
Thus we can select the query with the largest estimated error probability by maximiz-
ing the final expression. This is equivalent to selecting a query x whose probability
ˆ
estimate P(y = 1|x) is closest to 0.5.
When using SVMs for active learning, we do not have probability estimates and
instead select the query with the smallest Euclidean distance to the current decision
boundary. This is equivalent to using the following uncertainty term:
Uncertainty(x) = 0.5−Distance(x)
Similarly to the uncertainty function for logistic regression, the maximum uncertainty
is 0.5 at the decision boundary, and the value decreases monotonically as the distance
of a query to the boundary increases in either direction.
Diversity × Uncertainty. We select a query Q that maximizes the product of
diversity and uncertainty:
Q = arg