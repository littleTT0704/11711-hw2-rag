izertoupdatemultiplebeliefs
Measuring factual beliefs in language models.
sequentially, we recover much of the lost perfor-
Muchpastworkhasexploredhowinformationis
mance. Lastly,weadvocatethatthesemethodsbe
storedandrepresentedinpretrainedlanguagemod-
evaluated for their ability to fix false or morally
els(Rogersetal.,2020). Petronietal.(2019)pro-
undesirablemodelbeliefs,ratherthantoarbitrarily
videevidencethatLMsstorerelationalinformation
change beliefs to plausible alternatives as in past
between entities, and Roberts et al. (2020) show
work(DeCaoetal.,2021;Mitchelletal.,2021).
thatLMscanansweropen-endedquestions. Subse-
Visualizingbeliefgraphs. Weexploreanewform quentworkhasfurtherexploredhowmuchknowl-
ofvisualizationforunderstandinglanguagemod- edgeisstoredinLMs(HeinzerlingandInui,2021).
els,thebeliefgraph. Givenasetoffactualbeliefs, Most relevant to our work are studies from Tal-
weconstructbeliefgraphsbychangingeachmodel moretal.(2020)andElazaretal.(2021). Talmor
beliefandcheckingwhatotherbeliefsaresensitive etal.(2020)trainLMstoperformTrue/Falseclas-
tothosechanges. Eachbeliefbecomesanode,and sificationoffactualclaims,andtheymeasurehow
2715
beliefs correlate between entailed facts. We use modeltochangeonebeliefalsoresultsinachange
theirLeapOfThoughtdataasapartofourSLAG to the other belief, rather than there being a
objective (Eq. 1) and to measure model consis- probabilistic model specifying the relationship
tency under entailment before and after updating betweenthetwobeliefs.
beliefsinmodels. Meanwhile,Elazaretal.(2021)
3 UpdatingBeliefsinLanguageModels
measuretheconsistencyofmodelpredictionsfor
paraphrasedinputs. Weadopttheirmetricforpara-
Here