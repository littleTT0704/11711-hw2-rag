luencestheend-taskthroughbothtrainingandgeneralizationerror. Previous
theoryhaslargelyfocusedoncharacterizingtheimpactonend-tasktrainingerror. Liuetal.(2021),
forexample,showthatend-taskagnosticpre-trainingcancreateaperformancegapintrainingerror
comparedtotrainingwiththeend-taskalone. Thesizeofthisgapdependsonhowdissimilarthe
pre-trainingauxiliaryobjectiveisfromtheend-task. Theyintroducethefollowingassumption(which
wewillborrow)toformalizetheirnotionoftasksimilarity:
AssumptionA.1: Letf representtheend-taskobjectiveandf betheauxiliaryobjective. There
e a
exists∆ 0suchthat f (θ) f (θ) ∆ θ.
a e
≥ (cid:107)∇ −∇ (cid:107)≤ ∀
Notethatθrepresentsalltheparametersofthemodel. Smaller∆impliesf ismoresimilartothe
a
primarytaskf.Liuetal.(2021)boundtheend-taskagnostictrainingerrorgaptobelogarithmicin∆.
e
Unlike training error, end-task generalization error has gone unstudied in the auxiliary learning
setting.Boundingthegeneralizationerrornotonlyaddstoourtheoreticalunderstandingoftheimpact
ofauxiliarylearningbutalsoprovidesinsightstoguidealgorithmdesign. Toarriveatabound,we
adaptthetechniqueofHardtetal.(2016)whoderiveageneralizationboundontrainingwithonlythe
end-taskviastochasticgradientdescent. Weconsidertheend-taskawaresettingwheretheend-task
ismulti-taskedwiththeauxiliaryobjective. Thissettinghasrecentlybeenshowntoimproveend-task
performanceoverthepretrain-then-finetuneparadigm(Deryetal.,2021a;b;Yaoetal.,2021).
AuxiliarylearningwithDynamicSampling: Wearegivenanauxiliaryobjectivef (;z) [0,1]
a
· �