(TD)[14],VirtualHome(VH)[42],
that the planner encodes the environment as fully observ- andRoom-to-Room(R2R)[3].Thetotalnumberofdemon-
ableandhasperfectknowledgeaboutworlddynamics. For strationsorannotationsisgivenwiththedatasetlabel.
trainingandtestingagentmodels,however,theenvironment
ispartiallyobservable:itisonlyviewedthroughtheagent’s
egocentricvisionasactionsarecarriedout. annotationswithoutthevideo. Theworkerselectswhether
Wesplittheseexpertdemonstrationsintotraining, vali- the three directives describe the same actions, and if not,
dation, andtestfolds(Table2). Followingworkinvision- whichismostdifferent. Ifadirectiveischosenasmostdif-
and-languagenavigation[3],wefurthersplitthevalidation ferentbyamajorityofvalidationworkers,itisremovedand
andtestintotwoconditions:seenandunseenenvironments. the demonstration is subsequently re-annotated by another
Thissplitfacilitatesexamininghowwellmodelsgeneralize worker. Qualitatively,theserejectedannotationscontainin-
toentirelynewspaceswithnovelobjectclassvariations. correct object referents (e.g., “egg” instead of “potato”) or
directions(e.g.,“golefttowards...” insteadof“right”).
3.2.LanguageDirectives
4.BaselineModels
Foreveryexpertdemonstration,wecollectopenvocab-
ulary,free-formlanguagedirectivesfromatleastthreedif-
AnagenttrainedforALFREDtasksneedstojointlyrea-
ferent annotators using Amazon Mechanical Turk (AMT),
sonovervisionandlanguageinputandproduceasequence
resultingin25ktotallanguagedirectives. Languagedirec-
oflow-levelactionstointeractwiththeenvironment.
tives include a high-level goal together with low-level in-
structions, as shown in Figures 1 and 2. The distribution 4.1.Sequence-