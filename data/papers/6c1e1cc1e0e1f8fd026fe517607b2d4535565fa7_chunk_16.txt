Figure7: PALwithdifferentmodelsonGSM8K:though Figure 8: PAL with NL LMs on GSM8K: though
the absolute accuracies with code-cushman-001 COToutperformsPALwithtext-davinci-001,once
and code-davinci-001 are lower than the base LM is sufficiently strong, PAL is beneficial
code-davinci-002, the relative improvement of with text-davinci-002 and text-davinci-003
PALoverCOTisconsistentacrossmodels. aswell. Thatis,PALisnotlimitedtocode-LMsonly.
6.Analysis not only from having a better prompt. Additional details
areprovidedinAppendixB.Foradditionaldiscussionon
Does PAL work with weaker LMs? In all our experi-
theadvantagesofcode-promptsovertextual-prompts,see
mentsinSection5,PALusedthecode-davinci-002
AppendixG.
model;butcanPALworkwithweakermodelsofcode? We
comparedPALwithCOTwhenbothpromptingapproaches
Dovariablenamesmatter? Inallourexperiments,we
use the same weaker base LMs code-cushman-001
usedmeaningfulvariablenamesinthePALprompts,toease
andcode-davinci-001. AsshowninFigure7, even
themodel’sgroundingofvariablestotheentitiestheyrep-
thoughtheabsoluteaccuraciesofcode-cushman-001
resent. ForthePythoninterpreter,however,variablenames
andcode-davinci-001arelower,therelativeimprove-
aremeaningless. Tomeasuretheimportanceofmeaningful
mentofPALoverCOTremainsconsistentacrossmodels.
variablenames,weexperimentedwithtwopromptsvariants:
ThisshowsthatPALcanworkwithweakermodels,while
itsbenefitscaleselegantlytostrongermodelsaswell.
1. PAL
−comment
–thePALpromptwithoutintermediate
NLcomments.
Does PAL work with LMs of natural language? We
also experimented with PAL using the