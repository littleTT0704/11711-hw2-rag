othesegmentationmapSt.ThetransformerdecoderdecodesthefusedtokenO(cid:48) intoan
order-preserving instance embedding et in which each slot corresponds to a specific instance in It. The final predictions, instance classes Ct and instance
masksMt,areobtainedfromtheinstanceembeddinget andsegmentationmapSt withasimpledotproductoperation.Fortheinstanceidentitymatching,
we constrain the slot indices (indicated in red and green) of instance embedding et to represent the instance identity. The optional audio signal serves as
anothercontextandcanbefusedinthesamewayasreferenceframes.
strongabilitytofacilitatehuman-computerinteraction.R-VOS (RPN) equipped with RoIAlign feature pooling strategy and
[62], [5], [34], [51], [15], [32] aims to segment object masks a feature pyramid networks (FPN) [36] to obtain fixed-sized
throughout the entire video by giving a linguistic expression. featuresofeachproposal.Thepooledfeaturesarefurtherused
URVOSfirstsegmentsobjectmasksbyvisualcuesthenselect forboundingboxpredictionandmasksegmentation.Followed
the referred one by referring expression. MTTR follows this by Mask R-CNN, several methods are proposed to improve
paradigmwhileenablethemultimodalfusionbyatransformer pooling and confidence scoring strategy [33], [39], [22].
encodertoenhancethesemanticconsensusbetweenlinguistic
and visual modalities. ReferFormer directly segments the
referred object by employing a language-conditioned instance
query in the transformer decoder which avoids segmenting
irrelevant objects. Audio-visual representative learning. Audio-visual repre-
Image Instance Segmentation Most of image instance seg- sentative learning aims to correspond the sound to their
mentation methods adopt either bottom-up [12], [64], [58], sources in the video frames. Sound localization [70], [53],
[59], [57], [69], [10], [56] or top-down [20], [8], [39], [22] [50], [65], [44], [14] is one of the more extensively explored
paradigm.Forbottom-upmethods