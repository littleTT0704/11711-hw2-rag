. In Proceedings of The 20th
nual Meeting of the Association for Computational SIGNLLConferenceonComputationalNaturalLan-
Linguistics, pages 7871–7880, Online. Association guage Learning, pages 280–290, Berlin, Germany.
forComputationalLinguistics. AssociationforComputationalLinguistics.
Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Matthew E. Peters, Sebastian Ruder, and Noah A.
Optimizing continuous prompts for generation. In Smith. 2019. To tune or not to tune? adapting pre-
Proceedings of the 59th Annual Meeting of the trainedrepresentationstodiversetasks. InProceed-
Association for Computational Linguistics and the ings of the 4th Workshop on Representation Learn-
11thInternationalJointConferenceonNaturalLan- ing for NLP (RepL4NLP-2019), pages 7–14, Flo-
guage Processing (Volume 1: Long Papers), pages rence,Italy.AssociationforComputationalLinguis-
4582–4597, Online. Association for Computational tics.
Linguistics.
Jonas Pfeiffer, Andreas Ru¨ckle´, Clifton Poth, Aish-
Chin-YewLin.2004. Rouge: Apackageforautomatic warya Kamath, Ivan Vulic´, Sebastian Ruder,
evaluation of summaries. In Text summarization Kyunghyun Cho, and Iryna Gurevych. 2020a.
branchesout,pages74–81. Adapterhub: A framework for adapting transform-
ers. arXivpreprintarXiv:2007.07779.
Zehui Lin, Liwei Wu, Mingxuan Wang, and Lei Li.
Jonas Pfeiffer, Ivan Vulic´, Iryna Gurevych, and Se-
2021. Learning language specific sub-network for
bastianRuder.2020b. MAD-X:AnAdapter-Based
multilingualmachinetranslation. InProceedingsof
Framework for Multi-Task Cross-Lingual Transfer.
the59thAnnualMeetingoftheAssociationforCom-
InProceedingsofthe2020ConferenceonEmpirical
