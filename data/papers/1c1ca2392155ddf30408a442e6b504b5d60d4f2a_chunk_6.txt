ancesinthecognitivescienceofmoraljudgment
whichrevealthestructurebehindhumanvalue-guidedjudgment(Levineetal.,2018;Awadetal.,
2022b). Integratingmodelsofvalue-drivenhumandecisionsinAIsystemscanbringusclosertothe
goalofaligningAIwithhumanvalues.
AnUrgentNeedforSafeLLMs. AIsafetyresearchinNLPhasbecomeincreasinglyurgentdueto
therecentadvancementofLLMs(Radfordetal.,2018,2019;Devlinetal.,2019;Liuetal.,2019;
Brownetal.,2020)andtheirbroadapplicationstomanytasks(Chenetal.,2021;Stiennonetal.,
2020;Rametal.,2018;Fanetal.,2019). ExistingAIsafetyworkinNLPincludes(1)high-level
methodologydesign(Irvingetal.,2018;Ziegleretal.,2019;Askelletal.,2021),(2)traininganalysis
suchasthescalingeffect(Raeetal.,2021),(3)identificationofchallengingtaskssuchasmathematics
(Hendrycksetal.,2021c;Cobbeetal.,2021),coding(Hendrycksetal.,2021a),andtruthfulquestion
answering(Linetal.,2021),(4)analysisofundesiredbehaviorsofLLMssuchastoxicity(Gehman
etal.,2020;Perezetal.,2022),misinformationharmsandotherriskareas(Weidingeretal.,2021),(5)
risksarisingfrommisspecification(Kentonetal.,2021),and(6)improvementssuchasencouraging
LLMstoexplicitlyretrieveevidence(Borgeaudetal.,2021;Talmoretal.,2020),amongmanyothers.
Inthiscontext,ourMoralExceptQAworkintersectswith(3)â€“(6)inthatweaddresstheimportant
potentialriskthatLLMsmightfollowhuman-misspecifiedrulescommandstooliterallywhichmight
triggerdangerousfailuremodes(for(5)),contributeachallengesettopredicthumanmoraljud