at-
streamtasks,weextendourmodeltothesemi-supervisedsetting.In
taininmanyareas.Therefore,wedevelopacontrastiveself-training
thisscenario,itisstraightforwardtoplugintheself-supervisedloss
algorithmtoleveragelabelinformationmoreeffectivelythancross
asaregularizerforrepresentationlearning.However,theinstance-
entropyinthesemi-supervisedscenario.Inthealgorithm,wetrain
wisesupervisionlimitedtostandardsupervisedlearningmaylead
themodelusingasmallamountoflabeleddataandthenfine-tune
tobiasednegativesamplingproblems[10].Totacklethischallenge,
itbyiteratingbetweenassigningpseudo-labelstounlabeledexam-
wecanuseasmallamountoflabeleddatafurthertogeneralize
plesandtrainingmodelsusingtheaugmenteddataset.Inthisway,
thesimilaritylosstohandlearbitrarynumberofpositivesamples
weharvestmassivepseudo-labelsforunlabeledexamples.
belongingtothesameclass:
Withincreasingsizeoftheaugmentedlabeleddataset,thedis-
Lsupcon=∑︁ 𝑖𝐾 =𝑙
1
𝐾𝑁1
𝑦 𝑖′
∑︁ 𝑗𝐾 =𝑙 1I 𝑖≠𝑗 ·I 𝑦 𝑖′=𝑦′
𝑗
·Lcon(𝐺 𝑖,𝐺 𝑗) (5) c i anr ci g cm umi mn o ua rt lei av p te eop s hio it giw v he e -r qp uo a af ir lI isG tybS eD plo sc una egn din ob g -e lati om betp h lsr eo av s fae temd rei ete c ar l caa hst si iv. te eInl ry at tb h ioy is nc wo ton ayt cr, oa w