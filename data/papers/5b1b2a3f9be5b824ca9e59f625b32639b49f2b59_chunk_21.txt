 test videos in this dataset.
• AVIS has 20 overlapped categories with Youtube-VIS
IV. EXPERIMENT
dataset, 2390 unique video instances. There are 1427
In this section, we will elaborate on the dataset, implemen- videos with synchronized raw audio recordings in it.
tation details and experiment results for our online VIS and To the best of our knowledge, AVIS is the first dataset
AVIS frameworks. with densely annotated instance-level masks matched to
corresponding audio recordings.
A. Implementation Details. Metrics. The evaluation metric for this task is defined as the
Training. We implement our method in the PyTorch frame- area under the precision-recall curve with different IoUs as
work.Followingpreviousmethods[18],[35],wefirstpre-train thresholds.
our model with both Youtube-VIS and overlapped categories
on MS-COCO dataset [37] then finetune the model on the
B. Video Instance Segmentation Results
Youtube-VIS dataset. We train our model for 60k iterations
with a “poly” learning rate policy with the learning rate Wefirstpresentthemainresultsandablationexperimentsof
(1− iter )0.9 for each iteration with an initial learning rate VIStaskonYoutube-VIS-2019andYoutube-VIS-2021dataset
of 0.0it 0e 0rm 6a fx or all ResNet backbones and 0.0003 for all Swin without audio involved.
backbones in experiments. We adopt batchsize = 16 and an 1) Main results
AdamW [41] optimizer with weightdecay = 10−4 for all We compare our method with state-of-the-art methods in
ResNet backbones and weightdecay = 10−2 for all Swin this section.
backbones is leveraged. A learning rate multiplier of 0.1 is Quantitativeresult.Wecompareourmethodagainststate-of-
appliedtoResNetbackbones,and1.0isappliedtotransformer art VIS methods on Youtube-VIS-2019 dataset in Table I. (1)
backbones. Multi-scale training is adopted to obtain a strong Compared to online methods: Our method achieves the best
baseline. performance of 40.8 mAP when using the same Res