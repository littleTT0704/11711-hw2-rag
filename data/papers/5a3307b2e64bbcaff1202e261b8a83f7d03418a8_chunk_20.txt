ï¿½e ğ‘˜ğ¶db oy nt th he ese err so prs lito sn.Dğ‘£1,wecaneasilygetsignificantly ğ‘„ shğ‘˜ a( pÂ· e),c io tm isp aut de is ffa ed reis nt ta in ac be le,a fup nro ctp io or nt.io Tn h, eor oa pn timan ig zl ae tio of nth oe bj3 eD ctf ivac eia isl
Optionalphonatorymodule.Inspiredbylinearpredictivecoding givenbelow.
(LPC) [25] which leverages voice producing to learn vocal tract ğ¾
geometry,weaimtofacilitatefacegeometrycapturebylearning ğ›½âˆ—=argminğœ†âˆ¥ğ›½âˆ¥2 2+âˆ‘ï¸ (ğ‘„ ğ‘˜(ğ‘ƒğ›½)âˆ’ğ‘šË†(ğ‘˜))2Â·ğ‘§(ğ‘˜) (7)
characteristicsofvoice.Weenrollaphonatorymoduleservingas ğ›½ ğ‘˜=1
an additional constraint when predicting facial AMs. In particu-
whereğœ†isthelossweightbalancingtwoterms.Thereconstructed
lar, we leverage a diffusion-based [18] voice generation method
3Dfacialshapeisgivenbyğ‘Ë†=ğ‘ƒğ›½âˆ—.
tomodelthetime-domainspeechsignals.AsshowninFig.2,the
diffusionmodelconvertsthenoisedistributiontoaspeechğ‘£Ëœ con-
trolledbythevoicecodeğ‘’extractedfromspeechğ‘£.Duringtraining 4 EXPERIMENTS
speechğ‘£â€² whichsharesspeakeridentitywithğ‘£ isfedtothediffu- Inthissection,weelaborateonthedatasetsetting,implementation
sionmodelasground-truth.Pleasenotethatthephonatorymodule detailsandexperimentalresults.
Conferenceâ€™23,July2023,Ottawa,Canada XiangLi1,YandongWen2,Mu