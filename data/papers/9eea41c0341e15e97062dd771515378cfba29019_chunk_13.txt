5randomrestarts).
roshotsummarization4 overtheoriginalSAMSum performs better than the fully supervised model
dialogues and over a perspective-shifted version trainedovertheoriginaldialogues. Inalow-data
ofthedialogues. Wealsoconsiderthefullysuper- setting,whereannotatingtheentiredatasetforsum-
vised case; we train models using the PreSumm marization may be cost-prohibitive, perspective
architectureforextractionovertheoriginalSAM- shift can serve as an alternative annotation goal.
Sumdialoguesandovertheperspective-shifteddi- The perspective shift model used to generate the
alogues. test data in Table 6 was trained on 545 dialouges
(withavalidationsetof137dialogues);bycontrast,
Results ResultsacrossallmodelsareinTable6. annotating the entire train and validation sets for
The zeroshot modelscores higher than thesuper- summarization would require annotating 15,550
visedmodelforSAMSum,whichatfirstappears conversations,amorethan20foldincreaseinanno-
unintuitive. We credit this to 2 factors. First, the tationeffort.
trainingdatasetforCNN/DMisapproximately21x
more training examples than SAMSum train set, 5.3 AnalysisofHallucination
allowing the model increased generalizability to
One of the oft-cited benefits of extractive sum-
an unseen test set. Second, the summaries in the
marization is that models that copy text directly
CNN/DMdatasetareoftenseveralsentences,while
from the input are less likely to present factually
thesummariesintheSAMSumdatasettendtobe
incorrectsummaries(Ladhaketal.,2022). Clearly,
asinglesentence. TheCNN/DMmodel’sbiasto-
perspective shifting introduces a rephrasing step
wardlongersummarylengthmayartificiallyinflate
intothesummarizationpipeline. Anaturalconcern
ROUGE scores, as the model selects more utter-
is the potential presence of “cascading errors”—
ances for the output. Despite these factors, the
where errors in the