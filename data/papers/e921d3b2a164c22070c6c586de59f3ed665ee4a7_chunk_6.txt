acan
belocallyseparated. Asaremedy,weadoptathresholding
strategy—settingathresholdtonysuchthaty =0ify <t
andy =1otherwise. Asaresult,weassignbinaryclasses
todataviathresholdingony. However,notethatbydoing
soweeffectivelymaketavariabletobeoptimized,namely,
wearenotonlypartitioningonx,butalsopartitioningon
y. Wewillexplainoptimizationofthisjoint-partitioninthe
latersection.
Atthispoint,let’sassumewehaveknowntheoptimaltree
settings—thatis,weknowthetreestructure(thedepthand
thenumberofnodes),andforeachnon-leafnode,theopti-
malsplittingthresholdt∗andtheclassifierh parameter-
β∗
izedbytheoptimalparameterβ∗,andforeachleafnode,
theregressorr parameterizedbytheoptimalparameter
Figure2.Illustration of the HRME model. It is a probabilistic θ∗
θ∗. Wethenexplainthepredictionofygivenaninputx.
binary tree. Each non-leaf node (circle) carries a classifier h
β
andapartitionthresholdt,andeachleafnode(square)carriesa Specifically,fornotationconvenience,weassumethenodes
regressorr θ.Predictionismadeviaprobabilisticcombinationof arenumberedsuchthatforanytwonodesn andn,ifi<j,
i j
leafregressors.ModelislearnedviarecursiveEM.
n occurseithertotheleftofn oraboveitinthetree. Each
i j
noden carriesaclassifierh :x(cid:55)→{n,n },which
i β∗ i+1 i+2
assigns any instance with inn pi ut x to one of the children
extraprocedures,suchaspruning(Waterhouse&Robinson,
nodesn orn. Weintroduceabinary-valuedrandom
i+1 i+2
1995) and Bayesian model selection (Bishop & Svensk