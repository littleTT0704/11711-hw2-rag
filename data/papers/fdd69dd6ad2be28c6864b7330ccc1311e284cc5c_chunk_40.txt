AAAI,volume5,pages813–818,2005.
[93] Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. Advances in neural
informationprocessingsystems,28,2015.
[94] YidongWang,HaoWu,AoLiu,WenxinHou,ZhenWu,JindongWang,TakahiroShinozaki,
Manabu Okumura, and Yue Zhang. Exploiting unlabeled data for target-oriented opinion
words extraction. In Proceedings of the 29th International Conference on Computational
Linguistics,2022.
15
[95] Ao Liu, An Wang, and Naoaki Okazaki. Semi-supervised formality style transfer with
consistency training. In Proceedings of the 60th Annual Meeting of the Association for
ComputationalLinguistics(Volume1: LongPapers),pages4689–4701,2022.
[96] JunxianHe,JiataoGu,JiajunShen,andMarc’AurelioRanzato. Revisitingself-trainingfor
neuralsequencegeneration. InInternationalConferenceonLearningRepresentations,2019.
[97] Jiaao Chen and Diyi Yang. Simple conversational data augmentation for semi-supervised
abstractivedialoguesummarization. InProceedingsofthe2021ConferenceonEmpirical
MethodsinNaturalLanguageProcessing,pages6605–6616,2021.
[98] LarryWassermanandJohnLafferty. Statisticalanalysisofsemi-supervisedregression. Ad-
vancesinNeuralInformationProcessingSystems,20,2007.
[99] Neal Jean, Sang Michael Xie, and Stefano Ermon. Semi-supervised deep kernel learning:
Regression with unlabeled data by minimizing predictive variance. Advances in Neural
InformationProcessingSystems,31,2018.
[100] Georgios Kostopoulos, Stamatis Karlos, Sotiris Kotsiantis, and Omiros Ragos. Semi-
supervisedregression: Arecentreview. JournalofIntelligent&FuzzySystems,35(2):1483–
1500,2018.
[101] Zhi-HuaZhou,M