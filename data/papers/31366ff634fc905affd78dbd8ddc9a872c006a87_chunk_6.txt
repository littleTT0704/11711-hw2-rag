 with human preference and more cor- tion outputs. The idea in BERTScore is to en-
related with execution correctness than all pre- code the candidate sentence (the prediction) and
vious approaches including BLEU, CodeBLEU, the reference sentence (the ground truth) sepa-
andCrystalBLEU.(c)Wepretrainandreleasefive rately,usingaBERT-basedmodel,whichencodes
language-specific CodeBERT models to use with eachsequenceoftokensasasequenceofvectors.
our publicly available code, for Java, Python, C, Then, BERTScore computes the cosine similarity
C++, and JavaScript. As of the time of this sub- betweeneveryvectorfromthecandidatesequence
mission, our models have been downloaded from andeveryvectorfromthereferencesequences.
theHuggingfaceHubmorethan1,000,000times.
Giventhesesimilarityscores,BERTScorecom-
2 EvaluatingGeneratedCode putes sentence-level precision by taking the max-
imum similarity score for every candidate vec-
2.1 ProblemFormulation
tor and averaging, and computes recall by tak-
Given a context x ∈ X (e.g., a natural language ing the average of the maximum similarity scores
instructionorcomment),acodegenerationmodel for every reference vector. Intuitively, a high
M : X → Y produces a code snippet yˆ ∈ Y BERTScore-recall is obtained, for example, if ev-
by conditioning on the intent specified by x. The eryvectorfromthereferencesentencehasatleast
quality of the generation is evaluated by compar- one vector from the candidate sentence that is
ing yˆ ∈ Y with the reference implementation highly cosine-similar to it; a high BERTScore-
y∗ ∈ Y, usingametricfunctionf : Y ×Y → R, precisionisobtainedifeveryvectorfromthecan-
essentiallycomputingf(yˆ,y∗). didatesentenceishighlycosine-similartoatleast
Alargervalueoff(yˆ,y∗)indicatesthatthegen- one vector from the reference sentence. Ulti-
erated code is more accurate with respect to the mately,