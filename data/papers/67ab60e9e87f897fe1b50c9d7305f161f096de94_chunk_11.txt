 Music transcription.
Mridingham Stroke and Mridingham Tonic Non-Western pitched percussion.
Classification of stroke or tonic.
Vocal Imitations Match a vocal imitation to the type of sound imitated, using
classification.
VoxLingua107 Top 10 Spoken language identification.
OpenL3 2-D CNN. Multi-modal contrastive self-supervised pretraining of audio/video
correspondence on 6K hours of AudioSet broad-domain YouTube content. (Cramer et al.
(2019), earlier Arandjelovic and Zisserman (2017)) HEAR implementation by Jon Nordby.
4.2. Submitted models
AMAAI Lab SUTD wav2vec2+DDSP An ensemble of wav2vec2 (Baevski et al.,
2020) and two DDSP encoders (Engel et al., 2020). The wav2vec2 model is pretrained on
theLibrispeech(Panayotov et al.,2015)andMAESTRO(Hawthorne et al.,2019)datasets.
One DDSP encoder is CREPE, the other is a non-pretrained loudness encoder.
AMAAI wav2vec2 music+speech wav2vec2 model (Baevski et al., 2020). Pretrained
on Librispeech (Panayotov et al., 2015) and MAESTRO (Hawthorne et al., 2019).
CP-JKU PaSST base, base2level, base2levelmel Patchout fast (2-D) spectrogram
transformer (PaSST, Koutini et al. (2021)). Initialized from a ImageNet vision transformer
model, and further pretrained on 10s audio from AudioSet to perform supervised tagging.
base2level concatenates a longer window (160 ms and 800ms) for timestamp embeddings.
base2levelmel additionally concatenates the raw melspectrogram as well.
CVSSP (University of Surrey) PANNs 2-D CNN14. Pretrained on AudioSet with
supervision (Kong et al., 2020).
Descript/MARL Wav2CLIP 2-DResNet18. Pretrainedmultimodallyusingcontrastive
learning on the 600h VGGSound corpus (