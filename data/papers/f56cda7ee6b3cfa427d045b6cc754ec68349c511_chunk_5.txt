wealsoannotatetheirgrammaticalandcontextual
Ourmaincontributionsinclude: (1)Werelease
plausibilitygiventhecontext. Ascreenshotofour
TOXICHAT,acorpusof2,000Redditconversations
annotation interface is shown in Figure 8 in the
thatareaugmentedwithautomaticresponsesfrom
Appendix.
DialoGPTandGPT-3,andannotatedwithtargeted
offensivelanguageandstance. (2)Wepresentan
3 DataCollection
analysisofstanceinoffensiveandsafecontextsus-
ingTOXICHAT,demonstratingthatneuraldialogue OurannotateddatasetcontainslabeledRedditcon-
modelsaresignificantlymorelikelytoagreewith versationsextendedwithdialoguemodelresponses
offensivecomments. (3)WeshowTOXICHAT sup- (§3.1). We gather Reddit posts and comments
portstrainingandevaluatingmachinelearningclas-
3AlthoughSafecommentsarenottoxic,theycanstillbe
sifiers for stance in toxic conversations. (4) We inappropriate,forexamplemisleadinginformation.But,for
conduct preliminary experiments on controlling simplicity,welimitourannotationtoonlyoffensivevsnot.
4Inpractice,wefindthistobeaveryreasonableassump-
the stance of neural responses to prevent models
tion.90.7%ofRedditreplycommentsagreeingwithprevious
fromagreeingwithoffensivestatements. offensiveutteranceareannotatedasoffensiveinourdataset.
(Baumgartner et al., 2020)5 that were written be- GPT-3model,‘davinci’with175Bparameters,in
tweenMayandOctober,2019. Fromthis,wecon- ourdataconstruction.
structthreads,eachofwhichcompriseatitle,post Blender - More recently, Facebook released
and subsequent comment sequence. We extract Blender Bot; a 2.7B parameter dialogue model
threads from two sources: (1) Any SubReddits: (Rolleretal.,2021). Blenderbotisfirstpretrained
threads from all SubReddits, (2) Offensive Sub- on 1.5B Reddit comment threads (Baumgart