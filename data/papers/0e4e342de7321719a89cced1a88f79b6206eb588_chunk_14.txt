.47 85.02 77.98 69.17 73.52 58.97 68.72 67.95 67.89 31.74
VGQCw/ofusion 80.01 83.02 73.94 66.37 73.11 56.50 65.50 65.44 65.75 27.92
Table 1: Comparison of top-1 accuracy (%) with previous methods on RefCOCO [Yu et al., 2016], RefCOCO+ [Yu et al., 2016] and
RefCOCOg [Mao et al., 2016]. “val-g” stands for RefCOCOg-google’s validation set, and “val-u”, “test-u” stand for RefCOCOg-umd’s
validation, test set, respectively. The results of TransVG [Deng et al., 2021] are reproduced using its released source code. The column
“Time”showstheinferencetimeofasinglesample. WerepeattheinferencetimemeasurementovertheentireRefCOCOtestAsetonan
NVIDIAT4GPUandreporttheaverage.
Candidate Kernel #1 Candidate Kernel #2 Candidate Kernel #3
ground
truth
TransVG
Candidate Kernel #4 Candidate Kernel #5
VGQC
w/ fusion
(a) female (b) woman (c) man sitting (d) woman red
behind the serving the on the bike gloves
driver sub
Figure 4: Qualitative results of VGQC w/ fusion on RefCOCO+
testAset.Thegreenboxesarethegroundtruthlabels,theredboxes
Figure 5: Ablations on candidate kernels. We force the model to
arethepredictedlabelsfromTransVG,theblueboxesarethepre-
relyononlyonecandidatekernelinthefinalQCMblockandshow
dictedlabelsfromourVGQCw/fusion, andthelastrowcontains
thepredictions. Thegreenboxesarethegroundtruthlabelsandthe
thecorrespondingqueries.
blueboxesarethepredictedlabelsfromourVGQCw/fusion. The
queryis“womanservingthesub”.Usingdifferentcandidatekernels
givedifferentpredictionresults.
Attention in