,k)andcx(i,j,k)bethe
tend to background so it is masked out (result in Figure 3) respectiveoffsetsandconfidences,thenthefinalpredictedxˆ
Weusetheoperator*torepresenttheinnerproduct.
coordinatefortheblock-to-moveiscomputedas:
(cid:2)
Ai,j,k =10(one hot(World i,j,k)∗da)
(4) xˆ= gx(i,j,k)+cx(i,j,k)dx(i,j,k) (6)
Ai,j,k =Ai,j,k∗bg mask
i,j,k i,j,k
OperationSoftmax Theseconddistributionwepredictis
Here, confidences cx(i,j,k) are softmax normalized
acrossallgridpoints.Predictionsforyˆ,zˆarecomputedsim-
overfunctionsforspatialrelations.Herethemodelneedsto ˆ
ilarly. We compute θ without a coordinate grid such that:
choosehowfarandinwhatdirectionstogofromtheblocks (cid:3)
ithaschosentofocuson.Unfortunately,thereisnoapriori
θˆ= i,j,kcθ(i,j,k)dθ(i,j,k).
set of such functions as we have specifically chosen not to
tryandpretrain/biasthemodelinthiscapacity,sothemodel ImplementationDetails
must perform a type of clustering where it simultaneously Our model is trained end-to-end using Adam (Kingma and
choosesaweightedsumoffunctionsandtrainstheirvalues. Ba 2014) with a batch size of 32.The convolutional aspect
As noted previously, for the sake of interpretability, we ofthemodelhas3layersandoperatesonaworldrepresen-
forcetheencodingforoperations(dop)tobealatentsoftmax tationofdimensions32×4×64×64×32(batch,depth,
distributionover32logits.Thefinaloperationvectorthatis height,width,channels).The