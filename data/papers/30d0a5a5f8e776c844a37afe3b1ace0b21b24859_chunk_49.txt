visual simulators,withscenesdesignedby3Dartists,toonly
appearanceofobjectsfromsim-to-real[156],andother having on the order of 100 scenes available for train-
works built models [51, 194, 195], or learned latent ing[51,105,186].Static3Dscansdonotsupportinter-
embeddingsoftherobotâ€™sdynamics[103,196,221]to actingormanipulatingobjectsandmaybeincredibly
adapt to the actuation noise found in the real world. timeconsumingtoannotatesemantically,capturethe
Models of real-world camera and actuation noises scenes, and clean up the meshes. To create HM3D-
have since been integrated into simulators, and in- Semantics [151], it took over 100 hours to semanti-
cludedaspartoftheHabitat,RoboTHOR,RVSUand cally annotate each of 120 scenes to make them use-
iGibsonChallenges,therebyimprovingtherealismof able for ObjectNav. Thus, it is incredibly difficult to
the challenge and decreasing the sim2real gap. Con- scale the creation of both hand-designed scenes and
tinuingthiscloseintegrationbetweenreal-worldeval- 3Dscannedscenes.
uation and improving simulators and benchmarks
will help accelerate the speed of progress in robotics
research.
A final future direction, is in addressing the dif-
ferences between simulated and real-world sensori-
motor interfaces. It is common currently for actua-
tion to be broken into discretised chunks, and simu-
Figure16.ExamplesofProcedurallygeneratedhousesfrom
latedsensorinputstreatedthesameasreal-worldin-
ProcTHOR[52].
puts. While simulators and datasets will continue to
advance, there will likely always be a difference be-
Procedurallygeneratingenvironmentsoffersanal-
tween emulated and real-world sensorimotor experi-
ternative approach towards scaling data in embod-
ences. Research approaches that leverage simulated
ied AI, which randomly samples scenes with respect
datatolearnpolicies,thenembracethelimitationsof
to a prior distribution. ProcTHOR [52] procedurally
thesepolicieswhentransfer