] 42.0 70.0
MMT[14] CollaborativeExperts – – – – 26.6 57.1 69.6 4.0 28.7 61.4 94.5 3.3
TACo(Ours) R-152+S3D-HM 27.3 56.5 68.8 4.0 28.4 57.8 71.2 4.0 30.4 61.2 93.4 3.0 TACo(Ours) 42.5 68.4
Table 8: A complete comparison of TACo under zero-shot and finetuning evaluation Table 9: Action step localization
protocols. Note that the zero-shot and upper part of finetuned performance for MSR- onCrossTask(avg. recall)andac-
VTTisonsplit2,whilethebottomisonsplit1forfaircomparison. tionsegmentationonCOIN(acc.).
Zero-shot and finetuned performance. In Table 8, we 5.2.Othervideo-relatedtasks
showthecomparisonsacrossdifferentmodelspretrainedon
Following[35,60,33],weevaluateactionsteplocaliza-
Howto100M.Intheupperpartofthetable,wecomparethe
tion performance on CrossTask dataset [61]. It covers 18
zero-shotperformanceonYouCook2andMSR-VTT.Wedo
tasksandeachvideocontainsmultiplevideosegmentsan-
notevaluateonActivityNetsinceithasdifferentnumberof
notatedwithactionstepsandnaturallanguagedescriptions.
inputvideotokenscomparedwiththepretrainedmodeland
Similar to [35, 60, 33], we use our model to compute the
thusisnotdirectlycompatibletothepretrainedmodel. As
similarity between each frame and the action step descrip-
wecansee,TACooutperformspreviousworkssignificantly
tions, which results in a score matrix. Using the official
onYouCook2andslightlyonMSR-VTT.SinceYouCook2
algorithmprovidedby[61],wecanfindtheoptimalframe-
hascloserdomaingaptoHowto100MthanMSR-VTT,the
wise order of action steps for a video. By comparing