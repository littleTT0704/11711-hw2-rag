. [45] adapt the ConvNet frame-level features by VLAD
anencoder-decoder approachwithadual-channelranking pooling over the timestamps to generate video representa-
losstolearnthreevideorepresentations,oneforeachVideo tion,whichshowsgreatadvantagesoverthetraditionalav-
QA subtasks, i.e., past inference, present description, and erage pooling. Recently, a general sequence to sequence
futureprediction. Oneappealingfeatureofourapproachis frameworkencoder-decoderwasintroducedbySutskeveret
that,theencoder-decoderapproachisabletomodelawider al.[33], whichutilizeamultilayeredRNNtoencodease-
rangeoftemporalinformation, andthereducednumberof quence of input into one hidden state, then another RNN
weight parameters in GRU makes it more robust to over- takes the encoded state as input and decode it into a se-
fitting in temporal modeling. Further, the approach avoids quenceofoutput. Ngetal.[25]applytheencoder-decoder
the needs of creating a large number of labels to train the frameworkonlarge-scalevideoclassificationtasks. Srivas-
sequencemodelbyembeddingvisualfeaturetoasemantic tava et al. [32] extend this general model to learn features
space. from consecutive frames and propose a composite model
forunsupervisedLSTMautoencoder.
Third, we should have a well-defined quantitative eval-
uation metric and datasets from different domains to track
Bridging vision and language: captioning and question
progressofthisimportantresearch[2]. Manuallyproviding answering. There are increasing interests in the field of
groundtruth for a large amount of videos is extremely hu- multimodallearningforbridgingcomputervisionandnat-
manlaborintensive.BLEU[26]hasbeenwidelyusedasan urallanguageunderstanding[7,15,40,41,46]. Captioning
evaluation metric for image captioning but a few research is one of the most popular tasks among them, and Long
papers and competition reports have indicated that BLEU Short-Term Memory (LSTM) is heavily used as a recur-
is not a reliable metric, and