forallexperiments.
mentswerecollectedviaratingsonascalefrom1 Since previous work has shown that models are
(very unlikely to be an agent) to 5 (very likely to highly sensitive to the ordering of examples (Lu
be an agent). For nouns that have multiple com- etal.,2021),weruneachexperimenttwice: once
monwordsenses(e.g. “model”canrefertobotha with the order shown in Figure 1 where an agent
fashionmodelormachinelearningmodel,among
4Additional details on collecting human ratings can be
otherthings)weincludeadisambiguatingdescrip- foundinAppendixC.
tion. Thisdescriptiondoesnotcontainanyverbsor 5We used Propbank annotations for BOLT, EWT,
and Ontonotes 5.0 from https://github.com/
otherexplicitindicationsofwhateventsthenoun
propbank/propbank-release.
Figure 2: Correlation between subject ratio (from Figure3: Correlationbetweenδ-LLinExperiment1
GoogleSyntacticNgrams)andhumanratingsforeach forGPT-3davinci-003andthenormalizedhuman
noun(r = 0.762). Thesemanticrolelabelistherole rating in the APAP experiment. Note that a negative
the noun takes as the subject of the intransitive verb δ-LLmeansthe“patient”labelismorelikely.
withinourtestset.
with human ratings, with the exception of
is first (APAP ordering) and again with the first GPT-3 text-davinci-003 (henceforth
example moved to the bottom (PAPA ordering). davinci-003), shown in Figure 3. We also
Wecomparemodelsbasedontheiraverageperfor- see that davinci-003 is not only both better
manceacrossbothorderings. Note,however,that correlated with human judgements than with
somemodelsaremoresensitivetoorderingsthan corpus statistics, but surprisingly there is also a
others;somemodels(liketext-davinci-003) strongercorrelationbetweenitsδ-LLandhuman
are largely invariant to example ordering. In