 Shift
bleanswerspansinthecorpuswhichisintractable.
BioASQ 0.3027 0.1765 Label
Weinsteadsampleasetofanswerspanstoapprox-
CliCR -0.8839 0.2352 Full
imatethenormalizer. Quasar-S -0.6697 0.0767 Covar.
Quasar-T 0.2016 0.1694 Label
NewsQA -0.1967 0.1800 Full
(cid:81) SearchQA 0.6165 -0.0063 No
M(at|a<t,q,c )
p(a g|q,c q) = (cid:80) (cid:81)t Mg (atg |a<t,qq
,c )
(2)
Table1: Wassersteindistance: Computedover100ex-
t k k q
ak∈A ampleslabeledexamplesfromtargetdomain. Theref-
erenceofsourcedomainmodelhasdr=0.2925
u
3.3 Predictingtypeofdatasetshift
Adaptingorfine-tuningapre-trainedsourcemodel Output/Reader Distribution: In the second
to match thetargetdomain, can be formulated in stage, we follow a similar procedure to charac-
a Bayesian framework. The source model acts terize for the output distribution. To analyze the
as a prior which when exposed to interventional compatibilitybetweentheoutputanswerdistribu-
data,thatestimatesthelikelihoodoftargetdomain, tionandauniformdistribution,weneedtocompute
aprobabilitydistributionoverasetofanswerssim- reader model with contexts retrieved by BM25 –
ilar to stage 1. However, the conditional answer theoverallstrongestretriever.
generationmodelisnottrainedwithacontrastive Upperbound-Retriever a target domain trained
lossliketheretrieverleadingtotheanswerlikeli- reader model with gold contexts to approximate
hood distribution having a higher entropy. Also, upper-boundperformance.
thesupportsetofanswersusedfornormalization Overall, when testing models on the new tar-
containsonlygrammaticallycorrectanswerspans getdomainswe