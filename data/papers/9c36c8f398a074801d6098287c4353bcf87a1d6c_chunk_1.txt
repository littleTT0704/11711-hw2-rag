Enabling Classifiers to Make Judgements
Explicitly Aligned with Human Values
YejinBang1∗ TiezhengYu1∗ AndreaMadotto2
ZhaojiangLin2 MonaDiab2 PascaleFung1†
1TheHongKongUniversityofScienceandTechnology 2MetaAI
{yjbang,tyuah}@connect.ust.hk
Abstract
Many NLP classification tasks, such as sex-
ism/racismdetectionortoxicitydetection,are
basedonhumanvalues.Yet,humanvaluescan
vary underdiverse culturalconditions. There-
fore, we introduce a framework for value-
alignedclassificationthatperformsprediction
basedonexplicitlywrittenhumanvaluesinthe
command. Along with the task, we propose
apracticalapproachthatdistillsvalue-aligned
knowledge from large-scale language models
(LLMs) to construct value-aligned classifiers
intwosteps. First, wegeneratevalue-aligned
training data from LLMs by prompt-based
few-shotlearning. Next, wefine-tunesmaller
classification models with the generated data
for the task. Empirical results show that our
Figure1:Illustrationofproposedvaluealignmenttask.
VA-MODELs surpass multiple baselines by at
Given the same content, VA-MODEL makes variable
least 15.56% on the F1-score, including few-
predictionsbasedonexplicitlyprovidedhumanvalues.
shotlearningwithOPT-175Bandexistingtext
augmentationmethods. Wesuggestthatusing
classifierswithexplicithumanvalueinputim-
provesbothinclusivity&explainabilityinAI. (Hendrycks et al., 2020) or human preferences
(Christianoetal.,2017;Koren,2008).
1 Introduction
Value-alignment of AI systems is not a trivial
problem as human values are non-consensual by
The demand for responsible NLP technology –
nature(Haneletal.,2018). Valuescanbeverydi-
to make it more robust, inclusive and fair, as
verse and most existing works have attempted to
well as more explainable and trustworthy – has
alignmachineswithsharedhumanvaluesoraver-
increased since pre-trained large