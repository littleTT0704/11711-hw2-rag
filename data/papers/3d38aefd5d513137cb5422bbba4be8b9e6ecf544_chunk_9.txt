2(STFT) 1.71 13.30 11.42 43.52 4.86 17.76 5.21 19.45
VoxCeleb1(STFT) 4.16 16.41 14.95 42.02 4.74 15.90 5.06 15.64
blackbox VoxCeleb1(MFCC) 17.21 22.09 22.01 48.77 9.22 26.80 8.86 20.11
VoxCeleb1(AP) 39.75 41.27 44.89 45.46 45.58 46.06 41.65 42.94
VoxCeleb1(SP) 53.58 49.42 54.36 50.36 55.04 51.11 53.76 49.43
1R:Sametargetspeaker’srealutterancepair(+,#19086) 2RI:Differenttargetspeaker’srealutterancepair(−,#14844)
3IAB:Sameimpersonator,impersonationsfordifferenttargetpair(+,#3382) 4TI:Targetandimpersonationpair(−,#37554)
5IRAB:Differentimpersonator’srealutterancepair(−,#1988) 6IRT:Targetandimpersonator’srealutterancepair(−,#28080)
7Themodelpre-trainedwithVoxCeleb2devsetusingSpectrogramfeature
Table2. EERsofevaluationsetforASVspoof2019LAunderblack-boxandwhite-boxscenarios
ASVEER%
Attack A07 A08 A09 A10 A11 A12 A13 A14 A15 A16 A17 A18 A19 ALL3
VoxCeleb2(STFT) 34.03 23.20 5.70 48.51 37.37 43.42 23.67 40.45 43.14 50.51 4.99 7.10 11.26 21.42
VoxCeleb1(STFT) 27.93 25.30 11.01 47.77 37.36 44.77 30.93 43.33 40.91 43.36 7.65 10.83 13.97 22.03
VoxCeleb1(MFCC) 45.12 28.89 16.02 45.01 48.88 45.09 38.