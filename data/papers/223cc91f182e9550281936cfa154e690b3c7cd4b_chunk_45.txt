nm ϕax D(q,p θ)−Eq [f ϕ]+Ep
d
[f ϕ],
(6.4)
turns out to relate closely to generative adversarial learning.
In particular, with proofs adapted from Farnia and Tse (2018), Equation 6.4 recovers the vanilla GAN
algorithm when D is the Jensen-Shannon divergence and assuming the space of f ϕ, denoted as F, is convex.
More specifically, if we denote the probability C ϕ(t) = expf ϕ(t), then the equation reduces to the familiar
GAN objective in Equation 5.5. The results can be extended to the more general case of f-GAN (Nowozin et
al., 2016): if we set D to an f-divergence and do not restrict the form (e.g., classifier) of the experience
function f ϕ, then with mild conditions, the equation recovers the f-GAN algorithm. Now consider D as the
first-order Wasserstein distance and suppose the f ϕ-space F is a convex subset of 1-Lipschitz functions. It can
be shown that Equation 6.4 reduces to the Wasserstein GAN algorithm as shown in Equation 5.8 where φ now
corresponds to f ϕ. Note that for the above configurations, if f ϕ is parameterized as a neural network with a
fixed architecture (e.g., ConvNet), its space F is not necessarily convex (i.e., a linear combination of two
neural networks in F is not necessarily in F). In such cases we formulate the optimization of the experience
function over conv(F), the convex hull of F containing any convex combination of neural network
functions in F (Farnia & Tse, 2018), and see the various GAN algorithms as approximations by considering
only the subset F ⊆ conv(F).
Besides the above examples of divergence D that each leads to a different GAN algorithm, we can consider
even more options, such as the hybrid f-divergence and Wasserstein distance studied in (Farnia & Tse, 2018).
Of particular interest is to set D to the KL divergence D(q,p θ) = KL(q∥p θ), motivated by the simplicity