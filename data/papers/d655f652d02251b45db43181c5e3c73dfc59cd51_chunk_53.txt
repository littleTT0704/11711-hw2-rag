 disci- mixturesinteractwithperformanceinTable12.
pline.Theformerco-occurrencecanbeexplainedwithsome
What is the effect of dataset mixture on performance?
ofthetrolleyproblemsituationsfoundintheinputdata,such
Ourbasemodelwastrainedwithamixtureofallfourtask.
as Sacrificing eighty mens’ lives to save the former Ameri-
Wefindthatalltasksexceptrelevancearebenefitedfroma
canPresidentWilliamJeffersonClinton’slife.Thelatterco-
mixture as opposed to training a separete model for each,
occurring values are mentioned in the context of situations
suggesting that the tasks are complementary. As we ablate
suchasspankingkids.Frequentlyco-occurringitemscanei-
each task out of the mixture individually, we see minimal
therbeinsupportofeachother,suchasfinancialsecurityvs.
changesinperformanceacrossalltasks,suggestingthatno
risk-taking, or show two opposing viewpoints, such as de-
onetaskiscrucialtothegaininperformanceseenfrommix-
terrenceandrehabilitation.Similarvisualizationsforrights
ing.
anddutiescanbefoundintheAppendix(Fig.7,Fig.6).
What is the effect of model size on performance? For
C.3 RelationshipwithMachineJudgments alltasks,largermodelsperformbetter.Perplexityimproves
Machine judgments on morality vs. generated val- steadily with model size, whereas classification accuracies
ues/rights/duties Toseehowvalues,rights,anddutiesare (RelevanceandValence)seealargeboostgoingfrom60M
influenced by the all-things-considered judgment of a sit- to 220M parameters. As there are not large performance
uation, we collect predicted moral judgments from Delphi gainsingoingfromthe3Btothe11Bmodel(1%accuracy
(Jiang et al. 2022). Each situation gets labeled to be either and 0.01-0.15 perplexity), we think that the 3B model has
a good trade-off between performance and computational
19https://maartengr.github.io/BERTopic cost.
Entries 2-grams 3-gram