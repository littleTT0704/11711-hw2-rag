. Theleaderboard
evaluates these paths against held-out ground-truth
paths. Agent performance is reported as the average
ofepisodicperformance.Theofficialcomparisonmet- t=27 objectinteraction t=36 visualnavigation t=50 objectinteraction
ricbetweentheagentâ€™spathandthegroundtruthpath statechanges memory
is normalized dynamic time warping (nDTW) [111]
Figure 14. ALFRED involves interactions with objects,
which scores path alignment between 0 and 1 with
keeping track of state changes, and references to previ-
1 indicating identical paths. Additional metrics re-
ousinstructions. Thedatasetconsistsof25klanguagedi-
ported for analysis include path length (PL), naviga-
rectivescorrespondingtoexpertdemonstrationsofhouse-
tionerror(NE),successrate(SR)andsuccessweighted
holdtasks. Wehighlightseveralframescorrespondingto
byinversepathlength(SPL)[9]. portionsoftheaccompanyinglanguageinstruction.
RxR-Habitatisincrediblydifficult;theinterplaybe-
tweenperception,control,andlanguageunderstand- 3.3.2 InteractiveInstructionFollowing.
ing makes instruction-following an interdisciplinary
ALFRED is a benchmark for connecting human lan-
problem. Realistic environments and unconstrained
guage to actions, behaviors, and objects in interactive
natural language lead to a long tail of vision and
visual environments. Planner-based expert demon-
language grounding, and the low-level action space
strationsareaccompaniedbybothhigh-andlow-level
makes learning the relationship between instructions
human language instructions in 120 indoor scenes in
and actions highly implicit. The RxR-Habitat Chal-
AI2-THOR.Thesedemonstrationsinvolvepartialob-
lengetookplacein2021andagainin2022. Thebase-
servability,longactionhorizons,underspecifiednatu-
line model is a cross-modal attention (CMA) model
rallanguage,andirreversibleactions.
[101]thatattendsbetweenvisionandlanguageencod-
The dataset includes over 25K English language
ings, predicts actions end-to-end from observation