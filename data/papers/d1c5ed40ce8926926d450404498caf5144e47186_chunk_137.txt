 again use the collection of manually acquired
sources comprising encyclopedias, dictionaries, thesauri, newswire corpora, literature,
other sources of trivia knowledge, and the TREC 11 reference corpus. This baseline
is compared to a setup that includes expanded versions of Wikipedia, Wiktionary
and the other two encyclopedias in Section 6.2. Performance is evaluated in terms of
6.4. END-TO-END EXPERIMENTS 99
candidate recall and QA accuracy. Candidate recall is the percentage of questions for
which a correct candidate answer is generated, which is typically lower than search re-
callbecauseWatsonsometimesfailstoextractthecorrectanswerfromrelevantsearch
results. It is an upper bound on accuracy, the percentage of questions answered cor-
rectly in first place. For regular Jeopardy! questions, we also report precision@70,
the percentage of questions Watson answers correctly if it only attempts 70% of the
questions for which the top candidate answers have the highest confidence estimates.
This is a key measure of performance for regular Jeopardy! questions because contes-
tants do not have to answer all of these questions but can decide when to “buzz in”
based on their confidence.
Watson scores and ranks candidate answers using supervised models trained on
question-answer pairs with relevance judgments. For the Jeopardy! task, we trained
these models on an independent set of 11,550 questions and used the same test sets as
in previous search experiments. However, for the TREC task we did not have enough
training data to fit answer scoring models with the complete feature set. At first we
attempted training models on Jeopardy! data and applying them to TREC questions
without adaptation, but this approach proved to be ineffective because the question
characteristics and the feature set used by Watson differ between the two tasks.
Thus we used a transfer learning approach, fitting a base model to Jeopardy! data
and adapting it to the TREC task. In the adaptation step, the factoid questions from
TREC 8, 9, 10 and 12 were used to fit a new model that combines scores predicted
by the base model with a small set of additional features. Some of these features
were already used in the base model, others are specific to TREC. Transfer learning
became increasingly important throughout the development of Watson because