Bforgenerationdetails.
with an external LM (GPT-2 XL; Radford et al.,
2019),andmeaningsimilaritybetweentheinput
ParaGeDi utilizesaclass-conditionedlanguage
and the rewrite using BERTScore (Zhang et al.,
model(usingcontrolcodesfortoxicandnon-toxic
2019). SeeAppendixB.3forfurtherdetails.
styles)ontopofaparaphrasinglanguagemodelto
steergeneratedtexttowardsaspecificattribute.
HumanEvaluation Weconductahead-to-head
CondBERT follows a pointwise editing setup, human evaluation (Kiritchenko and Mohammad,
firstidentifyingtokenstomaskintheinput, then 2017)ofthetoxicityoftherewritesusingAmazon
usingamask-fillingmodeltoreplacethem. Incon- MechanicalTurk. Foreachdataset’svalidationand
trastto MARCO,CondBERTusesalexicon-based testsets,wesample75promptseach,thencompare
approachtomaskingwordsbyusingweightsfrom eachpairofMARCO,ParaGeDiandCondBERT’s
awhole-word,toxiclanguagelogisticclassifier. generationsagainsteachotherandaskwhichone
islesstoxic(alongwithanoptiontoflageitherof
4.3 EvaluationSetup therewritesasungrammaticalordisfluent). Inour
Weperformautomaticandhumanevaluations,fol- evaluation, we obtained head-to-head judgments
lowingpreviouswork. fromthreeworkersperrewritepair;workersagreed
4Asubredditisatopic-focusedcommunityonReddit 5www.perspectiveapi.org,accessed06-2022.
moderately, with a Cohen’s κ=0.575 on average. forcontrollablerevision,andhighlightstheuseful-
SeeAppendixDfordetails(e.g.,MTurkinterface). nessofusingLMsforcapturingtoxicity.
4.4 Results Limitations,EthicalConsiderations,and
BroaderImpacts
Automatic metrics (Table 1) show that MARCO
isbetteratdetoxificationthanbaselinesacrossall
