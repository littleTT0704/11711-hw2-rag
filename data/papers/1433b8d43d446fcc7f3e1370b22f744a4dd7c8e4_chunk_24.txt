viewed. This work was supported in part by a grant
Future research could further examine differ- from the National Science Foundation Graduate
encesbetweengeographicsubcommunitiesinNLP Research Fellowship Program under Grant No.
andmorecloselyexamineinfluencesonpeople’s DGE2140739. Widder gratefully acknowledges
participationinanddisengagementfromthecom- thesupportoftheDigitalLifeInitiativeatCornell
munity. Additionally, we leave to future work a Tech. Anyopinions,findings,andconclusionsor
moreintentionalexplorationofperspectivesfrom recommendations expressed in this material are
thoseoftheauthorsanddonotnecessarilyreflect
7Inordertocaptureperspectivesofthecommunitychang-
theviewsofthesponsors.
ingovertime,andtoselectforpeoplewhoarepartofthese
communities.
References Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
MartínAbadi,AshishAgarwal,PaulBarham,Eugene
deepbidirectionaltransformersforlanguageunder-
Brevdo,ZhifengChen,CraigCitro,GregS.Corrado,
standing. InProceedingsofthe2019Conferenceof
AndyDavis,JeffreyDean,MatthieuDevin,Sanjay
theNorthAmericanChapteroftheAssociationfor
Ghemawat,IanGoodfellow,AndrewHarp,Geoffrey
ComputationalLinguistics: HumanLanguageTech-
Irving,MichaelIsard,YangqingJia,RafalJozefow-
nologies,Volume1(LongandShortPapers),pages
icz,LukaszKaiser,ManjunathKudlur,JoshLeven-
4171–4186,Minneapolis,Minnesota.Associationfor
berg,DandelionMané,RajatMonga,SherryMoore,
ComputationalLinguistics.
DerekMurray,ChrisOlah,MikeSchuster,Jonathon
Shlens,BenoitSteiner,IlyaSutskever,KunalTalwar, Nic Fishman and Leif Hancox-Li. 2022. Should at-
PaulTucker,V