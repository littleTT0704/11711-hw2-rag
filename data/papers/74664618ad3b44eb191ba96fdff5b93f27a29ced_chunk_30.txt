.
PMLR,2020.
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventingdefensestoadversarialexamples. InInternationalconferenceonmachine
learning,pages274–283.PMLR,2018a.
NicholasCarlini,AnishAthalye,NicolasPapernot,WielandBrendel,JonasRauber,DimitrisTsipras,
IanGoodfellow,AleksanderMadry,andAlexeyKurakin. Onevaluatingadversarialrobustness.
arXivpreprintarXiv:1902.06705,2019.
Sylvestre-Alvise Rebuffi, Sven Gowal, Dan Andrei Calian, Florian Stimberg, Olivia Wiles, and
TimothyAMann. Dataaugmentationcanimproverobustness. AdvancesinNeuralInformation
ProcessingSystems,34:29935–29948,2021.
Aounon Kumar and Tom Goldstein. Center smoothing: Certified robustness for networks with
structuredoutputs. AdvancesinNeuralInformationProcessingSystems,34:5560–5575,2021.
BaiLi,ChangyouChen,WenlinWang,andLawrenceCarin. Certifiedadversarialrobustnesswith
additivenoise. Advancesinneuralinformationprocessingsystems,32,2019.
ChuanGuo,MayankRana,MoustaphaCisse,andLaurensVanDerMaaten. Counteringadversarial
imagesusinginputtransformations. arXivpreprintarXiv:1711.00117,2017.
EdwardRaff,JaredSylvester,StevenForsyth,andMarkMcLean. Barrageofrandomtransformsfor
adversariallyrobustdefense. InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition,pages6528–6537,2019.
AnishAthalye,LoganEngstrom,AndrewIlyas,andKevinKwok. Synthesizingrobustadversarial
examples. InInternationalconferenceonmachinelearning,pages284–293.PMLR,2018b.
12