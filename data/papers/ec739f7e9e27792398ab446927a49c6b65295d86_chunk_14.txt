denotesthenumberoftime-steps
goal k0+N f. Sincewearelearningaconditionaldistribution,wealso
intheplanninghorizon.
passthecontextembeddingmtotheflowmodel,following
Next, rather than learning a mapping to directly imitate priorworks(Dinhetal.,2016;Papamakariosetal.,2017).
these derived expert goals, we instead model an approxi-
mationp θ(x goal|m)oftheunderlyinggoaldistribution,by 4.4.GroundingActionPredictionswithRoad
leveragingabijectiveanddifferentiablemappingbetweena GeometryandVehicleDynamics
chosenbasedistributionp andtheaforementionedtarget
0
Given x ∼ GP(·|m), we want to find a trajectory to
approximate goal distribution p. This technique is com- goal
θ
x thatisconformanttobothvehicledynamicsandroad
monlyreferredtoasa‘normalizingflow’,whichprovides goal
geometry. Toconformtoroadgeometry,wepredictthegoal
a general framework for transforming a simple probabil-
stateinFrenétcoordinate(Figure3)andinverttoCartesian
itydensity(basedistribution)intoamoreexpressiveone,
coordinate. Weparameterisetheroadgeometryasacubic
throughaseriesofinvertiblemappings(Tabaketal.,2010;
splinealongthewaypoints, andcalculatetheFrenétand
Rezende & Mohamed, 2015; Papamakarios et al., 2021;
inverse-Frenéttransformationaccordingly.
Kingma&Dhariwal,2018;Parketal.,2020).
To be conformant to the vehicle dynamics, we formulate
Formally,letf beaninvertibleandsmoothfunction,with
f : Rd → Rd, x = f(z), z ∼ p, f−1 = g, and thus reachingadesiredgoalstateasaMPCproblem(Eqn. 4),
z
whichembedsavehiclemodel. Theobjective(Equation4a)
g ◦ f(z) = z, for d-dimensional random vectors x and
istoreachthegoalwithregular