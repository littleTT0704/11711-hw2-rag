corresponding
learnedembeddingswasexploredinin(Yosinskietal.2014). propertyisincludedinthelinearization(e.g.,oneof“type,”
Ourworkbuildsonthesebycreatingadeepmulti-taskmodel “value”or“name”).Intentsincludeaction,therolesonthe
forpredictingameaningrepresentationforspokenlanguage. action(e.g.,“object”),andthetypeofeachoftheroles.This
linearization enables the AMRL to be formulated as a se-
Approach quentialpredictionproblem,factoringintothreecomponents:
InthissectionwedescribetheAlexameaningrepresentation intents,types,andpropertiesasinFigure4.
language(AMRL),ourdeepmulti-taskmodel,mechanisms
forlearningrepresentationsforspokenlanguageunderstand- Models
ing(SLU)andtransferringthoserepresentationstoimprove AMRLparsingusemulti-tasklearningtojointlylearntasks
AMRLparsing. ofpredictingtheSLUorAMRLrepresentations.Inthissec-
tionwefirstdescribethebaselinemodelusedinourexperi-
AlexaMeaningRepresentationLanguage
ments.Thenwedescribemodelsthatleveragerepresentations
AMRLprovidesacommonsemanticsfornaturallanguage fromspokenlanguageunderstanding.Comparedtomodels
understandingforvoiceapplications.AnAMRLparsecon- trained separately for each of the tasks, multi-task models
sistsoffiveprimarycomponents: allowustoexploitcommonalitiesbetweentasks(Caruana
• Actionsdefinethecorefunctionalityusedforspokenlan- 1998)suchasoverlappingspansbetweenAMRLtypesand
guageunderstanding.InFigure1,thePlaybackActionis properties.
usedonaMusicRecording,butcanalsobeusedonBooks,
Baselinemodel Thebaselinemodelisadeepbi-directional
Videosandotherplayableobjects.
LSTM neural network trained using multi-task learning.
• Roles Actions operate on entities via roles. The.object
TherearethreeLSTMlayers,eachofwhichpredicts