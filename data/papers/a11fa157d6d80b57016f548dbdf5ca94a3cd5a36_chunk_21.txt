data. Advancesinneuralinformationpro-
cessingsystems,26.
We have developed an automatic framework that
extracts a KG from a pretrained LM (e.g, BERT,
AntoineBosselut,HannahRashkin,MaartenSap,Chai-
ROBERTA),inanefficientandscalableway,result-
tanya Malaviya, Asli Çelikyilmaz, and Yejin Choi.
inginafamilyofnewKGs,whichwerefertoas 2019. Comet:Commonsensetransformersforknowl-
BERTNET,ROBERTANET,etc. Ourframeworkis edgegraphconstruction. TheAssociationforCom-
putationalLinguistics.
capableofextractingknowledgeofarbitrarynew
relationtypesandentities,withoutbeingrestricted
Zied Bouraoui, José Camacho-Collados, and Steven
bypre-existingknowledgeorcorpora. Theresult-
Schockaert. 2020. Inducing relational knowledge
ingKGsalsoserveasinterpretationofsourceLMs. frombert. InAAAI.
Limitations Ourcurrentdesignandexperimental
TomB.Brown,BenjaminMann,NickRyder,Melanie
studiesarelimitedonLMsinthegenericdomain, Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
and are not yet been studied in specific domains Neelakantan,PranavShyam,GirishSastry,Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
suchasextractinghealthcareknowledgefromrele-
Gretchen Krueger, T. J. Henighan, Rewon Child,
vantneuralmodels. Weleavetheexcitingworkof
AdityaRamesh,DanielM.Ziegler,JeffWu,Clemens
harvestingknowledgefromvariouskindsofneural Winter,ChristopherHesse,MarkChen,EricSigler,
networks across applications and domains in the MateuszLitwin,ScottGray,BenjaminChess,Jack
Clark, ChristopherBerner, SamMcCandlish, Alec
futurework.
Radford, Ilya Sutskever, and D