�Ys (cid:88) −logps(yσik |yσik −1,...,yσ1k,y sk,Θ)
i=1
models only consider the correlation between the current
where σk is the permutation of {1...N}\{k}. Eqn. (10)
pixel with its neighbor pixels. However, the smoothness
could be modeled by Recurrent Neural Networks [41].
ofpredictedsegmentationmapsishighlydependentonthe
However, directly adopting recurrent approaches remains
window size used in Markovian approaches (the number
some potential limitations. Particularly, as the recurrent
of neighbor pixels being selected). In our work, to suffi-
approachesuseapre-definedpermutationofregressiveor-
cientlycapturetheconditionalstructuralconstraint,instead
ders, it requires different conditional structure models for
ofmodelingonlyneighborhooddependenciesasMarkovian
approaches,wegeneralizeitbymodelingp (y\k|yk)viaa
different initial pixel conditions, e.g., p s(y s\k1|y sk1) and
conditional structure network (detailed in
Ss ec.s 4)s
to con-
p s(y s\k2|y sk2)shouldbemodeledtwodifferentmodels.This
problemcouldbealleviatedbyconsideringthepermutation
siderthecorrelationbetweenallpixelsinthesegmentation.
ofregressiveorderasannetwork’sinput.However,learning
Relaxation of Ideal Data Distribution One of the key
asinglenetworktomodelconditionalstructuralconstraints
challengingproblemsinoptimizingEqn.(8)isthatthecon-
ofdifferentpermutationsisaheavytaskandineffective.
ditionalidealdatadistributionsp′(y\k|yk)andp′(y\k|yk)
s s s s t t Insteadofregressivelyformingp (y\k|yk),wepropose
arenotavailable. Therefore,insteadofdirectlyoptimizing s s s
theseterms,letusconsiderthetightboundasinEqn. (9). to model p s(y s\k|