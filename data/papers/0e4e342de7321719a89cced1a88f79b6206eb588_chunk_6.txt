 RelatedWork
proposes fusion bottlenecks in transformer encoders, while
2.1 VisualGrounding [Zhaoetal., 2021]appendscross-modalattentionafterself-
attentionintheirfusiontransformerencoders.
Two-stage methods. Two-stage methods, also known as
propose-and-rankmethods,generateimageregioncandidates
3 Methodology
and then rank them using the information from text queries
to select the best matching one. The candidates are usu- We leverage the transformer-based network to tackle the vi-
ally generated using a pre-trained object detector [Wang et sual grounding problem. Unlike previous methods [Chen et
al., 2019] or unsupervised methods [Yu et al., 2018]. Some al., 2018; Yang et al., 2020; Deng et al., 2021; Chen et al.,
earlymethodsutilizemodularnetworkstocomputematching 2021] that extract visual and textual features separately, we
…
…
…
…
… …
…
sredocnE
remrofsnarT
query token𝑓 weightedsumofthecandidatekernelscomputedas:
$%&’(
non-linear transformation 𝜑
!!→# K
(cid:88)
W = α w (2)
softmax i i
𝛼!𝛼" 𝛼# attention weight 𝛼 i=1
By incorporating query information into the generation of
𝑤
! convolutional kernels, QCM blocks can extract distinct fea-
+ 𝑊 turesaccordingtodifferenttextqueriestoproducevisualfea-
𝑤 " turesthataremorerelevanttotargetobjects.
candidate kernels aggregated kernel Visualencoder. Thevisualencoderconsistsofabackbone
equipped with QCM followed by a stack of transformer en-
Figure3: Thestructureofaquery-conditionedconvolutionmodule coderstoextractquery-awarevisualfeatures. Specifically,to
(QCM).ThereareKcandidatekernels{w 1,w 2,...,w K}. Anat- considermulti-scalefeatures,wereplacethefirstvanillacon-
tention weight α is derived from the query