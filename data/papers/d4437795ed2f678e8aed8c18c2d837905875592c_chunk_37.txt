 called Von Neumann bottleneck created by the separa­
tion of memory from processors. The development of effective architectures for supporting
operations in active memories is an important issue to be addressed.
5.2.6. Artificial neural networks
In the next few years it is expected that artificial neural networks can contribute in very
important ways to grand challenge applications that require subtasks such as pattern
classification. Although neural network technology in its modern incarnation is only 6 or 7 years
old, and most successes to date have been on simple classification problems, it may eventually
be able to handle high-level recognition and planning tasks. Besides the applications involving
low-level operations in computer vision and speech processing discussed earlier, it is recognized
that neural networks can complement learning and classification tasks studied in traditional AI.
November 23, 1992 33
An important research is, therefore, to develop techniques that can exploit both neural networks
and traditional machine learning methods in grand challenge applications.
5.3. Implications for System Architectures
Prior to designing HPCC systems, there is need for understanding the systems requirements
imposed by the A1 computation paradigm. The more we understand about the nature of AI pro­
cessing, the more efficient HPCC systems we can build. Although most of the current research
in AI is based on sequential reasoning, we expect that many future AI systems will use mas­
sively parallel processing techniques. This is straightforward in some AI paradigms which can
take advantage of the natural parallelism in applications. However, the design of large scale
parallel systems for supporting a large spectrum of AI techniques may impose a difficult task on
computer architects and programmers. It is clear that this research could benefit from interdisci­
plinary teamwork among AI researchers, knowledge engineers, computer architects, and applica­
tion designers. We identify the following issues in designing computers for AI processing.
1) Understanding the requirements. More work is needed for understanding the computa­
tional requirements for each AI processing paradigm used in high performance systems. It is
important to determine the processor structure for each paradigm. Architectures suited to sup­
porting AI will almost certainly differ significantly from conventional, numeric-oriented parallel
processing architectures. The computation models deemed most suited for AI computations tend
to exhibit large degrees of dynamical parallelism, dictating architectural support for dynamic
load balancing and dynamic extraction of parallelism. The grain sizes in AI computations will
most likely