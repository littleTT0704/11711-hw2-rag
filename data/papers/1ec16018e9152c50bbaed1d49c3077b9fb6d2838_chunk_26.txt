arXiv:2101.00027. MichaelCollins,ZacharyCLipton,GrahamNeubig,
and William W Cohen. 2020. Evaluating explana-
Peter Hase and Mohit Bansal. 2020. Evaluating ex-
tions: How much do explanations from the teacher
plainable AI: Which algorithmic explanations help
aidstudents? arXivpreprintarXiv:2012.00893.
userspredictmodelbehavior? InProceedingsofthe
58thAnnualMeetingoftheAssociationforCompu-
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
tational Linguistics, pages 5540–5552, Online. As-
Dario Amodei, Ilya Sutskever, et al. 2019. Lan-
sociationforComputationalLinguistics.
guage models are unsupervised multitask learners.
OpenAIblog.
Matthew Honnibal and Ines Montani. 2017. spaCy 2:
NaturallanguageunderstandingwithBloomembed-
dings, convolutionalneuralnetworksandincremen- ShauliRavfogel,GrushaPrasad,TalLinzen,andYoav
talparsing. Toappear. Goldberg. 2021. Counterfactual interventions re-
veal the causal effect of relative clause represen-
Alon Jacovi, Swabha Swayamdipta, Shauli Ravfogel, tations on agreement prediction. arXiv preprint
YanaiElazar,YejinChoi,andYoavGoldberg.2021. arXiv:2105.06965.
Contrastive explanations for model interpretability.
In Proceedings of the 2021 Conference on Empiri- Skipper Seabold and Josef Perktold. 2010. Statsmod-
calMethodsinNaturalLanguageProcessing,pages els: Econometric and statistical modeling with
1597–1611,OnlineandPuntaCana,DominicanRe- python. InProceedingsofthe9thPythoninScience
public.AssociationforComputationalLinguistics. Conference,volume57,page61.Austin,TX.
193
AvantiShrikumar,PeytonGreenside,AnnaShcherbina, neuralmachinetr