i-
Springer. 95–133.
tionalconstraintsinthedecoder(e.g.,IOBandfinalproperty)
resultsinourbestmodel.Fortheseexperiments,weuseda Chiu, J. P., and Nichols, E. 2015. Named entity
decoderwithabeamofsize3andaminimumprobability recognition with bidirectional lstm-cnns. arXiv preprint
of 10−7. As expected the decoder does not impact any of arXiv:1511.08308.
theintentmetrics(F1 IC andICER).Thestructurallyincor- Collobert,R.,andWeston,J. 2008. Aunifiedarchitecture
rectnessofthepredictedoutputsisupperboundedby0.96% fornaturallanguageprocessing:Deepneuralnetworkswith
IRERusingourproposedmodelwiththecustomdecoder. multitasklearning. InProceedingsofthe25thinternational
conferenceonMachinelearning,160–167. ACM.
Conclusion
Dong,L.;Wei,F.;Sun,H.;Zhou,M.;andXu,K. 2015. A
AMRLisanewgraph-basedrepresentationforthemeaning hybrid neural model for type classification of entity men-
ofasentence.SinceannotatingAMRListimeconsuming tions. InProceedingsofthe24thInternationalConference
andcostly,onlyalimitedamountofdataisavailable.Inthis onArtificialIntelligence,1243–1249. AAAIPress.
paperweshowthatlearnedembeddingsfromrelatedtasks Graves, A.; rahman Mohamed, A.; and Hinton, G. 2013.
can improve the accuracy of AMRL models. Domain and Speechrecognitionwithdeeprecurrentneuralnetworks. In
slotembeddingshelpsignificantly,improvingtheaccuracy IEEE International Conference on Acoustics, Speech and
by3.56%IRER(full-parseaccuracy).Aconstraineddecoder SignalProcessing(ICASSP).
thatleveragesIOBandtype/propertyconstraintsisakeycom- Guha,R.V.;Brickley,D.;andMacbeth,S.2016.Schema.org:
ponent,decreasingIRERby1%