25-stepAPGDattackwith∥δ∥ = 0.004. Weseethataccuracyoncleanandperturbeddatais
∞
maximizedwhenthewidthofthein-focusregionis48(thiscorrespondstovd=3)andaggregating
overmorefixationpointsimprovesaccuracyoncleanandperturbeddata.
measuredtheaccuracyoncleanandperturbeddataaftervaryingtheviewingdistance(see2.4)and
thenumberoffixationpointsoverwhichthelogitsareaggregated. TheseresultsareplottedinFigure
15,andtheyshowthataccuracyoncleanandperturbeddataismaximizedwhenthewidthofthe
in-focusregionis48(thiscorrespondstovd=3)andaggregatingovermorefixationpointsimproves
accuracyoncleanandperturbeddata.
F TrainingConfiguration
Table3presentstheconfigurationsusedtotrainthemodelsusedinourevaluation. Forallthemodels
theSGDoptimizerwasusedwithNesterovmomentum=0.9.
G ImplementationDetails
WeusedPytorchv1.11andPython3.9.12toforourimplementation. Weusedtheimplementationof
Auto-PGDfromtheTorchattackslibrary(https://github.com/Harry24k/adversarial-attacks-pytorch).
For R-Warp we used the code from the official repo https://github.com/mvuyyuru/adversary.git.
Likewise, for VOneBlock we used the code from https://github.com/dicarlolab/vonenet, and
for DeepGaze-III models we used the code from https://github.com/matthias-k/DeepGaze.
The training code for DeepGaze-III with R-Blur and R-Warp backbones is based on
https://github.com/matthias-k/DeepGaze/blob/main/train_deepgaze3.ipynb, and can be found in
adversarialML/biologically_inspired_models/src/fixation_prediction/train_deepgaze.py.
Our clones of these repositories are included in the supplementary material. For
multi-