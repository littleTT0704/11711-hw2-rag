ds
theN datastoreentriescorrespondingtoeachoftheV vocabularyentries.Eachcolumninthismatrixconsists
ds
ofaone-hotvectorwithavalueof1andtheindexcorrespondingtothevocabularyitemw correspondingto
i
thedatastoreentryforc.
i
Withinthisformulation,itbecomesobviousthattherearemanydesignchoicesforkNN-LM-likemodels. One
importantthingtonoteisthattherightsideofEquation5isactuallyverysimilartotheleftsiderepresenting
thestandardparametriclanguagemodel,withafewadditionalcomponents: M,mask-to-k,and⊗. More
specifically,someofthedesigndecisionsthatgointothekNN-LM,andparallelswithstandardparametric
modelsare:
1. SizeofW : Inthestandardparametricmodel,thesizeofW isV embeddingvectors,eachwith
ds sm
Ddimensions. InthekNN-LMthesizeofW isverylarge: N,thesizeofthedatastore,usually
ds ds
thenumberoftokensintheentiretrainingcorpus.
2. Inputrepresentation: Intheparametricmodel,h istheoutputfromthefeedforwardlayerinthe
sm
lasttransformerblock,whichweabbreviate“ffn”. Incontrast,Khandelwaletal.(2020b)ratheruse
ash theoutputfromthemulti-headedattentionlayerofthelasttransformerblock(beforerunning
ds
therepresentationsthroughthefeed-forwardnetwork,andaftertheLayerNorm(Baetal.,2016)),
whichweabbreviateas“att”.
3. Similarity&Temperature: Intheparametricmodel,thefunctionalformof⊗istheinnerproduct
(abbreviatedIP),whereasKhandelwaletal.(2020b)usenegativesquaredL2distance(abbreviated
L2)asasimilarityfunctionbetweenW andh. Asthesimilarityscoresareturnedintoprobability
ds ds
distributionswiththesoftmaxfunction,thechoiceofsoftmaxtemperature(τ)cancontrolt