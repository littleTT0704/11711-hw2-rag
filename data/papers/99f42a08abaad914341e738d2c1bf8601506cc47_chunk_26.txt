θ 0)= δl θi →m
0
0
δθ
0 ≈η(cid:48)(θ 0) (15) i Sn pg hest ra et Fic aci en aC no dsF Sa pc he e). reT Fh ae ced -i Rsc vu 1s,si so in nca eb to hv ee ya ap rp eli mes odto ifb yo inth
g
which naturally leads to the proposed CGD where we thetargetangularfunction.Asaconcreteexample,applying
can simply apply gradient detachment to the characteristic CGDtoSphereFace-Rv1yieldsthetargetangularfunction:
function ∆(θ). Specifically, we stop the gradient of the ψ(θ)=cos(θ)−Detach(cos(θ)−cos(min{m,π}·θ))whose
θ
characteristicfunctionwithadetachmentoperator: gradientisidenticaltoCosFace.
For SphereFace-R v2 that modifies the non-target angu-
ψ(θ)=η(θ)−Detach(∆(θ)) (16)
lar function, the derivation is similar except that we focus
where Detach(·) denotes the detachment operator that al- on approximating the gradient of the non-target function
lowsforwardcomputationbutstopsthebackwardgradient η(θ) instead of the target function ψ(θ). Therefore, we can
)(
noitcnuF
citsiretcarahC
)(
noitcnuF
citsiretcarahC
)(
noitcnuF
citsiretcarahC
)(
noitcnuF
citsiretcarahC
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 8
similarly apply gradient detachment to the characteristic parameter varies depending on the training sample), while
functioninthenon-targetangularfunction: SphereFace-R v2 implements a static one (i.e., the effective
margin parameter stays the same for all training samples).
η(θ)=ψ(θ)+Detach(∆(θ)).