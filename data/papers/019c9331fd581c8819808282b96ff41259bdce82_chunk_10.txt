 links that improved annotator agree-
aresignificantlymoredenseintermsofeventmen-
ment and reduced inconsistencies. However,
tions. Our documents contain ∼41 mentions (on
they rely on experts to create the within-doc
avg.),muchhighercomparedtopriorwork,ECB+
contains-subeventlabelbeforehand. Instead,we
(15.3), GVC (14.3), FCC (5.8). Given the dense
8seeTable14inAppendixfortheexactformulationof
7theexpertannotatorisanauthorofthiswork. thesefollow-upquestions.
linkingasrequiredbyourannotationtask. Figure2
presentsasnapshotofourannotationinterface. We
highlighteventmentionsinboththedocumentsand
allowtheannotatortoiteratethrougheachmention
ontheleftdocument. Inadditiontodedicatedlinks
toinstructionsandexamples,weprovideon-screen
instructionstoassisttheannotatorinreal-time. We
alsouseanEnglishNERtool(MaandHovy,2016)
Figure 2: Tool for annotating cross-document event
to highlight the named entities in the documents.
coreference. The two documents are shown side-by-
side,witheventmentionspre-highlighted. Weprovide Theseentitieshelptheannotatorkeeptrackofvari-
on-screen instructions as well as dedicated pages for ouseventparticipantsinthetwodocuments.
viewingdetailedinstructionsandexamples. Asseenin Weutilizethistoolforourentiredatasetcollec-
theexamplehere,weallowannotationofeverypairof tion. While we show an application of our anno-
mentionsinthegivendocumentpair. Inourannotation
tationtoolforCDEC,webelieveit’sadaptableto
effort, we present every pair of related documents on
othercross-documenttaskslikeentitycoreference
thistool,leadingtoadenselyannotateddataset.
and event/entity relation labeling tasks. We will
release our toolkit to encourage future work on
focus solely on cross-document links and frame cross-documentNLPtasks.
