 fromg. WefoundvaluesofC between-2and2
end
completehypothesis(i.e.,endswiththe<eos>to- toworkwellacrossallmodelsandlanguagepairs.
ken),thentheCTCprobabilityofh = g <eos>
⊕
is: 3 ExperimentsandResults
3.1 Models
(b) (n)
p (h X) = γ (g)+γ (g), (2)
ctc | T T Our offline multilingual ST models are based on
whereT isthefinaltimestamp.
attentionalencoder-decoderarchitecture. Specifi-
Ifh = g cisnotfinal,i.e.,c = <eos>,then
cally,theencoderisbasedonWavLM(Chenetal.,
⊕ ̸
theprobabilityis: 2022), and the decoder is based on multilingual
BART (Lewis et al., 2019) or mBART for short.
ThemodelisimplementedintheNMTGMinorli-
T
p (h X) = Φ (g) p(z = c X), (3) brary.2 For details on the offline model see KIT
ctc t t
| · |
submissiontoIWSLT2023Multilingualtrack(Liu
t=1
X
etal.,2023).
where
Thesmallsimultaneousspeechtranslationmod-
elsforEnglish-to-GermanandEnglish-to-Chinese
0 last(g) = c
Φ (g) = γ(b) (g)+ language pairs follow the blockwise streaming
t t 1 (n)
− (γ t 1(g) otherwise. Transformerarchitecture(Tsunooetal.,2021)im-
−
plemented in ESPnet-ST-v2 (Yan et al., 2023).
2.3 CTCOnlinePolicy
Specifically,theencoderisablockwiseConformer
Based on the the definition of p ctc(h X) in Equa- (Gulati et al., 2020) with a block size of 40 and
|
tions(2)and(3),wecandefinetheoddsofg being look-ahead of