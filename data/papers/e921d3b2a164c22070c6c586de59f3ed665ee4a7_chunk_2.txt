tion,stillrequiringcomplexregressionmodelstocapture
recursiveExpectation-Maximization(EM)based
theinput-outputrelationineachofthem. Thisproblemcan
algorithmtolearnboththetreestructureandthe
beavoidedbyjointlypartitioningboththeinputandoutput
expert models. Experiments on a collection of
spaces,suchthateachpartitiononlyrequiresasimplerlocal
regressiontasksvalidatetheeffectivenessofour
regression. Thisisthemotivationbehindourwork.
methodcomparedtoavarietyofotherregression
models. Addressing the above-mentioned issues of conventional
partition-based regression methods, we propose a hierar-
chical routing mixture of experts (HRME) model, which
separatesoutputvariablesmodesbyjointlypartitioningthe
1.Introduction
inputandoutputspaces,andmakesprobabilisticinferences
Oneofthechallengesinmodelingaregressiontaskisthat byassigningsimpleregressionmodelstoeachoftheresul-
ofdealingwithdatawithcomplexdistributions. Thedistri- tantpartitions. OurHRMEmodelcanbeviewedasanew
butioncanbemulti-modal,renderinganysingleregression member of the family of hierarchical mixture of experts
modelhighlybiased. Forinstance,Figure1ashowsasyn- (HME)(Jordan&Jacobs,1994)models. Itisbinary-tree
thetic data set uniformly sampled from three intersecting structured,andhastwotypesofexpertsâ€”thenon-leafnode
lines with different amount of noise. A single regression expertsandleafnodeexperts. Thenon-leafnodeexperts
modelwouldfailtocapturethemulti-modalityofthisdata function as a new gating mechanism to soft-partition the
andyieldpoorperformance. Thisnecessitatesanotherstrat- databasedontheirmodes,definedonthejointdistribution
egy,ofdivideandconquer,topartitiontheinputspaceinto ofinputandoutputvariables. Thepartitioningisperformed
simplesub-regionsandassignaregressionmodeltoeach bynode-specificbinaryclassifier. Together,theclassifiers
inthenon-leafnodeshierarchicallypart