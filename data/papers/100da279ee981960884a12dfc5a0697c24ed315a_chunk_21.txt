 error rate, the quantity, and the quality of pseudo-labels to analyze the
proposedmethod,usingthegroundtruthofunlabeleddatathatisunseenduringtraining.
SoftMatch utilizes the unlabeled data better. From Fig. 2(b) and Fig. 2(c), one can observe
that SoftMatch obtains highest quantity and quality of pseudo-labels across the training. Larger
error with more fluctuation is present in quality of FixMatch and FlexMatch due to the nature of
confidence thresholding, where significantly more wrong pseudo-labels are enrolled into training,
leading to larger variance in quality and thus unstable training. While attaining a high quality,
SoftMatchalsosubstantiallyimprovestheunlabeleddatautilizationratio,i.e.,thequantity,asshown
in Fig. 2(b), demonstrating the design of truncated Gaussian function could address the quantity-
quality trade-off of the pseudo-labels. We also present the quality of the best and worst learned
classes,asshowninFig.2(d),wherebothretainthehighestalongtraininginSoftMatch. Thewell-
solvedquantity-qualitytrade-offallowsSoftMatchachievesbetterperformanceonconvergence
anderrorrate,especiallyforthefirst50kiterations,asinFig.2(a).
4.5 ABLATIONSTUDY
SampleWeightingFunctions. Wevalidatedifferentinstantiationsofλ(p)toverifytheeffective-
¯
nessofthetruncatedGaussianassumptiononPMFλ(p),asshowninFig.3(b).Bothlinearfunction
andQuadraticfunctionfailtogeneralizeandpresentlargeperformancegapbetweenGaussiandue
tothenaiveassumptiononPMFasdiscussedbefore. TruncatedLaplacianassumptionalsoworks
wellondifferentsettings,buttruncatedGaussiandemonstratesthemostrobustperformance.
GaussianParameterEstimation. SoftMatchestimatestheGaussianparametersµandσ2 directly
fromtheconfidencegeneratedfromallunlabeleddataalongthetraining. Herewecompareit(All-
Class) with two alternatives: (1) Fixed: which uses pre-defined µ and σ2 of 0.95 and 0