 is that results on ESC-50 and GTZAN genre tagging are strongly predictive
of results on the more nuanced FSD50K task, despite being an order of magnitude smaller
and not using the corrected GTZAN artist-conditional splits from (Sturm, 2013), suggest-
ing faster inroads for research iteration. One valuable point-based contribution of HEAR
is that the CP-JKU PaSST models achieve a new state-of-the-art on FSD50K despite no
fine-tuning, a mean average precision (mAP) of 0.641 on FSD50K, compared to the recent
literature (Gong et al., 2021b; Wu et al., 2022a; Fonseca et al., 2021a).
Vocals FSD50K scores are also similar to those of Vocal Imitations and LibriCount. This
is perhaps because Vocal Imitations comprises broad non-semantic vocalizations and Libri-
Countinvolves detectingmultiplesimultaneousaudioevents. ThestrongspeechandPaSST
models do the best on Vocal Imitations. On LibriCount, SERAB BYOL-S does the best as
a non-semantic speech model, with decent performance from strong speech models.
9
Turian et al.
GURA Fuse Cat H+w+C.966.747.826.734.420.805.928.935.697.441.972.923.885.846.961.968.197.720
GURA Fuse Cat H+w+C (t).962.743.826.653.374.760.944.905.659.441.975.924.891.854.951.968.215.629
GURA Fuse Hubert.949.752.826.743.413.796.936.929.683.166.974.909.688.382.947.957.185.714
GURA Fuse wav2vec2.945.692.798.695.403.793.953.967.653.111.962.838.606.330.957.969.174.706
Logitech SERAB BYOL-S.549.953.657.642