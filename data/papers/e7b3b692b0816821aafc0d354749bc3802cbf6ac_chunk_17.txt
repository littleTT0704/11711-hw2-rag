4, and form the longest utterances. They also have more precise verb selection, as measured
byF1. Speakerstrainedondistractorsthatwereselectedwithhybridorcaptionsimilarity,achieved
highnounF1scoresof0.49comparedto0.41forthebasespeakermodel,indicatingthatsemanti-
callysimilardistractorsintrainingmaybebetterforidentifyingsalientnouns. Wefindthattraining
onmoredifficultdistractorsdoesnotconsistentlyimprovemodelperformancewhenevaluatingon
easierdistractors. Thissuggestssomedisconnectbetweenalanguage’sfluencyanditssuitabilityto
8
PublishedasaconferencepaperatICLR2023
the image referential game environment. However, speakers that train on more semantically simi-
lar distractors still achieve up to 5 percent higher accuracy than the base speaker, indicating some
benefitstoperformancefromtrainingoncertainharderdistractors.
7 RELATED WORK
Parallels in Human Language Acquisition. The concept of learning language through repeated
exposure to referents is a popular model within the psychology community. Smith & Yu (2008)
foundthatinfantsresolvetheuncertaintyofdeterminingwhichreferentinasceneawordreferstoby
statisticallearningoverword-scenepairings.Yu&Ballard(2007)incorporatedasocialelementinto
modelsbyconsidering“social-cognitive”capacities,suchasattentionreading,thatactasaformof
ToM.Yu&Smith(2012)studiedcaregivers’socialimpactonearlylanguageacquisitionusinghead-
mounted cameras, finding that caregiver feedback during moments where a referent was visually
dominant directly led to language learning in the infant. Bergelson & Aslin (2017b) found that
unrelatedimageswereeasierforinfantstodifferentiatebetweenthansemanticallysimilarimages.
Pragmatic Modelling. Andreas & Klein (2016) used pragmatic models to jointly train neural
speakerandlistenermodelstoplayareferentialgamethatinvolveddescribingcontrastingscenes.
They also use a sample-and-rerank method for selecting utterances in this setup. However, they
use the actual listener, rather