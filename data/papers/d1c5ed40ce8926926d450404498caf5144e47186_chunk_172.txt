 separable, the worst-case expected rate of convergence to the true decision
boundary is maximized by a query selection strategy that halves the size of the
current version space in each iteration [Tong and Koller, 2001]. The version space
[Mitchell, 1982] is the set of all decision boundaries that are consistent with the
already labeled data, i.e. that classify all instances correctly. By always choosing a
query with maximum uncertainty, i.e. an unlabeled instance that is closest to the
current decision boundary, we approximately achieve the goal of cutting the version
space in half.
The multi-strategy approach Diversity × Uncertainty is most effective after 1,000
active learning iterations in most configurations. Like uncertainty sampling, it some-
times performs poorly in early iterations when combined with logistic regression, but
becauseofthediversitycriterionitusuallyrecoversandthenimprovesrankingperfor-
mance rapidly. When used with SVMs, this method consistently yields competitive
results independently of how many queries have been labeled. The cross-over method
8.1. ACTIVE LEARNING 127
85%
80%
75%
70%
65%
P
A 60%
M
Random
55%
Maximum Score
Diversity
50%
Uncertainty
45%
Diversity × Uncertainty
Diversity → Uncertainty
40%
Supervised
35%
0 200 400 600 800 1000
Steps
Figure 8.1: Active learning curves for logistic regression models that make indepen-
dent predictions using only the original features.
85%
80%
75%
70%
65%
P
A 60%
M
Random
55%
Maximum Score
Diversity
50%
Uncertainty
45%
Diversity × Uncertainty
Diversity → Uncertainty
40%
Supervised
35%
0 200 400 600 800 1000
Steps
Figure 8.2: Active learning curves for logistic regression models that include features
of adjacent instances to capture dependencies.
128 CHAPTER 8. EXTENSIONS FOR RELEVANCE ESTIMATION
85%
80%
75%
70%
65%
P
A 60%
M
Random
55%
Maximum Score
Diversity
50%
Uncertainty
45%
D