-
non-contrastive explanations. This suggests that
trastiveGradientNormbecausethesemethodsdo
contrastive explanations particularly outperform
3AlthoughHaseandBansal(2020)suggestnotshowing
non-contrastiveoneswhentheknownevidenceis
explanationsforcertainmethodsattesttimeduetopotential
relativelyfurtherawayfromthetargettoken,thatis, fordirectlyrevealingthemodeloutput,thisislessofaconcern
contrastiveexplanationscanbettercapturemodel forsaliency-basedmethodsastheirdesignmakesitnon-trivial
toleakinformationinthisway.Weopttoshowexplanations
decisionsrequiringlonger-rangecontext.
to measure whether they sufficiently help the user make a
InAppendixB,wealsoprovideatablewiththe predictionsimilartothemodelonanindividualexample.
188
ecnatsiD ecnatsiD
sentences in a row. We balance the data so that
there were an equal number of examples where
the true output x = a and x = b, and also by
t t
model correctness so that the model chooses the
correct output 50% of the time, preventing users
fromguessingmodelbehaviorbyselectingacer-
tain token or the true token. In total, we obtain
4000datapointsformodelsimulatability.
5.2 Results
InTable4,weprovidetheresultsofouruserstudy.
For each explanation method evaluated, we com-
Figure3: Exampleofapromptinourhumanstudy. puted the simulation accuracy over all samples
(Acc.) as well as accuracy over samples where
notprovideinformationondirectionality. Fornon- themodeloutputisequaltothegroundtruth(Acc.
contrastivemethods,weprovidetheexplanationfor Correct)anddifferentfromthegroundtruth(Acc.
whythemodelpredictedatoken. Forcontrastive Incorrect). Wealsocomputedthepercentageofex-
methods,weprovidetheexplanationforwhythe planationsthatusersreporteduseful,aswellasthe
modelpredictedonetokeninsteadofanother. simulationaccuracyoversampleswheretheuser
Weinclude20pairsofhighlyconf