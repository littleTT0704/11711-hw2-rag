themodelsweretrainedonthe
normaltestsetornot. AswediscussinSec6,this
doesn’t mean that ToM has “emerged” in LLMs,
sincetheymayhavebeenexposedtotrainingdata
Figure7: AnillustrationofUllman’sVariationsforthe orsimilarexamples.
unexpected transfer task. Image taken from Ullman
(2023). 11https://chat.openai.com/chat
12https://www.ai21.com/blog/introducing-j2
13https://leaderboard.allenai.org/socialiqa/
submissions/public
15
TheoryofMindDatasets
Model Triangle SocialIQa ToMi Epistemic Adv-CSFB FauxPas
COPA Reasoning EAI
MFC 52 36 56 63 – 55,30
Flan-ul2 95 – – 60 – 60,07
Flan-T5-xxl 96 – – 57 – 68,18
Flan-T5-xl 92 – – 61 – 68,14
Flan-T5-large 92 – – 44 – 53,07
Flan-T5-base 84 – – 52 – 52,07
Flan-T5-small 58 – – 54 – 58,07
gpt4-0314 94 79 70 43 75,57 74,27
gpt-3.5-turbo-0301 84 67 70 45 70,42 73,25
text-davinci-003 95 60 67 59 79,61 67,07
text-davinci-002 92 19 39 58 76,53 63,14
j2-grande-instruct 06 – – 37 – 58,0
j2-jumbo-instruct 48 – – 47 – 45,0
j2-grande 75 – – 63 – 45,0
j2-jumbo 68 – – 63 – 38,0
j2-large 58 – – 63 – 31,0
Table7: AccuracyofLLMsondifferentdatasetscomparedtoamostfrequentclassbaseline. ForAdv-CSFBand
FauxPas-EAIwereporttwometrics: questionlevelandstorylevel.
Averagescore Jointscore thestory,itmightstillfailtoanswermorecomplex
