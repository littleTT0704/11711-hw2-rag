 cows, rather than the illogical trievedimagesrepresenteverydayscenariosandarerelatively
situation of “A cow is lassoing a horse.” described by the similartothoseinMSCOCO,thepretrainedmodelperforms
baselinegenerationinTable4.Manyeverydayimagesare quitewell.SeeexamplecaptionsinTable1.
relativelysimilartothoseinimagecaptioningdatasetssuch
asMSCOCO,sopretrainedcaptioningmodelsshouldwork 4.3 CaptionSelectionandInputAugmentation
quiteeffectively.Wethushypothesizethatusingimagesand
AfterwehavecaptionsS ={c,c,...,c }foreachconcept
theircaptionstovisuallygroundconcept-to-textgeneration c 1 2 n
setinallthreesplits,wereorderthembydescendingcoverage
canpotentiallydealwithissuesmentionedin3.1.Retrieved
to the concept set to obtain S = {c′,c′,...,c′ }. If two
imageswithcorrespondingcaptionsgeneratedbyapretrained c′ 1 2 n
captionsaretiedforcoverage,wekeepthemintheiroriginal
image captioning model (see §4.2) and final baseline and
searchresultorder.Thisallowsustoselectthecaptionsthat
VisCTGgenerationsforselectconceptsetsareinTable1.
havehighestcoverageandaremostrelevant.
Textualcorporaalsosufferfromreportingbias(Gordon
Sincemostretrievedimagesandcorrespondingcaptions
andVanDurme2013),whereeveryday,commonsensealbeit
coveronlyafractionoftheentireconceptset,andthequality
“uninteresting”actions(walking),objects(bench)andfacts
ofeachvaries,wehypothesizethatusingmultiplecaptions
(bananasareyellow)areunderrepresentedcomparedtoreal-
forgenerationmayleadtomorerobustandhigher-quality
worldfrequency,while“newsworthy”actions(murdering),
outputswithmorecoverage.Themodelsmaylearntopiece
objects(spaceships)andfacts(blueGMObananas)areexag-
togetherinformationfromcaption(s)while