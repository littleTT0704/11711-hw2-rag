sec) morenegativecontinuationsthanpositivecontinu-
ationsthanviceversa. Basedonthesegenerations,
GPT-2/DAPT 0.094
DEXPERTS(small) 0.186 wecreatethreesetsofpromptsasdescribedin§4.
DEXPERTS(medium) 0.240
DEXPERTS(anti-only) 0.248 C HumanEvaluation
GeDi 0.276
DEXPERTS(large) 0.334
OurinterfaceforhumanevaluationisshowninFig-
PPLM 25.39
ure7. Foreachcategory,theannotatorisallowed
to choose either one of the continuations, or rate
Table 14: Generation time (in seconds) per continua-
tion of maximum length 20 tokens for toxicity experi- thetwooptionsasequal.
ments in §3, all run on the same architecture for com-
parison. D AdditionalResults
D.1 ToxicityHyperparameterControl
Figure 8 shows the relationship between output
B CollectionofSentimentPrompts
toxicityandfluencyfordifferentvaluesofαinour
We build our prompts for sentiment experiments method. Therelationshipissmooth,reflectingthe
(§4)fromtheOpenWebTextCorpus(Gokaslanand correspondingfigureforsentimentin§4.3.
Cohen,2019),acorpusofEnglishwebtextscraped
D.2 HumanEvaluationonNeutralPrompts
fromoutboundlinksonReddit. Werandomlysam-
ple100KdocumentsfromOpenWebTextandtok- Figure9showstheresultsofhumanevaluationon
enizeeachdocumentintosentences. Followingthe sentimentcontrolconditionedonneutralprompts.
Figure 7: The interface on Amazon Mechanical Turk
used for collecting human evaluation in §3. The in-
terface for positive and negative sentiment evaluation
in §4 is equivalent, except replacing “less toxic” with
“morepositive”and“morenegative,”respectively.
Figure8: Therelationshipbetweenoutputfluencyand
toxicity for different values of α P r1.0,2.2s, which
controlsthestrengthofcontrol. Resultsarecalculated
onasubsetof1Knont