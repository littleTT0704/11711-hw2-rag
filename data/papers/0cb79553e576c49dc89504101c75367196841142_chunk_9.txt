am*ng
notablyonthesubtletoxicitydatasets(MAgrandSBF).
MARCO Iwouldn’teatfoodthathasbeentouched
byahumanbeing.
CondBERT i wouldn’t be eating food that has been
SBFfromthemicroaggressionssubreddit,4 which touchedbyam*ng
ParaGeDi Iwouldnoteatfoodtouchedbyamonk.
contains subtly biased content (Breitfeller et al.,
2019). Weuseallpostswherethemajorityofanno-
Table2: Differentrewritingmethodsonthreetoxicex-
tatorsmarkedthetextasoffensive. Thevalidation
amplesfromSBF(top),MAgr(middle),andDynaHate
andtestsetsizesare92and114respectively. (bottom). InthetoxicexamplefromSBF(containing
aracistslaveryreferencetocottonpicking). MARCO
DynaHate (Vidgen et al., 2021) is an adversar-
detectsandmasks“cotton”asatoxicityindicator,which
ially collected set of hate speech, where human baselinesfailtorewrite.Inthelastexample,CondBERT
annotatorscreateexamplesthatan iterativelyim- failstorecognizethetoxicityoftheword“m*ng”(un-
proved hate-speech classifier cannot detect. We censoredinthedata)whichisconsideredanableistslur
utilizeallfourroundsofhate-speechdataanduse (Clark,2011).
allexamplesmarkedashateful. Thevalidationand
testsetsizesare1,858and2,011respectively.
AutomaticMetrics Weassessthequalityofthe
models’ rewrites with automatic metrics used in
4.2 Baselines
previous work (Liu et al., 2021; Ma et al., 2020).
We compare MARCO to the two baseline ap-
Wereporttheaveragetoxicityscoreofrewritesus-
proaches from Dale et al. (2021), which have ingthePerspectiveAPI.5 Additionally,wemeasure
shownstate-of-the-artdetoxificationperformance.
fluencyofrewritesbycomputingtheirperplexity
SeeAppendix