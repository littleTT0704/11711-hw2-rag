linguisticvariationfromthesharedsemanticin-
the language variables z will handle language-
formationintranslationpairs. Wietingetal.(2020) li
specific peculiarities or specific style differences
consideredthisforbitext,witheachlanguagehav-
that are not central to the meaning of the transla-
ingitsownencoderanddecoderparameters. This
tionandarethereforenotcontainedinmanyofthe
approachhoweverdoesnotscale,sinceitisnotfea-
sentences. Concretely, the likelihood function of
sibletohavethousandsofencodersanddecoders
ourmodelcanbewrittenforasingleN-waytuple
if one wants to model all of the more than 7,000
oftranslationsx = (x,...,x ):
languagesintheworld. 1 N
N
(cid:89)
3 Model p(x|z,z,...,z ) = p(x |z,z )
sem l1 lN i sem li
i
The generative process of our underlying proba-
bilistic model and the computation graph of our Inthenextsection,wediscusshowthissepara-
training objective procedure are depicted in Fig- tionofinformationisencouragedduringlearning.
4 LearningandInference unnecessarilydoublestheoverallcost. Ineffect,we
canviewtheselanguage-specificlatentvariablesas
We would like to train our model on a set of par-
collectinginformationthatcannotbecapturedina
allelsentencesX consistingofM examplesinN
commonsemanticspace,separatingitoutfromthe
languages and a collection of latent variables Z.
variables collecting shared semantic information
However, N-way parallel corpora are not avail-
thatweusefordownstreamtasks.
ableatthescaleofbilingualtext,andsowethere-
fore approximate an N-way parallel corpus by ObjectiveFunction. Theoverallobjectivefunc-
sampling translation pairs from a large pool of tionforVMSSTconsistsofconsistsoftwoterms,
pairscontainingtextinN languages. Thereforein thefirstbeingELBOasdescribedearlier:
our model, X = {‚ü®x1