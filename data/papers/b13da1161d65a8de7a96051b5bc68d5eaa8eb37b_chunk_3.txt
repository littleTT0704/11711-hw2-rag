 object-regions are
data introduces domain shift due to differences in visual leveraged to formulate a contrastive objective [10,22,44]
characteristics of simulated images (source domain) and thatpullstogetherpixelrepresentationswithinanobjectre-
realimages(targetdomain). Tomitigatesuchshifts,unsu- gion and pushes apart those from different semantic cate-
perviseddomainadaptationstrategies[2,5,18,48,60,61,64] gories. Such an objective can improve semantic segmen-
for semantic segmentation have been extensively studied tation by causing the pixel representations of a semantic
intherecentyears. Amongtheseapproaches, self-training category to form a compact cluster that is well separated
[16]hasemergedasaparticularlypromisingapproachthat from other categories. We empirically demonstrate the ef-
involves pseudo labelling the (unlabelled) target-domain fectiveness of our constraint on popular benchmark tasks,
data using a seed model trained solely on the source do- GTA→Cityscapes and SYNTHIA→Cityscapes, on
main. Pseudo-label predictions for which the confidence which we achieve competitive segmentation performance.
exceedsapredefinedthresholdarethenusedtofurthertrain Tosummariseourcontributions:
themodelandultimatelyimprovethetarget-domainperfor- • Weproposeanovelobjectnessconstraintderivedfrom
mance. depthandRGBinformationtoregulariseself-training
Whileself-trainingbasedadaptationisquiteeffective,it approachesinunsuperviseddomainadaptationforse-
issusceptibletoerroneouspseudolabelsarisingfromcon- mantic segmentation. The use of multiple modalities
firmationbias[3]intheseedmodel. Confirmationbiasre- introduces implicit model supervision that is comple-
sults from training on source domain semantics that might mentarytothepseudo-labelsandhence,leadtoamore
introduce factors of representation that serve as nuisance robustself-training.
factors for the target domain. In the context of semantic
• We empirically validate the most important aspect of
segmentation,suchabiasmanifestsaspixel-wiseseedpre-
our regulariser, i.e.,