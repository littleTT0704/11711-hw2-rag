basedonwordfrequency,ortotaltraininglossfortheword. Basedon
theintuitionofZipf’slaw(Clausetetal.,2009),weassign1+log f foreachwordtypev ∈V,basedon
b v
14
eitherthefrequencyorthetotaltraininglossoftheword,f. Thebisahyperparameterthatcouldbetuned.
v
Toensurefaircomparison,wetunebsothatforeachexperimentthetotalnumberofembeddingsmatches:
(cid:80)
1+log f =nV. TheresultsareshowninTable6. Wecanseethatalthoughniceinpaper,giventhe
v∈V b v
samenumberoftotalembeddings,adaptivelyincreasingthenumberofembeddingsassignedforeachword
typedoesnotmakeasignificantdifferenceinthefinalperplexity,whencomparedwiththemodelsthatuse
equalnumberofembeddingsforeachwordtype.
h N ⊗ +#params PPL λ Interp.PPL Oracle
ds ds
BaseLM - - - 0 21.750 - - -
KNN att Big L2 N ×D ∞ 0.271 19.174 14.230
ds
KNN att Big IP N ×D ∞ 0.266 19.095 14.077
ds
EqualPerWord att 3x IP 3V ×D 22.434 0.417 20.395 17.132
LossWeighted att 3x IP 3V ×D 21.948 0.437 20.440 17.303
Freq.Weighted att 3x IP 3V ×D 22.507 0.412 20.387 17.105
KNN ffn Big L2 N ×D ∞ 0.065 20.734 15.594
ds
KNN ffn Big IP N ×D ∞ 0.050 21.101 16.254
ds
EqualPerWord ffn 3x IP 3V ×D 20.829 0.622 20.603 18.717
LossWeighted ffn 3x IP 3V ×D 20.764 0.713 20.659 18.978
Freq.Weighted ffn 3x IP 3V ×D 20.757 0.658