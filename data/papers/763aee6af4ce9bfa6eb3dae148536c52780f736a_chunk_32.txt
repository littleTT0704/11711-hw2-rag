angella, DanicaSutherland, and tionandconfidenceintervals. JournaloftheRoyalStatistical
Nathan Srebro. Does invariant risk minimization capture Society.SeriesB(StatisticalMethodology),2016. 1,2
invariance? InAISTATS,2021. 1 [57] AntoinePlumerault,Herve´LeBorgne,andCe´lineHudelot.
[38] Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. Controlling generative models with continuous factors of
Learning the difference that makes a difference with variations. InICLR,2019. 6
counterfactually-augmenteddata. InICLR,2019. 3 [58] AlexanderRobey,LuizChamon,GeorgePappas,HamedHas-
[39] HyunjikKimandAndriyMnih. Disentanglingbyfactorising. sani, and Alejandro Ribeiro. Adversarial robustness with
InICML,2018. 3 semi-infiniteconstrainedlearning. AdvancesinNeuralInfor-
[40] DiederikPKingmaandJimmyBa. Adam: Amethodfor mationProcessingSystems,34,2021. 3,4
stochasticoptimization. InICLR,2015. 17 [59] Alexander Robey, Hamed Hassani, and George J. Pappas.
[41] PangWeiKoh,ShioriSagawa,SangMichaelXie,Marvin Model-basedrobustdeeplearning: Generalizingtonatural,
Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Ya- out-of-distributiondata,2020. 3
sunaga,RichardLanasPhillips,IrenaGao,TonyLee,etal. [60] Alexander Robey, George J. Pappas, and Hamed Hassani.
Wilds: A benchmark of in-the-wild distribution shifts. In Model-baseddomaingeneralization. InNeurIPS,2021. 1,2,
ICML,2021. 6 3,4,5,13,19
[42] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, [61] M. Rojas-