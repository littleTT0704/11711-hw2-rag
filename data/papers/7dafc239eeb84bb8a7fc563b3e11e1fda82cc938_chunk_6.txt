featureforzero-shotclasses. [Fe-
3.1 FeatureExtractor
lixetal.,2018]addedacycle-consistentlossongeneratorto
ensurethegeneratedfeaturescapturestheclasssemanticsby The pretrained feature extractor model is zero-shot attentive
using linear regression to map visual features back to class graph recurrent neural networks (ZAGRNN) modified from
semanticfeatures. [Nietal., 2019]furtherimprovedthese- zero-shot attentive graph convolution neural networks (ZA-
mantics preserving using dual GANs formulation instead of GCNN), which is the only previous work that is tailored
a linear model. Previous works focused on vision domain towards solving zero-shot ICD coding [Rios and Kavuluru,
wherethefeaturesareextractedfromwell-traineddeepmod- 2018]. Weimprovetheoriginalimplementationbyreplacing
els on large-scale image dataset. We introduce the first fea- the GCNN with GRNN and adopting the label-distribution-
turegenerationframeworktailoredforzero-shotICDcoding aware margin loss [Cao et al., 2019] for training. Figure 2
byexploitingexistingmedicalknowledgefromlimiteddata. shows the architecture of the ZAGRNN. At a high-level,
givenaninputx,ZAGRNNextractslabel-wisefeaturef and
Zero-shottextclassification. [PushpandSrivastava,2017] l
performsbinarypredictiononf foreachICDcodel.
exploredzero-shottextclassificationbylearningrelationship l
between text and weakly labeled tags on large corpus. The Label-wise feature extraction. Given an input clinical
idea is similar to [Rios and Kavuluru, 2018] in learning the documentxcontainingnwords,werepresentitwithamatrix
4019
ProceedingsoftheTwenty-NinthInternationalJointConferenceonArtificialIntelligence(IJCAI-20)
2019],wherewesubtractthelogitvaluebeforesigmoidfunc-
tionbyalabel-dependentmargin(cid:1) :
l
y^m =(cid:27)(g>(cid:1)f (cid:0)1(y =1)(cid:1) ) (5)
