idencethresholdingmechanism
canbeformulatedbysettingλ(p)asastepfunction-whentheconfidenceisabovethreshold,the
14
PublishedasaconferencepaperatICLR2023
sampleweightissettoλ,andotherwise0. Wecanderive:
max
(cid:26)
λ, if max(p) τ,
λ(p)= max ≥ (21)
0.0, otherwise.
(cid:40)
1(max(p) τ) 1, if max(p) τ,
λ¯(p)= (cid:80)NU 1(max(p≥ ) τ) = 0Nˆ.U 0, otherwise. ≥ (22)
i i ≥
f(p)=(cid:88)NU 1(max(p i) ≥τ)λ
max =λ
Nˆ
U, (23)
N maxN
U U
i
g(p)=(cid:88)Nˆ
U 1(pˆ
i
=y iu)
, (24)
Nˆ
i U
(25)
where we set Nˆ = (cid:80)NU 1(max(p ) τ), i.e., number of unlabeled samples whose prediction
U i i ≥
confidencemax(p)areabovethresholdτ.
Interestingly,onecanfindthatconfidencethresholdingdirectlymodelingthePMFoverthepredic-
tionconfidencemax(p). Althoughitstillmakestheuniformassumption, asshowninEq. (22), it
constrainstheprobabilitymasstoconcentrateintherangeof[τ,1]. Asthemodelismoreconfident
aboutthepseudo-labels,andtheunconfidentonesareexcludedfromtraining,itismorelikelythat
pˆ would be close to yu, thus ensuring the quality of the pseudo-labels to a high value if a high
threshold is exploited. However, a higher threshold corresponds to smaller Nˆ, directly reducing
U
the quantity of pseudo-labels. We can clearly observe a trade-off between quantity and quality of
usingfixedconfidencethresholding. Inaddition,assumingthePM