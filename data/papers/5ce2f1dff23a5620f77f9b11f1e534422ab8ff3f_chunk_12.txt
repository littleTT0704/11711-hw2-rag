(Ot), and embedding of action (a ).
i GPT-Neo-2.7B (Black et al., 2021), and an industry-
Finally, we compute the dot-product of the query and scale LLM with 530B parameters (Smith et al., 2022).
Plan, Eliminate, and Track
Figure 5. Agent (Action Attention). Action Attention block is a transformer-based framework that computes a key K for
i
each permissible action and output action scores as dot-product between key and query Q from the observations.
Template Goal Specification Human Goal Specification
Model seen unseen seen unseen
BUTLER + DAgger* (Shridhar et al., 2020b) 40 35 8 3
BUTLER + BC (Shridhar et al., 2020b) 10 9 - -
GPT (Micheli & Fleuret, 2021) 91 95 42 57
PET + Action Attention (Ours) 70 67.5 52.5 60
Table 1. Comparison of different models in terms of completion rate per evaluation split (seen and unseen), with and
without human annotated goals. PET under-performs GPT on Template goal specifications but generalizes better to
human goal specifications. * We include the performance of BUTLER with DAgger for completeness. All other rows are
trained without interaction with the environment, MLE for GPT and behavior cloning for BUTLER+BC and PET.
For the Eliminate module (receptacle/object mask- weeksforDAggerv.s. 6hoursforBehaviorCloning). In
ing), we choose Macaw-11b (Tafjord & Clark, 2021), addition, we demonstrate that our models surpass the
which is reported to have common sense QA perfor- DAgger training performance of the BUTLER (Shrid-
mance on par with GPT3 (Brown et al., 2020) while har et al., 2020b) agents trained with DAgger, even
being orders of magnitudes smaller. We use a decision when our agent does not have the option to interact
threshold of 0.4 for Macaw score below which the ob- with the environment.
jects are masked out. For the Track module (progress
tracking), we use the same Macaw-11b model as the
Eliminate module answer to Yes/No questions.
Actor Model Design. Our Action Attention
agent (M