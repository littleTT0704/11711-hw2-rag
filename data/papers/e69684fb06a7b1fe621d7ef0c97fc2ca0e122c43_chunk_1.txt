PROMPT2MODEL:
Generating Deployable Models from Natural Language Instructions
VijayViswanathan1∗,ChenyangZhao1,2∗,
AmandaBertsch1, TongshuangWu1,GrahamNeubig1
1CarnegieMellonUniversity,2TsinghuaUniversity
Abstract
Input: Prompt (task description + optional examples)
Answer questions given context from a
Largelanguagemodels(LLMs)enablesystem
relevant Wikipedia article.
builders today to create competent NLP sys-
temsthroughprompting,wheretheyonlyneed
Prompt2Model
to describe the task in natural language and
provide a few examples. However, in other
ways, LLMs are a step backward from tradi-
Retrieve Generate Retrieve
tional special-purpose NLP models; they re-
Data Data Pretrained model
quire extensive computational resources for
deployment and can be gated behind APIs.
Output: Deployment-ready model
In this paper, we propose Prompt2Model, a
BERT Score: 94.0, ChrF++: 58.9, EM: 61.5
general-purpose method that takes a natural
Question: What does LPC stand for?
languagetaskdescriptionlikethepromptspro-
Context: The psychoacoustic masking codec was...
vided to LLMs, and uses it to train a special-
Answer: linear predictive coding
purpose model that is conducive to deploy-
ment. This is done through a multi-step pro-
Figure1: Prompt2Modelisaframeworkforgenerat-
cess of retrieval of existing datasets and pre-
ingasmallyetaccuratemodelfromaprompt.
trainedmodels,datasetgenerationusingLLMs,
andsupervisedfine-tuningontheseretrieved
LLMs like GPT-3 (Brown et al., 2020; Liu
and generated datasets. Over three tasks,
et al., 2023b) offer a lighter-weight paradigm
wedemonstratethatgiventhesamefew-shot
for NLP system construction through “prompt-
prompt as input, Prompt2Model trains mod-
elsthatoutperformtheresultsofastrongLLM, ing”(Re