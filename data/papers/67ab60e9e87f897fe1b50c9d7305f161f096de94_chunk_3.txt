 general-purpose, open-source, and freely available to use off-the-shelf.
AllHEARcompatiblemodelsfollowacommonAPI,whichmakesswitchingbetweenmodels
as simple as changing one line of code.
The HEAR benchmark includes nineteen tasks. During NeurIPS 2021, five were open
tasks derived from three datasets for which the problem definition and evaluation data
were available to participants, and 14 additional were secret tasks for evaluation, to which
participants were completely blind. While most of the tasks (open or secret) have good or
promisingsolutionswhenworkedoninisolation,thenoveltyoftheHEARbenchmarkisthat
the same representation must be used to solve all of them. These tasks encompass multiple
audio domains: speech, environmental sound, and music, with tasks that involve short and
long time spans. HEAR datasets are easy to use: all are preprocessed to a common format
with standard splits and self-explanatory human-readable metadata, and are distributed as
tarfiles online.1 This alleviates the engineering effort required to work with datasets that
require YouTube scraping, have variably documented preprocessing requirements, or are
gatekept through closed-access request forms. Researchers are also welcome to use HEAR
datasets under entirely open licenses (many of which allow commercial use), without using
our downstream evaluation code.
Evaluation consists of classification tasks, both multiclass and multilabel, requiring ei-
ther prediction over the entire audio scene (clip), or temporal-based onset detection of
sound event (Mesaros et al., 2016). HEAR-compatible models can generate an embedding
of arbitrary size, which is fed into a simple generic predictor by our open-source eval-
uation algorithm. Evaluation code, submitted models, and datasets are all available at
https://neuralaudio.ai/hear.html.
1. https://zenodo.org/record/5885750
2
HEAR: Holistic Evaluation of Audio Representations
2. Background on representation learning
At a high level, a learned representation (embedding) consists of a machine learning model
that takes a low-level representation of the input and outputs a numerical representation,
typically a fixed-size vector, that lends itself well to discriminative tasks (e.g., by training
a simple MLP on these embeddings). A