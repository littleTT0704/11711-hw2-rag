:1)
T i K i
tokens ‘Yes’ and ‘No’ as follows: p (“Yes”|P ) and (4)
MT a
p (“No”|P ). If p (“Yes”|P )>p (“No”|P )
MT a MT a MT a π =softmax([Q·K i|i∈all permissible actions])
then we increment the tracker p to track the next sub-
(5)
task.
If the tracking ends prematurely, meaning that p > 4. Experiments and Results
len(S ) but the environment has not returned “done”,
T
we fall back to conditioning with T. We study the rate We present our experiments as follows. First, we ex-
of pre-mature ends in Section 4.4 in terms of precision plain the environment setup and baselines for our ex-
and recall. periments. Then we compare PET to the baselines on
different splits of the environment. Finally, we conduct
3.4. Agent ablation studies and analyze the PET framework part
by part. We show that PET generalizes better to hu-
Since the number of permissible actions can vary a
man goal specification under efficient behavior cloning
lot by the environment, the agent needs to handle
training.
arbitrary dimensions of action space. While Shridhar
et al. (2020b) addresses this challenge by generating
4.1. Experimental Details
actionstoken-by-token, suchagenerationprocessleads
to degenerate performance even on the training set. AlfWorld Environment ALFWorld (Shridhar
et al., 2020b) is a set of TextWorld environments
We draw inspiration from the field of text summariza-
(Coˆt´e et al., 2018b) that are parallels of the ALFRED
tion, where models are built to handle variable input
embodied dataset (Shridhar et al., 2020a). ALFWorld
lengths. Seeetal.(2017)generatesasummarythrough
includes6tasktypesthateachrequiresolvingmultiple
an attention-like “pointing” mechanism that extracts
compositional sub-goals. There are 3553 training task
the output word by word. Similarly, an attention-