Improving weakly supervised sound event detection with self-supervised
auxiliary tasks
SohamDeshmukh1,BhikshaRaj2,RitaSingh2
1Microsoft,2CarnegieMellonUniversity
sdeshmukh@andrew.cmu.edu, bhiksha@cs.cmu.edu, rsingh@cs.cmu.edu
Abstract [10,11,12,13,14]. However,fewworkshavefocusedonhow
soundeventdetectionmodelsperformineitherlimiteddataor
Whilemultitaskandtransferlearninghasshowntoimprovethe
noisysettingsletaloneinbothofthem.
performanceofneuralnetworksinlimiteddatasettings,theyre-
The noisy data also affects the training of networks for
quirepretrainingofthemodelonlargedatasetsbeforehand. In
soundeventdetection.Specifically,thedeepCNNarchitectures
thispaper, wefocusonimprovingtheperformanceofweakly
[15,16]currentlyusedtoprovidebenchmarkperformancefor
supervisedsoundeventdetectioninlowdataandnoisysettings
differentspeechandaudiotasks[17]requirelargelabelledclean
simultaneouslywithoutrequiringanypretrainingtask. Tothat
datasetstotrainonandwhenconsideredinanoisyenvironment
extent, we propose a shared encoder architecture with sound
theperformanceisknowntodeteriorate[10]. Thetwogeneral
eventdetectionasaprimarytaskandanadditionalsecondary
learning strategies used as solutions are transfer learning and
decoder for a self-supervised auxiliary task. We empirically
multitasklearningwhichwererecentlyutilisedforsoundevent
evaluatetheproposedframeworkforweaklysupervisedsound
detection[18,19,20].However,inthemultitasklearningsetup,
eventdetectiononaremixdatasetoftheDCASE2019task1
itâ€™sassumedyouhaverichlyannotatedlabelsforallthetasks.
acousticscenedatawithDCASE2018Task2soundseventdata
Weinvestigateacounterpartofthiswhereonlyweaklabelsare
under0,10and20dBSNR.Toensureweretainthe