problematic
provements or even worse performance than the incaseswherethemetricassignsawrongscoreto
zero-shotcase(Jainetal.,2023). Wethereforeex- atranslation,asitismuchhardertodiagnosewhy
ploretwosamplingapproachestoselectin-context the evaluation model made a mistake, and iden-
examplesfromapre-defined“pool”oftranslation tifyandpreventsimilarmistakesinthefuture. In
qualityassessments: uniformsamplingandstrati- fact,reducingtranslationqualitytoasinglescore
fiedsampling,wheretheexamplepoolisbucketed hasprovenproblematicevenforhumanannotators:
by score ranges and examples are sampled from asking raters to solely provide a single score can
eachbucket. leadtorushedandnoisyjudgments(Freitagetal.,
1Whilethispromptwasn’tthebestforsystem-level,itled 2Whilethesemetricsallleveragepowerfulpretrained(lan-
tothebestsegment-levelperformanceinGEMBA. guage)models,thesegenerallyaren’tconsideredLLMs
Based on the given source and reference, identify the major and minor errors in this
translation. Note that Major errors refer to actual translation or grammatical errors,
and Minor errors refer to smaller imperfections, and purely subjective opinions about
the translation.
{src_lang} source: "{source}"
{tgt_lang} human reference: "{reference}"
{tgt_lang} translation: "{candidate}"
Errors: {error1:span} - {error1:severity}/{error1:category}; {error2:span} -...
Figure3: TheAUTOMQMpromptusedinthispaper. Partsinpurpleareonlyincludedforreference-based
evaluation,whilepartsinorangerepresentslotsforoutputs,andareonlyincludedforin-contextexamples.
2021a) and the current gold standard for transla- LP #Sys #Seg
LP #Sys #Seg
tionqualityevaluationinvolvinghumanannotators
en→kk 11 998
isinsteadbasedonmethodologiesliketheMQM en→de 13 1315 kk→en 11 1000
zh