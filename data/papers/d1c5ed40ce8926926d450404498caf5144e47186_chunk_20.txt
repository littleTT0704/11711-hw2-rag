 estimation, and we
introduce sequential models that estimate the relevance of text nuggets in the context
of surrounding nuggets. Finally, we summarize our findings and propose directions
for future research in Chapter 9.
Chapter 2
Related Work
In this chapter we compare source expansion to related disciplines of natural lan-
guage processing that influenced our work (Section 2.1). We further give an overview
of previous approaches for constructing local sources that can be used by QA systems
(Section 2.2) and related work on document expansion for information retrieval (Sec-
tion 2.3). In Section 2.4 we describe a summarization algorithm that was adapted to
estimate the relevance of text passages for source expansion. The chapter concludes
with an overview of text segmentation approaches that motivated features used in a
sequential model for relevance estimation (Section 2.5).
2.1 Relations to Established Research Areas
We identified ties between our statistical source expansion approach and various es-
tablished NLP tasks, including multi-document summarization, definitional question
answering, content-based information filtering, and topic detection and tracking.
Theproblemofextractingtextnuggetsthatrelatetoagiventopicfromdocuments
isperhaps mostsimilarto multi-documentsummarization(e.g. Goldsteinet al.[1999,
2000], Nenkova et al. [2006]), but it differs in the following important ways:
1. The selection of relevant text for source expansion is guided by the content of a
seed document. For instance, we have designed features that evaluate the topi-
cality of text nuggets using term weights and topic language models estimated
from seed content. In multi-document summarization, on the other hand, seed
documents are usually not available and instead the relevance of text passages is
estimated based on much shorter query strings. In our experiments, topicality
features that use the seed content are combined with other relevance features
that are based on web search results and the surface forms of text nuggets in
a statistical model. By leveraging the seeds, we were able to substantially im-
prove relevance estimation performance. However, we will show that even if the
seed documents are sparse or of low quality, or if no seed content is available
at all, our approach for selecting relevant text nuggets still outperforms several
strong baselines.
