 sm sm ds ds
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
PLMparametriccomponent PkNNnon-parametriccomponent
Figure 1 provides an illustration of Equation 5. The first term of the equation is the standard parametric
languagemodel,whereasthesecondrepresentsageneralizedversionofutilizinganexternaldatastore. The
firstcomponent,theoutputlayerofacommonparametriclanguagemodel,isrelativelystraightforward. W
sm
ofsizeV ×Distheembeddingmatrixoftheoutputtoken,andh isthecontextvectorusedtocalculatethe
sm
distributionoftheoutputtoken,usuallytheoutputofthefinalfeedforwardlayerinthetransformer.
Inthesecondcomponent,W representsthedatastore,ofsizeN ×D. N isthenumberofentriesin
ds ds ds
thedatastore,andD isthesizeofeachcontextvector. h representsthecontextvectorusedtoquerythe
ds
datastore. AsshowninFigure1,thesevectorscancomefromdifferentlayersofthetransformerarchitecture.
⊗representstheoperationtypeusedtocalculatethesimilaritybetweencontextvectorsandthequeryvector,
whichalsohasseveralalternativesthatwediscussbelow.
mask-to-k(·)representsafunctiontosparsifysimilarityscoresacrossthedatastore,settingallbutksimilarity
scores to −∞, which results in probabilities of zero for all masked similarity scores after the softmax.
3
Practically, this is necessary for kNN-LMs because the size of the datastore N makes it infeasible to
ds
calculatealloutputsatthesametime. Withmaskedlogits,weapplyamoregeneralizedversionofsoftmax
withtemperatureτ. Intuitivelyaddingthetemperaturecanadjustthepeakinessorconfidenceofthesoftmax
probabilitydistributionoutput. Afterthesoftmax,thematrixM ofdimensionV ×N sumstheprobabilityof
