Masked Proxy Loss For Text-Independent Speaker Verification
JiachenLian∗,AiswaryaVinodKumar∗,HiraDhamyal∗,BhikshaRaj+,RitaSingh+
∗ElectricalandComputerEngineering,+LanguageTechnologiesInstitute
CarnegieMellonUniversity
Pittsburgh,PA,USA-15213
{jlian2, avinodku}@andrew.cmu.edu, {hyd, bhiksha, rsingh}@cs.cmu.edu
Abstract computationofsuchcomparisonsscalesbyO(N3),aninfeasi-
blecomputationforanyreasonably-sizedtrainingcorpus.
Open-setspeakerrecognitioncanberegardedasametriclearn- Secondly,modelupdatesareusuallyperformedovermini-
ing problem, which is to maximize inter-class variance and batches of data rather than the entire training set, and most
minimizeintra-classvariance. Supervisedmetriclearningcan metriclearningapproachesrestrictthemselvestocomparisons
becategorizedintopair-basedlearningandproxy-basedlearn- of classes that are present within the minibatches [3,11,12].
ing[1]. Mostoftheexistingmetriclearningobjectivesbelong Whilethecomputationhereislessdaunting–scalingonlyby
totheformerdivision,theperformanceofwhichiseitherhighly O(NB2)forminibatchesofsizeBforasinglepassthroughthe
dependent on sample mining strategy or restricted by insuffi- data–adifferentsuboptimalityresults.Thesizeofminibatches
cient label information in the mini-batch. Proxy-based losses istypicallymuchsmallerthanthetotalnumberofclassesinthe
mitigatebothshortcomings,however,fine-grainedconnections training data. Even with exhaustive comparison of all triplets
amongentitiesareeithernotorindirectlyleveraged. Thispa- withineachminibatch,updatesmadetothemodelwillnothave
perproposesaMaskedProxy(MP)losswhichdirectlyincor- considered the complete possible set of comparisons across
poratesbothproxy-basedrelationshipandpair-basedrelation- classes.
ship. We further propose Mult