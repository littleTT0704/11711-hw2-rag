thatGPUsthatlack tensor optimizations reduces the latency of static
TensorCoresupportforhalfprecisionoperations, CUDAgraphsby80.56%atbatchsize128when
such as the 1080Ti, are notably slower and less processingsparseinputs.
framework-boundthannewerGPUs. Conversely,
Atlargeinputsizes,frameworkoverheadfrom
thisleadsfasterGPUs,suchastheRTX3090and
graphoperationsisnegligible. Forbatchsizes
the A100, to remain framework bound at larger
larger than 16, we find that there is minimal la-
batchsizesforbothResNet-50andBERT.These
tencydifferenceacrossmodels,inferenceruntimes,
observations indicate that framework bounds on
and frameworks. In the compute-bound regime,
modelexecutionwillcontinuetoworsenashard-
numberofFLOPsisstillapoorlatencypredictor
wareimprovesunlessdeeplearningframeworksare
duetovariableexecutiontimefordifferentopera-
commensurately improved. For example, BERT-
tions. Forexample,efficientmobilearchitectures
Base is not framework bound for older 1080Ti
that depend on inverted-residual layers are mem-
GPUsbutisonnewer3090GPUs.
oryinefficientandaremuchslowerper-FLOPthan
Framework boundedness is mainly caused by
standardconvolutionandlinearlayers.
bottlenecksduetoCPUdispatchoperations. Asa
result,thefixedlatencyforframework-boundmod- Forframework-boundmodels,modeldepthisa
elsisaproductoftheentiresystemconfiguration, reasonableproxyforlatency. Numberoffloat-
dependentonhardwarespecificationssuchasCPU ingpointoperationsisapoorindicatoroflatency
and memory speeds. In contrast, the latency of in a framework-bound setting, as total runtime
compute-bound models is mainly determined by is generally constant and tied to framework over-
the properties of kernels: operation type, kernel headsandthesizeofthecomputationalgraph. In
size,andtheirsupportedGPUFLOPspersecond framework-boundmodels,thesizeofthecomputa-
â€”withf