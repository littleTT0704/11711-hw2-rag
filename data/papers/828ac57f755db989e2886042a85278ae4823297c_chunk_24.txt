 Correctanswersaremarkedin
greenwhilefailedcasesareinred.
Past Present Future
ConvNets Ours Improv ConvNets Ours Improv ConvNets Ours Improv
Easy 74.8% 78.3% 3.5% 76.3% 79.7% 3.4% 76.4% 78.7% 2.3%
TACoS Hard 62.7% 64.7% 2.0% 65.5% 67.1% 1.6% 64.5% 67.3% 2.8%
Easy 66.8% 72.1% 5.3% 72.0% 74.2% 2.2% 68.7% 73.6% 4.9%
MPII-MD Hard 45.6% 47.0% 1.4% 47.3% 48.2% 0.9% 46.9% 48.0% 1.1%
Table5.ComparisonsbetweenConvNetsandourmodelforpast,presentandfuturemodeling.
ble5. Fromtheresult,wehavethefollowingobservations: duetolackofcontext.
(2) Ourmodel can achievebetter resultsfor futurepre-
(1)GRUmodeloutperformsConvNetmodelinallcases,
diction than past inference. For future prediction, we feed
andrelativelyperformsbetterthanConvNetintasksofin-
input frames in the order of 4, 5, 6 (Figure 4) and the de-
ferringthepastandpredictingthefuturecomparedwithde-
coderisaskedtoreconstructframeintheorder7,8,9. As
scribing the present. By comparisons of the performance
to past inferring, we feed the same input, but ask the de-
among tasks, we find that our GRU model performs rela-
codertoreconstructtargetsequenceof1,2,3.Asthefuture
tively better than ConvNets in tasks of inferring the past
prediction model has shorter term dependencies than past
andpredictingthefuture,whichshowstheeffectivenessof
inferring model, future prediction model can be easier to
our GRU encoder-decoder framework in modeling tempo-
learn the temporal dependencies, which is consistent with
ral structures in videos. As our GR