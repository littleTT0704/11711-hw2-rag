ches,
andPhoto).Theexperimentalprotocolistotrainamodelonthreedomains
and test on the remaining domain.
– VLCS [27]: five classes over four domains. The domains are defined by
four image origins, i.e., images were taken from the PASCAL VOC 2007,
LabelMe, Caltech and Sun datasets.
– Office-Home[28]:65objectcategoriesover4domains(Art,Clipart,Prod-
uct, and Real-World).
– ImageNet-Sketch [30]: 1000 classes with two domains. The protocol is to
train on standard ImageNet [22] training set and test on ImageNet-Sketch.
4.2 Ablation Study
We conducted five ablation studies on possible configurations for RSC on the
PACSdataset[13]. Allresultswere produced basedontheResNet18 baselinein
[4] and were averaged over five runs.
(1) Feature Dropping Strategies (Table 1). We compared the two atten-
tion mechanisms to select the most discriminative spatial features. The “Top-
Activiation” [20] selects the features with highest norms, whereas the “Top-
Gradient” (default in RSC) selects the features with high gradients. The com-
parison shows that “Top-Gradient” is better than “Top-Activation”, while both
are better than the random strategy. Without specific note, we will use “Top-
Gradient” as default in the following ablation study.
(2) Feature Dropping Percentage (choice of p) (Table 2): We ran RSC at
differentdroppingpercentagestomutespatialfeaturemaps.Thehighestaverage
accuracy was reached at p = 33.3%. While the best choice of p is data-specific,
our results align well with the theoretical discussion: the optimal p should be
neither too large nor too small.
(3) Batch Percentage (Table 3): RSC has the option to be only randomly
appliedtoasubsetofsamplesineachbatch.Table3showsthattheperformance
Self-Challenging Improves Cross-Domain Generalization 11
FeatureDropStrategies backbone artpaintcartoonsketch photo Avg↑
Baseline[4]