akerandattack. Thereare20
ersindevelopmentset.
speakersand6typesofattackintheASVspoof2019LAtrain-
ingset,meaningthatthereare120”spoofedidentities”. Thus
our modified training set contains 140 identities. We call
IAB + RI, showing that the IRAB pairs are valid, also indi-
theseASVspooftrainingidentities(ASVTIs).
cating the true differences between the impersonator’s real
voices. AndtheIAB+TIgivesanEERof43.52%. Thishigh
2.2.1. Impersonationattacks EERcomesfromtheformationofthisevaluationset. Differ-
entfromothersets,boththenegativepairsandpositivepairs
Our black-box evaluations on impersonation attacks use the can be seen as the spoofing attacks because the professional
CID dataset. We run several experiments to evaluate the impersonator could impersonate different target to a certain
dataset’s attacking potential. The results are shown in Table extent, which makes the ’positive’ pairs negative in nature.
1. ThemodelthatispretrainedonVoxCeleb2isabletover- Therefore, both the positive pairs of IAB and the negative
ify open-set speakers best and gives 1.71% EER for target pairs of TI are hardest cases, also showing by the EERs of
speakers’realutterances(positiveandnegativepairsR+RI); theircombinationwiththeRandRI.
ThispretrainedmodelcanbeseenasablackboxASVunder The R + IRT corresponds to positive pairs for the real
open-setevaluation. voiceutterancesofthesametargetsandnegativepairsofim-
Fromourtests,weobservethatcombiningtheimperson- personator’srealvoicewiththetargets’realvoice.The5.21%
ation/targetpairs(TI)withthepositivepairsfromrealspeak- EERshowsthattheimpersonator’srealvoicesareindeednot
ers (R) improves the speaker verification EER to 11.42%, similartothetargets’voices.
which indicates that professional impersonation can fool the The overall results