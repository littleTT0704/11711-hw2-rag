Regularizing Self-training for Unsupervised Domain Adaptation
via Structural Constraints
RajshekharDas1*† JonathanFrancis1,2∗ SanketVaibhavMehta1∗ JeanOh1 EmmaStrubell1 Jose´ Moura1
1CarnegieMellonUniversity 2BoschCenterforArtificialIntelligence
{rajshekd, jmf1, svmehta, hyaejino, strubell, moura}@andrew.cmu.edu
Abstract
Self-training based on pseudo-labels has emerged as a
dominantapproachforaddressingconditionaldistribution
shifts in unsupervised domain adaptation (UDA) for se-
mantic segmentation problems. A notable drawback, how-
ever, is that this family of approaches is susceptible to er-
roneous pseudo labels that arise from confirmation biases
in the source domain and that manifest as nuisance fac-
tors in the target domain. A possible source for this mis-
match is the reliance on only photometric cues provided
by RGB image inputs, which may ultimately lead to sub-
optimal adaptation. To mitigate the effect of mismatched
pseudo-labels, we propose to incorporate structural cues
fromauxiliarymodalities,suchasdepth,toregularisecon-
ventionalself-trainingobjectives.Specifically,weintroduce
acontrastivepixel-levelobjectnessconstraintthatpullsthe
pixel representations within a region of an object instance
closer,whilepushingthosefromdifferentobjectcategories
apart. To obtain object regions consistent with the true Figure 1. Motivation for Objectness Constraints: The above
underlying object, we extract information from both depth examplescomparetarget-domainground-truthsegmentation,pre-
maps and RGB-images in the form of multimodal cluster- dicted segmentation and prediction confidence (brighter regions
ing. Crucially, the objectness constraint is agnostic to the aremoreconfident)ofaseedmodelthatwasadaptedfromsource
ground-truth semantic labels and, hence, appropriate for totargetdomainviaadversarialadaptation[48].Mostself-training
unsupervised domain adaptation. In this work, we show approaches use such a seed model to predict pixelwise pseudo-