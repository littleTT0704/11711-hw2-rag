 The Word2Vec tests were run on pre-
trainedmodelsaswellasmodelswebuiltfromscratchand
trainedusingthedatawecollected.WeusedtheWord2Vec
approach to find approximate nearest neighbors and exact
nearestneighborsforcertainwordsonboththeDemocratic
and the Republican sides. This nearest-neighbor approach
led to some interesting insights. We expected to see some
Figure2:Background
disparity in the nearest neighbor searches for the Repub-
lican data and Democratic data basis the assumption that
there is polarization. However using the simple Word2Vec
LanguageModel
models the 15 nearest neighbors we got were quite simi-
Natural Language Processing based applications have been lar but as there were certain words for whom the order of
dominated by transformer-based language models where the neighbors changed based on the party, for example, for
models like BERT(Devlin et al. 2018) and RoBERTa(Liu the word ’GUN’, ’VIOLENCE’ is the 2nd nearest neigh-
bor(approximatenearestneighborusingspotify’sannoyal-
gorithm)fordemocraticdatahoweverthesamewordis9th
for the republican case, similarly the word ’CHECKS’ is
the 3rd nearest neighbor for democrats while it is the 8th
for republicans. There are more such interesting examples
whichcoupledwiththeresultsfromtheDoc2Vecclassifica-
tion results, prove that political polarization exists and can
be learned using Natural Language Processing based tech-
niques.
Mainanalysis Figure 4: Nearest neighboring words to the word immigrant in the
democraticcorpusacrosstimefromlefttoright,aswecansee,words
As part of our preliminary analysis, we use RoBERTa,
likeamericanswerecloselyassociatedintheearly20thcentury.
we notice the removal of the words ”Democratic”, ”Re-
publican” etc. causing a drop in classification. This is ex-
pected as we lose obvious information and classifying just
based on the first 512 tokens is challenging. We hence
use Longformer since it can consider 4096 tokens at a
time. As expected, this increases the score significantly, as
can be seen in