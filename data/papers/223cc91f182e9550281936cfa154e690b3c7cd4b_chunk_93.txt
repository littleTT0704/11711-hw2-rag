22). BertNet: Harvesting knowledge graphs
from pretrained language models. arXiv. https://doi.org/10.48550/arXiv.2206.14268 ↩
64
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
Hinton, G. E., Dayan, P., Frey, B. J., & Neal, R. M. (1995). The" wake-sleep" algorithm for unsupervised
neural networks. Science, 268(5214), 1158–1161. https://doi.org/10.1126/science.7761831 ↩
Hinton, G., Vinyals, O., & Dean, J. (2015). Distilling the knowledge in a neural network. arXiv.
https://doi.org/10.48550/arXiv.1503.02531 ↩
Houthooft, R., Chen, X., Duan, Y., Schulman, J., De Turck, F., & Abbeel, P. (2016). VIME: Variational
information maximizing exploration. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, & R. Garnett (Eds.),
Proceedings of the 30th International Conference on Neural Information Processing Systems, (Vol. 29; 1117–
1125). Curran Associates Inc. https://papers.nips.cc/paper/2016/file/abd815286ba1007abfbb8415b83ae2cf-
Paper.pdf
↩
Hu, Z., Ma, X., Liu, Z., Hovy, E., & Xing, E. (2016). Harnessing deep neural networks with logic rules. In
K. Erk & N. A. Smith (Eds.), Proceedings of the 54th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) (pp. 2410–2420). http://doi.org/10.18653/v1/P16-1228
↩
Hu, Z., Tan, B., Salakhutdinov, R., Mitchell, T., & Xing, E. P. (2019). Learning data manipulation for
augmentation and weighting. In H. Wallach, H. Lar