(cid:88) L dice(M t,Mˆ t) 2018),S-MeasureS α (Fanetal.2017)andMeanAbsolute
Error(MAE)M(Borjietal.2015).
t=1 t=1
(6)
where M and Mˆ are predicted and ground-truth salient ImplementationDetails
t t
maps respectively. λ is a scalar. M can be Mstu and Followingthebenchmarksetting(Zhang,Chao,andZhang
dice t t
MtchforcomputingLstu andLtch. 2021),ourmodelisfirstpre-trainedonDUSTdataset(Wang
t struc struc
etal.2017)andthenfinetunedonASOD60K(Zhang,Chao,
Distillationloss. Tohelpthestudentblocklearntheaudio-
andZhang2021).Themodelistrainedfor20epochswith
visual correspondence, we enforce a consistency between
a learning rate of 1e-4. We adopt a batchsize of 2 and an
ftchandfstu.AMSElossisutilizedastheconstraint
t t AdamW(LoshchilovandHutter2017)optimizerwithweight
(cid:88)T decay0.Allimagesarecroppedtohavethelongestsideof
L distill = L MSE(f ttch,f tstu) (7) 832pixelsandtheshortestsideof416pixelsduringtraining
t=1 andevaluation.Thewindowsizeissetto3.Theλ isset
distill
to5.0andλ issetto1ifnospecification.Weleveragea
Inference dice
3-layertransformerencoder(Dosovitskiyetal.2020)ontop
Sincethepurposeofintroducingteacherblockistofacilitate
oftheResNet-50(Heetal.2016)toextractvisualfeatures.
networklearnaccurateaudio-visualcorrespondenceduring
WeleverageanaugmentedSELDNet(Adavanneetal.2018)
training, we disable the teacher block and only keep the
as our acoustic encoder. Our method is implemented with
studentblockduringinference.
