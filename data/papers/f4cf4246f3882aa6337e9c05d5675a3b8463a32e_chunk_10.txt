to-SequenceModels
of language annotation token lengths in ALFRED versus
We model the interactive agent with a CNN-LSTM
relateddatasetsisgiveninFigure3.
AMT workers are told to write instructions to tell a
sequence-to-sequence(SEQ2SEQ)architecture.ACNNen-
odesthevisualinput,abidirectional-LSTMgeneratesarep-
“smartrobot”howtoaccomplishwhatisshowninavideo.
resentationofthelanguageinput,andadecoderLSTMin-
We create a video of each expert demonstration and seg-
fers a sequence of low-level actions while attending over
ment it such that each segment corresponds to an instruc-
theencodedlanguage.SeeFigure4foranoverviewandthe
tion. We consult the PDDL plan for the expert demon-
supplementarymaterialforimplementationdetails.
stration to identify task sub-goals, for example the many
low-level steps to navigate to a knife, or the several steps
to heat a potato slice in the microwave once standing in Supervision. We train all models using imitation learn-
front of it. We visually highlight action sequences related ingonexperttrajectories. Thisensuresthelanguagedirec-
to sub-goals via colored timeline bars below the video. In tives match the visual inputs. At each timestep, the model
eachHIT(HumanIntelligenceTask),aworkerwatchesthe istrainedtoproducetheexpertactionandassociatedinter-
video, then writes low-level, step-by-step instructions for actionmaskformanipulationactions.
eachhighlightedsub-goalsegment. Theworkeralsowrites We note that a DAgger-style [44] student-forcing
ahigh-levelgoalthatsummarizeswhattherobotshouldac- paradigminALFREDisnon-trivial,evendisregardinglan-
complishduringtheexpertdemonstration. guage alignment. Obtaining expert demonstration actions
These directives are validated through a second HIT by ontheflyinnavigation-onlydatasetslikeR2R[3]onlyre-
atleasttwoannotators,withapossiblethirdtie-breaker.For quires