complexityto
sificationtaskandconventionalclassificationtasks
actasacasestudy.
is that our task expects the model to incorporate
explicitlyprovidedvaluesalongwithotherinputs
4 Methodology
formakingjudgements.
Weseparatetheprocessofvaluedefinitionfrom
There is no existing resource for training value-
the development of the value-aligned models so
aligned classification models. We therefore pro-
thatthemodelscanlearntomakedynamicjudge-
pose to leverage LLMs for generating synthetic
mentsbasedonexternalvalues. Forinstance, ex-
trainingdata. LLMshavebeenfoundtolearnsig-
istingsexismclassifiersimplicitlylearnafixedset
nificantamountsofinherentknowledgeaswellas
ofdefinitionsofsexismfromlabeleddata,sothe
human values during pre-training (Petroni et al.,
contentwillbejudgedbasedonthesestaticvalues.
2019; Hendrycks et al., 2020; West et al., 2021;
Ourtaskrequiresthemodeltopredictdynamicla-
Robertsetal.,2020). However,thedirectusageof
belsdependingonthedifferentexplicitvalueseven
LLMsinzero-shotsettingforNLPtaskscanbeun-
whenthecontentisthesame.
stableandstilllimited(Weietal.,2021). Therichly
embeddedknowledgeinLLMsneverthelessmakes
3.2 Value-alignedSexismClassification
themgoodresourcegenerators. Therefore,weat-
We showcase the value-aligned judgement task
tempttobuildvalue-alignedmodels(VA-MODELs)
with an application to sexism classification. The
through fine-tuning smaller models on the value-
model needs to judge whether natural language
alignedtrainingdatageneratedbyLLM(s).
content is sexist or non-sexist based on a given
Ourproposedmethod(Figure2)consistsoftwo
valueV. Ifthevalueisnotapplicableorirrelevant,
steps: 1)promptinghumanvalue-alignedcontents
the model needs to predict that it is not applica-
fromLLMsbyprovidingexplicithumanvaluesand
ble (NA). Our rationale for choosing the sexism
instructions,and2)