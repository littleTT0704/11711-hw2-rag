 than a learned listener, to rerank utterances. Additionally, we apply
this process to a computational model of language acquisition. Nematzadeh et al. (2018) created
a dataset to evaluate question-answering modelsâ€™ ability to keep track of inconsistent worldviews.
They found that state-of-the-art neural models lack this ability, indicating that they cannot solve
tasks with ToM. Monroe et al. (2017) studied the effects of visually similar distractors on a prag-
maticmodelofcoloridentification,findingthatpragmaticmodelshadthelargestgainsinthemost
difficultsettings.Vedantametal.(2017)alsoconsidertheeffectsofincludingpragmaticcomponents
inimagecaptioningmodels,namelyaninternalmoduletobetterdiscriminatebetweenimages.
EmergentLanguage. Lazaridou&Baroni(2020)surveyedrecentprogressinemergentlanguage
from multi-agent communication, claiming that further progress can help deep networks become
moreinteractiveandinterpretable. Lazaridouetal.(2020)placeagenerallytrainedlanguagemodel
in a multi-agent environment with task-specific rewards. Similarly to our work, this results in a
task-conditionallanguagemodelwhichtheauthorsclaimcanbettercommunicatewithhumansover
visualtasks. Chaabounietal.(2022)analyzedtheeffectsoftaskdifficultyonemergentcommuni-
cationtasksbyvaryingthenumberofdistractors,leadingtonegativeeffectsonmodelperformance
during evaluation. Mu & Goodman (2021) attempted to improve interpretability of learned lan-
guages in referential games by forcing speakers to communicate over sets of objects representing
abstractvisualconcepts,andanalyzedthecompositionalityoftheensuingemergentlanguages.
8 CONCLUSION AND FUTURE WORK
Inthispaper,weextendanexistingcomputationalframeworkthatmodelsthelanguageacquisition
processinanimagereferentialgameenvironment. Mostnotably,weaddaToMcomponenttoour
speakermodels,allowingourspeakerstopragmaticallyrerankcandidateutteranceswithalearned
internallistener. Wealsoexperimentwithincreasingdistractordifficultybyupweightingmorese-
manticallyandvisuallysimilard