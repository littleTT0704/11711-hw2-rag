Generated Knowledge Prompting for Commonsense Reasoning
JiachengLiu♥ AlisaLiu♥ XimingLu♥♠ SeanWelleck♥♠
PeterWest♥♠ RonanLeBras♠ YejinChoi♥♠ HannanehHajishirzi♥♠
♥PaulG.AllenSchoolofComputerScience&Engineering,UniversityofWashington
♠AllenInstituteforArtificialIntelligence
liujc@cs.washington.edu
Abstract
It remains an open question whether incorpo-
rating external knowledge benefits common-
sense reasoning while maintaining the flexi-
bility of pretrained sequence models. To in-
vestigate this question, we develop generated
knowledge prompting, which consists of gen-
erating knowledge from a language model,
thenprovidingtheknowledgeasadditionalin-
put when answering a question. Our method
does not require task-specific supervision for
knowledge integration, or access to a struc-
tured knowledge base, yet it improves perfor-
Figure 1: Generated knowledge prompting involves
mance of large-scale, state-of-the-art models
(i)usingfew-shotdemonstrationstogeneratequestion-
onfourcommonsensereasoningtasks,achiev-
related knowledge statements from a language model;
ing state-of-the-art results on numerical com-
(ii) using a second language model to make predic-
monsense (NumerSense), general common-
tionswitheachknowledgestatement,thenselectingthe
sense (CommonsenseQA 2.0), and scientific
highest-confidenceprediction.
commonsense (QASC) benchmarks. Gener-
ated knowledge prompting highlights large-
scale language models as flexible sources of
edge,asmanybenchmarkscurrentlylackappropri-
external knowledge for improving common-
ateknowledgebaseswithsufficientcoverage. Fur-
sense reasoning. Our code is available at
github.com/liujch1998/GKP thermore,priormethodsoftenrequiretask-specific,
customsupervisionforknowledgeintegration(Mi-
1 Introduction traetal.,2019;Changetal.,2020),introducinga
burdenforrapidlyadaptingnewpretrainedmodels
Itremainsanopenresearchquestionwhetherex