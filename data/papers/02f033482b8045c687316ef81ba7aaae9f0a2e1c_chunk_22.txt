ixonetal.,2018)ortextwrittenby
racialminorities(Sapetal.,2019;Davidsonetal., Adam M Croom. 2013. How to do things with slurs:
Studies in the way of derogatory words. In Lan-
2019),thereforehavingtherealpossibilityofback-
guage&communication.
firingagainstitsveryaimoffairnessandinclusive
dialogue. To address this limitation, we also per- SumanthDathathri,AndreaMadotto,JaniceLan,Jane
form a human evaluation of toxicity, for which Hung,EricFrank,PieroMolino,JasonYosinski,and
Rosanne Liu. 2020. Plug and play language mod-
we obtained IRB approval and sought to pay our
els: Asimpleapproachtocontrolledtextgeneration.
workersafairwage(„US$7–9/h).
InProceedingsofthe2020InternationalConference
We also acknowledge that any controllable onLearningRepresentations(ICLR).
detoxification method runs the risk of dual use
Thomas Davidson, Debasmita Bhattacharya, and Ing-
(Pandya,2019),specifically,thistechnologycould
mar Weber. 2019. Racial bias in hate speech and
beusedtoautomaticallygeneratehatefultext(e.g.,
abusivelanguagedetectiondatasets. InProceedings
extremist texts; McGuffie and Newhouse, 2020). oftheThirdWorkshoponAbusiveLanguageOnline.
Forabroaderdiscussionofsuchrisks,andofthe
risksoflargepretrainedLMsingeneral,pleasesee LucasDixon,JohnLi,JeffreySorensen,NithumThain,
andLucyVasserman.2018. Measuringandmitigat-
Benderetal.(2021).
ing unintended bias in text classification. In Pro-
Nevertheless, toxicity in pretrained LMs is an ceedings of the 2018 AAAI/ACM Conference on AI,
unsolvedissue(Shengetal.,2019;Gehmanetal., Ethics,andSociety(AIES).
2020). Therefore, we hope future work contin-
Li Dong, Shaohan Huang, Furu Wei, Mirella Lapata,
ues