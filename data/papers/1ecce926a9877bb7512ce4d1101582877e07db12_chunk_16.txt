PyTorch.
Experiment
MainResults
DatasetandMetrics Inthissection,wecompareourmethodwithpreviousstate-
Dataset. We conduct experiments on the ASOD60K of-the-artmethods,includingCPD-R(Wu,Su,andHuang
dataset(Zhang,Chao,andZhang2021)whichisanaudio- 2019a),MINet(Pangetal.2020),SCRN(Wu,Su,andHuang
Frames GT CPD-R LDF CSFR2 RCRNet Ours
Figure6:Qualitativecomparisontostate-of-the-artVSODmethodsonASOD60Kdataset.
2019b), F3Net (Wei, Wang, and Huang 2020), LDF (Wei ASOD60K-TestAll
MultimodalFusion
etal.2020),CSFR2(Gaoetal.2020),GateNet(Zhaoetal. F ↑ S ↑ E ↑ M↓
β α φ
2020),COSNet(Luetal.2019),RCRNet(Yanetal.2019), None.396.660.714.037
PCSA(Guetal.2020),3DC-Seg(Mahadevanetal.2020) +ACF(Concat).385.667.697.027
andRTNet(Renetal.2021a)onASOD60Kdataset. +ACF(MMAttn).397.670.722.026
+ACF(MMAttn)+SPE.404.678.732.026
Quantitativeresults. Wecompareourmethodwithstate-
of-the-artmethodsontheASOD60KdatasetinTable1.In
Table2:Impactofdifferentmultimodalfusionmethods.
general, our method achieves the best result of 0.404 F,
β
Thecontentinthebracketindicatesdifferentfusionmethods
0.678 S, 0.732 E and 0.026 M on the ASOD60K test
α φ
inACFblock.Concat:Concatenate,MMAttn:multimodal
set. For each sound event split, all