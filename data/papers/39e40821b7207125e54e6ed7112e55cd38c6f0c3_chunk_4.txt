ting_pies_on_plates,
serve_potpies_on_plate; serve_potpies_on_plate),
fill_pies_onto_plates_evenly -> (fill_pies_onto_plates_evenly,
serve_potpies_on_plate; serve_potpies_on_plate),
serve_potpies_on_plate -> end; (serve_potpies_on_plate, end)
} ]
(c)Straightforwardencodingsofthegraphusingthe“DOT” (d)Textformat,orasalistofedges(nodepairs)
Figure 1: An illustration of COCOGEN for the task of script generation. An input graph (1a) is typically rep-
resented using the DOT format (1c) or as a list of edges (1d), which allows modeling the graph using standard
languagemodels. Thesepopularchoicesaresufficientinprinciple;however,theseformatsarelooselystructured,
verbose, andnotcommonintextcorpora, precludinglanguagemodelsfromeffectivelygeneratingthem. Incon-
trast, COCOGEN converts structures into Python code (1b), allowing to model them using large-scale language
modelsofcode.
etal.,2021),showthatCode-LLMsareabletoper- data. We call our method COCOGEN: models
form complex reasoning on structured data such of Code for Commonsense Generation, and it is
as programs. Thus, instead of forcing LLMs of demonstratedinFigure1.
natural language (NL-LLMs) to be fine-tuned on Ourcontributionsareasfollows:
structured commonsense data, an easier way to
1. We highlight the insight that Code-LLMs
closethediscrepancybetweenthepre-trainingdata
arebetterstructuredcommonsensereasoners
(free-form text) and the task-specific data (com-
thanNL-LLMs,whenrepresentingthedesired
monsensereasoninggraphs)istoadaptLLMsthat
graphpredictionascode.
were pre-trained on code to structured common-
2. We propose COCOGEN: a method