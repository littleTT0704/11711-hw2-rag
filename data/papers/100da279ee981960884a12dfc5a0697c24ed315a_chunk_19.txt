 We conduct experiments with different target distribu-
tions for alignment. Specifically, the default uniform target distribution u(C) can be replaced by
ground-truthclassdistributionortheempiricalclassdistributionestimatedbyseenlabeleddatadur-
ingtraining. TheresultsinFig.3(a)showaclearadvantageofusinguniformdistribution. Uniform
targetdistributionenforcestheclassmarginaltobecomeuniform,whichhasastrongregularization
effectofbalancingtheheadandtailclassesinimbalancedclassificationsettings.
4.3 TEXTCLASSIFICATION
Setup. In addition to image classification tasks, we further evaluate SoftMatch on text topic clas-
sification tasks of AG News and DBpedia, and sentiment tasks of IMDb, Amazon-5, and Yelp-5
(Maasetal.,2011;Zhangetal.,2015). Wesplitavalidationsetfromthetrainingdatatoevaluate
thealgorithms. ForAmazon-5andYelp-5,werandomlysample50,000samplesperclassfromthe
training data to reduce the training time. We fine-tune the pre-trained BERT-Base (Devlin et al.,
2018)modelforalldatasetsusingUDA(Xieetal.,2020),FixMatch(Sohnetal.,2020),FlexMatch
(Zhangetal.,2021),andSoftMatch. WeuseAdamW(Kingma&Ba,2014;Loshchilov&Hutter,
2017)optimizerwithaninitiallearningrateof1e 5andthesamecosineschedulerasimageclassi-
ficationtasks. Allalgorithmsaretrainedforatotaâˆ’ literationof218. Thefine-tunedmodelisdirectly
used for evaluation rather than the EMA version. To reduce the GPU memory usage, we set both
B andB to16. Otheralgorithmichyper-parametersstaythesameasimageclassificationtasks.
L U
Detailsofthedatasplittingandthehyper-parameterusedareinAppendixA.3.3.
Results.TheresultsontextdatasetsareshowninTable5.SoftMatchconsistentlyoutperformsother
methods,especiallyonthetopicclassificationstasks. Forinstance