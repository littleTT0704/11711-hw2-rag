s Genera-
generation. InProceedingsofthe2021Conference
tion. In Findings of the Association for Computa-
of the North American Chapter of the Association
tionalLinguistics: EMNLP2021,pages2138–2149,
for Computational Linguistics: Human Language
Punta Cana, Dominican Republic. Association for
Technologies, pages 864–881, Online. Association
ComputationalLinguistics.
forComputationalLinguistics.
Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit
NasrinMostafazadeh,NathanaelChambers,Xiaodong
Goyal, Danfei Xu, Jonathan Tremblay, Dieter
He, Devi Parikh, Dhruv Batra, Lucy Vanderwende,
Fox, Jesse Thomason, and Animesh Garg. 2022.
Pushmeet Kohli, and James Allen. 2016. A cor-
Progprompt: Generating situated robot task plans
pus and evaluation framework for deeper under-
using large language models. arXiv preprint
standing of commonsense stories. arXiv preprint
arXiv:2209.11302.
arXiv:1604.01696.
Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Shao-Hua Sun, Te-Lin Wu, and Joseph J Lim. 2019.
Huan Wang, Yingbo Zhou, Silvio Savarese, and Programguidedagent. InInternationalConference
Caiming Xiong. 2022. A conversational paradigm onLearningRepresentations.
forprogramsynthesis. arXivpreprint.
NiketTandon,BhavanaDalvi,KeisukeSakaguchi,Pe-
Gabriel Poesia, Alex Polozov, Vu Le, Ashish Tiwari,
ter Clark, and Antoine Bosselut. 2019. WIQA: A
Gustavo Soares, Christopher Meek, and Sumit Gul-
dataset for “what if...” reasoning over procedural
wani.2021. Synchromesh:Reliablecodegeneration
text. In Proceedings of the 2019 Conference on
frompre-trainedlanguagemodels.