kits (e.g. machine translation’s use of Moses
methodology,withresearchers’choicesofmethods
(Koehnetal.,2007)),thecurrentcentralizationis
influencedbyrelativeeaseofimplementation. This
transcendssubfields.
appearedtobearelativelynewphenomenon;partic-
ipantsdescribedpreviouslyusingcustom-designed Centralizationonspecificmodels Participants
softwarefromtheirownresearchgroup,orwriting identified another shift after the release of BERT
codefromscratchforeachnewproject. andsubsequentdevelopmentofHuggingFace. Be-
cause of pre-training, participants moved from
Centralization on frameworks As deep learn-
merely using the same libraries to “everyone
ingbecamemorepopularinNLP,participantsde-
us[ing] the same base models” (9). Participants
scribed the landscape shifting. As TensorFlow
expressedconcernthatthisledtofurthercentraliza-
(Abadi et al., 2015) increased support for NLP
modeling, PyTorch (Paszke et al., 2019) was re- 4Inthissection,weprimarilydiscussopensourceframe-
leased, along with NLP-specific toolkits such as workscommonlyusedbyacademicandindustryresearchers.
However,manyofourparticipantsworkinginindustryalso
DyNet(Neubigetal.,2017)andAllenNLP(Gard-
describeaffordancesandconstraintsofinternaltoolkitsthat
neretal.,2018),and“everythingstartedbeing[...] areusedattheirrespectivecompanies.
noitnem
taht
srepap
fo
noitcarF
tioninthecommunity,withoneparticipantidenti- citing the lack of well-supported NLP toolkits or
fyingatrendofsomepeople“notus[ing]anything community use in other languages. This is an in-
else than BERT [...] that’s a problem” (5). This stanceofasoftwarelotteryatahigherlevel,where
concentrationaroundparticularmodelingchoices thedominanceofasingleprogramminglanguage
has reached greater heights than any previous has