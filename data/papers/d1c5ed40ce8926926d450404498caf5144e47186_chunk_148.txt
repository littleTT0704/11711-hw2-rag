 model and the merging phase. In the following, we describe each of these
steps in more detail.
In these experiments, Wikipedia was again chosen as a seed corpus because it is
a useful resource for answering both Jeopardy! and TREC questions. The Wikipedia
seed articles are expanded with related content extracted from ClueWeb091, a large
open-domain web crawl generated in 2009. We used the English portion of the crawl,
which comprises about 12 TB of web content, including HTML markup. Web pages
that originated from Wikipedia or one of its mirrors were excluded to avoid selecting
content that is already in the seed corpus.
Seed Selection
Text corpora that can be stored and processed locally without using excessive hard-
ware resources are necessarily much smaller than the indices of major web search
engines such as Google, Yahoo! and Bing, and they can be expected to have lower
coverage for the topics in an open-domain seed corpus. Thus if seed documents are
1http://boston.lti.cs.cmu.edu/clueweb09/
7.1. EXTRACTION-BASED SOURCE EXPANSION 109
selected based on a measure of popularity, as we did for Wikipedia and Wiktionary in
Section 6.2, we risk choosing topics for which not much relevant content can be found
in a local corpus. Therefore the expansion should be focused on topics that have high
coverage in the source from which related information is extracted. If a text corpus is
chosen that is relevant for a given QA task, then many questions will revolve around
these topics, and the extracted content is likely to help for answering these questions.
The coverage of candidate topics in an unstructured source can be approximated by
corpus statistics such as the number of occurrences of a topic in the source or the
number of documents that mention it. Often different surface strings are used to refer
to the same topic (e.g. Barack Obama, President Obama, the president, he etc.) and
for more accurate estimates these variants should be taken into account. Note that
the candidate set of topics can be very large, and an efficient mechanism is required
for quickly looking up mentions in a text corpus.
In the experiments with Wikipedia and ClueWeb09, we ranked all articles in the
encyclopedia by the total number of occurrences of their topics in the web crawl.
