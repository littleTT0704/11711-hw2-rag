22 framework for hyperspherical FR. In this framework, we
2202
raM
61
]VC.sc[
3v56550.9012:viXra
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 2
summarize a general principle for any loss function to forhypersphericalFRmethodstoimprovethetrain-
achievelargeangularmargin.Followingthisprinciple,most ingstabilityandgeneralizability.
existing hyperspherical FR methods can be viewed as spe- • Toevaluatetheusefulnessoffeaturemagnitude,we
cial instantiations. This framework helps us gain a deeper comprehensively study SphereFace-R under three
understandingofhypersphericalFR,andservesasaportal differentFNschemes:NFN,HFNandSFN.
todesignnewlossfunctions. • Our paper comes with an easy-to-use codebase to
Under this unified framework, we extend our previous facilitate future research.1 It serves as a platform to
study of SphereFace [2] by proposing alternative yet effec- evaluatehypersphericalFRmethodsfairly.
tive ways to implement the multiplicative margin with im-
proved training stability and better empirical performance.
2 RELATED WORK
Specifically, the original realization of multiplicative mar- Deep face recognition. Deep face recognition has been an
gin in SphereFace is exact only when the angle between activeresearchareainthepastdecades.[6],[7],[11]address
the feature and the target classifier is sufficiently small. open-set FR using a convolutional neural network (CNN)
Whenthisangleislarge,themultiplicativemarginbecomes supervised by softmax-based loss, which essentially views
approximate and the original intuition no longer holds. open-setFRasamulti-classclassificationproblem.[12]com-
Motivated by this, we propose two novel variants that can bines contrastive loss and softmax loss to jointly supervise
exactly implement the intuition of multiplicative margin the CNN training, greatly boosting performance. [13] uses
for all possible angles. Along with the new multiplicative triplet loss and feature normalization to learn a unified
margins, we also propose a novel implementation strategy face embedding. After training on nearly 200 million