facerelationshipinafine-grainedmanner,
correlated with facial attributes. Specifically, each phoneme
i.e.,phonemesvs. facialanthropometricmeasurements(AM).
correspondstoadifferentvocaltrackstatusandalsoanaccord-
Webuildanestimatorforeachphoneme-AMpairandevaluate
inglyfacialmovement.Toconstructanaccuratevoice-facecor-
thecorrelationthroughhypothesistesting. Ourresultsindicate
relation, we argue that phoneme-level voice-face modeling is
thatAMsaremorepredictablefromvowelscomparedtoconso-
vital.
nants,particularlywithplosives. Additionally,weobservethat
To investigate and understand the voice-face correlation
ifaspecificAMexhibitsmoremovementduringphonemepro-
at a more fine-grained phoneme level, we propose an anal-
nunciation, it is more predictable. Our findings support those
ysis pipeline that leverages a common feature extractor with
inphysiologyregardingcorrelationandlaythegroundworkfor
a regression head to predict human anthropometric measure-
futureresearchonspeech-facemultimodallearning.
ments(AM)fromphoneme.Specifically,Humananthropomet-
IndexTerms:voice-facecorrelation,phoneme
ricmeasurementsareasetoffacialmeasurementssummarized
fromcognitivesciencestudiesthatcaneffectivelyrepresentthe
identityofahuman. Wedecomposetheaudiorecordingsinto
1. Introduction
phonemes and learn to predict AMs from phonemes. In this
way, we can quantitatively analyze the relationship between
The implicit relation between speech and anthropometry fea-
each facial AM and phoneme pairs. In this paper, we aim to
tures has been extensively researched in recent years. Nu-
answercoretwoquestions: 1)whetherthereexistsany“enig-
merous voice profiling studies [1, 2, 3, 4, 5, 6] have shown
matic”linkbetweenphonemeandfacialfeaturesand2)whether
that human voice carries a plethora of information about the
those“enigmatic”linkscanbequantitatively