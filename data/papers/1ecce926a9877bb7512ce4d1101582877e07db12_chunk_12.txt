 the encoder and three linear layers for both semantic and lo-
query Q from F and key K, value V from gaud by lin- cationhead(detailedstructureavailableinsupplementary)
ear projections. The MCA(F,gaud) can be computed by (Adavanneetal.2018).Sinceitisdifficulttoobtainthereal-
Softmax(K √TQ)V, where d is the dimension of query Q. world sound source location in panoramic videos, we first
d pretraintheacousticencoderona3Dsoundsourcelocaliza-
ThestudentfeatureFstucanbecomputedby
tionandsoundeventclassificationdataset,L3DAS(Guizzo
Fstu =Fsem(cid:12)ϕ (Floc) (4) et al. 2021). We remove final linear layer in each head to
C(cid:55)→1
formthesemanticembeddinggsem ∈ RC×L andlocation
whereϕ denotesaconvolutiontoreducechannelfrom
C(cid:55)→1 embeddinggloc ∈RC×L.
C to1and(cid:12)denoteselement-wisemultiplication.Thefinal
outputis{fstu}T =Reshape(Fstu).
t t=1 Decoder
Teacherblock. Theaudioencoderispretrainedona3D We adopt the same structure for decoding {fstu}T and
t t=1
soundsourcelocalizationdataset(Guizzoetal.2021)while {ftch}T. For decoding the salient object prediction, we
t t=1
it is difficult to obtain a 3D location of vocal objects in follow the FPN structure (Lin et al. 2017) to fuse the low-
panoramicvideosduringmaintraining.Inspiredbyprevious level features. Let the output salient object prediction be
work(Zhangetal.2022),webuildapseudo-siameseteacher {Mstu}T ∈RHo×Wo and{Mtch}T ∈RHo×Wo forstu-
t t=1 t t=1
blocktohelpthenetworkcaptureaccuratespatialinforma- dentand