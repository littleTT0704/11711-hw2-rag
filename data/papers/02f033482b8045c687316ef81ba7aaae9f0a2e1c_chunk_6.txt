q, which 3.2.2 Baselines
hasnon-zeroprobabilityonlyontokensinV1. In
Domain-adaptive pretraining (DAPT; Guru-
this way, adding in the (anti-)experts can be in-
ranganetal.,2020) Wefurtherpretrainthebase
terpretedasmodifyingtheprobabilitydistribution
model on the non-toxic subset of OpenWebText.
overthecandidatetokensinV1,withoutanychance
ThisdatasetisobtainedbyscoringthefullOpen-
ofreintroducingtokensv R V1 fromthetailofthe
WebText corpus with the toxicity classifier from
originalprobabilitydistribution.
PerspectiveAPI4 andkeepingtheleasttoxic2per-
centofdocuments,acorpusofabout150Kdocu-
3 ToxicityAvoidance
ments,or63Mtokens,followingtheimplementa-
GiventhatlargepretrainedLMsareatriskofpro- tionofthisbaselinefromGehmanetal.(2020).
ducingtoxiccontent(Shengetal.,2019;Gehman
Plug-and-play language models (PPLM;
et al., 2020), steering away from toxic “degener-
Dathathri et al., 2020) PPLM uses gradients
ation” is crucial for their safe deployment. Our
fromatoxicityclassifiertoupdatetheLM’shidden
approachusesananti-expertthatmodelsoverttox-
representations. We retrain the classifier to be
icity,aswellasanexpertthatisfinetunedonnon-
compatible with our larger base model size, on
toxicdatafromthesamedomain.
thesametoxicitydatausedintheoriginalpaper.5
Note that while obtaining an LM that is truly
Due to the extreme computational expense of
freefromsocialbiasesisimpossible(Fiske,1993;
PPLM(runtimesareshowninAppendixA.4),we
Lakoff, 1973), the “non-toxic” expert serves the
evaluatePPLMonarandomsubsetof1Kprompts.
purposeofmodelingt