TheThirty-FifthAAAIConferenceonArtificialIntelligence(AAAI-21)
Knowledge-driven Data Construction for Zero-shot Evaluation
in Commonsense Question Answering
KaixinMa1,FilipIlievski2,JonathanFrancis1,3,
YonatanBisk1,EricNyberg1,AlessandroOltramari3
1LanguageTechnologiesInstitute,SchoolofComputerScience,CarnegieMellonUniversity
2InformationSciencesInstitute,ViterbiSchoolofEngineering,UniversityofSouthernCalifornia
3Human-MachineCollaboration,BoschResearchPittsburgh
fkaixinm,jmf1,ybisk,ehng@cs.cmu.edu,ilievski@isi.edu,alessando.oltramari@us.bosch.com
Abstract led to leaps in accuracy—closing the gap between human
andmachineperformancetosingle-digitpercentagepoints.1
Recent developments in pre-trained neural language
However,duetoincreasingconcernthatlarge-capacityneu-
modeling have led to leaps in accuracy on common-
sensequestion-answeringbenchmarks.However, there ral systems are modeling individual datasets, rather than
is increasing concern that models overfit to specific learninghowtoperformlogicalreasoningortoutilizeexter-
tasks,withoutlearningtoutilizeexternalknowledgeor nalknowledgeeffectively(Mitraetal.2019),focusisshift-
performgeneralsemanticreasoning.Incontrast,zero- ingtoalternativetrainingandevaluationstrategies.Inpartic-
shotevaluationshaveshownpromiseasamorerobust ular,zero-shotevaluationshowspromiseasanefficientmea-
measureofamodel’sgeneralreasoningabilities.Inthis sure of model generalisability across tasks (Shwartz et al.
paper, we propose a novel neuro-symbolic framework
2020;Lietal.2020).Here,modelsaretrainedandvalidated
forzero-shotquestionansweringacrosscommonsense
ontaskA,andtestedonadifferenttaskB,withoutaccessto
tasks. Guided by a set of hypotheses, the framework
B’