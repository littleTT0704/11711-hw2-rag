igh-level,sequential,preference-basedpolicyfrom
asingledemonstrationusingaprompt-situationarchitecture. Weintroducedasimulateddishwasher
loadingdatasetwithdemonstrationsthatadheretovaryingpreferences. TTPcansolveacomplex,
long-horizondishwasher-loadingtaskinsimulationandtransfertotherealworld.
Wehavedemonstratedthe TTPâ€™sstrong performancein thedishwasher setting. This environment
isbothcomplexbyvirtueofitsstrictsequentialnatureandyetincompleteasweassumedoorsand
drawers can be easily opened and perception is perfect. In real settings, the policy needs to learn
how to recover from its low-level execution mistakes. More complex preferences may depend on
differences in visual or textural patterns on objects, for which the instance encoder would require
modifications to encode such attributes. An important question to address is how more complex
motion plans interact with or hinder the learning objective, especially due to different human and
8
robotaffordances. Finally,promptsareonlypresentedviademonstration,whilelanguagemightbe
amorenaturalinterfaceforusers.
References
[1] A.Kadian,J.Truong,A.Gokaslan,A.Clegg,E.Wijmans,S.Lee,M.Savva,S.Chernova,and
D.Batra.Sim2realpredictivity:Doesevaluationinsimulationpredictreal-worldperformance?
IEEERoboticsandAutomationLetters(RA-L),2020.
[2] J.Truong,D.Yarats,T.Li,F.Meier,S.Chernova,D.Batra,andA.Rai. Learningnavigation
skillsforleggedrobotswithlearnedrobotembeddings.InternationalConferenceonIntelligent
RobotsandSystems(IROS),2020.
[3] A. Kumar, Z. Fu, D. Pathak, and J. Malik. Rma: Rapid motor adaptation for legged robots.
Robotics: ScienceandSystems(RSS),2021.
[4] D. Kalashnikov, A. Irpan, P. Pastor, J.