 ad-
andthewaytoautomaticallygeneratetemplatequestionsin
ditiontothevideodatasets,weusedescriptionannotations
Section3.1. Taskdefinitionsanddatasetanalysiswouldbe
from Flickr8K [13], Flickr30K [47] and MS COCO [21]
discussedinSection3.2.
as description sources for similarity search. We first parse
3.1.DatasetandQAPairsGeneration the annotations using the way described above and gather
about8,000phrasesintotal,resultingaveragelengthof6.6
We in total collect over 100,000 videos and 400,000
words per phrase. After the preprocessing, we further fil-
questions, while QA pairs are generated from existing
terthecandidatesusingword2vec[24]toretrievethenear-
datasetsindifferentdomains,fromcookingscenario,DVD
estphrasesincosinedistance. Thephraserepresentationis
movies,towebvideos:
generatedbyaveragingthewordvectors[20,22].
1. TACoS Multi-Level [27]. TACoS dataset consists of 1https://wordnet.princeton.edu
127 long videos with total 18,227 annotations in the 2http://www.nltk.org/
3
Pineapple
Dog
Category: Animal Category: food/plant
plant Q: A/An ____ swims in a pool. Q: A man cutting a ____ in the food market.
Easy distractors: Hard distractors: Easy distractors: Hard distractors:
artifact - bee - cat - duck - dolphin - snowball - grapefruit - cucumber
food - horseback - clam - goose - bear - popcorn - broccoli - lemon
action - bird - cow - penguin - elephant - seed - orange - strawberry
- wheat - watermelon
animal Category: Actions
Q: He __ her.
- hugs
- kisses
Figure2.t-SNEvisualizationofwordembeddingsforeachcate-
- beats
gorylearnedfromword2vecmodel.Bestviewedincolor. - runs towards
Category: Actions
Q: Someone walks toward
Datasets verbs phrases animals food/plant otherobjects t -