!Left-to-Right!DenoiseToken }
simpleformulaforautomatically
New-Obj2= {In-domain!No-Op
..!.
RandomFactorized!TF-IDF
}
Figure 2: Our framework in the context of NLP. We
generatingalargesetofcandidate
decomposenamedobjectiveswithinourfourstagedtaxonomy:
objectives: take the cartesian
,,,. Bytakingthecartesianproductofchoicesacross
product of the design decisions
{D T R O}
stages,wereproducenamedobjectivesanddiscovernewones.
across given stages (Figure 2).
Using this compositional process, not only can we reconstruct existing named objectives, we
canalsogeneratenewcombinations. Thisovercomesthetediumofimplementingeachobjective
independentlysincewecanjustreuseasmallsetofsimplestage-wiseprimitives.
Generatingalargesetofobjectivesraisesthenaturalquestionofhowtoefficientlyselectthemost
helpfulonesforagivenendtask.Insteadofleavingthistopractitionerintuition,wedevelopprincipled
guidelinestoaddressthisquestionbytheoreticallystudyingtheimpactofauxiliarylearningona
particularend-task. Specifically,usingargumentsbasedonalgorithmicstability(Hardtetal.,2016;
2
Bousquet&Elisseeff,2002),wederiveend-taskgeneralizationerrorboundsthataredependenton
thechoiceofauxiliarytask. Thiscontributestoexistingtheory(Saunshietal.,2020;Xieetal.,2021)
onhowauxiliarylearningimpactstheend-taskbysuggestinganewcandidatemechanism: auxiliary
learningresultsinmorestableoptimizationend-pointsinthesenseofBousquet&Elisseeff(2002),
whichintheoryimprovesgeneralizationofthefinalmodel.
Guidedbyourtheory,weintroduceAANG(AutomatingAuxiliaryLearniNG),anefficient,structure-
awarealgorithmforadaptivelycombiningasetofrelatedobjectivestoimprovegeneralizationona
specificend-task. AANGincorporatest