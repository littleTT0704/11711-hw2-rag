embeddingandeverylabel’sembedding.
Giventhesesimilarityvalues,wethenuseaSoftMaxactivationandBinaryCrossEntropylossto
calculatethelossbetweenouroutputsandthetargetlabels. TheoverallframeworkisshowninFigure
4.
HerewereplacethebaselineOntologicalLayerwiththelabelembeddingsthattheGCNgenerates.
TocombineitwithSiameseNetwork,westillkeeptheλ,λ andλ forthelossterm. Nextwewill
1 2 3
discusstheexperimentsinmoredetailandtheresultsfromthevariousmodels.
4 Experiments
4.1 EvaluationMetrics
The performance of our models is evaluated using weighted average precision and AUC from
predictions. AllreportedmetricsareonthetestsetoftheAudiosetdataset. Asdiscussedpreviously,
6
Figure4: TheframeworkofSiameseNetwork+GraphConvolutionalNetwork
weextractthelabelsforeachsegmentfromthetoptwolevelsoftheAudiosetontology. Theaverage
precision(AP)metricisfirstcomputedforeachclassbyconsideringtheprecision(fractionoftrue
positivelabelsoutofallpredictedpositivelabels)-recall(fractionoftruepositivelabelsoutofactual
positive labels) curve at different thresholds. Thus it is an indication of how well the model can
identifypositiveclassesinthedata. TheothermetricweconsiderisAUC,whichconsidersnegative
labelsbycomputingtheareaundertheTPR(truepositiverate)-FPR(falsepositiverate)curveand
isanindicationofhowwellthemodelcandistinguishbetweenclasses. TheAP/AUCmetricforthe
classesonthesameontologyleveliscombinedthroughaweightedaveragebasedontheproportion
ofeachclassthatispresentinthetrainingdatatogetafinalweightedAPandweightedAUCscore
foreachlevel.
4.2 PerformanceofMLPModelwithnoOntologyInformation
TheMLPmodelwithnoontologyinformationachievesaweightedAP/AUCscoreof0.45099/0.8706,
respectivelyforsubclasses. Theweighted