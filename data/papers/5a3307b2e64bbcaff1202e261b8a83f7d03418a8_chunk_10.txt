the
research. complete list of AMs is available in the appendix). The chosen
AMsarecategorizedasproportion,anglesanddistanceofasetof
3 METHOD facelandmarks.Thoseintra-facefeaturesaremorerobustthan3D
coordinaterepresentationsasthevariationsresultingfromspatial
In this section, we first introduce the task formulation and then
misalignmentarecompletelyeliminated.
demonstrateourmethodindetail.
Uncertainty-aware AM estimation. The AM prediction is con-
3.1 Formulation ductedbyanestimatortrainedwithanuncertainty-awarescheme.
We aim to reconstruct any speakerâ€™s 3D facial shape from their
Letğ¹ ğ‘˜(ğ‘£;Eğ‘˜,ğœ” ğ‘˜):ğ‘£ â†¦â†’Rbeanestimatorthatmapsvoicerecording
voice recordings. Given a set of paired voice recordings and 3D ğ‘£ intotheğ‘˜-thpredictedAMs,whereEğ‘˜ andğœ” ğ‘˜ arethelearnable
facialshapes{(ğ‘£ ğ‘–,ğ‘“ ğ‘–)}fromdifferentindividuals,whereğ‘£ ğ‘– isavoice parameters.Asthisisaregressionproblem,weleverage
r s fae c cc a io n ar n ld e si dn hg af pros ep mo ğ‘“k t ohe fen asb npy yea st kh pee er ağ‘– ko- et fh rğ‘£ fğ‘–p r.e oTr ms ho e tn hg ea o in rad l vi oğ‘“ sğ‘– icti o es rra ee cc3 ooD rn ds if t nra u gc ci ğ‘£a t.l th Is neha o3p uDe
r
{E ğ‘˜âˆ—,ğœ” ğ‘˜âˆ—}=ar Eg ğ‘˜,m ğœ”ğ‘˜in |D1 ğ‘¡| (ğ‘£,ğ‘šâˆ‘ï¸ (ğ‘˜))âˆˆDğ‘¡(ğ¹ ğ‘˜(ï¿½