atorswithknowledge
plessothesystemcanlearnfromhumanshowto ofNLPwereaskedtoannotatethedata.2
discuss,accept,orobjecttotheprovidedopinions First,theannotatorswerepresentedwithpremise
aboutthetopic. and hypothesis sentences and asked to predict la-
Theresultsofbothquantitativeandhumaneval- bels such as entailment, contradiction, or neutral.
uation demonstrate that a system could perform Werandomlypairedtwoannotatorstohavethem
more informative discussions by training to have assign labels for the same premise and hypothe-
a discussion with few-shot learning (Section 5). sis. Then, theydiscussedthelabelsthattheyhad
We also found that providing the system with in- assigned differently and decided on the final la-
formationaboutthediscussiontopicimprovedits belsbasedonthosediscussions. Thepremiseand
performanceinmanycasescomparedtothesystem hypothesissentencesweresampledfrom300prob-
that did not have access to such information. On lemsfromthedevelopmentdataand750problems
theotherhand,thediscussionrevealedthatthesys- fromtheevaluationdataofSNLI.Thesewereused
temtendstobetoocompliantwithhumanopinions. asdevelopmentandevaluationdatainthediscus-
Therefore,addressingtheriskoftransmittingincor- siondata,respectively. Eachannotatorpairisasked
rectknowledgeormaliciouslyalteringthesystemâ€™s topredictthelabelsof150problems. SNLIdevel-
knowledgeofhumansisnecessary. Wealsoshow opmentdataoriginallyconsistsofproblemswith
thatfew-shotusageofdiscussiondatacanenable labels from five crowd workers, and the majority
thesystemtocounterhumanargumentscorrectly vote of these labels determines the golden label.
(Section6). Finally,wedemonstratethatusingdis- Tofindrelativelyhardcasesthatmightspurmore
cussiondatageneratedbythesystem(Wangetal., discussion, we sampled problems for annotation
2022b;Huangetal.,2022)canachieveequivalent fromthoseinwhichthreeofthefivehadthesame
results to those of the system that used manually