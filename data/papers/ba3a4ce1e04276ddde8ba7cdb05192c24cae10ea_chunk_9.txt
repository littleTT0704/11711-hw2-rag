ingtakesZ = {z }T asinput. Thisundergoestwoindepen-
i i=1 4.2. Setup
dentlearnedlineartransformationtoproduceclassificationand
attentionoutputrespectively. Theattentionoutputissquashed Therawdataisconvertedtotime-frequencyrepresentationby
toensureitsvalidprobabilitydistribution. Mathematically,the applying FFT with a window size of 2048 and an overlap of
attentionoutputZ a1 andclassificationoutputZ c1 are: 1024betweenwindows. ThisisfollowedbyapplyingMelfil-
ter banks with 64 bands and converting them to log scale to
Z =
eσ(ZWaT 1+ba1)
Z =(ZWT +b ) (4) obtainlogMelspectrogram. Thenetworkarchitectureusedis
a1 (cid:80)F i=1eσ(ZWaT 1+ba1) c1 c1 c1 describedinsection3.2. Theentirenetworkistrainedend-to-
end with a batch size of 24 and learning of 1e-3 using Adam
This is followed by a weighted combination of classification optimiser[32].Thecodeandsetupispubliclyreleased2.
outputZ byattentionweightsZ :
c1 a1
5. Results
F
(cid:88)
Z = Z ·Z (5)
p1 c1 a1 5.1. Soundeventdetection
i=0
Weevaluateourself-supervisionassistedarchitectureandpool-
Thetimelevelattentionissimilartofrequency(firststep)atten-
ingmethodagainstdifferentbaselines,benchmarkarchitectures
tionexceptitoperatesalongtimeaxis:
and pooling methods [14, 10]. Table 1 shows weakly super-
Z =
eσ(Zp1WaT 2+ba2)
Z =(ZWT +b ) (6)
v oi fse 2d 0,s 1o 0u,n ad ndev 0en dt Bd.e Tte hc etio imn pp oe rr tf ao nr tm ea vn ac le uaa tc ioro nss md ei tf rf ie cre hn et reSN unR