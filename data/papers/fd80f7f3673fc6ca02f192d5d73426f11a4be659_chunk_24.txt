%
MATESE-QE ✗ 73.4% 0.298 57.9% 0.468 50.1%
COMET-WL ✗ 71.6% 0.418 57.1% 0.406 51.5%
ScorePrediction
PaLM-2BISON ✓ 86.4% 0.394 56.8% 0.322 49.3%
PaLM-2UNICORN ✓ 86.4% 0.401 56.3% 0.349 51.1%
PaLM-2BISON ✗ 84.0% 0.355 57.0% 0.299 48.6%
PaLM-2UNICORN ✗ 80.5% 0.275 56.1% 0.252 48.3%
AutoMQM
PaLM-2BISON ✓ 84.0% 0.369 59.2% 0.355 48.4%
PaLM-2UNICORN ✓ 87.6% 0.432 59.1% 0.442 51.8%
PaLM2BISON ✗ 87.6% 0.297 55.2% 0.331 48.0%
PaLM2UNICORN ✗ 83.4% 0.368 56.4% 0.429 50.2%
Table5: Meta-evaluationresultsforPaLM-2modelsusingAutoMQM andscoreprediction,atthesystem
andsegmentlevelsformultiplelanguagepairs.
thattheexamplesetsthatperformwellforonetask Table 5 shows the meta-evaluation results for
generallyworkwellfortheother,withperformance PaLM-2 BISON and UNICORN prompted with
onbothsettingsgivenafixedin-contextsetbeing AUTOMQM(usingthebest-performingin-context
highlycorrelated,asshowninFigure9. learningsetsinFigure8). Foreaseofcomparison,
wealsoreporttheirperformancewhenprompted
for score prediction, as well as the performance
of the baselines. Overall, prompting LLMs with
Corr = 0.941
6 AUTOMQM seemstoleadtosignificantimprove-
0.35 ments in evaluating machine translation quality,
0.30 5 particularlyforlargermodels: UNICORNachieves
0.25 better performance (across all meta evaluations)