lim- and wave your hand in front of the robot – you should see
itedcomputethanisavailableonasimilarworkstation.We minimallatencywhenwavingahandinfrontofthecamera.
this with a simple network configuration shown in Fig. 4. Timingbetweentherobotandtheremoteworkstation.
Therearethreecomponents: We use ROS (Quigley et al. 2009) as our communications
layer,andtoimplementlow-levelcontrolontherobot.This
1. The desktop running code – in our case, the
alsoprovidesnetworkcommunication.However,duetopo-
eval episode.py script from HomeRobot – which
tentiallatencybetweentherobotanddesktop,wealsoneed
connectstoaremotemobilemanipulator.
tomakesurethatobservationsareuptodate.
2. Thededicatedrouter–anoff-the-shelfconsumerrouter, We set up the robot to block after executing most navi-
suchasaNetgearNighthawkrouter.Thisshouldideally gationmotions,inordertomakethisprocesssimpler,until
520
AgentsandEnvironments,similartohowmanyreinforce-
mentlearningbenchmarksaresetup(Savvaetal.2019).
• Agentscontainallofthenecessarycodetoexecutepoli-
cies.Weimplementagentswhichuseamixtureofheuris-
ticpoliciesandpolicieslearnedonourscenedatasetvia
reinforcementlearning.
• Environments provide Observations to the Agent, and
a function which allows them to execute actions in the
(realorsimulated)environment.
RobotControl
We expand on the basic Stretch low-level control in order
to make it easier to control the robot. In particular, we im-
plemented a high-level motion planner, integrated different
graspingandplacementstrategies,andalsoimplementedre-
activelow-levelcontroltomakeiteasiertomovetherobot
Figure4:SystemoverviewforHomeRobot.Werunvisual- aroundintherealworldfordifferentmethods.
izationsanddeepneuralnetworksonaGPU-enabledwork-
station; the