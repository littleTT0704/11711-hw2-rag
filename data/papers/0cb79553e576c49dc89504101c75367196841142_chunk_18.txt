oth.
Roberta: A robustly optimized bert pretraining ap-
2023. Conversation style transfer using few-shot
proach. ArXiv,abs/1907.11692.
learning. arXivpreprintarXiv:2302.08362.
XinyaoMa,MaartenSap,HannahRashkin,andYejin
MaartenSap,DallasCard,SaadiaGabriel,YejinChoi,
Choi.2020. PowerTransformer: Unsupervisedcon-
and Noah A. Smith. 2019. The risk of racial bias
trollablerevisionforbiasedlanguagecorrection. In
inhatespeechdetection. InProceedingsofthe57th
Proceedings of the 2020 Conference on Empirical
AnnualMeetingoftheAssociationforComputational
MethodsinNaturalLanguageProcessing(EMNLP),
Linguistics,pages1668–1678,Florence,Italy.Asso-
pages7426–7441,Online.AssociationforComputa-
ciationforComputationalLinguistics.
tionalLinguistics.
MaartenSap,SaadiaGabriel,LianhuiQin,DanJuraf-
EricMalmi,AliakseiSeveryn,andSaschaRothe.2020. sky, NoahA.Smith, andYejinChoi.2020. Social
Unsupervisedtextstyletransferwithpaddedmasked biasframes: Reasoningaboutsocialandpowerim-
languagemodels. InProceedingsofthe2020Con- plicationsoflanguage. InProceedingsofthe58th
ferenceonEmpiricalMethodsinNaturalLanguage AnnualMeetingoftheAssociationforComputational
Processing(EMNLP),pages8671–8680,Online.As- Linguistics,pages5477–5490,Online.Association
sociationforComputationalLinguistics. forComputationalLinguistics.
KrisMcGuffieandAlexNewhouse.2020. Theradical- Maarten Sap, Swabha Swayamdipta, Laura Vianna,
izationrisksofGPT-3andadvancedneurallanguage Xuhui Zhou, Yejin Choi, and Noah Smith. 2022.
models.