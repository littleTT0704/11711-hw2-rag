,FengjiZhang,AnhNguyen,DaoguangZan,
LanguageProcessing,pages1643–1652.
ZeqiLin,Jian-GuangLou,andWeizhuChen.2022.
Codet: Codegenerationwithgeneratedtests. arXiv
YuhangLai,ChengxiLi,YimingWang,TianyiZhang,
preprintarXiv:2207.10397.
Ruiqi Zhong, Luke Zettlemoyer, Scott Wen-tau
Yih, Daniel Fried, Sida Wang, and Tao Yu. 2022.
MarkChen,JerryTworek,HeewooJun,QimingYuan,
Ds-1000: A natural and reliable benchmark for
Henrique Ponde de Oliveira Pinto, Jared Kaplan,
data science code generation. arXiv preprint
Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
arXiv:2211.11501.
Brockman, et al. 2021. Evaluating large lan-
guage models trained on code. arXiv preprint
YujiaLi,DavidChoi,JunyoungChung,NateKushman,
arXiv:2107.03374.
Julian Schrittwieser, Rémi Leblond, Tom Eccles,
James Keeling, Felix Gimeno, Agustin Dal Lago,
NaihaoDeng,ShuaichenChang,PengShi,TaoYu,and
etal.2022. Competition-levelcodegenerationwith
Rui Zhang. 2021. Prefix-to-sql: Text-to-sql genera-
alphacode. arXivpreprintarXiv:2203.07814.
tionfromincompleteuserquestions. arXivpreprint
arXiv:2109.13066.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
maticevaluationofsummaries. InTextSummariza-
Li Dong and Mirella Lapata. 2016. Language to logi-
tion Branches Out, pages 74–81, Barcelona, Spain.
calformwithneuralattention. InProceedingsofthe
AssociationforComputationalLingu