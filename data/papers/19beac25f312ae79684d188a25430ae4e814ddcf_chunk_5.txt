 interfaces for vari-
icsofthereal-world,weassertthatthepotentialformodel
ous sensor modalities and provides an OpenAI-gym com-
transferfromtheseframeworksremainslimited.
pliant training and testing environment for learning-based
agents; (iii) an official L2R task and dataset with expert
2.3.LearningParadigms
demonstrations, metrics, and reference evaluation proce-
dures; and (iv) an academic release of the simulator, code Wediscussvariouslearningparadigmsthatareenabledby
for the L2R framework, and implementations of baseline thesimulationofautonomousdriving.
agentstofacilitatefullreproducibilityandextension.
Learn-to-Race (L2R)
Racing Simulator Agent
Task Framework
Sensor Models + Placement Camera Tracker + Obs. Policy
Interface Metrics
Signals
IMU Localisation
Environment / Maps
Interface Interface
Actions
Vehicle Building + Config. Commands Action Gym
Interface
Simulator Reward Rewards
API
Control Function
Figure2: Learn-to-Raceallowsagentstointeractwiththeracingsimulatorthroughaseries
ofinterfacesforobservations,actions,andsimulatorcontrol.
Simulation-to-realtransfer. DeepRacer[5],developedby OpenAISafetyGym)lackrealisticdynamicsandtheyeval-
Amazon WebServices, providesan end-to-end framework uateagentsatmuchlowerspeeds; thus,thenumerouslim-
for training and deploying 1/18th-scale autonomous rac- itations of existing methods cannot be studied comprehen-
ing cars. The Indy Autonomous Challenge [1] encourages sively.WeassertthatthephysicalrealismthatL2Rprovides
institutions to create autonomous vehicle technology; par- facilitatesimprovementofthoseunderlyingapproaches.
ticipants are given the proprietary VRXPERIENCE driv-
ing simulator, which focuses more on optimising human- 3.SimulationEnvironment
machine interactions within the vehicle, in the context of
situational highway driving, which contrasts with our fo- 3.1.ArrivalAutonomousRacingSimulator
cus in this work on autonomous racing. Roborace [2] is
The Arrival simulator is a powerful