 Toward a 'Standard Model' of Machine Learning
Mapping the standard equation to this setting, we show the informativeness measure u(x) is subsumed as part
of the experience. Intuitively, u(x) encodes our heuristic belief about sample ‘informativeness’. This heuristic
is a form of information we inject into the learning system. Denote the oracle as o from which we can draw a
label y∗ ∼ o(x∗). The active supervision experience function is then defined as:
f :=f active(x,y;D) =logEx∗∼D,y∗∼o(x∗)[I(x∗,y∗)(x,y)]+λ⋅u(x), (4.10)
where the first term is essentially the same as the supervised data experience function (Equation 4.2) with the
only difference that now the label y∗ is from the oracle rather than pre-given in D; λ > 0 is a trade-off
parameter. The formulation of the active supervision is interesting as it is simply a combination of the common
supervision experience and the informativeness measure in an additive manner.
We plug f into the SE and obtain the algorithm to carry out learning. The result turns out to recover
active
classical active learning algorithms.
Active learning. Specifically, in Equation 3.2, setting f = f, and (α = 1,β = ϵ) as in supervised
active
MLE, the resulting student-step in Equation 3.3 for updating θ is written as
m θaxEx∗∼p~
d(x)⋅exp{λu(x)},
y∗∼o(x∗)[logp θ(x∗,y∗)].
(4.11)
If the pool D is large, the update can be carried out by the following procedure: we first pick a random subset
D from D, and select a sample from D according to the informativeness distribution proportional to
sub sub
exp{λu(x)} over D. The sample is then labeled by the oracle, which is finally used to update the target
sub
model. By setting λ to a very large value (i.e., a near