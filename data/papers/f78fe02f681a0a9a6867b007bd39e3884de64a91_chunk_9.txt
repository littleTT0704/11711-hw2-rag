0
Figure2: Resultsofhead-to-headcomparisonbetweendialoguesfrom SODA,DailyDialog(Lietal.,2017),and
BlendedSkillTalk(Smithetal.,2020)viahumanjudgments(§3.2). They-axisrepresentsthenumberofsamples
preferredbyhumanjudges. ThedifferencesinallofthecategoriesexceptfortheContextDependencecomparing
SODAandBlendedSkillTalkarestatisticallysignificant(|z|>3.3, p<0.05).
SafetyFiltering Inordertoavoidconversations on the human-annotated subset, with a precision
with dangerous and harmful contents, we apply of 97 for answering “yes". We find 95% of the
twosafetyfilters: Canary(Kimetal.,2022a)and filteredconversationsareidentifiedbyGPT-3.5as
RewireAPI.6 Canaryisanarrativedialoguesafety containingtheheadevent. Pairsthatlackthehead
modelthatcanclassifywhetherthegivencontext event are removed to ensure relevance between
needscautionorintervention. Wediscardallcon- thenarrative-conversationpairsandcommonsense
versationsmarkedasneedingintervention(usually triples. MoredetailsareinAppendixB.1.
criticalsituations,e.g.,crimes,emergencies;4.3%);
Final Dataset After all filtering, 68.9% of the
RewireAPIisaweb-basedAPIfordetectingtoxic
initial conversations remain, which form the
content. Wediscardallconversationsthatareabove
thethresholdof0.5foranyofthe‘violence’,‘hate’,
1,486,896conversationsin SODA.
and‘sexuallyexplicit’criteria(∼1%).
NameBiasMitigation Weaimtominimizebi-
Commonsense Filtering We conduct a small- asesassociatedwithspecificnameswhileincreas-
scale human evaluation via Amazon Mechani- ing inclusion and diversity. Both language mod-
cal Turk with 100 randomly sampled narrative- elsandcurateddatasetsoftenexhibitdemographic
conversation pairs (3 annotators per instance) to