rast,bothSphereFace-Rv1 suchahardnormalizationonthefeaturex,weparameterize
m
andv2exactlyfollowtheintuitionofmultiplicativemargin theoriginalxinEq.(5)withs x andarriveatEq.(6).Since
(cid:107)x(cid:107)
in the entire domain of [0,π]. SphereFace-R v1 implements sisaprescribedconstant,itisequivalenttonormalizingall
a dynamic multiplicative margin (i.e., the effective margin thefeaturestoahyperspherewithradiuss.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 9
Softfeaturenormalizationasaninterpolation.Weconsider
thesoftfeaturenormalizationthatinterpolatesbetweenFN- 60 60
freelearningandHFN.Specifically,besidestheoriginalloss, 40 40
20 20
we combine an additional regularization term to constrain Q0 Q 0
-20 -20
thefeaturemagnitude: -40 -40
-60
(cid:13) (cid:13)2 3 3
wheretisahyperpL aS rF aN m= etet r· t(cid:13) h(cid:107) ax t(cid:107) co− nts r(cid:13) olstheregularizat( i1 o8 n) (a2 θ )i No1 rmali0 zed0 Softm1
ax
θ (y s=32
0)
3 2 θi (b1
)
Sph0 er0
eFace
(1 s=3θ 0y )2 3
strengthandsisaprescribedfeaturemagnitudethatserves
asimilarroletoHFN.Whent = 0,SFNreducestoFN-free
learning. When t = +∞, SFN reduces to HFN. Therefore, 50 100
50
SFN can be viewed as an interpolation between FN-free Q0 Q0
learningandHFN.SFNhasalsobeenstudiedin[10].
-50 -50
SFN can make use of the instance-level information -100