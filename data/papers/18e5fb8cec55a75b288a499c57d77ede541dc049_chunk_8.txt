Since there is no pre-defined train/dev/test split for CSKG, ExamplequestionswitheachpartitionareshowninTable
we randomly sample 5% of generated questions as devel- 1.ForATOMIC,thisproceduregenerates535KQApairsfor
opment set, while the other 95% are used for training, to training and 60K for development. For CWWV, the training
maximizethecoverageoftheknowledge. setcontains157Kandthedevsethas8KQApairs.
Generatingquestionsandanswers Ifatriple(h,r,t)has
DistractorSampling
an associated sentence, we directly employ it for question
generation; otherwise, we generate a sentence in a lexical- Existing data generation procedures are likely to introduce
ization step, using a set of pre-defined templates. Next, we annotation artifacts in datasets (Zellers et al. 2019; Sak-
generatethequestionQbyremovingthetailofthesentence, aguchi et al. 2019). Models may exploit these artifacts to
and extract this tail as the correct answer, A. Here, we en- achieve spuriously strong performance during training, at
surethatthereisnotokenoverlapbetweentheheadandthe theexpenseofdegradationinrobustness.Togeneratemore
correct answer. For ATOMIC, we: 1) compare the keyword challenging QA pairs from KGs and to alleviate potential
tokensinsteadofalltokens,inordertoavoidstopwords;and biasesinoursyntheticsets,wetesttwootherdistractorsam-
2) the agent templates (e.g., ‘PersonX’) are replaced with pling strategies in addition to the random strategy: 1) we
randomlysampledgender-neutralnamesfromapre-defined select distractors that are as similar as possible to the an-
set.ForCWWV,wefilteroutquestionswhereeitherthehead swer, while being under a certain threshold (adv-answer);
orthetailarenotcommonconceptsortheyarenamedenti- and 2) we select distractors that are as similar as possible
ties.Weusecorpusfrequencyasaproxyforcommonness,3 tothequestion,whilebeingunderacertainth