tionofdeepneuralnetworksfortheoremproving math-related tasks compared to natural language
isproposedin(Alemietal.,2016),whichrelieson tasks. There is also less mathematical or scien-
convolutionalnetworksforpremiseselection. tificdataavailableforlarge-scalepre-trainingcom-
paredtotextdata. Second,thesizeofpre-trained
Multimodalmathematicalreasoningtasks,such
models continues to grow, making it expensive
as geometry problem solving and diagram-based
totraintheentiremodelfromscratchforspecific
mathematicalreasoning,areformalizedasvisual
downstreamtasks. Additionally,downstreamtasks
question answer (VQA) problems (Kafle et al.,
may deal with different input formats or modali-
2018;Chenetal.,2021a;Luetal.,2021b). Inthis
ties, such as structured tables (Zhao et al., 2022)
domain, visual inputs are encoded using ResNet
or diagrams (Lu et al., 2021b). To address these
(Heetal.,2016)orFaster-RCNN(Renetal.,2015),
challenges,researchershavetoadjustpre-trained
whiletextualrepresentationsareobtainedviaGRU
modelsbyfinetuningthemondownstreamtasksor
orLTSM.Subsequently,thejointrepresentationis
adaptingtheneuralarchitectures.
learnedusingmultimodalfusionmodels,suchas
BAN(Kimetal.,2018),FiLM(Perezetal.,2018),
andDAFA(Gaoetal.,2019). 4.1 Self-SupervisedLearningforMath
Otherdeepneuralnetworkstructurescanalsobe
Self-supervisedlearningisamachinelearningap-
usedinmathematicalreasoning. AGraphNeural
proachinwhichanalgorithmlearnstoperforma
Network (GNN) is employed for geometry prob-
taskwithoutbeingexplicitlyprovidedwithlabeled
lem parsing in Zhang et al. (2022), taking advan-
training data. Table 2 provides a list of language
tageofitssuccessinspatialreasoning. WaveNet
models pre-trained