h d+ i))+∑ d− j∈B/Dn∗ exp(sim(h n,h d− j))
2https://github.com/elastic/elasticsearch
3
PublishedasaconferencepaperatICLR2023
whereh istherepresentationofxcomputedbyaneuralencoder,andBarepositivedocsforother
x
examplesinthebatch. Wedefinesim(h,h )asthecosinesimilaritybetweenh andh.
x y x y
Weuseall(n,d+)inthetrainingsetasoursupervisedtrainingdataset. Additionally,weuseall
i i
sentencesinthedocumentationpoolforweaksupervision:FollowingChenetal.(2020)andGaoetal.
(2021),representationsofthesamesentencewithdifferentdropoutmasksaretreatedasapositive
example. InsteadofusingeithersupervisedorweaklysupervisedtrainingasinGaoetal.(2021),we
simplymixthetworesultingsupervisionsignals,andexamplesarerandomlydistributedintobatches.
Thismixtureoftasksnotonlyfacilitatesthelearningprocess(§6.2),butalsoreducestheengineering
effortrequiredtostoreandreloadmodelsforseparatesupervisedandunsupervisedtrainingphases.
WeinitializetheretrieverencoderwitheitherthebestmodelofGaoetal.(2021)ortheencoderof
CodeT5-base(Wangetal.,2021). AdditionaltrainingdetailsareprovidedinAppendixC
3.2 GENERATORINSTANTIATION
Weexperimentedwithavarietyofgeneratormodels.WeusedGPT-Neo-125M,GPT-Neo-1.3B(Black
etal.,2021)andCodex(Chenetal.,2021),whereweconcatenatetheretrieveddocumentsandthe
NLintentasasingle, long, prompt. T5-base(Raffeletal.,2019)andCodeT5-base(Wangetal.,
2021)haveashorterinputsizeof512tokens,whichissometimestooshortfortheconcatenationof
multipledocs.