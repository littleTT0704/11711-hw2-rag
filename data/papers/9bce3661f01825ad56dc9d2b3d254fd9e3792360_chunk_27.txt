, Adam
takaMatsuo,andYusukeIwasawa.2022. Largelan- Roberts,NoahFiedel,andKarishmaMalkan.2020.
guagemodelsarezero-shotreasoners. arXivpreprint WT5?! trainingText-to-Textmodelstoexplaintheir
arXiv:2205.11916. predictions.
SawanKumarandParthaTalukdar.2020. NILE:Natu- YixinNie,AdinaWilliams,EmilyDinan,MohitBansal,
rallanguageinferencewithfaithfulnaturallanguage JasonWeston,andDouweKiela.2020. Adversarial
explanations. In Proceedings of the 58th Annual NLI:Anewbenchmarkfornaturallanguageunder-
Meeting of the Association for Computational Lin- standing. InProceedingsofthe58thAnnualMeet-
guistics,pages8730–8742,Online.Associationfor ingoftheAssociationforComputationalLinguistics,
ComputationalLinguistics. pages4885–4901,Online.AssociationforComputa-
tionalLinguistics.
HimabinduLakkaraju,DylanSlack,YuxinChen,Chen-
hao Tan, and Sameer Singh. 2022. Rethinking ex- DaisukeOba,MasahiroKaneko,andDanushkaBolle-
plainabilityasadialogue: Apractitioner’sperspec- gala.2023. In-contextualbiassuppressionforlarge
tive. languagemodels. ArXiv,abs/2309.07251.
WangLing,DaniYogatama,ChrisDyer,andPhilBlun- OpenAI.2023. IntroducingChatGPT.
som.2017. Programinductionbyrationalegenera-
tion: Learningtosolveandexplainalgebraicword DongHukPark,LisaAnneHendricks,ZeynepAkata,
problems. InProceedingsofthe55thAnnualMeet- AnnaRohrbach,BerntSchiele,TrevorDarrell,and
ingoftheAssociationforCom