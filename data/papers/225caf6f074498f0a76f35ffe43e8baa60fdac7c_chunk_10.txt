thesameamountofdataaswasdone
variable. TheotherencoderrepresentstheN lan-
in Artetxe and Schwenk (2019b), detailed in Ap-
guage inference networks and produces the lan-
pendix B. The only deviation being that we take
guagevariablesforeachlanguage. Theseinference
caretonotincludeanyTatoebatestdatainourtrain-
networks are shown on the left side of Figure 2.
ingdata. Ourfinalcorpushasnearly216million
Wemean-poolthehiddenstatesfollowedbyalin-
training examples, slightly less than 220 million
ear projection to produce each variable from the
reportedinArtetxeandSchwenk(2019b). Weuse
encoders.
both English and Spanish as pivot languages, so
Thesemanticinferencenetwork,whichmodels
each pair includes at least one English or Span-
q(z |x,x ;Ï•), is a multilingual encoder that
sem li lj
ishsentence,andweuseapproximatelythesame
encodeseachlanguage. Foreachtranslationpair,
wealternatewhichofthetwoparallelsentencesis 3http://opus.nlpl.eu/Europarl.php
fed into the semantic encoder within a batch for 4https://opus.nlpl.eu/UN.php
5http://opus.nlpl.eu/OpenSubtitles.php
theELBOtermintheobjective. Sincetheseman-
6https://opus.nlpl.eu/GlobalVoices.php
ticencoderismeanttocapturelanguageagnostic 7https://opus.nlpl.eu/Tanzil.php
semanticinformation,itsoutputsforatranslation 8https://opus.nlpl.eu/Tatoeba.php
amountofdataforeachlanguage. Wenotethatwe cosinesimilarityinbothdirectionsforall112lan-
onlyhavetrainingdatafor92languagesinsteadof guages (19 are unseen in the training data) and
the93inArtetxeandSchwenk(2019b)duetonot averagethisscoreforalllanguages.
havingtrainingdataforAymara(ay). The goal of the BUCC task is to find the gold
aligned