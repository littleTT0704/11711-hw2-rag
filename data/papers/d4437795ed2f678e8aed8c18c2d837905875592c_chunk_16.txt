 the challenge is to incrementally integrate a
vast amount of information over time to compactly and explicitly represent what we know, how
it can appear, and how it can be applied for object and scene interpretation.
3.2.4. Perception and action
Perception is more than just vision and is highly enhanced by directed “actions.” It should
be viewed as a composition of processes that use sensory information from several different
modalities and/or different cues. This view implies the following research agenda: a) modeling
of individual sensory capabilities and limitations; b) modeling of individual cue capabilities and
limitations; c) determining a common representation space for integrating the information
obtained from different modalities; d) designing integration rules and methods for combining
information; e) developing control strategies for data acquisition; and f) studying the amount
perceptual information needed for a given task.
The last question points us to the issue of “task” modeling. We believe that there is no
such thing as perception without purpose. Hence, the task drives what sensory information and
how much of it will be processed for a given task or subtask.
The “activity” is apparent in this agenda described above. If the task requires accuracy or
view that the first measurement did not provide then one must “act,” i.e., take more and dif­
ferent measurements. Many problems such as ambiguities that arise from spatial alignments can
be disambiguated by simple actions of moving, grasping, or pushing. The performance of the
task can then be used to evaluate the performance of the perceptual system.
3.3. Implications for System Architectures
The computational requirement of vision algorithms is high and is predicted to be at least
tens of trillions of operations per second. Consider an autonomous vehicle moving through an
unstructured environment (e.g., a mobile robot operating as a hazardous-waste cleanup
machine). Assuming color stereo sensors operating at 30 frames per second, the input data rate
November 23,1992 13
will be roughly 50 megabytes per second using standard resolution images (512-by-512 pixels),
or 200 megabytes per second at higher resolution (1024-by-1024 pixels). From this data it is
necessary to extract multiple features (such as two-dimensional lines, regions and texture
patches, and three-dimensional lines, surfaces and volumes).