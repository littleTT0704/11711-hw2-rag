 of each token in the
code to verify its functional correctness (Chen generated code and each token in the reference
et al., 2021; Athiwaratkun et al., 2022; Li et al., code. Finally,thebestmatchingtokenvectorpairs
2022; Wang et al., 2022; Lai et al., 2022). This are used to compute precision and recall. Code-
provides a direct measure of the functionality of BERTScore allows comparing code pairs that are
the generated code while being agnostic to di- lexically different while taking into account the
versity in implementation and style. However, (1) programmatic- or natural-language-context, if
execution-based evaluation requires datasets that such provided; the (2) contextual information of
areprovidedwithhand-writtentestcasesforeach eachtoken;and(3)implementationdiversity. Our
example, which is costly and labor-intensive to approachisillustratedinFigure2.
create; thus, only few such datasets exist. Addi-
Example A concrete example is shown in Fig-
tionally, executing model-generated code is sus-
ure1: whileBLEUandCrystalBLEUprefer(rank
ceptibletosecuritythreats,andthusshouldberun
higher) the non-equivalent code in Figure 1(b)
inanisolatedsandbox,whichmakesittechnically
given the reference code in Figure 1(a), Code-
cumbersometoworkwithiteratively.
BERTScoreprefersthecodeinFigure1(c),which
Ourapproach Inthiswork,weintroduceCode- is functionally equivalent to the reference (Fig-
BERTScore,anevaluationmetricforcodegenera- ure 1(a)). We note that in this example, the vari-
tion,leveragingself-supervisedpretrainedmodels ablenamesareidenticalacrossallthreecodesnip-
of code such as CodeBERT (Feng et al., 2020), pets. When the variable names of the reference
and adopting best practices BERTScore (Zhang aredifferentthanthecandidateâ€™s,itisevenharder
Natural Language Instruction Pairwise Cosine Similarity Similarity Matrix
(only between non-punctuation
# Find the square root of x
code tokens) Gener