. arXiv dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
preprintarXiv:1702.08734. Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
ArmandJoulin,EdouardGrave,PiotrBojanowski,and
proach. arXivpreprintarXiv:1907.11692.
Tomas Mikolov. 2017. Bag of tricks for efficient
text classification. In Proceedings of the 15th Con- Matteo Pagliardini, Prakhar Gupta, and Martin Jaggi.
ferenceoftheEuropeanChapteroftheAssociation 2017. Unsupervised learning of sentence embed-
forComputationalLinguistics: Volume2, ShortPa- dings using compositional n-gram features. arXiv
pers, pages 427–431, Valencia, Spain. Association preprintarXiv:1703.02507.
forComputationalLinguistics.
Nghia The Pham, Germán Kruszewski, Angeliki
Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Lazaridou, and Marco Baroni. 2015. Jointly opti-
Zettlemoyer,andMikeLewis.2019. Generalization mizing word representations for lexical and senten-
through memorization: Nearest neighbor language tial tasks with the C-PHRASE model. In Proceed-
models. arXivpreprintarXiv:1911.00172. ings of the 53rd Annual Meeting of the Association
387
for Computational Linguistics and the 7th Interna- JohnWieting,MohitBansal,KevinGimpel,andKaren
tional Joint Conference on Natural Language Pro- Livescu.2016a. Charagram: Embeddingwordsand
cessing (Volume 1: Long Papers), pages 971–981, sentencesviacharactern-grams. InProceedingsof
Beijing, China. Association for Computational Lin- the2016ConferenceonEmpiricalMethodsinNatu-
guistics. ralLanguageProcessing,pages1504–1515,Austin,
Texas.AssociationforComputationalLinguistics.