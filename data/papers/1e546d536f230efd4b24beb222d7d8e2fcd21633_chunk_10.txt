 parsing in ACL 2013,
atingpredictiveuncertainty,visualobjectclassifica-
EMNLP2014andAAAI2015.
tion,andrecognisingtectualentailment,pages177–
190.Springer,NewYork,NY.
Anca Dumitrache, Oana Inel, Lora Aroyo, Benjamin Adam Poliak, Jason Naradowsky, Aparajita Haldar,
Timmermans, and Chris Welty. 2018. Crowdtruth Rachel Rudinger, and Benjamin Van Durme. 2018.
2.0: Quality metrics for crowdsourcing with dis- Hypothesis only baselines in natural language in-
agreement. In Joint Proceedings SAD 2018 and ference. In Proceedings of the Seventh Joint Con-
CrowdBias 2018, CEUR Workshop Proceedings, ference on Lexical and Computational Semantics,
pages11–18.CEUR-WS. pages 180–191, New Orleans, Louisiana. Associa-
tionforComputationalLinguistics.
Suchin Gururangan, Swabha Swayamdipta, Omer
Levy,RoySchwartz,SamuelBowman,andNoahA. PranavRajpurkar,JianZhang,KonstantinLopyrev,and
Smith. 2018. Annotation artifacts in natural lan- Percy Liang. 2016. SQuAD: 100,000+ questions
guage inference data. In Proceedings of the 2018 formachinecomprehensionoftext. InProceedings
Conference of the North American Chapter of the oftheConferenceonEmpiricalMethodsinNatural
Association for Computational Linguistics: Human LanguageProcessing.
Language Technologies, Volume 2 (Short Papers),
pages107–112.AssociationforComputationalLin- Jorge Ram´ırez, Simone Degiacomi, Davide Zanella,
guistics. Marcos Baez, Fabio Casati, and Boualem Benatal-
lah. 2019. Crowdhub: Extending crowdsourcing
DivyanshKaushik, EduardHovy, andZacharyLipton. platforms for the controlled evaluation of tasks de-
2019. Learning the difference that makes a differ- signs. arXivpreprint1909.02800.
encewithcounterfactually-augmenteddata. InInter-