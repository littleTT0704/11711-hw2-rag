.RelatedWork ofthemodel,andthesectionsbelowformoredetails.
Single-future trajectory prediction. Recent works have 3.1.HistoryEncoder
triedtopredictasinglebesttrajectoryforpedestriansorve-
Theencodercomputesarepresentationofthescenefrom
hicles.Earlyworks[35,59,62]focusedonmodelingperson thehistoryofpastlocations,L,andframes,V. Ween-
1:h 1:h
2 https://en.wikipedia.org/wiki/The_Garden_of_ code each ground truth location L t by an index Y t ∈ G
Forking_Paths representingthenearestcellina2DgridGofsizeH×W,
Figure 2: Overview of our model. The input to the model is the ground truth location history, and a set of video frames,
whicharepreprocessedbyasemanticsegmentationmodel. Thisisencodedbythe“HistoryEncoder”convolutionalRNN.
The output of the encoder is fed to the convolutional RNN decoder for location prediction. The coarse location decoder
outputsaheatmapoverthe2DgridofsizeH ×W. Thefinelocationdecoderoutputsavectoroffsetwithineachgridcell.
ThesearecombinedtogenerateamultimodaldistributionoverR2forpredictedlocations.
indexed from 1 to HW. Inspired by [22, 31], we encode (knownasthe“beliefstate”)bedenotedbyC (i)=p(Y =
t t
locationwithtwodifferentgridscales(36×18and18×9); i|Y,H), for ∀i ∈ G and t ∈ [h+1,T]. For brevity,
h:t−1
we show the benefits of this multi-scale encoding in Sec- we use a single index i to represent a cell in the 2D grid.
tion5.4.Forsimplicityofpresentation,wefocusonasingle RatherthanassumingaMarkovmodel,weupdatethisusing
H ×W grid. aconvolutionalrecurrentneuralnetwork,withhiddenstates
To make the model more invariant to low-level visual HC. Wethencomputethebelief