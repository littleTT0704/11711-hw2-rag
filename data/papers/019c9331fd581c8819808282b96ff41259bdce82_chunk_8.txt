ofourdocuments,weappropriatelydesign
#subtopics 55 ourannotationtaskandinterface.
#documents 176
4 AnnotatingCoreferencevia
#sentencesperdoc(avg.) 14.6
Crowdsourcing
#tokensperdoc(avg.) 344
#eventmentions 7220
Corefering event mentions share their identity.
#mentionsperdoc(avg.) 41
However,theextentofsharingforthemtobecon-
#documentpairs 198 sidered coreferential is unclear. To empirically
#CDEClinks 4282 study this behavior, we crowdsource annotations
#CDEClinksperdocumentpair 21.6 on Mechanical Turk. We use the crowd workersâ€™
responsestoanalyzetheinfluenceofquasi-identity
#fullcoreferencelinks 2914
oncoreferencedecisions.
#partialcoreferencelinks 1368
4.1 AnnotationTask
Table1: AnoverviewofthecompiledCDECdataset.
Theinputtoourannotationtaskconstitutesapairof
documents,withalleventmentionspre-identified.
work,ourdatasetconstitutesofasingletopic(Dis- Annotator iterates through every mention on the
aster and accidents) and 55 subtopics (individ- leftdocumentandselectcoreferingmentionsfrom
ual storylines). We restrict CDEC annotations to therightdocument. Wealsoprovidethedocument
subtopicsthatcontain3or4documents. Ouralgo- titlesandpublicationdatestohelpsetthecontext
rithmaimsforcompletenessoftheCDECdataset forthearticles. Notethatwefocussolelyoncross-
bymaximizingforintra-subtopicandminimizing document coreference in this work and leave the
inter-subtopiccoreference. additionofwithin-documentlinkstofuturework.
Prior work has highlighted the difficulty in
EventMentionIdentification: Toannotatethe
capturing event coreference, specifically in cases
eventmentionsintheabove-collecteddocuments,
wherethementionsareonlyquasi-identical(Hovy
we first run a combination of mention detection
etal.,2013). Notably,Recasensetal.(2012)found
system