 fluency, achieving the best overall performance. The case study demonstrates
the necessity of integrating the diverse experience for solving the problem.
9.2. Repurposing Learning Algorithms for New Problems
The standardized formalism sheds new light on fundamental relationships between a number of learning
problems in different research areas, showing that they are essentially the same under the SE perspective. This
opens up a wide range of opportunities for generalizing existing algorithms, which were originally designed for
specialized problems, to a much broader set of new problems. It is also made easy to exchange between the
diverse research areas in aspects of modeling, theoretical understanding, approximation, and optimization. For
example, an earlier successful approach to challenges in one area can now be readily applied to address
challenges in another. Similarly, a future progress made in one problem could immediately unlock progresses
in many others.
46
Harvard Data Science Review â€¢ Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
Figure 7. Example outputs of pose-conditioning human image generation. Given an image of
a person as well as a target pose represented as a skeleton, the goal is to generate a new
image of the same person under the target pose. The base model that learns a neural model
with only limited available supervised data fails to make meaningful generation. Hu et al.
(2018) added a structured constraint on the human body structure, based on a pretrained
human part parser. Learning with the fixed constraint (i.e., with the pretrained parser) does not
improve the generation quality. In contrast, learning the constraint together with the target
model within the dynamic standard equation framework leads to substantially improved output
(learned constraint), close to the true target.
Case study: Learning with imperfect experience. To illustrate, let us consider a set of concrete problems
concerning with distinct types of experience, which were often studied by researchers in different areas: (1)
The first problem is to integrate structured knowledge constraints in model training, where some components
of the constraints, as well as the constraint weights, cannot be specified a priori and are to be induced
automatically; (2) The second problem concerns supervised learning, where one has access to only a small set
of data instances with imbalanced labels, and we want to automate the data manipulation (e.g., augmentation
and reweighting) to maximize the training performance; (3)