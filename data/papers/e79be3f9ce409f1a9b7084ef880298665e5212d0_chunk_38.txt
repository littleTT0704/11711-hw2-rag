
alignment,andhencethefinalperformance. mm #params. FLOPs
method text video
(M) (G)
self cross
Setting R@1 R@5 R@10 MR
ActBert[60] 12 12 0 24 369.1 13.80
Laterstageonly 13.3 35.7 48.8 11.0 MMT[14] 12 4 0 0 133.3 4.63
Earlystage+Laterstage 13.6 35.9 49.1 11.0 UniVL[33] 12 6 2 0 169.0 5.82
Cascadesampling 14.5 38.3 50.7 11.0 Ourlargest 12 4 2 0 154.9 5.14
Table 12: Text-video retrieval performance on YouCook2
Table 14: Comparison of model size and FLOPs. “mm”
onlyusinglaterstagealignmentscorefordifferentsettings.
meansmulti-modalfusion, and“self”meansself-attention
layerswhile“cross”meanscross-modalattention.
D.Effectofvideoencoderlayers
F.Visualizations
In our main paper, we noticed the number of video en- We visualize the text-video retrieval results by varying
coderlayersaffectsthefinalperformance. Tohaveamore theweightsforthetoken-levelalignmentscoresduringtest-
comprehensivestudy,weuseR-152andS3D-HMasthe2D ing. In Fig. 3, we show two text-video retrieval examples
and3Dfeaturesandtrainthevideo-textalignmentmodelon on YouCook (top) and MSR-VTT (bottom). From top to
YouCook2 with different video encoder layers. As shown bottom, the five rows in each block correspond to the top
in Table 13, using more video encoder layers can signifi- five retrieved results from the whole test set. As we can
cantly boost the text-video retrieval performance. Particu- see, when we gradually increase the weight for the token-
larly,whennovideoencoderlayersareused,themodelcan levelalignmentscore,therearemorerelatedvideosappear-
hardy capture the long-range temporal dynamics, and thus inginthetopfivecandidates. ForYouCook