 18.948 14.885
diff ffn 3x IP F +3V ×D 22.206 18.981 14.853
Table 8: Performance comparison of kNN baselines and models with different size output embeddings
re-trainedfromscratch.
However, just because ensembling two LMs of the same architecture provides better performance than
interpolatingthebaseLMwithkNNdoesnotnecessarilysuggestthatkNN’sperformanceimprovementcan
befullyreplacedbymodelensembling. Inotherwords,weareinterestedinwhetherthekNNperformance
improvementsareorthogonaltothatofmodelensembling. Totestthis,wecomparetheperformanceofthe
ensembleofK multipleLMsversustheensembleofK −1multipleLMsplusthekNNcomponent. The
comparisonisfairbecausewehavethesamenumberofmodelsintheensemble,andtheonlydifferenceis
whetherthekNNcomponentisincluded. TheresultsareshowninFigure8. Forthe“LM”series,eachpoint
isK LMsensemble,andforthe“kNN”series,eachpointisK−1LMspluskNN.Wecanseethatevenat
4-ensemble,theensemblethatcontainkNNasacomponentstillhaveaconsiderableedgeoverthe4-ensemble
thatcontainjustLMs.
LM and KNN
LM KNN
22
20
18
16
1 2 3 4
Ensemble Components
Figure 8: Ensembling effect comparison, between multiple base LMs and multiple base LMs plus kNN
component.
E.6 ArekNN-LMJustAlternativeTrainingMethods?
E.6.1 Overfitting
Since kNN-LM improves perplexity even with the same training dataset as datastore, we are curious if
kNN-LMworksbyonly“memorizing”thetrainingdata. ThehypothesisisthatthedatastoreandthekNN
19
Prev.Layers h N ⊗ +#params PPL Interp. Oracle
ds ds
BaseLM same - - - 0 21.750 - -
KNN same att Big L2 N ×D ∞ 19.174 14.230
ds
KNN same att Big IP N ×