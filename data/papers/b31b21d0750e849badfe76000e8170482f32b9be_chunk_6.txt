
Overall,wedecomposetheprobabilityofgeneratingcintotheprobabilityofchoosingaparticular
subsetofdocumentsP(D ∣D,n),andtheprobabilityofgeneratingthecodeconditionedonthe
n
intentandtheselecteddocumentsP(c∣D,n);finally,wemarginalizingoverallD ⊆D:
n n
P(c∣D,n)=∑ P(c∣D,n)⋅P(D ∣D,n) (1)
Dn⊆D n n
assumingthatcisindependentofDgivenD (thatis,(cÆD∣D )). Sinceenumeratingallpossible
n n
subsets D is computationally infeasible, we follow the common practice and approximate the
n
marginalizationoverD inEquation(1)bytakingthemostprobablesubsetofretrieveddocuments
n
Dˆ,andthenconditioningthepredictionofconthesemostlikelydocuments:
n
Dˆ ∶=argmax P(D ∣D,n) P(c∣D,n)≈P(c∣Dˆ,n)⋅P(Dˆ ∣D,n) (2)
n Dn⊆D n n n
2.2 DocPrompting: GENERATINGCODEBYRETRIEVINGTHEDOCS
Equation 2 implies that DocPrompting relies of two main components: A retriever R retrieves
relevantdocumentsDˆ giventheintentn;andageneratorGgeneratesthecodesnippetcconditioned
n
on the retrieved documents Dˆ and the intent n, which compose a new prompt. Specifically, R
n
computesasimilarityscores(d,n)betweenaintentnandeverydocumentd ∈D. Thus,thesubset
i i
Dˆ ⊆Disthetop-kdocumentswiththehighestsimilarityscores: Dˆ =top-k (s(d,n)).
n n di∈D i
AnoverviewofourapproachisillustratedinFigure1: