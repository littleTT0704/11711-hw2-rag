responses
commentsunlesstheyagree. Thismaybiastheset
aremoreoffensivetowardsindividualsandwomen.
of respondents towards those who align with the
On an average, they respond more with personal
offensive statement, essentially creating an echo-
attacksdirectedtowardsindividualsasopposedto
chamber(Cinellietal.,2021;Solimanetal.,2019).
offendingacertaindemographic. Weshowsome
Regardless of the cause, this behavior is also re-
qualitativeexamplesfromourdatasetinFigure5.
flectedindialoguemodelstrainedonpublicRed-
ditthreads. Inourhuman-annotateddataset,both ProfanityinModelResponses. Dialoguemod-
DGPTandGPT-3arealmosttwotimesmorelikely elsoccasionallygenerateprofaneresponseschar-
to agree with a previous offensive comment, as acterized by explicit offensive terms. We check
comparedtoasafecomment. Furtheranalysisus- themodel’soffensiveresponsesforprofanityusing
%
egatnecreP
eergA
%
Reddit responses top 10 target groups DGPT responses top 10 target groups GPT3 responses top 10 target groups
christian folks asian folks black folks
people from a region women jewish folks reddit user feminists reddit user
121 33 60
91 25 45
comment author 60 celebrity muslim folks 16 women Other 30 women
30 8 15
LGBTQ folks reddit user LGBTQ folks comment author muslim folks celebrity
religious folks Other people from a region celebrity people from a region comment author
feminists christian folks LGBTQ folks
Figure4: Top10targetgroupsforReddituserresponses,DGPTresponsesandGPT-3responseswithfrequencies.
Targetgroupsareorganizedindecreasingfrequencyineachdecagon,startingclockwisefromthetop-rightcorner.
Toxicity Triggers (Zhou et al., 2021) which is a task and “[CLS] u [SEP] u [SEP]” for the
i j
lexiconof378“bad”words,phrases,andregular Stance task. Then, a softmax layer on the
expressions.10 Wefindthatonly3.35%ofDG