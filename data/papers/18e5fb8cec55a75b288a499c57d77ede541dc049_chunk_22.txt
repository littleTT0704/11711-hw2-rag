 CommonSenseQA mostly requires knowledge modeling,asitpreservedbetterthestructureofthetask.Our
about properties of objects (e.g., function or appearance) analysis and human evaluation indicated that the generated
which is the focus of ConceptNet, Wikidata, and questionsweretypicallyeasierforhumansthanforlanguage
VisualGenome,butnotofATOMIC.Thisindicatesaten- models,whichisappropriateforcommonsensequestions.
sionbetweenH3andH4:whilemoreknowledgeoftenhelps, Yet,thehumanevaluationrevealedthatanotableportion
itmightnotbethecasewhenthetaskandtheknowledgeare of the questions is nonsensical or difficult, hinting that au-
not well-aligned. Our current understanding of the dimen- tomatically generating high-quality, informative common-
sionsofcommonsenseknowledgeinknowledgesourcesand sensequestions isnon-trivial andshould be revisedin sub-
benchmarksislimited,andwouldbenefitfromfurtherstudy. sequent work. Future work should also investigate the im-
pact of this approach on knowledge injection systems (Ma
etal.2019)andgraphrelationalnetworks(Linetal.2019).
GeneratingFairandInformativeQuestions
It should also consider: (1) other, less structured knowl-
Alternatively, this result may be explained by our human edge sources, like WikiHow; (2) different distractor sam-
evaluation:notallautomaticallygeneratedquestionsarefair plingstrategies,e.g.,basedoniterativesampling(Niuetal.
and a subset has more than one correct answer, as a direct 2020);and(3)additionalLMscoringfunctions,e.g.,based
consequence of the inherent incompleteness of KGs. Be- onscoringsequencesoftokens(Tamborrinoetal.2020).
sidesbeingadisadvantageofautomaticquestiongeneration,
5Question formulation is another challenge. Template-based
4Forexample,scoringsequencesoftokensbyalanguagemodel questionsmaybetriviallyeasyforLMstosolve,asdiscussedin
mightimprovetheperformanceofLMs(Tamborrinoetal.2020). https://cs.nyu.edu/faculty/davise/papers/CYC