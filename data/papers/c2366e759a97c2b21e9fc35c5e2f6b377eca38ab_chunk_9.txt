a combinatorially large training dataset. At test time, we record one prompt demo from a seen or
unseenpreferenceanduseittoconditionπandψ:a=π(S,ψ(τ )).Allpolicyweightsarekept
prompt
fixedduringtesting,andgeneralizationtonewpreferencesiszero-shotusingthelearnedpreference
representation γ. Unlike [24], γ captures not just the final state, but a temporal representation of
the whole demonstration. Building a temporal representation is crucial to encode demonstration
preferenceslikeorderofloadingracksandobjects. Eventhoughthefinalstateisthesamefortwo
preferencesthatonlydifferinwhichrackisloadedfirst,ourapproachisabletodistinguishbetween
them using the temporal information in τ. To the best of our knowledge, our approach is the
prompt
firsttotemporallyencodepreferencesinferredfromademonstrationinlearnedtaskplanners.
4
Figure 4: Dishwasher Loading demonstration in AI Habitat Kitchen Arrange Simulator. Objects
dynamicallyappearonthecounter-top(ii-iv),andneedtobeplacedinthedishwasher. Ifthedish-
washerracksarefull,theylandinsink(v)
3 Experiments
We present the “Replica Synthetic Apartment 0 Kitchen”3 (see figure 4, appendix and video), an
artist-authored interactive recreation of the kitchen of the “Apartment 0” space from the Replica
dataset[28]. WeuseselectedobjectsfromtheReplicaCAD[29]dataset, includingseventypesof
dishes, and generate dishwasher loading demonstrations using an expert-designed data generation
script (see Appendix B). Given 7 categories of dishes and two choices in which rack to load first,
the hypothesis space of possible preferences is 2×7!. Our dataset consists of 12 preferences (7
train, 5held-outtest)with100sessionsperpreference. Inasession, n ∈ {3,...,10}instancesare
loadedineachrack. Thetrainingdataconsistsofsessionswith6or7objectsallowedperrack. The
held-out test set contains 5 unseen preferences and settings for {3,4,5,8,9,10} objects per rack.
