Note that we only consider the LEARNED-
Following Swayamdipta et al. (2020), we set
MIXIN-ONI and LEARNED-MIXIN-TOXTRIG
the target filtered subset size to 33% of the orig-
models for lexical debiasing, due to poor ac-
inaltrainingsetforbothfilteringmethods,butour
curacies of the bias-only models for NOI and
filtering additionally preserved the original label
OI.10
proportions. We then fine-tune a RoBERTa-large
classifer on these filtered subsets; see Appendix
3.2 DataFilteringforSpuriousBiases
A.2formoredetails.
In addition to debiasing methods that handle
4 Experiments: LexicalBiases
known biases, we also explore automated ap-
proaches which filter out instances exhibiting un-
We investigate the effect of debiasing approaches
specified, spurious biases. Specifically, we de-
(§3)onremovinglexicalbiasesinhatespeechde-
scribebelowtwodataselectionmethodsthathave
tection. First, we discuss the evaluation frame-
shownstrongOODperformance.
work for measuring bias reduction (§4.1). We
present quantitative (§4.2) and qualitative (§4.3)
AFLite(Brasetal.,2020) isanalgorithmbased
resultsonlexicalbiasremovalforalldebiasingap-
on the key intuition that examples predicted cor-
proaches, andOODevaluationfordebiasedtrain-
rectly by the simplest methods likely exhibit spu-
ing methods (§4.4). See Appendix A.3 for hyper-
rious biases. An ensemble of simple linear clas-
parametersandotherexperimentalsettings.
sifiers is trained and tested on different partitions
ofthedata;testinstanceswhichare“predictable”,
4.1 EvaluationFramework
or classified correctly by most classifiers in the
ensemble are discarded. The algorithm is iter- We report the performance of all models as over-
ative, and is repeated until a target data size is allaccuracyandF 1 withrespecttothetoxicclass.
achieved.