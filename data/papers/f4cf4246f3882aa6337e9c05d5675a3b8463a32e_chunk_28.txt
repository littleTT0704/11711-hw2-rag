-Baptiste Alayrac, Ramazan Gokberk
StefanThater,BerntSchiele,andManfredPinkal. Ground-
Cinbis,DavidFouhey,IvanLaptev,andJosefSivic. Cross-
ingactiondescriptionsinvideos. TACL,2013. 2,3
task weakly supervised learning from instructional videos.
[44] SteÂ´phaneRoss,GeoffreyGordon,andDrewBagnell. Are- InCVPR,2019. 3
ductionofimitationlearningandstructuredpredictiontono-
regretonlinelearning. InAISTATS,2011. 4
[45] Manolis Savva, Abhishek Kadian, Oleksandr Maksymets,
Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia
Liu,VladlenKoltun,JitendraMalik,DeviParikh,andDhruv
Batra. Habitat: A platform for embodied ai research. In
ICCV,2019. 1
[46] OzanSener,AmirR.Zamir,SilvioSavarese,andAshutosh
Saxena.Unsupervisedsemanticparsingofvideocollections.
InICCV,2015. 3
[47] MohitShridharandDavidHsu. Interactivevisualgrounding
ofreferringexpressionsforhuman-robotinteraction.InRSS,
2018. 3
[48] HaoTan,LichengYu,andMohitBansal. Learningtonav-
igate unseen environments: Back translation with environ-
mentaldropout. InNAACL,2019. 1
10
AppendixA.DatasetDetails 35
We give additional information about the generation of 30
expert demonstrations in AI2-THOR, language directives,
25
theannotationinterfaceusedtocollectdirectives,andsam-
plesofannotationswiththeirassociateddemonstrations. 20
A.1.ExpertDemonstrations 15
When sampling task parameters, we employ an active 10
strategy to maximize data heterogeneity. Figure F1 shows
5
the distribution of high-level task across train, validation
seen,andvalidationunseenfolds. Figure