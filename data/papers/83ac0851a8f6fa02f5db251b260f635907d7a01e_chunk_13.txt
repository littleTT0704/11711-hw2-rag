 using a trained neural
networkrerankertoselectthegoalstateG.
3.4.Results
Table1comparestheperformanceofourmodelagainst
published numbers of existing models. Our approach sig-
nificantly outperforms the existing model in terms of effi-
ciency, matching the best overall success rate despite tak-
ing 150 - 1,000 fewer steps. This efficiency gain can be
seenintheSPLmetric,whereourmodelsoutperformpre-
vious approaches in every setting. Note that our short tra-
jectory model appreciably outperforms current approaches Figure5.Circlesizesrepresentthewhatpercentageofagentsdi-
inbothSRandSPL.Ifouragentcouldcontinueexploring, vergeonstepN.Mostdivergencesoccurintheearlysteps. FAST
recoversfromearlydivergences.
it matches existing peak success rates in half of the steps
(196vs373).
rate for SPEAKER-FOLLOWER and SMNA, respectively.
ValidationUnseen SR(%) SPL(%) TL
Due to those models’ new ability to backtrack, the trajec-
SPEAKER-FOLLOWER 37 28 15.32 torylengthsincreaseslightly. However,thesuccessratein-
+FAST 43(+6) 29(+1) 20.63 creasessomuchthatSPLincreases,aswell.
SMNA 47 41 12.61
+FAST 56(+9) 43(+2) 21.17
4.Analysis
Table2.Plug-n-playperformancegainsachievedbyaddingFAST
tocurrentSoTAmodels. Here, we isolate the effects of local and global knowl-
edge,theimportanceofbacktracking,andvariousstopping
Anotherkeyadvantageofourtechniqueishowsimpleit criteria. In addition, we include three qualitative intuitive
istointegratewithcurrentapproachestoachievedramatic examples to illustrate the model’s behavior in the Supple-
performance gains. Table 2 shows how the sum-of-logits mentaryMaterials(§A.1). Wecanperformthisanalysisbe-
fusion method enhances the two previously best perform- cause our approach has access to the same information as
ingmodels.Simplychangingtheir