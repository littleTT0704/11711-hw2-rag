ascribementalstatestootheragents(Tomasello,2005),
anabilityalsoknownasTheoryofMind(ToM).
Some previous studies have attempted to perform computational modeling of ToM. For instance,
ToM-like mechanisms have been demonstrated to allow models to better predict the behavior of a
future agent (Rabinowitz et al., 2018), model agents’ beliefs in a negotiation (Cao et al., 2018) or
acooperativegame(Bardetal.,2020),orchoosegoodutterancesbasedonthelistener’slinguistic
abilities(Zhuetal.,2021).However,theeffectsofToMhavenotyetbeenstudiedinthehigher-level
contextofcomputationallanguageacquisition.
Inthispaper,westudyhowaninternalToMmechanismandexternalenvironmentalpressurecon-
tribute to language learning. We use an image referential game setting consisting of a series of
trainingepisodesbetweenaspeaker, whichrepresentsalanguagelearner(Zhuetal.,2022), anda
listener,whichrepresentsafluentteacher. Whenpresentedwithasetofimages,oneofwhichisthe
target referent, the speaker must learn to generate an English utterance that the listener can use to
selectthetarget. Thespeakerisrewardedforgeneratingutterancesthatareusedtocorrectlyguess
the target image. Additionally, the speaker may be given feedback depending on the confidence
the listener has in the selection. This setting provides an attractive test-bed for testing the effects
of various reward signals or model designs on the speaker’s learned language; previous studies of
pragmaticsinlanguageacquisition,suchasAndreas&Klein(2016),haveusedsimilarsettings.
1Codeanddatacanbefoundathttps://github.com/neulab/ToM-Language-Acquisition.
1
3202
raM
2
]LC.sc[
1v20510.3032:viXra
PublishedasaconferencepaperatICLR2023
Target Image Distractor Image
1. Yellow shirt man throw frisbee
2. Frisbee front of trees
1. Three people play frisbee
3. Three people play frisbee
2. Frisbee front