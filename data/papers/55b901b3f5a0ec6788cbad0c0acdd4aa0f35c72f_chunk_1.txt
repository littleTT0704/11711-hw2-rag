PublishedasaconferencepaperatICLR2023
AANG: AUTOMATING AUXILIARY LEARNING
LucioM.Dery1âˆ— PaulMichel2 MikhailKhodak1 GrahamNeubig1 AmeetTalwalkar1,3
1CarnegieMellonUniversity 2ENSPSLUniversity 3HewlettPackardEnterprise
ABSTRACT
Auxiliaryobjectives,supplementarylearningsignalsthatareintroducedtohelp
aid learning on data-starved or highly complex end-tasks, are commonplace in
machinelearning. Whilstmuchworkhasbeendonetoformulateusefulauxiliary
ICMLExperiments
objectives,theirconstructionisstillanartwhichproceedsbyslowandtedioushand-
derylucio
design. Intuitionforhowandwhentheseobjectivesimproveend-taskperformance
November2021
has also had limited theoretical backing. In this work, we present an approach
forautomaticallygeneratingasuiteofauxiliaryobjectives. Weachievethisby
deconstructingexistingobjectiveswithinanovelunifiedtaxonomy, identifying
connections between them, and generating new ones based on the uncovered
structure. Next, we theoretically formalize widely-held intuitions about how
auxiliary learning improves generalization on the end-task. This leads us to a
principledandefficientalgorithmforsearchingthespaceofgeneratedobjectives
tofindthosemostusefultoaspecifiedend-task. Withnaturallanguageprocessing
(NLP)asourdomainofstudy,wedemonstratethatourautomatedauxiliarylearning
pipelineleadstostrongimprovementsovercompetitivebaselinesacrosscontinued
trainingexperimentsonapre-trainedmodelon5NLPtasks1.
1 INTRODUCTION
The auxiliary learning paradigm,
Objective Data( ) Transform( ) Representation( ) Output( )
where we augment a primary D T R O
BERT Out-of-domain BERT-Op Bidirectional DenoiseToken
objective with extra learning TAPT Taskdata BERT-Op Bidirectional DenoiseToken
signals to boost end-task DAPT In-domain BERT-Op Bidirectional DenoiseToken
performance, is a staple of ELMO