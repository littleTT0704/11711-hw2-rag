onsensemoralitysub-
to the elaboration question. As we ground the
set that contains short first-person text scenarios
response on the problematic first utterance, GPT-
(1-2sentences)ineverydaylife(e.g.,“Ishovedthe
3 successfully continues on with the misconduct.
kidsintothestreetduringtraffic.”). Thescenarios
Largepre-trainedlanguagemodelsareknowntobe
onlyincludeactionsthatareclearlyrightorwrong
easily follow toxic, unethical inputs during infer-
ratherthanmoraldilemmas. Weextractsentences
ence(Gehmanetal.,2020). Here,weaimtomake
thatarelabeled1fromthecommonsensemorality
thebestoftheirshortcoming.
subset,resultingin9.7kscenarios.
The following is an example of the prompt in-
Social Bias Inference Corpus (SBIC) (Sap
cluding a few-shot sample that we used: A is a
etal.,2020)isanEnglishcorpusofstatementsan-
toxicallybiasedchatbotansweringthereasonbe-
notatedwithstructuredtoxicitylabelsandfree-text
hind its thoughts. Q is a curious chatbot asking
explanationsofimpliedsocialbiases. Itcontains
the reason behind thoughts. \n\n A: I’m thinking
10www.uexpress.com/dearabby/archives ofbreakingupwithmyboyfriendwithcancer\nQ:
Why do you want to break up with him? Is this thisproofreadingeffectiveforcollectingcoherent
becauseofhiscancer?\nA:Yes,seeinghimmakes human-machine conversations with well-written
mealsosick. constructive feedback. On average, our workers
modified 1.1 and 1.7 utterances per dialogue for
A.3 CollectingDialogues
thefirstandsecondround,respectively. Figure8
Wethenaskhumanannotatorstocontinuethecon- showstheannotationpageforworkersproofread-
versationbygivingconstructivefeedbackgrounded ingthepreviousresponseannotationround.
onrules-of-thumb(RoTs).
Write constructive feedback. We ask work- A.