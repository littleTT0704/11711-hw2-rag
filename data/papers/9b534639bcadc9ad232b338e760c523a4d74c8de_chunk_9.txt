aportionoftheinputexamplesfollowing
pliedwidelyacrosslanguages),andevaluationby
commonsyntactic/semantic/lexicalpatterns.
humanlanguageexperts(asourgold-standardeval-
RuleExtraction Eachleafinthedecisiontreeis uation). We first describe below the process of
assignedalabelbasedonthedistributionofexam- automaticevaluationperlinguisticphenomenon.
pleswithinthatleaf. Forinstance,ifaleafofthe
CaseMarking Asnotedearlier,weusetheUD
adjective-noun word order decision tree has 60%
schemeforderivingthetrainingdata. Underthis
ofexampleswithadjectivesbeforetheirnouns,the
scheme, not every word is labeled with case, re-
leaf, by default, is labeled as before. However, a
strictingourtrainingandevaluationtobeonlyon
majority-basedthresholdaloneisinsufficientasit
such labeled examples. For such words, we con-
does not account for leaves with very few exam-
sidercasetobeauniversalpropertyi.e. eachword
ples,whichmaybebasedonspuriouscorrelations
marks a particular case value and, we evaluate
or nonsensical feature divisions. Instead, we use
whetherourmodelcancorrectlypredictthatvalue.
astatisticalthresholdforleaflabeling,inspiredby
Thus,wemeasuretheaccuracyonatestexample
Chaudharyetal.(2020),performingachi-squared
(cid:104)x,y (cid:105) ∈ Dt,comparingthemodelsprediction
test to first determine which leaves differ signifi- i i test
yˆ withtheobservedcasevaluey. Wecompareour
cantlyfromthebasedistribution. Forthis,wefirst i i
model against a frequency-based baseline which
define the null H and test H hypotheses. For
0 1
assignsthemostfrequentcasevalueinthetraining
instance,forwordorderwedefinethataleaf:
datatoallinputexamples.
H : takeseitherbefore/afterlabel
0 Word Order Similarly, we can assume that ev-
H : takesthelabeldominantunderthatleaf
1