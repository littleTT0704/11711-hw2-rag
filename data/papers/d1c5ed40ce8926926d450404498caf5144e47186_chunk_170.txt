
addition, Donmez et al. do not use a fixed cross-over point but switch to a different
sampling method when the expected error reduction on unlabeled data falls below a
threshold. We do not use density-based sampling strategies because these methods
depend on parameters that must be tuned on held-out data. For instance, a separate
dataset should be used to optimize the number of components in a Gaussian mix-
ture model, or the bandwidth when using kernel density estimation. Similarly, the
threshold for a cross-over based on estimated error reduction cannot easily be chosen
based on intuition or a visual inspection of learning curves but must be optimized on
independent development data.
Each combination of learning method and query selection strategy was evaluated on
the manually annotated dataset that was used previously to fit and evaluate super-
vised models. We performed 12-fold cross-validations on the topics marked as CV in
Table 5.1, using the instances in the training folds as a pool for query selection. Since
the entire dataset has been labeled by annotators, we did not need to query a human
at runtime but simulated active learning by only revealing the label of an instance
once it had been selected as a query. We focused on paragraph-length text nuggets
delimited by structural markup because relevance estimation performance is higher
for this type of nuggets (cf. Section 5.3). For each fold, we performed 1,000 active
learning steps, evaluated performance on the test data after each step, and averaged
the results over 10 random restarts to reduce their variance. We trained models that
are based on only the original 19 relevance features described in Section 4.3.2, as well
as models that include features of adjacent instances to capture the context of a text
nugget, using a total of 55 features. Since we are primarily interested in the ranking
performance of the models, we evaluate mean average precision (MAP) after each
iteration.
8.1.2 Results and Analysis
In Figures 8.1 and 8.2 we show learning curves for logistic regression models that use
only the original relevance features, and LR models that also leverage features of ad-
jacent instances. Comparable learning curves for linear SVMs are given in Figures 8.3
126 CHAPTER 8. EXTENSIONS FOR RELEVANCE ESTIMATION
and 8.4. In each