 the predicted sequence of subgoals matches ground truth
[22]. Natural language communication with robotics also execution.
allows for learning joint multimodal representations [23],
IV. APPROACH
[24] which harness the unique perceptual and manipulation
capabilities of robotics. Wetrainthesystemend-to-endusingsimulateddata.This
allows us to automatically generate training sequences for
While accurate grasping and placement is not a focus of bothimagesandhigh-levelsubgoals.Subgoalstaketheform
our work, it has been explored in the literature [25], [26], of semantic predicates like grasp and move with block
[27]. In particular, high-precision grasping with deep neural arguments. To simplify notation, throughout the paper, we
networks generally takes the form of predicting a grasp refer to the union of RGB, pose, and depth images with
success classifier [25], [26]. the single world state variable W. At every timestep the
tile Predictor
cconv(5) cconv(5) cconv(5) deconv(5) cconv(1)
1x1x64 8x6x64 +pad
cat
8x6x64
8x6x128 8x6x64 4x3x128 8x6x64 8x6x64
+
Fig. 3: Diagram of a single prediction cell. The prediction cell predicts a change in hidden state âˆ†z, and is an important
component of the DREAMCELL, used both for visualizing possible futures and for predicting the goal of a particular motion
for execution on our robot.
model is provided the current world observation (W ), a tuplesateachtimestep,toahorizonoflengthfive.Wedivide
t
description of the goal configuration in natural language thesubgoalG into:verbtheactiontobetaken,to objthe
t
(encoded as L(cid:126)). In practice W also includes the initial state object to servo towards, and with obj the optional object
t
W to capture changes over time. All aspects of the model inhand(e.g.,move(red,yellow)movestheyellowblockin
0
(including the encoders for both language and the world) hand to the target red block).
are trained together. The model is trained on