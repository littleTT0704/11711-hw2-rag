informationfromneighboringnodes.
5
Followingtheideasofpreviouswork,[8],[9],wedefinethesubclasslabelsandsuperclasslabels
as the nodes of the graph and aim to learn the label representation. The knowledge in the graph
isencodedasacorrelationmatrix,whichisacrucialpartoftheGCN.Wewilldescribehowitis
constructedinSection3.5.1.
Weuseone-hotencodingoflabelsastheinitialnoderepresentationanduse2GCNlayerstoextract
embeddingswithneighboringinformation. ForeachGCNlayerweuse2linearlayerstotransform
theinputembeddingofthenodeitselfandagraphconvolutiontoaggregatetheembeddingsfrom
itsneighbor. GivenalabelembeddingZ ∈ RC×d (whereC isthenumberofnodesanddisthe
dimensionalityofnodefeatures),thegraphconvolutionoperationsis:
Zl+1 =h(A(cid:48)ZlWlWl)
1 2
whereWl ∈Rd×d(cid:48) andW2l ∈Rd(cid:48)×d(cid:48)(cid:48) are2transformationmatricestobelearnedandA(cid:48) ∈RC×C
1
isthecorrelationmatrixandh(.)isanon-linearoperationwhichisaLeakyReLUinourexperiments.
Thedimensionsofeachthelinearlayersare280and512forthefirstGCNlayerand320and128for
thesecondGCNlayer.
3.5.1 CorrelationMatrix
The GCN learns node representations by collecting information from other nodes based on the
correlationmatrixprovided. Thus,howwebuildthecorrelationmatrixiscrucialbutalsochallenging
forGCN.Inthiswork,wereferredtopreviouswork[8,9]andexperimentedon3differentcorrelation
matrices.
LabelsCo-occurrencebasedCorrelationMatrix: [9]proposedawaytomodellabeldependency
intheformofconditionalprobability,i.e. P(L |L )denotestheprobability