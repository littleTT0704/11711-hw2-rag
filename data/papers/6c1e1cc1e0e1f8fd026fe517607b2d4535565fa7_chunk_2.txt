.,2022)prompt-
correctly. In this paper, we present Program-
AidedLanguagemodels(PAL):anovelapproach
ing. Inparticular,thewidelyusedchain-of-thought(COT)
methodpresentsthemodelwiththeexplicitintermediate
thatusestheLLMtoreadnaturallanguageprob-
stepsthatarerequiredtoreachthefinalanswer. Then,the
lemsandgenerateprogramsastheintermediate
modelisexpectedtoapplyasimilardecompositiontotheac-
reasoningsteps,butoffloadsthesolutionsteptoa
tualtestexample,andconsecutivelyreachanaccuratefinal
runtimesuchasaPythoninterpreter. WithPAL,
answer(Lingetal.,2017;Aminietal.,2019). Nevertheless,
decomposingthenaturallanguageprobleminto
whileLLMscandecomposenaturallanguageproblemsinto
runnablestepsremainstheonlylearningtaskfor
stepsandperformsimplearithmeticoperations,theirperfor-
theLLM,whilesolvingisdelegatedtotheinter-
mancefallsdramaticallywhendealingwithcomplexarith-
preter. We demonstrate this synergy between a
metic(Hendrycksetal.,2021;Madaan&Yazdanbakhsh,
neuralLLMandasymbolicinterpreteracross13
2022)orlargenumbers(Nogueiraetal.,2021;Qianetal.,
mathematical,symbolic,andalgorithmicreason-
2022). Infact,evenwhenfine-tuningaPaLM-basedmodel
ingtasksfromBIG-BenchHardandotherbench-
on 164B tokens of explicit mathematical content, its two
marks. In all these natural language reasoning
mostcommonfailuresarereportedly“incorrectreasoning”
tasks, generating code using an LLM and rea-
and“incorrectcalculation”(Lewkowyczetal.,2022).
soningusingaPythoninterpreterleadstomore
accurateresultsthanmuchlargermodels. Forex- In this paper, we propose Program-Aided Language
ample,PALusing