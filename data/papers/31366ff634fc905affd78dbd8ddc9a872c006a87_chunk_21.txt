Linguistics:EMNLP2020,pages
1536–1547, Online. Association for Computational Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie
Linguistics. Liu,DuyuTang,NeelSundaresan,MingZhou,Am-
brosio Blanco, and Shuai Ma. 2020. Codebleu: a
Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida method for automatic evaluation of code synthesis.
Wang,EricWallace,FredaShi,RuiqiZhong,Wen- ArXivpreprint,abs/2009.10297.
tau Yih, Luke Zettlemoyer, and Mike Lewis. 2022.
Incoder: A generative model for code infilling and Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019.
synthesis. ArXivpreprint,abs/2204.05999. BERT rediscovers the classical NLP pipeline. In
Proceedingsofthe57thAnnualMeetingoftheAsso-
Suchin Gururangan, Ana Marasovic´, Swabha ciationforComputationalLinguistics,pages4593–
Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, 4601, Florence, Italy. Association for Computa-
and Noah A. Smith. 2020. Don’t stop pretraining: tionalLinguistics.
Adapt language models to domains and tasks. In
Proceedings of the 58th Annual Meeting of the LewisTunstall,LeandrovonWerra,andThomasWolf.
Association for Computational Linguistics, pages 2022. Natural Language Processing with Trans-
formers. "O’ReillyMedia,Inc.".
8342–8360, Online. Association for Computational
Linguistics.
Zhiruo Wang, Shuyan Zhou, Daniel Fried, and Gra-
ham Neubig. 2022. Execution-based evaluation
Junjie Huang, Chenglong Wang, Jipeng Zhang, Cong
for open-domain code generation. ArXiv preprint,
Yan, Haotian Cui, Jeevana Priya Inala, Colin
abs/2212.10481.
Clement, and Nan Duan. 2022