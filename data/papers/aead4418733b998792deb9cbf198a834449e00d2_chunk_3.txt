olicsolversandachievingnearperfecttestaccuracy.
setofinput-outputsequences–itisespeciallyinterestingto
Recent studies suggest that achieving strong and sys-
studywhetheritgeneralizessystematically.
tematic generalization is difficult with vanilla sequence-to-
In this paper, we find a discrepancy between the tradi-
sequencemethods,astheylatchontoregularitiesinthetrain-
tional notion of generalization captured by test set accu-
ingdata,learningdataset-specificsolutionsthatdonotgen-
racy and the generalization needed in symbolic mathemat-
eralize beyond the training distribution (e.g. Agrawal, Ba-
ics. While the model’s test accuracy is nearly perfect, we
tra, and Parikh (2016); Lake and Baroni (2018); Bahdanau
find this breaks down when testing its robustness, compo-
et al. (2019); Hupkes et al. (2020)). Symbolic integration
sitionality, and out-of-distribution generalization (e.g. Ta-
Copyright©2022,AssociationfortheAdvancementofArtificial ble 1). We describe a methodology for evaluating these as-
Intelligence(www.aaai.org).Allrightsreserved. pects,byconstructingproblemsetsanddevelopingagenetic
8629
Robustness Compositionality Out-of-Distribution model’s output is considered correct if any of its k candi-
✓ ✓ ✓ dates {yˆ,...,yˆ } is correct. In this view, the neural net-
1 k
2x42✓ x2 cos(x)2 sin(x)2 Training d✓ istribution work narrows the search space to a small set of candidates
thatarechecked,tradingoffcorrectnessforsearchandveri-
ficationcost.Wedenotecheckingkcandidatesolutionsas,
x2 + sin(x)2 ✗ e5 xx px lo2✗ it (cid:26) 0 x≡ d yˆ foranyi∈1tok,
3x42✗
5x +10+cos(x)sin(x)2+...✗ m(x,f θ(x