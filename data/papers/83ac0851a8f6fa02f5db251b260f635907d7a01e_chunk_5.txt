Atoreachadesired sualobservationsandactions,wetrainaseq2seqcaptioning
1 2 T
location. Consistent with recent work [13, 10], we use a modelasa“speaker”[10]toproduceatextualdescription.
panoramic action space, where each action corresponds to Doing so provides two benefits: (1) the new speaker can
automaticallyannotatenewtrajectoriesintheenvironment
2ThisiscalculatedbasedonthelengthofSPEAKER-FOLLOWERagent
withthesyntheticinstructions,and(2)thespeakercanscore
pathsandhumanpathsontheR2Rdataset.
3https://evalai.cloudcv.org/web/challenges/challenge- thelikelihoodthatagiventrajectorywillcorrespondtothe
page/97/leaderboard/270 originalinstruction.
(a) Instructions and visual observations are encoded as hidden vectors (b) Ateachtimestep,thepredictedactionsequenceandvisualobservation
definingmultiplepathsthroughtheworld. Thesevectorscanthenbeac- arefedintoanattentionmodulewiththeencodedinstruction,toproduce
cumulatedtoscoreasequenceofactions. boththelogitsforthenextactionsandaprogressmonitorscore.
Figure3.(a). Howthethreesignalsareextractedfromthepartialtrajectoryinaseq2seqVLNframework;(b). Howtocomputethethree
signals.
2.2.Framework destination. Theagentmovesintheenvironmentbychoos-
ingtoextendapartialtrajectory: itdoesthisbymovingto
We now introduce an extendible framework4 that inte-
the last node of the partial trajectory and executing its last
gratestheprecedingthreesignals(l,ppm,S)5 andtotrain
t t actionto arrive ata newnode. Theagent thenrealizes the
newindicators,equippinganagenttoanswer:
actionsavailableatthenewnodeandcollectsthemtobuild
1. Shouldwebacktrack? asetofnewpartialtrajectories.
At each time step, the agent must (1) access the set of
2. Wheresh