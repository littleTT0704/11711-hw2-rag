fourparaphrasesoftheprompt(by
varyingthefirstandlast-sentenceinstruction,andwordingofthe“ok”question,asinAppendixB.3).
(2)Benefit:howaccurateisInstructGPTwhenaskedabouthowmuchbenefitwillthisdecisioncause;
and(3)Purpose: whetherInstructGPTcanunderstandcorrectlythepurposebehindtherule. Seeour
implementationanddataannotationdetailsintheAppendix.
In Table 4, we can see that, for InstructGPT, the
subquestionaboutLossistheeasiesttoanswer,asit $10B
followstheliteralrule(e.g.,waitinginlineisfairfor $1B
$100M
previouspeopleintheline),whereasthesubquestion $10M
about Purpose (whether the action adheres to the $1M
$100k
underlyingpurposeofarule)isthemostchallenging. $10k
$1k
UnderstandingUtility.Acentralinsightoftheprop- $100
ertyviolationstudy(Levineetal.,2018)isthathu-
manssometimesimplicitlycomparetheutilityoftwo
alternativeswhendecidingwhetheritwouldbeper-
property
mittedtobreakarule. Toprobethecostofanaction
Figure 2: Box plots of human responses (·)
a,inthatstudy,100humansubjectswereasked“how
andInstructGPT’sestimation(·)oftheutility
muchsomeonewouldhavetobepaidtovoluntarily
ofpropertydamageactions.
havetheirpropertydamagedbya?” Thusactionscan
bemappedontomonetaryvalues. Weplotall100humananswersinFigure2andcomparewiththe
InstructGPT’sanswer.
Wecalculatelog-MAEtocomparethemagnitudeofhumanresponsesandInstructGPT.Wealso
collectalargesetofgeneralactionswithhuman-annotatedvalues(whosedetailsareintheAppendix).
GPT does relatively well in estimating the cost of the general actions with a log-MAE of 0.711.
However, in the property violation study, when the question is presented in