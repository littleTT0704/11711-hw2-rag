frequent,uniformlysam-
56.63
Quasar-T 69.73 pledfromentitytypecategories,randomlysampled
70.53
9.62 fromvariousentitytypecategoriesandsampling
12.05
NewsQA 37.47 inproportiontoentitytypedistributionofanswers
51.25
71.88 intrainingsetoftargetdataset.
57.66
SearchQA 72.61 WechooseBioASQtoperformthesecontrolled
70.76
62.38 experiments because the source model has a rea-
COLIEE 61.47 sonableend-to-endperformanceonBioASQeven
82.56
whenretrievingpassagesfromthesourcedomain
0 20 40 60 80 Wikipedia corpus (Figure 7), suggesting that the
source corpus contains sufficient information for
Figure6: RetrieverPerformance(Acc@100): Varying
context distribution by creating a combined document answering many BioASQ questions. This allows
index ustousetheWikipediacorpusaloneforretrieval,
whichisusefultocontrolforfixedpassagedistribu-
Additionally,inFigure7weshowthattheFiD tionandgaugetheimpactoftheanswerdistribution
readerisnotassensitiveastheretrievertochanges inisolation.
incontextdistribution(targetvscombined)aswe In Table 2, we show that choosing the answer
observe only a drop of 3% in F1 for NewsQA in distributionproportionaltotheuniformdistribution
worstcasescenario. across entity type categories boosts retriever per-
formancecomparedtorandomsampling,allowing
Varyinganswerdistribution Manyworks(Gu-
themodeltocapturealltypesofanswersandgen-
ruranganetal.,2018;Duaetal.,2020;Jiangand
eralize better to unseen answer distributions. On
Bansal,2019)haveshownthatunanticipatedbias
theotherhand,thebestreadermodelperformance
inanswerpriordistributioncanintroducespurious
isachievedwhenweknowthecorrectanswerdis-
correlationsinmodellearning. Inthisexperiment,
tribution of the target dataset upfront, as we