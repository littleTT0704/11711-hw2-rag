brain.
ELIZAEffect&AnecdotalGenerativevs. Au- Machine intelligence and Anthropomorphism
tomatic Large-Scale Multiple-Choice Testing Relatedly,ourresultsalsopointtoaneedforcau-
The impressive anecdotal examples produced by tion when discussing the abilities of machines in
LLMs in generative settings (e.g., observed with relationtoconceptsreferringtohumancognition,
ChatGPT and GPT4 web-demo; Bubeck et al., such as Theory of Mind. While it is common in
2023), tends to captivate non-expert individu- computer science to use human-related concepts
als. However, it is important to recognize that andmetaphorsforAIsystems,wecautionreaders
thesemodelsarespecificallydesignedtogenerate to interpret “neural ToM” carefully and without
textthatappearshigh-qualitytohumanobservers aimingtomakeclaimsabout“AIcognition,”espe-
(Ouyangetal.,2022). Thisinherentbiasintheirde- ciallysincegivenourpropensityforanthropomor-
signcanleadtothe“ELIZAeffect”(Weizenbaum, phizingnon-humananimalsandcomputers(Epley
1976;Shapiraetal.,2023b),i.e. thehumanassump- etal.,2007;KimandSundar,2012);ourmeasuring
tionthatcomputerbehaviorsareanalogoustohu- theperformanceonthesebenchmarksisnotmeant
manbehaviors. Thus,theillusionthataLLMhas asanendorsementofthepursuitofahuman-like
acquired human-like N-ToM often says more socialintelligenceforAIsystems.8 Instead,inlight
aboutthehumansreadingthetextthanabout of the hype around AI and it’s “intelligence,” we
themodelitself(Whang,2023). soughtouttoprovideamoresoberlookattheem-
Moreover, later models are by design trained pirical performance of LLMs on tasks related to
to practice “epistemic humility” (i.e., hedge and socialintelligenceandToM.
prov