 active
learning schemeto learncausal manipulations onimages,
ThebasicideaofDDGistolearndisentangledrepresenta-
whichenrichesthedatasetfromobservationaldataandim-
tionsbyimposinginvariantconstraintsinthesemanticspace
provesgeneralizationonbothcausalandpredictivelearning S andvariationspaceV. Suchadisentanglementcanalso
tasks. In contrast, DDG seeks to learn underlying causal
be applicable for augmenting the training data so that the
featuresbyapproximatingthedatamanipulationfunction.
learnedrepresentationscanbemoreinvarianttobothinter-
Thisisdonewithoutatask-specificmetrictodifferentiate
andintra-domainvariations. Toformalizethis,webeginby
theaugmenteddataandtheoracle. Ourworkintroducesa
introducingsomenecessarydefinitionsandassumptions.
simpleyeteffectiveapproachforaugmentingtrainingdata,
whichreinforcestheimportanceofdatadiversityinDG. Definition1 (Invariance based on disentanglement).
Fairness. Fairnessresearch[22,28,52]aimstodevelop GivenadecoderD:S×V→X,asemanticfeaturizerf
s
amodelthatperformswellundergroupassignmentsaccord- isinvariantifforalldomainsd ∈Dandavariationfea-
i
ingtosomefairnesscriteriaforaddressingtheunderperfor- turizerf,x=D(f (x;θ),f (x˜;φ))holdsalmostsurely
v s v
manceinminoritysubgroups. Learningfairrepresentations whenx,x˜∼P(X).
can be naturally translated to a constrained optimization
problem[15,16,43]. Therearealsoexchanginglessonsbe- Thepropertyenforcestheinvarianceoftheoriginalinput
tweenalgorithmicfairnessanddomaingeneralization[20], xandtheoneD(f (x;θ),f (x˜;φ))thatreconstructsjointly
s v
showingthatbothfieldsareoptimizingsimilarstatistics