Match. (a) Target distributions for Uniform Alignment (UA) on
long-tailedsetting;(b)Errorrateofdifferentsamplefunctions;(c)ErrorrateofdifferentGaussian
parameterestimation,withUAenabled;(d)AblationonUAwithGaussianparameterestimation;
Wefurtherincludethedetailedablationofsamplefunctionsandseveraladditionalablationstudyin
AppendixA.5duetospacelimit. ThesestudiesdemonstratethatSoftMatchstaysrobusttodifferent
EMAmomentum,variancerange,andUAtargetdistributionsonbalanceddistributionsettings.
5 RELATED WORK
Pseudo-labeling(Leeetal.,2013)generatesartificiallabelsforunlabeleddataandtrainsthemodel
inaself-trainingmanner. Consistencyregularization(Samuli&Timo,2017)isproposedtoachieve
the goal of producing consistent predictions for similar data points. A variety of works focus on
improving the pseudo-labeling and consistency regularization from different aspects, such as loss
weighting(Samuli&Timo,2017;Tarvainen&Valpola,2017;Iscenetal.,2019;Renetal.,2020),
dataaugmentation(Grandvaletetal.,2005;Sajjadietal.,2016;Miyatoetal.,2018;Berthelotetal.,
2019b;a;Xieetal.,2020;Cubuketal.,2020;Sajjadietal.,2016),labelallocation(Taietal.,2021),
featureconsistency(Lietal.,2021;Zhengetal.,2022;Fanetal.,2021),andconfidencethresholding
(Sohnetal.,2020;Zhangetal.,2021;Xuetal.,2021b).
Loss weight ramp-up strategy is proposed to balance the learning on labeled and unlabeled data.
(Samuli & Timo, 2017; Tarvainen & Valpola, 2017; Berthelot et al., 2019b;a). By progressively
increasing the loss weight for the unlabeled data, which prevents the model involving too much
ambiguousunlabeleddataattheearlystageoftraining