The Thirty-Second AAAI Conference
on Artificial Intelligence (AAAI-18)
Multi-Task Learning for Parsing the
Alexa Meaning Representation Language
VittorioPerera TagyoungChung ThomasKollar EmmaStrubell
CarnegieMellon AmazonInc. AmazonInc. Universityof
University tagyoung@amazon.com kollart@amazon.com MassachusettsAmherst
vdperera@cs.cmu.edu strubell@cs.umass.edu
Abstract “playrayoflightbymadonna”
TheAlexaMeaningRepresentationLanguage(AMRL)isa
(cid:51)(cid:79)(cid:68)(cid:92)(cid:69)(cid:68)(cid:70)(cid:78)(cid:36)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)
compositional graph-based semantic representation that in-
cludesfine-grainedtypes,properties,actions,androlesand
(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)
canrepresentawidevarietyofspokenlanguage.AMRLin-
creasestheabilityofvirtualassistantstorepresentmorecom-
(cid:48)(cid:88)(cid:86)(cid:76)(cid:70)(cid:53)(cid:72)(cid:70)(cid:82)(cid:85)(cid:71)(cid:76)(cid:81)(cid:74) (cid:49)(cid:68)(cid:80)(cid:72) (cid:89)(cid:68)(cid:79)(cid:88)(cid:72)
plex requests, including logical and conditional statements
(cid:179)(cid:85)(cid:68)(cid:92)(cid:3)(cid:82)(cid:73)(cid:3)(cid:79)(cid:76)(cid:74)(cid:75)(cid:87)(cid:180)
aswellasoneswithnestedclauses.Duetothisrepresenta-
(cid:69)(cid:92)(cid:36)(cid:85)(cid:87)(cid:76)(cid:86)(cid:87)
tionalcapacity,theacquisitionoflargescaledataresources
ischallenging,whichlimitstheaccuracyofresultingmodels. (cid:48)(cid:88)(cid:86)(cid:76)(cid:70)(cid:76)(cid:68)(cid:81) (cid:49)(cid:68)(cid:80)(cid:72) (cid:89)(cid:68)(cid:79)(cid:88)(cid:72)
Thispaperhastwoprimarycontributions.Thefirstcontribu-
(cid:179)(cid:80)(cid:68)(cid:71)(cid:82)(cid:81)(cid:81)(cid:68)(cid:180)
tionisalinearizationoftheAMRLparsesthatalignsittoa
relatedtaskofspokenlanguageunderstanding(SLU)anda
deepneuralnetworkarchitecturethatusesmulti-tasklearning Figure1:MeaningrepresentationofasentenceusingAMRL.
topredictAMRLfine-grainedtypes,propertiesandintents.
Thesecondcontributionisadeepneuralnetworkarchitecture
thatleveragesembeddingsfromthelarge-scaledataresources “playrayoflightbymadonna”
thatareavailableforSLU.Whencombined,thesecontribu-
tionsenablethetrainingofaccuratemodelsofAMRLparsing, Domain: MusicApp
eveninthepresenceofdatasparsity.Theproposedmodels, Intent: ListenMediaIntent
whichusethelinearizedAMRLparse,multi-tasklearning, Slots: play[rayoflight] by[madonna]
Song Singer
residualconnectionsandembeddingsfromSLU,decreasethe
errorratesinthepredictionofthefullAMRLparseby3.56%
Figure 2: Example of the spoken language understanding
absolute.
(SLU)representation.
Introduction
Asintelligentassistantsbecomemoreopenandconnected,
isageneralcategoryforarequest(e.g.,music,calendar),an
thereisaneedtoexpandtheircapacitytounderstandtask-
intentisanactionwithinthatdomain(e.g.,play,search)and
orientedlanguage.Expandingthiscapacityrequiresarepre-
slotsarementionswithintheutterance(e.g.,“rayoflight”is
sentationthatcanhandlemanyformsofspokenlanguageand
thesongtobeplayed).Byfactoringtheproblemthisway,
modelsthatcanpredictthisrepresentation.Thispaperusesa
each SLU domain may have its own unique set of intents
newrepresentationthatcansupportawidevarietyofspoken
and slots. In contrast, AMRL provides a common seman-
languagecalledtheAlexaMeaningRepresentationLanguage
ticrepresentationforspokenlanguage(Figure3).Thereare
(AMRL).AMRLisacompositional,graph-basedsemantic
threeprimarybenefitstothiscommonrepresentation.The
representationthatisbackedbyalarge-scaleontology.An
firstbenefitisthatintentsandslotsthathavethesamemean-
AMRLparsecontainsactions,fine-grainedtypes,properties,
inghavethesamelabels.Forexample,“ordermeanecho
andverbroles(asinFigure1).AMRLprovidestherepresen-
dot”and“Alexa,ordermeataxi”fallintodistinctdomains
tationalcapacitytonotonlyunderstandsimplerequeststoa
(e.g.,shoppingandtaxi),resultingindistinctintentsforeach
virtualassistant,butalsocomplexlogical,conditional,and
domain(e.g.,OrderProductandOrderTaxi).Thefactthatre-
nestedstatements.
questssuchasthese,whichhaveasimilarsurfaceform,can
AnalternativerepresentationtoAMRLarethoseusedfor
appearindifferentdomainsalsomakesitchallengingtoadd
spokenlanguageunderstanding(SLU),whichcategorizere-
newfeatureswithoutdegradingSLUaccuracy.Thesecond
questsintodomains,intentsandslots(Figure2).Adomain
benefitofAMRListhatcross-domainutterancesaredirectly
Copyright(cid:2)c 2018,AssociationfortheAdvancementofArtificial supported.Forexample,“findmearestaurantneartheshark
Intelligence(www.aaai.org).Allrightsreserved. game”wouldbelongtoboththeSLUlocalsearchandthe
5390
(cid:54)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:36)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:16)(cid:19) (cid:38) (cid:50)(cid:82) (cid:83)(cid:80) (cid:72)(cid:83) (cid:85)(cid:68)(cid:68) (cid:87)(cid:85) (cid:82)(cid:68) (cid:85)(cid:87) (cid:16)(cid:76)(cid:89) (cid:19)(cid:72) (cid:87)(cid:68)(cid:85)(cid:74)(cid:72)(cid:87) (cid:51)(cid:82)(cid:86)(cid:87)(cid:68)(cid:79)(cid:36)(cid:71)(cid:71)(cid:85)(cid:72)(cid:86)(cid:86)(cid:16)(cid:20)
(cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87) (cid:89)(cid:68)(cid:79)(cid:88)(cid:72) (cid:79)(cid:82)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:179)(cid:85)(cid:72)(cid:86)(cid:87)(cid:68)(cid:88)(cid:85)(cid:68)(cid:81)(cid:87)(cid:180) (cid:87)(cid:92)(cid:83)(cid:72) (cid:53)(cid:72)(cid:86)(cid:87)(cid:68)(cid:88)(cid:85)(cid:68)(cid:81)(cid:87)(cid:16)(cid:19) (cid:179)(cid:81)(cid:72)(cid:68)(cid:85)(cid:180) (cid:54)(cid:83)(cid:82)(cid:85)(cid:87)(cid:86)(cid:40)(cid:89)(cid:72)(cid:81)(cid:87)(cid:16)(cid:19) (cid:87)(cid:92)(cid:83)(cid:72) (cid:179)(cid:74)(cid:68)(cid:80)(cid:72)(cid:180) (cid:36)(cid:81)(cid:71)(cid:50)(cid:83)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:16)(cid:19) (cid:68)(cid:85)(cid:74)(cid:21) (cid:44)(cid:81)(cid:70)(cid:85)(cid:72)(cid:68)(cid:86)(cid:72)(cid:36)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:16)(cid:19) (cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87) (cid:57)(cid:82)(cid:79)(cid:88)(cid:80)(cid:72)(cid:16)(cid:19) (cid:81)(cid:68)(cid:80)(cid:72) (cid:179)(cid:20)(cid:19)(cid:180)
(cid:68)(cid:85)(cid:74)(cid:20)
(cid:79)(cid:82)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81) (cid:70)(cid:82)(cid:81)(cid:86)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:72)(cid:71) (cid:75)(cid:82)(cid:80)(cid:72)(cid:55)(cid:72)(cid:68)(cid:80)
(cid:51)(cid:79)(cid:68)(cid:92)(cid:69)(cid:68)(cid:70)(cid:78)(cid:36)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:16)(cid:19) (cid:82)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87) (cid:48)(cid:88)(cid:86)(cid:76)(cid:70)(cid:53)(cid:72)(cid:70)(cid:82)(cid:85)(cid:71)(cid:76)(cid:81)(cid:74)(cid:16)(cid:19) (cid:81)(cid:68)(cid:80)(cid:72) (cid:179)(cid:70)(cid:75)(cid:68)(cid:85)(cid:79)(cid:76)(cid:72)(cid:3)(cid:69)(cid:85)(cid:82)(cid:90)(cid:81)(cid:180)
(cid:51)(cid:82)(cid:86)(cid:87)(cid:68)(cid:79)(cid:36)(cid:71)(cid:71)(cid:85)(cid:72)(cid:86)(cid:86)(cid:16)(cid:19) (cid:54)(cid:83)(cid:82)(cid:85)(cid:87)(cid:86)(cid:55)(cid:72)(cid:68)(cid:80)(cid:16)(cid:19)
(cid:81)(cid:68)(cid:80)(cid:72)
(cid:179)(cid:86)(cid:75)(cid:68)(cid:85)(cid:78)(cid:86)(cid:180)
(a)Cross-domain (b)Sequential(multipleactions)
Figure3:(a)istheAMRLfor“findrestaurantsnearthesharksgame.”.(b)istheAMRLfor“playcharliebrownandturnthe
volumeupto10”.TherearetwoactionsthatAMRLcouldhandlewithasequentialoperator.Theserequestsarechallengingto
handleusingthecurrentdomain-basedSLUrepresentation.
“playrayoflightbymadonna’ baselinemodelthathasaccesstoadditionalinputs,suchas
gazetteersandgeneral-purposewordembeddings.Therestof
Properties: play [ray of light] object.name by thisdocumentisorganizedasfollows,wereviewtherelated
[madonna] object.byArtist.name work, introduce the AMRL and SLU representations, the
Entities: play [ray of light] by
name@MusicRecording baselineandproposedmodels,acustomdecoderandresults.
[madonna]
name@Musician
Intents: PlaybackActionobject@MusicRecording
RelatedWork
Figure4:LinearizedannotationforAMRL. TheAlexaontologyisaversionofschema.org(Guha,Brick-
ley,andMacbeth2016)thathasbeenadaptedforspokenlan-
guageunderstanding.TheAlexaOntologyisusedasabasis
fortheAlexaMeaningRepresentationLanguage.Someal-
sports domains. The third benefit is that more complex re-
ternativesemanticrepresentationsincludeFrameNet(Baker,
questscanbesupported.Forexample,“playhungergames
Fillmore,andLowe1998),whichisasemanticrepresenta-
andturnthelightsdownto3”isnoteasilysupportedexisting
tionthatrepresentsanutterance,alongwithverbroles.Other
SLUrepresentationsinceitinvolvesmultipledomainsand
approacheshavearepresentationsimilartoAMRLincluding
mustalsosupportsequentialactions.
lambda-DCS(Liang2013)andcombinatorycategorialgram-
ThispaperpresentsmodelsthatcanpredictAMRLgiven mars(CCG)(SteedmanandBaldridge2011).AMRisarep-
anaturallanguageutterance.Inordertoaddressthelimited resentationthathasahierarchicalgraph-basedapproachthat
availability of AMRL data, a simple linearization scheme iswell-suitedforlongertexts(Banarescuandothers2013;
hasbeendeveloped(Figure4).ThelinearizedAMRLformat KevinKnight2017).Otherapproachesfocusmoreonsyntax
factorsintothreecomponents:intents,types,andproperties, thansemantics,suchasuniversaldependencies(Nivreand
whicharepredictedusingadeepneuralnetworkarchitecture others2016).Unliketheseapproaches,AMRLfocuseson
that is trained using multi-task learning. Each layer of the directlysupportingspokenlanguageunderstandingandcon-
modelpredictsacomponentofthelinearizedAMRLrepre- tainsfine-grainedtypesalongwithactions,verbroles,and
sentation.Byorderingthesetasksfromcoarsetofine,each properties.Anoverviewofothersemanticrepresentationsis
subsequentlayerisabletoreuserepresentationsfromprevi- coveredin(AbendandRappoport2017).
ouslayers.Thesimplestmodelconsistsofaword-embedding DNNsarewidelyusedforsequencelabeling.(Shimaokaet
layerandthreebi-directionalLSTMlayers,residualconnec- al.2016)performfine-grainedentitylabelingusinganeural
tions,andacustomdecodertoimproveaccuracy(Heetal. attention model. (Dong et al. 2015) use a combination of
2017). NNstoembedwordsandentitiesforcoarse-grainedentity
InadditiontolinearizingtheAMRLparsegraphs,wealso labeling.Morerecently,twotypesofnetworkarchitectures
leverageembeddingstrainedfromthemuchlargerdatasets havegainedpopularity.ThefirstoneisLSTM-CNNs(Chiu
thatareavailableforSLU.Asacomparison,thelinearized andNichols2015),whichuseacombinationofword-level
AMRLcorpusconsistedof300kexamples,whiletheSLU andCNN-extractedcharacter-levelfeaturestoaugmentthe
corpusconsistedofaround3millionexamples.Toleverage inputtobi-LSTMs.ThesecondoneisLSTM-CRFs(Huang,
thesedatasets,newlayersforintentsandslotswereadded Xu, and Yu 2015), which apply a CRF constraints to bi-
to our DNN models, and were trained as new tasks using LSTMs.Recently,(MaandHovy2016)combinedthetwo
multi-tasklearning.Slotembeddingsarefoundtoproduce approaches to get the state of the art results on standard
a 2.6% improvement in IRER (full-parse accuracy), while CONLL2003NERtask.
domainembeddingsimprovetheaccuracybyanother0.1% LSTMs (Long Short Term Memory) (Hochreiter and
IRER.Anadditional1%IRERimprovementisobtainedby Schmidhuber 1997) perform well on many NLP tasks in-
usingacustomdecoderthatleveragesspan-basedIOBand cludingsequencetagging,intentclassification,andlanguage
ontologicalconstraints.Ourproposedmodelevendecreases modeling due to their inherent ability to model long term
thefull-parseerrorrateby1.5%IRERwhencomparedtoa sequential dependencies. Bi-LSTMs (Graves, rahman Mo-
5391
hamed, and Hinton 2013) are layered architectures which • Properties define relationships between variables of a
effectivelyusepastandfutureinformationviaForwardand giventype.Forexample,the“byArtist”propertyofaMu-
BackwardLSTMlayers.Bi-LSTMshavebeensuccessfully sicRecording,defineswhowroteasong.
appliedtofeaturegenerationfortaskslikedependencypars-
• Operators Operators can be used to represent complex
ing(KiperwasserandGoldberg2016)andsemanticrolela-
logicalorspatialrelationships.
beling (Zhou and Xu 2015). All our models adopt a deep
neural-networkarchitecturewithBi-LSTMsasourprimary TheaimofAMRListoprovideacommonsemanticrep-
buildingblocks.Fortextclassification,therehasbeenalotof resentationforspokenlanguage.Itcanrepresentanaphora,
recentinterestinusingcharacter-levelembeddings(Kimetal. conditionalstatements,sequentialactions,andlogicalexpres-
2015)asanadditionalinputtoneuralarchitecturesbecause sions.AMRLcanhavearbitrarynesting,enablingittorepre-
oftheirabilitytomodelmorphologicalfeaturesaswellasef- sentcomplexstatements.Figure1showsasimpleexample
fectivelyhandleout-of-vocabularywords.(Ballesteros,Dyer, ofAMRL.Figure3showshowsequentialandcross-domain
andSmith2015)usecharacterembeddingfordependency queriescanberepresentedinAMRL.
parsing,(XiaoandCho2016)combinecharacterembeddings In this paper, we investigate linearization as a means to
withCNNsforthetextclassificationtask. addressthedatasparsityofannotatedAMRLexamples.Lin-
Semantic parsing and spoken language understanding earizationisacommonmethodtosimplifysyntactic(Vinyals
(SLU)learntomapnaturallanguagetoaformalrepresen- etal.2015),CCG(e.g.,viasupertagging) (Lewis,Lee,and
tation.Althoughsemanticparserscanbetrainedusingsen- Zettlemoyer2016),andAMRparsing(Pengetal.2017).The
tencesannotatedwiththisformalrepresentation(Zelleand linearization addresses data sparsity in two primary ways.
Mooney 1996; Zettlemoyer and Collins 2012; Wong and First,weusealinearizationschemesimilartoonethathas
Mooney2006;Kwiatkowskietal.2010;Krishnamurthyand beenshowntoimproveparseaccuracyforAMRparsingon
Mitchell2012),theyhavenotgenerallybeenuseddirectly similar size datasets (Peng et al. 2017). Secondly, we use
forspokenlanguage.Mostapplicationsofspokenlanguage a representation that aligns to the spoken language under-
understandingmapsutterancesontoafixeddomain,intent, standingproblem,aligningtheseslotsandintentswiththose
andslotstructure(Guptaetal.2006).Itcannotgenerallyrep- usedinAMRLparsing.Thisalignmentshouldimprovethe
resentcomplex,cross-domain,orcompositionalutterances. alignmentofembeddingsfromtheSLUdomain.
Multitasklearningindeepneuralnetworkshasbeenshown An example of the linearization scheme for AMRL can
tohelpgeneralization.SimilartoourworkbutwithCNNs beseeninFigure4.AMRLisarootedgraph.Startingatthe
(XuandSarikaya2013)jointlymodelsentenceclassification root,thepropertylinearizationrecursivelydescendstoaleaf,
andsequencelabeling.(Guoetal.2014)userecursiveneural appendingeachpropertyvisitedalongthewayuntilaleaf
networkstojointlyclassifyintentsandfillslots.(Miwaand node is reached. Incoming property arcs to a visited node
Bansal2016)achievedstateoftheartforentityandrelation areinvertedtoavoidcyclesandhandlemulti-headedgraphs.
classification. (Zhang and Weiss 2016) used them for part Typesoftheleafnodesaretheonlyonesthatappearinthe
ofspeechtagginganddependencyparsing.Transferringof linearization.Whenaleafnodeisvisited,thecorresponding
learnedembeddingswasexploredinin(Yosinskietal.2014). propertyisincludedinthelinearization(e.g.,oneof“type,”
Ourworkbuildsonthesebycreatingadeepmulti-taskmodel “value”or“name”).Intentsincludeaction,therolesonthe
forpredictingameaningrepresentationforspokenlanguage. action(e.g.,“object”),andthetypeofeachoftheroles.This
linearization enables the AMRL to be formulated as a se-
Approach quentialpredictionproblem,factoringintothreecomponents:
InthissectionwedescribetheAlexameaningrepresentation intents,types,andpropertiesasinFigure4.
language(AMRL),ourdeepmulti-taskmodel,mechanisms
forlearningrepresentationsforspokenlanguageunderstand- Models
ing(SLU)andtransferringthoserepresentationstoimprove AMRLparsingusemulti-tasklearningtojointlylearntasks
AMRLparsing. ofpredictingtheSLUorAMRLrepresentations.Inthissec-
tionwefirstdescribethebaselinemodelusedinourexperi-
AlexaMeaningRepresentationLanguage
ments.Thenwedescribemodelsthatleveragerepresentations
AMRLprovidesacommonsemanticsfornaturallanguage fromspokenlanguageunderstanding.Comparedtomodels
understandingforvoiceapplications.AnAMRLparsecon- trained separately for each of the tasks, multi-task models
sistsoffiveprimarycomponents: allowustoexploitcommonalitiesbetweentasks(Caruana
• Actionsdefinethecorefunctionalityusedforspokenlan- 1998)suchasoverlappingspansbetweenAMRLtypesand
guageunderstanding.InFigure1,thePlaybackActionis properties.
usedonaMusicRecording,butcanalsobeusedonBooks,
Baselinemodel Thebaselinemodelisadeepbi-directional
Videosandotherplayableobjects.
LSTM neural network trained using multi-task learning.
• Roles Actions operate on entities via roles. The .object
TherearethreeLSTMlayers,eachofwhichpredictsadif-
roledefinestheentityonwhichtheactionoperates.
ferentcomponentoftheparse.Thefirstlayerperformstype
• Typesapplytoeachentitymentioninarequestandare prediction,thenextlayerperformspropertypredictionand
hierarchical.InFigure1,thereisaMusicRecordingand thefinallayerperformsintentclassification.Thisstructures
Musiciantype. theproblemasacoarse-to-finepredictionproblem.Thetypes
5392
(cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:79)(cid:84)(cid:75)(cid:64) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:75)(cid:77)(cid:74)(cid:75) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:68)(cid:73)(cid:79) serialmodel(+SLUSlotspipe)predictstheSLUslotsbefore
predictingtheAMRLtypes,leveragingtheembeddingfrom
theSLUtasktodirectlypredictthelaterstagesofAMRL.
ThismodelcanbeseeninFigure6b.
(cid:74)(cid:73)(cid:64)(cid:3)(cid:67)(cid:74)(cid:79) Theremainingtwomodelingarchitecturesleverageboth
domain and slot embeddings. The domain of a query is a
strongindicatorontheentitiesandtheirrelationships.For
example,ifanutteranceisfromthe“Music”domain,thenit
islikelyinclude,forexample,artistsandsongs,aswellas
certainrelationshipsbetweentheentities(e.g.,“xxo”isbythe
Figure5:Topologyofthebaselinemulti-taskDNNmodel.
artist“Coldplay”).Assuch,theremainingtwoarchitectures
Eachcomponent(above)isabi-LSTMlayer.Thefinallayer
incorporatedomainembeddingsasinputtotheAMRLtypes
isasoftmax,andthedashedlineistherecurrentconnection.
andpropertylayers.Inbothmodels,weonlyinvestigateserial
“type”and“prop”performsequentialprediction,while“int”
embeddingsfortheSLUslotssincetheywerefoundtobe
categorizestheintentoftheuser.
betterthantheparallelarchitectureinearlyexperiments.
Inthethirdmodelarchitecture(+SLUSlots/Domain),the
domain layer is trained as a task in parallel to the AMRL
arepredictedatacoarse-grainedlevel,afterwhichthefine- typelayerandisinputtothepropertylayer.Therationale
grained properties and the actions are predicted. Residual behind this choice is that, although domain and property
connectionsareincludedtoleverageembeddingsfromprevi- predictionareverydifferenttasks,thedomain,whencorrectly
ousstages.Forexample,thewordembeddingsareusedas classified,canrestrictwhatkindofpropertiesweexpect(e.g.,
inputtotheLSTMlayerspredictingthepropertiesandthe if a sentence is classified in the Music domain we expect
actions.Figure5showsthetopologyofthismodel. propertiessuchasbyArtistbutnotweatherCondition).There
EachblockinFigure5isabi-directionalLSTM,which is still a shared embedding space learned as input to the
isusedforbothsequentialpredictionandclassification.At typemodel.Thismodel(+SLUSlots/Domain)isshownin
theoutputlayers,weformapredictionbyfeedingthecon- Figure6c.
catenated hidden representations for the token we wish to Thefinalmodelarchitecture(+SLUSlots/Domainpipe),
labelintoanotheraffinetransformfollowedbyasoftmaxto acommonLSTMembeddinglayeristrainedforSLUslots
obtainposteriorprobabilitiesoverthesetoflabels.Dropout and domains. This layer is input to the layer that predicts
isappliedaftereachLSTMlayer.Forclassification,onlythe theAMRLtypes.ThehypothesisisthatasingleLSTMem-
finalstatefromtheforwardandbackwardLSTMisusedto beddinglayermightbeenoughtoencodealltheinformation
predictthecategory. fromtheSLUrepresentation.Figure6dshowsthetopology
The first layer provides a shared word embedding (Col- forthisnetwork.
lobertandWeston2008),whiletheremainingthreeLSTM
Word embeddings and gazetteers We add to the input
layers are connected to an affine transform and a softmax
featureofourbaselinepre-trainedwordembeddingvectors
layertoprovidetheoutputforeachofthethreetasks(i.e.,
andgazetteers.Weusethreehundreddimensionalpre-trained
properties,type,andintentprediction).IOBtaggingisused
word2vecembeddings,trainedontheGoogleNewscorpus
todenotetheinside,outside,andbeginningofeachproperty
on100billionutterances(Mikolovetal.2013)andweincor-
andtypespan.Theinputofthisbaselinemodelisaone-hot
poratethemasanadditionalinputtotheone-hotencoding
vectorforeachwordinthesentence.
ofeachword.Gazetteers(listsofentitymentions)fromthe
AlexaontologythatbacksAMRLwereusedinasimilarway
Transferringlearnedrepresentations Therearefourpri-
towordembeddings(e.g.,asanadditionalinputperword).
marymodelingarchitecturesthathavebeenusedtoaddem-
Forexample,aMusiciangazetteerwillcontainalistofmusic
beddinglayersfordomains,intentsandslots.Thesearchi-
ofmusiciannameslike“Sting.”Thesefeaturesareindicators
tecturesusedomainandslotembeddingsfromtheSLUtask.
thataresetto1ifthecurrentwordorwordsequenceappears
IntentembeddingsfromtheSLUtaskwereaddedtoinitial
ina gazetteer,and setto0 otherwise. Thismodel usesthe
models,butdidnotresultsignificantperformancegains.
sametopologyofthebaseline,showninFigure5.
The first two model architectures leverage embeddings
fromSLUslots.Weinvestigatethisfirstbecauseweexpect Decoding Abeam-searchdecoderwaswrittentoleverage
thatSLUslotsandAMRLtypeswilloftenbecorrelatedin twoprimaryconstraintsofthismodelinordertoimprovethe
termsofthespansandsemantics.Weexpectthatasharedrep- accuracyoftheresult.Thefirstconstraintistoensurethese-
resentationthatleveragesthiscorrelationislikelytoimprove quenceoflabelsobeytheIOBconstraints.Theseconstraints
theoverallparseaccuracy. include(1)thatanI−tagfollowseitheranotherI−tagora
Two architectures that leverage a common embedding B−tagwiththesamelabel,and(2)aB−tagfollowsonlyan
layer either in parallel or in serial to the AMRL type- O−oranI−tag.Thesecondconstraintensuresthatthefinal
predictiontask.Theparallelmodel(+SLUSlots),includes propertylabel(e.g.,name,type,orvalue)matchestheinitial
aseparateSLUslot-predictiontaskinparalleltotheAMRL property label, which ensures that we produce predictions
type-predictiontaskresultinginacommonwordembedding consistentwiththeAMRLontology.Forexample,inFigure4,
layer. The resulting model can be seen in Figure 6a. The if“rayoflight”werepredictedas“type@MusicRecording”
5393
(cid:22)(cid:15)(cid:24)(cid:3)(cid:63)(cid:74)(cid:72)(cid:60)(cid:68)(cid:73)
(cid:22)(cid:15)(cid:24)(cid:3)(cid:78)(cid:71)(cid:74)(cid:79)(cid:78)
(cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:79)(cid:84)(cid:75)(cid:64) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:75)(cid:77)(cid:74)(cid:75) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:68)(cid:73)(cid:79) (cid:22)(cid:15)(cid:24)(cid:3)(cid:78)(cid:71)(cid:74)(cid:79)(cid:78) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:79)(cid:84)(cid:75)(cid:64) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:75)(cid:77)(cid:74)(cid:75) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:68)(cid:73)(cid:79)
(cid:74)(cid:73)(cid:64)(cid:3)(cid:67)(cid:74)(cid:79) (cid:74)(cid:73)(cid:64)(cid:3)(cid:67)(cid:74)(cid:79)
(a)Topologyofthe+SLUSlotsmodel. (c)Topologyofthe+SLUSlots/Domainmodel
(cid:22)(cid:15)(cid:24)(cid:3)(cid:63)(cid:74)(cid:72)(cid:60)(cid:68)(cid:73)
(cid:22)(cid:15)(cid:24)(cid:3)(cid:78)(cid:71)(cid:74)(cid:79)(cid:78) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:79)(cid:84)(cid:75)(cid:64) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:75)(cid:77)(cid:74)(cid:75) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:68)(cid:73)(cid:79) (cid:22)(cid:15)(cid:24)(cid:3)(cid:78)(cid:71)(cid:74)(cid:79)(cid:78) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:79)(cid:84)(cid:75)(cid:64) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:75)(cid:77)(cid:74)(cid:75) (cid:4)(cid:16)(cid:21)(cid:15)(cid:3)(cid:68)(cid:73)(cid:79)
(cid:74)(cid:73)(cid:64)(cid:3)(cid:67)(cid:74)(cid:79) (cid:74)(cid:73)(cid:64)(cid:3)(cid:67)(cid:74)(cid:79)
(b)Topologyofthe+SLUSlotsPipemodel (d)Topologyofthe+SLUSlots/DomainPipemodel
Figure6:Multi-taskmodelsusedfortrainingAMRLmodelsalongsideslotanddomainembeddingsfromtheexistingSLU
system.Highlightedinbluethebi-LSTMlayersaddedcomparedtothebaselinemodel.
butasapropertywaspredictedat“object.name,”thenthis generalizationperformance.
wouldbeaninvalidtransition.Thebeamsearchlimitsprop-
ertycandidatestothosethatareaboveminimumprobability. Datasets
The value of the lower bound probability determines how
Thetwodatasetsusedintheseexperimentsare(1)alarge
aggressivethepruningis.Thesearchisperformedoverthe
corpuscollectedforspokenlanguageunderstanding(SLU)
combinationofpropertiesandtypescreatedbycombining
and (2) a smaller corpus of linearized AMRL parses. The
thepropertycandidateswithallthepossiblematchingtypes.
SLU corpus is composed by a total of ∼2.8m unique sen-
tences.Thesesentencesspanontheorderof20domains,200
Optimization Weoptimizedtheparametersintwoways.
intents,and200slots.Thevocabularyofthisdatasetamounts
Inthefirstwefine-tunedpretrainedembeddingsfordomain
to∼150kdistinctwords.Therepresentationforthiscorpusis
andslots.Inthesecond,weperformedjointtraining,learning
showninFigure2.TheAMRLcorpusissignificantlysmaller
theSLUembeddinglayersatthesametimeastheAMRL
thentheSLUcorpusandcontainsonlyaround350kunique
ones. Each model is trained until it fully converges on the
sentencesinthelinearizedrepresentation.Thisdataconsists
trainingset,typicallythistakesaround60epochs.Weuse
ofintents,typesandproperties.Figure4showsanexample
a fixed learning rate of 0.0005 with an L2 penalty of 1e-
oftheannotationforthesamesentenceshowninFigure1.
8, and a batch size of 128 sentences each. The output of
TheAMRLcorpusspansover60linearizedintents,200prop-
each bi-LSTM layer is a vector of size 256 that is created
ertiesand200types.Thetotalvocabularyofthiscorpusis
byconcatenatingthehiddenrepresentationofforwardand
around42kwords,oneorderofmagnitudesmallerthenthe
backwardLSTMs(eachofsize128).
SLUone.Thedevelopmentsetandtestsetcontainaround
Topreventoverfittingtoourtrainingsetwetaketwomea-
48ksentencesannotatedusingAMRL.Accuracyisreported
sures.Firstweconnecttheoutputofeachbi-LSTMlayerto
onlyontheAMRLtestset.
adrop-outcomponentwithretentionrateof80%.Theoutput
ofthedrop-outcomponentisthenusedasinputforthefol-
Metrics
lowinglayers.Secondweuseweightedcross-entropyloss
functionswithaweightofλwhenjointtraining(seebelow). Fourmetricsareconsideredtoevaluateourmodels.Thefirst
We evaluate our accuracy on the development set to show two, F1IC, F1SC, are F1 scores evaluated respectively at
5394
Models F1 F1 ICER IRER
IC SC
Baseline 0.9383 0.8439 6.4464 25.7176
+SLUSlots 0.9416 0.8551 6.1254 24.2876
+SLUSlots(jt) 0.9389 0.8449 6.4587 25.6867
+SLUSlotspipe 0.9432 0.8602 5.8867 23.1312
+SLUSlotspipe(jt) 0.9390 0.8456 6.3311 25.3534
+SLUSlots/Domain 0.9431 0.8614 5.9649 23.0222
+SLUSlots/Domain(jt) 0.9435 0.8621 6.0204 23.1147
+SLUSlots/Domainpipe 0.9351 0.8232 6.8270 29.9418
+SLUSlots/Domainpipe(jt) 0.9400 0.8538 6.1789 24.4501
Table1:Modelsandtheirresults.Modelsmarkedas(jt)aretrainedusingthejointtrainingapproach.
intentandslotlevel.F1SC isastrongmetric,asitrequires Forthefirsttwomodelspretrainingappearstoresultinhigher
thespansandlabelsforboththepropertyandthetypetasks accuracybutfortheremainingtwotheoppositeseemstohold
tobecorrect. true. One possible explanation for this behavior is the use
TheIntentClassificationErrorRate(ICER)isinversely ofcrossentropylossfunctioninconjunctionwiththejoint
correlatedwiththeF1IC andmeasuresthenumberofincor- trainingapproach.Inourexperimentswefixedtheweight
rectintents.ICERisnotalwayssufficientastheremaybe forthelossfunctionbutadditionalhyper-parametertuning
multipleintentsinanutterance.TheformulaforICERis: mightimprovetheoverallresult.
Wealsocomparedtheaccuracyofthebaselineandourbest
#incorrect(intents)
performingmodelacrossdifferentactions.Figure7shows
#totalintents
thatourdatasetisskewed,withtwooftheactions(Playback
Finally,theIntentRecognitionErrorrate(IRER)iscom- and Search) covering more then 97% of the total training
putedas: instances;theremaining15actionshaveanalmostuniform
#incorrect(interpretation) amount of sentences. Table 2 shows the gain in ICER for
#totalutterances eachaction.Weobservehowtheimprovementismodeston
thetwomostrepresentedactionsbutmuchmorepronounced
whereweconsideraninterpretationincorrectifanyofthe
onthelessrepresentedones.Ingeneral,wefindthatwhen
slotsorintentsdiffersfromthegroundtruth.
thereissufficientdataavailable(i.e.,forthePlaybackand
Searchactions)addingmoreinformationfromtheSLUtask
Results
is not very helpful. On the other hand, when fewer train-
Table1showstheresultsfordifferentmodelarchitectures. inginstancesareavailabletheinformationprovidedbythe
ThebaselinemodelwastrainedusingonlytheAMRLcor- SLUtasksbecomesveryvaluableandstronglyimprovesthe
pus.Thevocabularywasprunedandonlywordsappearing results.
twiceormoreareused.Everyotherwordismappedtoan In Table 3, we evaluate the best models against those
“unknown”tokenresultinginavocabularyof∼25kwords. trainedwithwordembeddingsandgazetteers.Thebaseline
FromtheseresultsitappearsthatusingSLUtasksclearlypro-
videsbenefitwhentrainingAMRLmodels;ourbestmodel
(+SLUSlots/Domain)outperformsthebaselineacrossallthe
metricsandsomebyaconsiderablemargin.
Wealsocomparedfine-tuningpretrainingembeddingsand
jointtraining(learningtheSLUembeddinglayersatthesame
time as the other embeddings). For pretraining, we train a
networktopredicttheSLUtasks;onceconvergedtheAMRL-
specificcomponents(i.e.,thelastthreeLSTMlayersofeach
model)areaddedandtraineduntilconvergenceusingacross-
entropy loss. Joint training optimizes both SLU tasks and
AMRLonesatthesametime.Ateachtime-steparandom
training instance is selected from one of the two corpora
withprobability(p = |AMRL|/|SLU|).Sincethesizeof
the SLU corpus is much bigger then the AMRL one, we
need to prevent overfitting on the SLU tasks. To do so we
usedweightedcrossentropylossfunctionswheretheSLU
tasksweredown-weightedbyafactorλ=|AMRL|/(10×
|SLU|).
Figure7:Actiondistributiononthetrainingandtestingset
We see a slight improvement in accuracy of the models
fortheAMRLcorpus.
thatusejointtraining,thoughtherearenoconclusiveresults.
5395
Actions Traininginstances ΔICER F1 IC F1 SC IRER
PlaybackAction HIGH -0.53 baseline 0.93 0.84 25.71
SearchAction MED -0.17 baseline+emd+gaz 0.94 0.86 23.65
NextAction LOW -3.34 proposedmodel 0.94 0.86 23.11
ResumeAction LOW -10.81 proposedmodel+decoder 0.94 0.87 22.15
BrowseAction LOW +5.88
StopAction LOW -1.93 Table3:Resultsascomparedtovariousbaselines.Baseline
CreateAction LOW 0
isthemulti-taskmodeltrainedonlyonAMRLdata.Base-
RepeatAction VLOW +3.13
line+emb+gazisthebaselinemodelwithwordembedding
PreviousAction VLOW -23.23
andgazetteerfeaturesasinputtothemodel.Proposedmodel
CheckAction VLOW -5.08
isthebestmodelwithoutwordembeddingsorgazetteerfea-
DislikeAction VLOW -1.96
PauseAction VLOW -11.86 tures.Proposedmodel+decoderincludesresultsafterdecod-
NavigateAction VLOW -5.12 ingofthebestmodel(withoutgazetteersorwordembeddings
LikeAction VLOW -6.94
asinput).Beamsizeisthreeandafloorprobabilityof10−7
RestartAction VLOW 0 isused.
Table2:ΔatICER.TheHIGHbincontainsmorethan100k
examples.TheMEDbincontainsbetween2kand100kexam- and 17th International Conference on Computational Lin-
ples.TheLOWbincontainsbetween800and2kexamples. guistics-Volume1,ACL’98,86–90. Stroudsburg,PA,USA:
The VLOW bin contains between 100 and 800 examples. AssociationforComputationalLinguistics.
Theactionsareordered,indecreasingfashion,basedonthe
Ballesteros,M.;Dyer,C.;andSmith,N.A. 2015. Improved
numberofoccurrencesintheAMRLtrainingset.
transition-basedparsingbymodelingcharactersinsteadof
wordswithlstms. arXivpreprintarXiv:1508.00657.
Banarescu,L.,etal. 2013. Abstractmeaningrepresentation
model, which only has access only to the AMRL training
forsembanking. InProceedingsofthe7thLinguisticAnnota-
datasethaslowestaccuracy.Addinggazetteerandwordem-
tionWorkshopandInteroperabilitywithDiscourse,178–186.
beddings improves accuracy, though the best model is the
Sofia,Bulgaria:AssociationforComputationalLinguistics.
onethattransfersthelearnedrepresentationsfromtheSLU
Caruana,R. 1998. Multitasklearning. InLearningtolearn.
task(proposedmodelfromTable1).Incorporatingtheaddi-
Springer. 95–133.
tionalconstraintsinthedecoder(e.g.,IOBandfinalproperty)
resultsinourbestmodel.Fortheseexperiments,weuseda Chiu, J. P., and Nichols, E. 2015. Named entity
decoderwithabeamofsize3andaminimumprobability recognition with bidirectional lstm-cnns. arXiv preprint
of 10−7. As expected the decoder does not impact any of arXiv:1511.08308.
theintentmetrics(F1 IC andICER).Thestructurallyincor- Collobert,R.,andWeston,J. 2008. Aunifiedarchitecture
rectnessofthepredictedoutputsisupperboundedby0.96% fornaturallanguageprocessing:Deepneuralnetworkswith
IRERusingourproposedmodelwiththecustomdecoder. multitasklearning. InProceedingsofthe25thinternational
conferenceonMachinelearning,160–167. ACM.
Conclusion
Dong,L.;Wei,F.;Sun,H.;Zhou,M.;andXu,K. 2015. A
AMRLisanewgraph-basedrepresentationforthemeaning hybrid neural model for type classification of entity men-
ofasentence.SinceannotatingAMRListimeconsuming tions. InProceedingsofthe24thInternationalConference
andcostly,onlyalimitedamountofdataisavailable.Inthis onArtificialIntelligence,1243–1249. AAAIPress.
paperweshowthatlearnedembeddingsfromrelatedtasks Graves, A.; rahman Mohamed, A.; and Hinton, G. 2013.
can improve the accuracy of AMRL models. Domain and Speechrecognitionwithdeeprecurrentneuralnetworks. In
slotembeddingshelpsignificantly,improvingtheaccuracy IEEE International Conference on Acoustics, Speech and
by3.56%IRER(full-parseaccuracy).Aconstraineddecoder SignalProcessing(ICASSP).
thatleveragesIOBandtype/propertyconstraintsisakeycom- Guha,R.V.;Brickley,D.;andMacbeth,S.2016.Schema.org:
ponent,decreasingIRERby1%absolute.Althoughtraining Evolution of structured data on the web. Commun. ACM
timeisalimitingfactor,wewouldalsoliketoexplorethe 59(2):44–51.
useofaCRFoutputlayertoencodesomeofthedecoding
Guo,D.;Tur,G.;Yih,W.-t.;andZweig,G. 2014. Jointse-
constraints.
manticutteranceclassificationandslotfillingwithrecursive
neuralnetworks. InSpokenLanguageTechnologyWorkshop
References
(SLT),2014IEEE,554–559. IEEE.
Abend,O.,andRappoport,A. 2017. Thestateoftheartin Gupta,N.;Tur,G.;Hakkani-Tur,D.;Bangalore,S.;Riccardi,
semanticrepresentation. InProc.ofACL. G.;andGilbert,M. 2006. Theat&tspokenlanguageunder-
Baker, C. F.; Fillmore, C. J.; and Lowe, J. B. 1998. The standingsystem. IEEETransactionsonAudio,Speech,and
berkeleyframenetproject. InProceedingsofthe36thAnnual LanguageProcessing14(1):213–222.
Meeting of the Association for Computational Linguistics He,L.;Lee,K.;Lewis,M.;andZettlemoyer,L. 2017. Deep
5396
semanticrolelabeling:Whatworksandwhatsnext. InPro- Steedman,M.,andBaldridge,J. 2011. CombinatoryCatego-
ceedingsoftheAnnualMeetingoftheAssociationforCom- rialGrammar. Wiley-Blackwell. 181–224.
putationalLinguistics. Vinyals, O.; Kaiser, Ł.; Koo, T.; Petrov, S.; Sutskever, I.;
Hochreiter,S.,andSchmidhuber,J. 1997. Longshort-term andHinton,G. 2015. Grammarasaforeignlanguage. In
memory. Neuralcomputation9(8):1735–1780. AdvancesinNeuralInformationProcessingSystems,2773–
2781.
Huang, Z.; Xu, W.; and Yu, K. 2015. Bidirectional
lstm-crf models for sequence tagging. In arXiv preprint Wong,Y.W.,andMooney,R.J. 2006. Learningforsemantic
arXiv:1508.01991. parsingwithstatisticalmachinetranslation. InProceedings
of the main conference on Human Language Technology
Kevin Knight, Bianca Badarau, L. B. C. B. M. B. K. G.
ConferenceoftheNorthAmericanChapteroftheAssocia-
U. H. D. M. M. P. T. O. N. S. 2017. Abstract meaning
tionofComputationalLinguistics,439–446. Associationfor
representation(amr)annotationrelease2.0.
ComputationalLinguistics.
Kim, Y.; Jernite, Y.; Sontag, D.; and Rush, A. M. 2015.
Xiao,Y.,andCho,K. 2016. Efficientcharacter-leveldocu-
Character-aware neural language models. arXiv preprint
mentclassificationbycombiningconvolutionandrecurrent
arXiv:1508.06615.
layers. arXivpreprintarXiv:1602.00367.
Kiperwasser,E.,andGoldberg,Y.2016.Simpleandaccurate
Xu,P.,andSarikaya,R. 2013. Convolutionalneuralnetwork
dependencyparsingusingbidirectionallstmfeaturerepresen-
basedtriangularcrfforjointintentdetectionandslotfilling.
tations. TransactionsoftheAssociationforComputational
InAutomaticSpeechRecognitionandUnderstanding(ASRU),
Linguistics(TACL)(4):313327.
2013IEEEWorkshopon,78–83. IEEE.
Krishnamurthy,J.,andMitchell,T.M. 2012. Weaklysuper-
Yosinski, J.; Clune, J.; Bengio, Y.; and Lipson, H. 2014.
visedtrainingofsemanticparsers.InProceedingsofthe2012
Howtransferablearefeaturesindeepneuralnetworks? In
JointConferenceonEmpiricalMethodsinNaturalLanguage
Advancesinneuralinformationprocessingsystems,3320–
ProcessingandComputationalNaturalLanguageLearning,
3328.
754–765. AssociationforComputationalLinguistics.
Zelle, J. M., and Mooney, R. J. 1996. Learning to parse
Kwiatkowski,T.;Zettlemoyer,L.;Goldwater,S.;andSteed-
databasequeriesusinginductivelogicprogramming. InPro-
man,M. 2010. Inducingprobabilisticccggrammarsfrom
ceedingsofthenationalconferenceonartificialintelligence,
logicalformwithhigher-orderunification. InProceedingsof
1050–1055.
the2010ConferenceonEmpiricalMethodsinNaturalLan-
guage Processing,EMNLP’10, 1223–1233. Stroudsburg, Zettlemoyer, L. S., and Collins, M. 2012. Learning to
PA,USA:AssociationforComputationalLinguistics. map sentences to logical form: Structured classification
with probabilistic categorial grammars. arXiv preprint
Lewis, M.; Lee, K.; and Zettlemoyer, L. 2016. Lstm ccg
arXiv:1207.1420.
parsing. InHLT-NAACL,221–231.
Zhang, Y., and Weiss, D. 2016. Stack-propagation: Im-
Liang,P. 2013. Lambdadependency-basedcompositional
proved representation learning for syntax. arXiv preprint
semantics. CoRRabs/1309.4408.
arXiv:1603.06598.
Ma, X., and Hovy, E. 2016. End-to-end sequence la-
Zhou,J.,andXu,W. 2015. End-to-endlearningofsemantic
beling via bi-directional lstm-cnns-crf. arXiv preprint
rolelabelingusingrecurrentneuralnetworks.InTransactions
arXiv:1603.01354.
oftheAssociationforComputationalLinguistics(TACL).
Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013.
Efficientestimationofwordrepresentationsinvectorspace.
arXivpreprintarXiv:1301.3781.
Miwa, M., and Bansal, M. 2016. End-to-end relation ex-
tractionusinglstmsonsequencesandtreestructures. arXiv
preprintarXiv:1601.00770.
Nivre, J., et al. 2016. Universal dependencies v1: A mul-
tilingualtreebankcollection. InChair),N.C.C.;Choukri,
K.; Declerck, T.; Goggi, S.; Grobelnik, M.; Maegaard, B.;
Mariani,J.;Mazo,H.;Moreno,A.;Odijk,J.;andPiperidis,
S.,eds.,ProceedingsoftheTenthInternationalConference
onLanguageResourcesandEvaluation(LREC2016). Paris,
France:EuropeanLanguageResourcesAssociation(ELRA).
Peng, X.; Wang, C.; Gildea, D.; and Xue, N. 2017. Ad-
dressingthedatasparsityissueinneuralamrparsing. arXiv
preprintarXiv:1702.05053.
Shimaoka,S.;Stenetorp,P.;Inui,K.;andRiedel,S. 2016.
Neuralarchitecturesforfine-grainedentitytypeclassification.
arXivpreprintarXiv:1606.01341.
5397
