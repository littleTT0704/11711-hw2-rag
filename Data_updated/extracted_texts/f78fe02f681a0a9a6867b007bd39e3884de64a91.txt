SODA: Million-scale Dialogue Distillation
with Social Commonsense Contextualization
HyunwooKim♡♠ JackHessel♡ LiweiJiang♡♢ PeterWest♢ XimingLu♢
YoungjaeYu♡ PeiZhou♡♣ RonanLeBras♡ MaliheAlikhani†
GunheeKim♠ MaartenSap♡‡ YejinChoi♡♢
♡AllenInstituteforArtificialIntelligence ♠SeoulNationalUniversity ♢UniversityofWashington
♣UniversityofSouthernCalifornia †UniversityofPittsburgh ‡CarnegieMellonUniversity
Abstract
CO3 Distillation Framework
Datascarcityhasbeenalongstandingissuein
Social • Head: PersonX moves a step closer to the goal
the field of open-domain social dialogue. To Commonsense • Relation: xNeed
Knowledge • Tail: to take the first step
quenchthisthirst,wepresent SODA:thefirst
publicly available, million-scale high-quality Social Madeleine took the first step towards her
socialdialoguedataset. Bycontextualizingso- Narrative g wo oa rdl, sa , n sd h ew mith o vh ee sr oco na ec sh t’ es p e cn lc oo su er ra .ging
cial commonsense knowledge from a knowl-
edgegraph,weareabletodistillanexception- Social Madeleine: Hey coach, allybroadspectrumofsocialinteractionsfrom ConA ted xd t Dialogue I m w ya pn ete rfd o rt mo ata nl ck e t o to y do au y a . bout
with LLM
a large language model. Human evaluation Coach: Well Madeleine, you’re
shows that conversations in SODA are more progressing nicely. You’ve
come a long way since we first
consistent,specific,and(surprisingly)natural started working together.
…
thanthoseinpriorhuman-authoreddatasets.
UsingSODA,wetrain COSMO: ageneral-
izableconversationmodelthatissignificantly Cosmo
Soda
morenaturalandconsistentonunseendatasets Conversation
A Dataset of High-quality Model with
thanbest-performingconversationmodels(e.g., 1.5M Social Dialogues Greater Generalizability
GODEL, BlenderBot-1, Koala, Vicuna). Ex-
periments reveal COSMO is sometimes even Figure1: Anillustrationofour CO 3 framework(§2),
preferred to the original human-written gold SODA dataset (§3), and conversation model COSMO
responses. Additionally,ourresultsshedlight (§4)trainedonSODA. Conversationsaredistilledfrom
onthedistinctionbetweenknowledge-enriched alargelanguagemodel(LLM)bycontextualizingsocial
conversationsandnaturalsocialchitchats. We commonsense. ThefullexampleisinTable1.
makeourdata,models,andcodepublic.1
1 Introduction To alleviate this bottleneck, we introduce
SODA(SOcialDiAlogues),amillion-scaleEnglish
Conversationsthatoccurineverydayspokensitua-
dialoguedatasetcoveringawidevarietyofsocial
tionsareoftennotrecordedasdata. Andwhenthey
interactions. Asaresultofbeinggroundedonrich
are,suchasinthecaseoftextmessages,research
social commonsense and narratives, SODA goes
useisrightlyrestrictedduetoprivacyandlegalcon-
beyond specific skill-focused dialogues and fea-
cerns. Asaresult,collectinghigh-quality,everyday
turesmoregeneralconversations. Ourdatasetin-
socialconversationsonalargescalehaslongbeen
cludes1.5milliondialoguesdistilledfromalarge
recognizedasadifficulttask(Smithetal.,2020).
language model (in our case, GPT-3.5; Ouyang
Previousstudieshavereliedoncrowdsourcingfo-
etal.,2022)resultinginmorethan11millionutter-
cusedonspecificthemesofdialogue(e.g.,persona,
anceswith300milliontokens: SODAisthelargest
empathy;Zhangetal.,2018;Rashkinetal.,2019).
publiclyavailableopen-domainsocialconversation
However, this approach is limited in scale due to
dataset. Humanevaluation showsthat SODA sur-
itsassociatedcosts. Asaresult,theprogressmade
passesexistinghuman-authoreddialoguecorpora
inmachinedialogues,includinggeneration,evalua-
acrossaxeslikeconsistency,specificity,and(sur-
tion,andunderstanding,hasbeenseverelyhindered
prisingly,even)naturalness(§3.2).
bytherelianceonthesesmalldatasets(Kannetal.,
To make SODA, we propose CO 3, a frame-
2022;Mehrietal.,2022).
workforCOntextualizingCOmmonsensefordis-
1https://hyunw.kim/sodaverse tillingCOnversationsfromalargelanguagemodel
3202
tcO
32
]LC.sc[
3v56401.2122:viXra
(LLM).IllustratedinFigure1, CO infusescom- 2 CO : AContextualization
3 3
monsenseknowledgeintodialoguesbytransform- FrameworkforConversation
ingknowledgetriplesintonarratives,andtheninto DistillationusingCommonsense
dialogues. Such an approach offers two signifi-
We propose CO , a framework for distilling
cantadvantages: (1)maximizingdiversityand(2) 3
conversationsfromlargelanguagemodels(LLMs)
minimizingnonsensicalconversations. Although
bycontextualizing(i.e.,addingmorecontextinfor-
generatingcontentusingLLMsisrelativelyeasy,
mation)commonsenseknowledge. Ourgoalisto
determininghowtocoverdiversecontentposesa
obtainnaturalconversationscoveringawidevari-
non-trivialchallenge. Wefindthatsamplingfrom
ety of social interactions. CO consists of three
an LLM without contexts results in dull conver- 3
steps: (1)Retrievingsocialcommonsensefroma
sations(§3.3). Becausecommonsenseknowledge
symbolic commonsense knowledge graph (§2.2),
graphscoverawiderangeofeverydaysituations
(2)convertingitintosentenceformandgenerating
(West et al., 2022), conditioning on them results
anarrativefromthesentence(§2.3),and(3)infer-
in a broad spectrum of conversations. Moreover,
ringtheconversationparticipantsfromthenarrative
sinceLLMsarepronetohallucinations(Weidinger
andderiveaconversationgroundedinthenarrative
et al., 2021), the seed commonsense knowledge
(§2.4). We use GPT-3.5 (i.e., text-davinci-0022;
canhelpthemstayonasensiblegenerationpath.
Ouyang et al., 2022) to implement CO , though
3
With SODA, we train a COnverSation MOdel,
in practice, a different model could be used. We
COSMO. Human evaluation results demon- use CO
3
tocreate SODA: anexampleisinTable1.
strate that: (1) COSMO generalizes better to un- MoredetailscanbefoundinAppendixA.
seenconversationsthanexistingbest-performing
dialoguemodels,winningbymorethan40%onav- 2.1 InspirationBehind CO 3
erageinhead-to-headcomparisonsversusBlender- What is at the heart of conversation? At its core,
Bot (Roller et al., 2021), Koala (Geng et al., aconversationisafundamentalformofsocialin-
2023),andVicuna(Chiangetal.,2023)(§5.1);(2) teraction(Myllyniemi,1986). Theseexperiences
COSMO outperforms BlenderBot (with the same are abstracted into narratives or scripts (Mar and
number of parameters) on the dataset Blender- Oatley,2008;Rumelhart,1975;SchankandAbel-
Bot was trained on, despite never seeing the cor- son, 1975). Eventually, social experiences form
pus (§5.2); and (3) COSMO responses are even ourknowledgeforexplainingeverydayeventsand
preferred over human-authored, ground-truth re- inferringthementalstatesofothers(Heider,1958).
sponsesinDailyDialog(Lietal.,2017),adataset Thisinference iscoinedattribution insocial psy-
onwhich COSMOwasnottrainedon(§5.1). chology (Baumeister and Bushman, 2017), and
Finally, the distilled dialogues in SODA repre- has been studied in NLP as social commonsense
sent a significant resource contribution for open- (Rashkinetal.,2018;Sapetal.,2019). Inspiredby
domaindialogueresearch. Mostofall, SODA en- cognitivescience, wereversetheabstractionpro-
ables the research community to train smaller di- cess,startingfromsocialcommonsenseknowledge
alogueagentswithcompetitivecapabilities. Also, insymbolicforms,andunfoldrichnarrativesand
SODA can help enhance the generalizability of conversationsthatcouldhaveinitiallyencapsulated
otheradvancementsinthedialoguefield(e.g.,un- thosecommonsenseknowledge.
derstandingandevaluation),whichhavereliedon
2.2 CommonsenseKnowledgeGraph
existingsmalldatasets. Lastly, SODAhighlightsa
dimensionwhererecentLLM-basedconversational Concretely, westartwithacommonsenseknowl-
agents(e.g.,Koala,Vicuna,andChatGPT)struggle edge graph, which captures various relations of
– i.e., the naturalness of the responses (§5.1 and everydayeventsandinferencesonothers’mental
§5.3). As these models are designed to provide statesinsymbolicforms(Sapetal.,2019;Hwang
knowledge-basedresponses,theymaygeneratere- etal.,2021). Theknowledgegraphisrepresented
sponses that are informative but lack the natural- bysymbolictriplesdescribingtwoevents,denoted
nessfoundinsocialchitchat. Weplantopublicly astheheadandtail,andtherelationbetweenthose
releaseSODA,COSMO,andCO
3
underthepermis- two events, e.g., Head: PersonX moves a step
sivelicenseCC-BY-4.0,aimingtoaddressthedata
2https://beta.openai.com/docs/model-index-for-
scarcityissueinopen-domaindialogue. researchers/models-referred-to-as-gpt-3-5
closer to the goal, Relation: xNeed, Tail: to
SymbolicSocialCommonsenseKnowledge:
take the first step. WeuseAtomic10x (West • Head:PersonXmovesastepclosertothegoal
et al., 2022) as our knowledge graph: it includes • Relation:xNeed
• Tail:totakethefirststep
diversesocial(e.g.,intention,desire,reaction)and
Sentence-form Commonsense: Madeleine took the first
event-centered(e.g.,orderofevents)commonsense. step.Madeleinemovesastepclosertothegoal.
Since we are interested in distilling social inter-
Narrative:
actions, we only retrieve triples related to social Madeleinetookthefirststeptowardshergoal,andwithher
(ratherthan,e.g.,physical)commonsense.3 coach’sencouragingwords,shemovesonestepcloser.
Speakers:Madeleine,Coach
2.3 CommonsenseKnowledge→Narrative
Conversation:
Madeleine: Heycoach,Iwantedtotalktoyouaboutmy
TripleFormtoSentenceForm Sincecommon-
performancetoday.IwasreallypushingmyselfandIthink
sense knowledge graphs are represented in sym- Ididprettywell.ButI’mstillnotquitewhereIwanttobe.
bolicform(i.e.,triples),wefirstconverttheminto Coach:WellMadeleine,you’reprogressingnicely.You’ve
comealongwaysincewefirststartedworkingtogether.But
simplesentenceswithtemplatesforeachrelation.
ifyouwanttoreachyourfullpotential,there’sstillsome
Forexample,thecommonsenseknowledgeinTa- worktobedone.
ble1isconvertedto“Madeleinetookthefirststep. Madeleine: I know that. And I’m willing to put in the
work.It’sjustthatsometimesIfeellikeI’mnotmakingas
Madeleine moves a step closer to the goal.” To
muchprogressasIshouldbe.MaybeI’mnottraininghard
makethesentencessoundmorenatural,wereplace enough?Ormaybemytechniqueisoff?
Coach:Itcouldbeanumberofthings,Madeleine.Butdon’t
thepersonvariables(e.g.,PersonX,PersonY)with
worry,we’llfigureitouttogether.Let’sjustkeepworking
Top-1KcommonnamesofUSSSNapplicantsrang- hardandseehowthingsgo.
ingfrom1990to2021.4 Madeleine:Alright,coach.Thanksforthetalk.
Coach:Noproblem.Seeyouatpracticetomorrow.
SentenceFormtoNarrative Next,weprompt
Table1: Asamplefrom SODA. Moreexamplescan
GPT-3.5toinstantiatethesentence-formintoatwo-
befoundinAppendixB.
orthree-sentenceshortnarrative,e.g.,forthecom-
monsenseexampleabove“Madeleinetookthefirst 3 SODA:
steptowardshergoal,andwithhercoach’sencour-
AMillion-scaleSocialDialogueDataset
aging words, she moves one step closer. ” Prior
workhasshownthatLLMscaneffectivelygener- WeobtainSODA(SOcialDiAlogues),alarge-scale
atestorieswithplausibledetailsthatgobeyondthe high-qualityconversationdatasetcoveringawide
contentsoftheprompt(Radfordetal.,2019). range of social interactions, by applying a series
ofpost-processing(§3.1)totheconversationsgen-
2.4 Narrative→Conversation eratedfromourcontextualizationframework(§2).
InferringConversationParticipants Inferring WecompareSODAwithexistinghuman-curateddi-
theconversationparticipantsfromthenarrativeis aloguecorpora(§3.2)andanalyzetheeffectiveness
straightforwardincaseswheretriplescontaintwo ofcontextualization(§3.3). Table1showsasample
personvariables(i.e.,PersonXandPersonY).But fromourdataset. MoredetailsareinAppendixB.
for triples that include only one person (e.g., the
3.1 Post-processingtheConversations
exampleinTable1),wequeryGPT-3.5topredict
theotherinterlocutor(e.g.,mom,coworker). BasicFiltering Startingwithaninitialsetof2.2
millionconversationssampledfromGPT-3.5,we:
GeneratingConversationgroundedinNarrative
(1) use lexical pattern matching to filter out con-
Withthenarrativeandspeakersasinput,weprompt
versationswitherroneouspatterns–e.g.,repetition
GPT-3.5togenerateafull,multi-turnconversation
and omission of speaker prefixes (6.3%); (2) re-
betweenthespeakersinthecontextofthenarrative.
moveconversationsthathavelessthanfourturns
Weappendthefirstspeakerasanutteranceprefix
ormorethantwentyturns(5.7%);(3)removecon-
totheprompt. Indicatingthespeakerswithprefixes versationswithmorethantwospeakers(11.3%);5
helps GPT-3.5 generate fluent conversations that
and (4) remove conversations where at least one
alternatebetweenthetwo.
ofthespeakerswasidentifiedasnon-human(e.g.,
3Weleaverelationsforphysicalandevent-centeredcom- broomstick,imaginaryfriend,dog;5.6%).
monsensetopotentialfuturework.
4catalog.data.gov/dataset/baby-names-from- 5Althoughourpipelinenaturallygeneratesmulti-partycon-
social-security-card-applications-national-data versationsaswell,wefocusondyadicdialoguesinthiswork.
300
SODA DailyDialog SODA BlendedSkillTalk
250
200
150
100
50
0
Figure2: Resultsofhead-to-headcomparisonbetweendialoguesfrom SODA,DailyDialog(Lietal.,2017),and
BlendedSkillTalk(Smithetal.,2020)viahumanjudgments(§3.2). They-axisrepresentsthenumberofsamples
preferredbyhumanjudges. ThedifferencesinallofthecategoriesexceptfortheContextDependencecomparing
SODAandBlendedSkillTalkarestatisticallysignificant(|z|>3.3, p<0.05).
SafetyFiltering Inordertoavoidconversations on the human-annotated subset, with a precision
with dangerous and harmful contents, we apply of 97 for answering “yes". We find 95% of the
twosafetyfilters: Canary(Kimetal.,2022a)and filteredconversationsareidentifiedbyGPT-3.5as
RewireAPI.6 Canaryisanarrativedialoguesafety containingtheheadevent. Pairsthatlackthehead
modelthatcanclassifywhetherthegivencontext event are removed to ensure relevance between
needscautionorintervention. Wediscardallcon- thenarrative-conversationpairsandcommonsense
versationsmarkedasneedingintervention(usually triples. MoredetailsareinAppendixB.1.
criticalsituations,e.g.,crimes,emergencies;4.3%);
Final Dataset After all filtering, 68.9% of the
RewireAPIisaweb-basedAPIfordetectingtoxic
initial conversations remain, which form the
content. Wediscardallconversationsthatareabove
thethresholdof0.5foranyofthe‘violence’,‘hate’,
1,486,896conversationsin SODA.
and‘sexuallyexplicit’criteria(∼1%).
NameBiasMitigation Weaimtominimizebi-
Commonsense Filtering We conduct a small- asesassociatedwithspecificnameswhileincreas-
scale human evaluation via Amazon Mechani- ing inclusion and diversity. Both language mod-
cal Turk with 100 randomly sampled narrative- elsandcurateddatasetsoftenexhibitdemographic
conversation pairs (3 annotators per instance) to imbalances (Dinan et al., 2020; Weidinger et al.,
checkwhetherornottheseedcommonsensetriple 2021;Shengetal.,2021). InspiredbySmithand
is meaningfully instantiated by the narrative and Williams (2021), we randomly replace all names
conversation. Accordingtomajorityvote,88%of inconversationswithTop-10KnamesofUSSSN
theinstancesincludetheseedcommonsenseknowl- applicantsfrom1990to2021.7 Thiscovers95%of
edge. Giventhatthemajorityofhuman-annotated allapplicants’namesfromthechosentimerange
samplesincludetheseedcommonsense,wefocus window,includingvariousnamesfromdiversegen-
our filtering on excluding narrative-conversation der8 andethnicbackgrounds.
pairsthatlacktheheadevent,astheyareirrelevant
tothegivenseedcommonsense. 3.2 Comparing SODAwith
Toapplythisfiltertoallentriesofthecorpus,we Human-authoredDialogues
useGPT-3.5asazero-shotclassifier. AsGPT-3.5
High Quality To assess relative quality of the
demonstrated great performance in question an-
corpus, we conduct head-to-head human evalu-
swering(Ouyangetal.,2022),wevalidatethegen-
ations on Amazon Mechanical Turk, comparing
erated narrative-conversation pairs by asking the
SODAwithtwowidelyusedopen-domaindialogue
languagemodelitselftojudgewhetherornotthe
datasets: DailyDialog(Lietal.,2017)andBlended-
headofthecommonsensetripleisimplied. Wefor-
SkillTalk(Smithetal.,2020). Werandomsample
mulatethisasthree-waymultiplechoicequestions
300dialoguesfromeachdatasetandevaluatethem
(i.e.,yes,no,andunknown)andranktheanswers
according to six criteria (Mehri et al., 2022): (1)
accordingtotheirperplexityscoresfromGPT-3.5.
Thiszero-shotclassifierachieveshighperformance 7WeuseTop-1Knameswhencontextualizingthecommon-
sensetriplesin§2.3.
6https://rewire.online/ 8Gender-neutralandnonbinarynamesarealsoincluded.
Avg. Avg.Utt. Lexical Commonkeywordsacrossallrelations
#Dialog
#Turns Length Diversity
friendship,help,support,communication,family,
DailyDialog 13K 7.9 14.6 63.0 car,happiness,school,success,work
PersonaChat 11K 14.8 14.2 43.6
WizardOfWikipedia 22K 9.1 16.4 60.3
Commonkeywordsforeachrelation(excludingtheabove)
EmpatheticDialogue 25K 4.3 13.7 64.2 xAttr kindness,anger,intelligent,responsibility,friend,
BlendedSkillTalk 7K 11.2 13.6 64.2 (18%) trust,conversation,food,generosity,smart
ProsocialDialog 58K 5.7 20.0 60.2 xEffect gratitude,anger,upset,hardwork,happy,money,
(17%) friend,boss,party,kindness
SODA 1.5M 7.6 16.1 68.0
xIntent independence,hardwork,determination,money,
(23%) relaxation,anger,kindness,store,understanding
Table 2: Statistics of SODA compared to other large-
scaledialoguedatasets. Utt. denotesutterance. Lexical xNeed job,money,confidence,comfort,advice,
diversityismeasuredwithMTLD(McCarthyandJarvis, (7%) interest,conversation,listening,store,park
2010). DescriptionforeachdatasetisinAppendixF. xReact frustration,anger,confidence,happy,pride,relief,
(25%) disappointment,relaxation,anxiety,satisfaction
xWant conversation,store,determination,apology,learning,
naturalflow,(2)contextdependence,(3)topiccon-
(11%) doctor,job,friend,improvement,marriage
sistency, (4) speaker consistency, (5) specificity,
and(6)overall. Judgesareaskedtoselectabetter Table3: Commontopickeywordsofthenarratives(i.e.,
dialogue between the two, regarding each crite- conversationcontext)inSODA.Numbersinparentheses
rion. For context dependence, we ask the judges
denotetheratiooftherelationsinSODA.
tochoosewhichconversationincludesresponses
thataremoredependentonpreviousturns. Further Wefindabroadspectrumoftopicsencounteredin
detailsareinAppendixB.2. socialinteractionsareincludedin SODA.
Despitebeingfullymachine-generated,human As a result, conversations in SODA contain di-
raters judge SODA as better in quality compared verselexicons. WecomputeMTLD(McCarthyand
tobothDailyDialogandBlendedSkillTalkacross Jarvis,2010)tomeasurethelexicaldiversityofcon-
all axes by a large margin, except for the context versations. Table2reportstheaverageddiversity
dependencecomparingwithBlendedSkillTalk(see ofdialoguesforeachtrainingset. AsPersonaChat
Figure2). Inparticular,evaluatorsratetheflowof (Zhangetal.,2018)containsconversationsbased
SODA to be significantly more natural than other on a few persona-related sentences, it shows the
human-authoredartificialconversationdatasets.9 lowestlexicaldiversity. SODA,ontheotherhand,
includesconversationsfromavarietyofsocialsitu-
Large Scale With 1.5 million conversations, ations,whichleadstoawiderrangeofwords.
SODA is the largest in scale compared to exist-
RichEmotion-relatedInformation Sincecom-
ingcrowdsourcedopen-domaindialoguedatasets
monsense knowledge from Atomic10x includes
andthemachine-humangeneratedProsocialDialog
emotional reactions of people to events (i.e., the
dataset(Table2). Itcontainsmorethan11million
xReacttriples),conversationswithrichemotional
utterances and each conversation is grounded in
contentsarealsoincludedinSODA. Intotal,SODA
a short narrative describing the context. In total,
includes385Kconversationsgeneratedfrom1.7K
SODAconsistsof300milliontokens,makingita
uniqueemotiondescriptionsofthexReacttriples’
richsourcefortrainingconversationmodels.
Tail(e.g.,happy,ashamed,motivated,irritated).11
Therefore,itcontainssignificantlymoredescriptive
DiverseContent SODAisbuiltontopof1.5mil-
lioncommonsenseknowledgetriplesofAtomic10x, emotion labels (i.e., the Tail) than other datasets
whichhavefixednumberofclasses(Lietal.,2017;
whichhavebeenidentifiedasbeingsoftlyunique
Rashkin et al., 2019). Furthermore, because we
(West et al., 2022). Each seed triple is converted
construct conversations in a bottom-up fashion
toasocialnarrativethatservesasthedistincttopic
fromthoseemotionreactioninthecommonsense
for each conversation. The Top-10 common key-
wordsfromthesenarrativesarelistedinTable3.10 triples,weknowwhichspeakerintheconversation
is experiencing the emotion (i.e., PersonX) and
9Apoweranalysissuggeststhatwithoursetup,wecande- whatcausedtheemotion(i.e.,theHeadevent).
tecteffectsizesassmallas0.17withapowerandsignificance
levelof95%(Fauletal.,2014). 11Wenotethatconversationsfromotherrelationsalsonatu-
10WepromptChatGPTtooutputkeywordsofthenarrative. rallyincludeemotionalutterances.
DailyDialog BlendedSkillTalk SODA 100
SODA Conversations Sampled without Context
80
Emotion Ratio Emotion Ratio Emotion Ratio
60
admiration 20.42 curiosity 17.86 curiosity 12.92
gratitude 18.84 admiration 13.16 admiration 11.23 40
curiosity 12.85 sadness 8.50 approval 10.24 20
approval 10.91 joy 5.32 gratitude 7.39
0
j e
s
lo oux vy rc
p
eit re ism eent 3 34 3. .. .6 07 24 1
5
6
e s
d
feux
i
asrc
a
rpi pt re i psm oe ie nn tt
ed
4 44 4. .. .3 34 34 12
4
d sj co uoiy s rna pfp
ru
ip
s
so
i
eoin nted 46 5 4. .
.
.3 4
6
408 1
8
Natur Ca ol ntF el xo
t
w Depen Td oe pn ic
c
e Con Ss pis et ae kn ec
r
y Consistency Specific Iit nty erestingness Overall
optimism 2.94 approval 4.19 realization 3.90
Figure3: Resultsofhead-to-headcomparisonhuman
caring 2.23 optimism 3.95 caring 3.77
evaluationbetweenconversationsfromSODAandthose
sampledfromGPT-3.5withoutcontext(§3.3). They-
Table4: Theratio(%)ofTop-10emotionsin10Kutter-
axisindicatesthenumberofsamplesthathumanjudges
ancesfromDailyDialog,BlendedSkillTalk,andSODA,
preferred. Thedifferencesareallstatisticallysignificant
labeledbytheGoEmotions’27-emotion-typeclassifier
with|z|>2.6, p<0.05exceptfortheNaturalFlow
(Demszkyetal.,2020). FulltableisinAppendixB.2.
classwithz =1.1andp>0.05.
Wealsofindthedistributionofemotionstobe
(MTLD;McCarthyandJarvis,2010): 68.0vs63.1.
lessskewedtowardsspecificemotions. Tocompare
theemotionalcomposition,weusethe27-emotion- 4 COSMO:
typeclassifierfromGoEmotions(Demszkyetal.,
ASociallySituatedConversationModel
2020) for labeling and compare 10K utterances
from DailyDialog, BlendedSkillTalk, and SODA. We use SODA to train COSMO: a COnverSation
Thedistributionofemotionsforeachdatasetispre- MOdelthatcanconverseinawiderangeofsocial
sentedinTable4. SODA exhibitsamorebalanced situations. COSMOcantakeinsituationnarrative,
distributionofemotionswhilemaintainingsimilar along with dialogue history, and generate a next
rankingswithotherhuman-authoreddialogues. utteranceaccordingtoagivenrole.
Cost & Time-Efficient Compared to dialogue Training COSMO We use several structured
crowdsourcing, collecting SODA via our contex- components of SODA during training: (1) the
tualization framework is significantly more time contextual narrative n (§2.3), (2) the perspec-
andcostefficient. WithGPT-3.5text-davinci-002, tive/speaker instruction i (e.g., “Imagine you are
to go from a commonsense triple to a dialogue Madeleineandspeaktohercoach”)builtwiththe
costsabout$0.02,and10queriestakelessthan2 inferred conversation participants (§2.4), and (3)
minutes,countingourfullfiltrationpipeline. the dialogue context c. The model is trained to
generateatargetresponser whengivenn,i,and
3.3 DoWeNeedContextualization?
c – i.e., p(r|n,i,c). We do so in a sequence-to-
To isolate the effect of contextualization (vs. sequencefashion,concatenatingn,i,cwithasep-
straightforward sampling from a large language arator<SEP>toserveasinput. cismadeupofthe
model),wecompareSODAwithdialoguesnaively previousconversationutterancesconcatenatedwith
sampledfromGPT-3.5withoutanygivencontext. aturnindicator<TURN>.
Wesample100dialoguesusingthesamehyperpa- Because conversational models often agree to
rametersandthebasicfilteringstepsin CO ,but toxic or unethical behavior (Baheti et al., 2021),
3
with the following prompt: “The following is foradditionaltrainingdata,weincludeProsocial-
a long in-depth conversation between two Dialog (Kim et al., 2022a) (adapted to the same
people.\nPerson 1:.” Weaskhumanjudgesto formatas SODA, seeAppendixC).ProsocialDia-
evaluatetheconversationsinahead-to-headcom- logincludesawiderangeofnegativeconstructive
parisonasbefore(§3.2),withtheadditionalcrite- feedbackbasedonsocialrules-of-thumb,e.g.,“So
rionofinterestingness(Seeetal.,2019). Ithinkit’sbesttocontinuebeinghonest,andapol-
Figure 3 shows that judges significantly prefer ogize that you were lying.” The inclusion of this
context-grounded conversations. Conversations corpusassistsconversationmodelsinhandlingsen-
sampledwithoutcontextarenotonlylessspecific sitive contexts (e.g., biased, harmful, unethical)
and less interesting, but also exhibit lower lexi- withoutaffectingthemodelperformanceonother
caldiversitythanthosefromourCO framework datasets(Kimetal.,2022a).
3
WebuildCOSMOontopoftheLM-adaptedT5 Model Natural Consistent Specific Overall
(Raffel et al., 2020; Lester et al., 2021), which
BlenderBot-3B 23% 26% 39% 28%
achievesstrongbenchmarkperformanceacrossvar- COSMO-3B 77% 74% 61% 72%
iousclassificationandgenerationtasks. (Sanhetal., GODELL 13% 14% 15% 14%
2021;Chungetal.,2022). Wetraintwoversions COSMO-3B 87% 86% 85% 86%
ofthemodel: COSMO-3Band COSMO-11Busing Koala-7B 30% 34% 30% 29%
the T5X library (Roberts et al., 2022). For better COSMO-3B 70% 66% 70% 71%
robustnessandgeneralizablitytodatasetsthatdon’t Vicuna-7B 42% 42% 44% 42%
havecontextsordialoguestartingprompts,weran- COSMO-3B 58% 58% 56% 58%
domlydropnarrativenandroleinstructioni30% GroundTruth 43% 45% 46% 45%
and50%ofthetime,respectively. COSMO-3B 57% 55% 54% 55%
Table5: Resultsofhead-to-headhumanevaluationbe-
5 Generalizabilityof COSMO
tween model responses on an unseen dataset: Daily-
WecompareCOSMOtootherconversationalagents Dialog(Lietal.,2017)(§5.1). Thedifferencesareall
statisticallysignificantwith|z|>12.45andp<0.05,
onsocialconversationdatasetsunderbothout-of-
exceptfortheSpecificinthebottomrow.
domain and in-domain settings. Since automatic
responseevaluationisbrittle,wefocusonhuman
situationswithemotions. Table5summarizesthe
evaluation(Smithetal.,2022). Automaticevalua-
head-to-headcomparisonresultsoftheresponses
tionresultsviaGPT-4areinAppendixD.
fromCOSMOandothermodels. AlthoughCOSMO
istrainedonsignificantlysmalleramountofdata
Baselines We compare COSMO with four best-
(1.5Mdialoguesvs. 1.5BRedditcomments,551M
performing stand-alone conversation models:
Reddit threads) and is significantly smaller (3B
BlenderBot-1(Rolleretal.,2021),GODEL(Peng
vs. 7B), it outperforms all other existing mod-
etal.,2022),Koala(Gengetal.,2023),andVicuna
els with a significant margin across all aspects.
(Chiangetal.,2023). BlenderBotisatransformer
pretrained on 1.5B Reddit comments and trained
Specifically,COSMOdemonstratesthelargestper-
formancegapintermsofnaturalness. Itisworth
on various chitchat datasets. GODEL utilizes a
notingthatwhileKoalaandVicunafocusonpro-
pretrainedlanguagemodelT5(Raffeletal.,2020)
vidinginformativeresponses,theseresultssuggest
trainedonwebtextdata,andfurthertrainson551M
thatknowledge-seekingassistiveconversationsdif-
Redditthreadsand5Minstructionandgroundeddi-
ferfromnaturalsocialconversations.
aloguedatasets. KoalaandVicunaaremodelsthat
In addition, we compare the responses from
finetunedLLaMA(Touvronetal.,2023),whichis
anopen-sourceLLM,usingdialoguedatafromthe
COSMO and 200 ground-truth responses in Dai-
lyDialogwhichwereoriginallywrittenbyhumans.
web. Theyarebothknowntoachievecomparable
performancetoChatGPT(OpenAI,2022),which
Surprisingly, human judges prefer COSMO’s re-
sponses even over the original gold responses in
isamodelfinetunedforconversationalinteraction
thedataset,suggestingthatdialoguemodelstrained
based on GPT-3.5 – i.e., our teacher model. We
alsocompareCOSMOwithGPT-3.5andChatGPT;
onSODAcanleadtohighgeneralizabilityandnat-
uralness,evenforunseenconversations. Table14
promptingdetailsareinAppendixD.
intheAppendixshowstheground-truthresponse
Evaluation Metrics We perform head-to-head andresponsesfromeachmodelforagivencontext.
comparison between two responses, each from a
differentagent. Wesample100testexamplesran- 5.2 One-sidedOut-of-domainSetting
domlyfromdatasetsandaskthreehumanjudges Foranevenhardersetting,weevaluateCOSMOvs.
on Amazon Mechanical Turk to select the better BlenderBotonthedatasetBlenderBotwastrained
responsebetweenthetwointermsoffourdistinct on: BlendedSkillTalk (BST; Smith et al., 2020).
criteria (Mehri et al., 2022): (1) naturalness, (2) Table6(top)showsthehead-to-headcomparison
consistency,(3)specificity,and(4)overall. resultsoftheresponsesfromCOSMOandBlender-
Bot(forsymmetry,wealsoevaluatedBlenderBot
5.1 Out-of-domainSetting
on SODA with similar results; bottom row in Ta-
Weevaluatemodelsonanunseendialoguedataset, ble6). COSMOsignificantlyoutperformsBlender-
DailyDialog(Lietal.,2017),coveringvariousdaily BotonBST,itstrainingdomain(BlenderBotalso
showslowperformanceon SODA). Theseresults Model Natural Consistent Specific Overall
suggestthat SODA containspatternsnotpresentin BlendedSkillTalk
existingdatasets,butalsocoverspatternsfoundin BlenderBot-3B 32% 35% 40% 36%
thosedatasets. MoreresultsareinAppendixD. COSMO-3B 68% 65% 60% 64%
SODA
5.3 In-domainSetting
BlenderBot-3B 21% 17% 25% 17%
WealsocompareCOSMOonSODAwithitsteacher COSMO-3B 79% 83% 75% 83%
GPT-3.5andalsoChatGPT,achatbot-variantofthe
Table 6: Human evaluation results for head-to-head
teacher.12 Table7displaysthehead-to-headcom-
comparisonofmodelresponsesunderone-sidedout-of-
parison results. In this setting, COSMO performs
domain setting with COSMO and BlenderBot (Roller
on-par with its teacher and ChatGPT, overall. In et al., 2021) (§5.2). BlendedSkillTalk (Smith et al.,
termsofspecificity,COSMO’sresponsesaresignif- 2020)isanunseendatasetforCOSMO,andSODAisan
icantlymorespecificthanitsteacher. Thus,SODA unseendatasetforBlenderBot. Thedifferencesareall
statisticallysignificantwith|z|>4.24andp<0.05.
enablestrainingcompetitiveconversationmodels
withasignificantlysmallersize(3B/11B)incom-
parisontoexistinglargelanguagemodels(175B). Model Natural Consistent Specific Overall
HumanjudgesevaluateChatGPT’sresponsesto
GPT-3.5 50% 46% 31% 47%
bemuchmorespecific,butsignificantlylessnatural COSMO-11B 50% 54% 69% 53%
compared to COSMO. We hypothesize this is be-
ChatGPT 39% 49% 70% 50%
causeChatGPTisspeciallytrainedtogivehelpful COSMO-11B 61% 51% 30% 50%
andinformativeresponsestouserrequests. Future
work would be well-suited to compare the non- Table7: Head-to-headhumanevaluationbetweenmod-
equivalenceofsimulatingnaturalconversationsvs. elsonresponsegenerationforSODA(§5.3). Thediffer-
ences in the Specific from the top row, and the differ-
producingusefulresponsesforusers.
encesintheNaturalandSpecificfromthebottomrow
6 RelatedWork arestatisticallysignificantwith|z|>7.6andp<0.05.
Building Dialogue Datasets with Large Lan-
2022)ortask-specificlabels(Kulháneketal.,2021;
guage Models Several studies have used large
Chenetal.,2022). Comparedtoexistingworks,we
languagemodelstoaugmentorsynthesizedialogue
arethefirsttocontextualizecommonsenseknowl-
datasets. Zhengetal.(2023)andChenetal.(2022)
edge graphs for generating narratives and derive
useGPT-J(Wang,2021)toaugmentresponsesfor
full conversations from scratch in a significantly
emotionalsupportconversationsandunderstanding
large-scale. Thisallowsustoencompassanexcep-
tasks, respectively. Chen and Yu (2021) trains a
tionallybroadspectrumofsocialinteractions.
pseudo-labelertoincreasetheout-of-domaingen-
eralization of dialogue models. Ou et al. (2022)
7 Conclusion
uses counterfactual reasoning to alter the seman-
ticsofresponsesandcollectnewones. Kimetal.
Wepresented SODA,thefirstmillion-scaledia-
(2022a)proposesahuman-machinecollaborative
loguedatasetcoveringanexceptionallywiderange
framework,whereaworkerandGPT-3taketurns.
ofsocialinteractionstoalleviatethedatascarcity
Kimetal.(2022b)buildsBlendedSkillBotsTalk
issue. SODAisnotonlyordersofmagnitudelarger
bylettingmultipleagentsgroundedintargetskills
thanpopulardialoguedatasets;itisalsoperceived
engageformulti-skilldialogues. Chenetal.(2023)
tobesignificantlybetterthanthemacrossmultiple
generatedyadicandmulti-partyconversationswith
aspects(e.g.,naturalness,specificity,consistency).
topicwordsandshowtheyhavecomparablequal-
ity to human-authored conversations. GPT-3 has
Formaking SODA,wealsointroduced CO 3,a
frameworkfordistillingconversationsfromalarge
also been used to help simulate task-oriented di-
languagemodelbycontextualizingcommonsense
alogues (Li et al., 2022) on a small scale. Oth-
knowledge. With SODA,wetrainedaconversation
ersalsoaugmentdialogueswithadditionalannota-
tions–e.g.,commonsenseinferences(Zhouetal., model COSMOthatcangeneralizesignificantly
better than existing models to unseen dialogues;
12Evaluation was run on the 2022 Dec 15 ver-
andgenerateresponsesthatareevenmorepreferred
sion: https://help.openai.com/en/articles/6825453-
chatgpt-release-notes thanground-truthresponsesofanexistingdataset.
8 Limitations hopefutureworkwillextendhumanevaluationto
havepotentiallymoreannotatordiversity.
PrecautionstakenduringDatasetConstruction
Also, since SODA mainly focuses on social
Miningcontentfromlargelanguagemodelsmight
chitchatgroundedonsocialcommonsense,itlacks
surface or even amplify harmful content within
conversationsgroundedinscientificknowledgeor
thesemodels,suchasbiasesandprivateinforma-
historicalfacts. Weseektointegrateotherexisting
tion. Withthegoalofmitigatingsuchdanger,we
knowledge-groundeddialoguedatasetsinto CO
3
takeparticularprecautionstovetthesafetyofthe
inthefuture.
distilledconversations.
Finally,ourchoiceoflargelanguagemodel(i.e.,
First, previous studies have shown that human
GPT-3.5)willlikelyaffectthetypesofdialogues
names commonly associated with certain gender
created. Futureinvestigationmaylookintoother
and/or ethnicity result in biases in conversations
potential large language model as sources to di-
producedbystate-of-the-artdialogsystems(Smith
versify the types and content of dialogues being
andWilliams,2021), suchasBlenderBot(Roller
generated. Similarly,futureworkscaninvestigate
etal.,2021). Todiversifythenamerepresentations,
other base models for COSMO that may lead to
wedrawawiderangeofcommonnamesrepresen-
differentqualityofresponsegeneration.
tativeofdifferentgenderandraceidentitiesfrom
theUSSSNnamerepository. Furthermore,tomini- Intent of Technology and AI Regulation We
mizepotentialharmfulcontentfromlargelanguage wanttostressthattheintentionofourworkisnot
models,wefiltergenerateddialoguesbyCanary,a to build AI systems to replace humans. Instead,
dialoguesafetydetectormodel(Kimetal.,2022a), we want to build better assistive technologies, as
andRewireAPI,apubliclyavailableAPIfortoxic chatbots are increasingly used in user-AI interac-
contentdetection,13 toremovedialogueswithpo- tionsandaugmentinghuman-humanconversations.
tentiallytoxicanddangerouscontent. Finally, to avoid situations where humans might
Ourmethodstopre-emptpotentialharmfulcon- be manipulated, we stress the need for improved
tentmaynotcatcheverything. Forexample,even regulationsontheuseandmisuseofconversational
withourdiversepoolofnames,thereisstillafocus AIsystems(Crawford,2021;Reichetal.,2021).
oncommonnamesacrossgenderandrace,running
the risk of misrepresenting marginalized groups. Acknowledgement
Similarly, no existing dialogue safety module or
WethankJenaD.Hwangforhelpfuldiscussions,
off-the-shelftoxicitydetectorisperfectatcaptur-
and our colleagues on the Beaker Team at the
ing all potentially harmful content. We strongly
AllenInstituteforAIforhelpingwiththecompute
encouragefutureresearchalongthesedirectionsto
infrastructure. This work was supported in part
pushtheboundaryofsafeandresponsibleapplica-
byDARPAMCSprogramthroughNIWCPacific
tionusageoflargelanguagemodels.
(N66001-19-2-4031). HyunwooKimandGunhee
Duringmanualvalidationofcommonsenseand
KimaresupportedbytheInstituteofInformation
humanevaluation,wecompensateworkerswithan
&communicationsTechnologyPlanning&Eval-
hourlywageof$15,whichisovertheUSfederal
uation (IITP) grant funded by the Korea govern-
minimumhourlywage.
ment(MSIT)(No.2019-0-01082,SWStarLab;and
Limitation of the Current Dataset and Future No.2022-0-00156,Fundamentalresearchoncon-
Work Here, we note some limitations of our tinual meta-learning for quality enhancement of
work and suggest future directions. First, the di- casualvideosandtheir3Dmetaversetransforma-
alogues in SODA are two-party only for now; be- tion). Lastly, we also thank OpenAI, as well as
cause our framework also allows multi-party dia- GoogleCloudCompute.
loguegeneration,weplantoexplorethispromising
directioninthefuture.
Additionally,annotatorbiasesmightarisefrom References
thepoolofannotatorswerecruit: wesubselected
AshutoshBaheti,MaartenSap,AlanRitter,andMark
annotatorsfromaspecificplatformusingspecific Riedl.2021. Justsayno:Analyzingthestanceofneu-
filters which may cause unintended biases. We raldialoguegenerationinoffensivecontexts. InPro-
ceedingsofthe2021ConferenceonEmpiricalMeth-
13https://rewire.online/ ods in Natural Language Processing, pages 4846–
4862,OnlineandPuntaCana,DominicanRepublic. Emily Dinan, Angela Fan, Adina Williams, Jack Ur-
AssociationforComputationalLinguistics. banek, Douwe Kiela, and Jason Weston. 2020.
Queensarepowerfultoo: Mitigatinggenderbiasin
RoyF.BaumeisterandBradJ.Bushman.2017. Social dialoguegeneration. InProceedingsofthe2020Con-
PsychologyandHumanNature,4thedition. Cengage ferenceonEmpiricalMethodsinNaturalLanguage
Learning. Processing(EMNLP),pages8173–8188,Online.As-
sociationforComputationalLinguistics.
JasonBaumgartner,SavvasZannettou,BrianKeegan,
Megan Squire, and Jeremy Blackburn. 2020. The Emily Dinan, Stephen Roller, Kurt Shuster, Angela
PushshiftRedditDataset. InICWSM. Fan,MichaelAuli,andJasonWeston.2018. Wizard
ofWikipedia: Knowledge-PoweredConversational
Derek Chen and Zhou Yu. 2021. GOLD: Improving Agents. In International Conference on Learning
out-of-scopedetectionindialoguesusingdataaug- Representations.
mentation. InProceedingsofthe2021Conferenceon
F Faul, E Erdfelder, AG Lang, and A Buchner. 2014.
EmpiricalMethodsinNaturalLanguageProcessing,
G* power: statistical power analyses for windows
pages429–442,OnlineandPuntaCana,Dominican
andmac.
Republic.AssociationforComputationalLinguistics.
XinyangGeng,ArnavGudibande,HaoLiu,EricWal-
MaximillianChen,AlexandrosPapangelis,Chenyang
lace,PieterAbbeel,SergeyLevine,andDawnSong.
Tao, SeokhwanKim, AndyRosenbaum, YangLiu,
2023. Koala: A dialogue model for academic re-
ZhouYu,andDilekHakkani-Tur.2023. PLACES:
search. Blogpost.
Promptinglanguagemodelsforsocialconversation
synthesis. InFindingsoftheAssociationforCom- Fritz Heider. 1958. The Psychology of Interpersonal
putationalLinguistics: EACL2023,pages844–868, Relations. PsychologyPress.
Dubrovnik,Croatia.AssociationforComputational
AriHoltzman,PeterWest,VeredShwartz,YejinChoi,
Linguistics.
and Luke Zettlemoyer. 2021. Surface form com-
MaximillianChen,AlexandrosPapangelis,Chenyang petition: Why the highest probability answer isn’t
Tao, AndyRosenbaum, SeokhwanKim, YangLiu, alwaysright. InProceedingsofthe2021Conference
Zhou Yu, and Dilek Hakkani-Tur. 2022. Weakly onEmpiricalMethodsinNaturalLanguageProcess-
superviseddataaugmentationthroughpromptingfor ing,pages7038–7051,OnlineandPuntaCana,Do-
dialogue understanding. NeurIPS 2022 Workshop minican Republic. Association for Computational
SyntheticData4ML. Linguistics.
JenaDHwang,ChandraBhagavatula,RonanLeBras,
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
JeffDa,KeisukeSakaguchi,AntoineBosselut,and
ZhanghaoWu,HaoZhang,LianminZheng,Siyuan
YejinChoi.2021. (comet-)atomic2020: Onsym-
Zhuang,YonghaoZhuang,JosephE.Gonzalez,Ion
bolic and neural commonsense knowledge graphs.
Stoica, and Eric P. Xing. 2023. Vicuna: An open-
InProceedingsoftheAAAIConferenceonArtificial
sourcechatbotimpressinggpt-4with90%*chatgpt
Intelligence,volume35,pages6384–6392.
quality.
KatharinaKann,AbteenEbrahimi,JoewieKoh,Shiran
Hyung Won Chung, Le Hou, Shayne Longpre, Bar-
Dudy,andAlessandroRoncone.2022. Open-domain
ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
dialogue generation: What we can do, cannot do,
Wang,MostafaDehghani,SiddharthaBrahma,etal.
andshoulddonext. InProceedingsofthe4thWork-
2022. Scalinginstruction-finetunedlanguagemodels.
shoponNLPforConversationalAI,pages148–165,
arXivpreprintarXiv:2210.11416.
Dublin,Ireland.AssociationforComputationalLin-
guistics.
Kate Crawford. 2021. Atlas of AI. Yale University
Press. Hyunwoo Kim, Youngjae Yu, Liwei Jiang, Ximing
Lu,DanielKhashabi,GunheeKim,YejinChoi,and
CristianDanescu-Niculescu-MizilandLillianLee.2011. MaartenSap.2022a. ProsocialDialog: Aprosocial
Chameleonsinimaginedconversations: Anewap- backboneforconversationalagents. InProceedings
proach to understanding coordination of linguistic ofthe2022ConferenceonEmpiricalMethodsinNat-
styleindialogs. InProceedingsofthe2ndWorkshop uralLanguageProcessing,pages4005–4029,Abu
onCognitiveModelingandComputationalLinguis- Dhabi,UnitedArabEmirates.AssociationforCom-
tics,pages76–87,Portland,Oregon,USA.Associa- putationalLinguistics.
tionforComputationalLinguistics.
MinjuKim,ChaehyeongKim,YongHoSong,Seung-
DorottyaDemszky,DanaMovshovitz-Attias,Jeongwoo won Hwang, and Jinyoung Yeo. 2022b. BotsTalk:
Ko,AlanCowen,GauravNemade,andSujithRavi. Machine-sourcedframeworkforautomaticcuration
2020. GoEmotions: Adatasetoffine-grainedemo- oflarge-scalemulti-skilldialoguedatasets. InPro-
tions. InProceedingsofthe58thAnnualMeetingof ceedingsofthe2022ConferenceonEmpiricalMeth-
theAssociationforComputationalLinguistics,pages ods in Natural Language Processing, pages 5149–
4040–4054,Online.AssociationforComputational 5170,AbuDhabi,UnitedArabEmirates.Association
Linguistics. forComputationalLinguistics.
Jonáš Kulhánek, Vojteˇch Hudecˇek, Tomáš Nekvinda, inNaturalLanguageProcessing,pages1635–1648,
andOndˇrejDušek.2021. AuGPT:Auxiliarytasks AbuDhabi,UnitedArabEmirates.Associationfor
anddataaugmentationforend-to-enddialoguewith ComputationalLinguistics.
pre-trainedlanguagemodels. InProceedingsofthe
3rdWorkshoponNaturalLanguageProcessingfor Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,
ConversationalAI,pages198–210,Online.Associa- Carroll L Wainwright, Pamela Mishkin, Chong
tionforComputationalLinguistics. Zhang, Sandhini Agarwal, Katarina Slama, Alex
Ray, John Schulman, Jacob Hilton, Fraser Kelton,
BrianLester,RamiAl-Rfou,andNoahConstant.2021. Luke Miller, Maddie Simens, Amanda Askell, Pe-
The power of scale for parameter-efficient prompt terWelinder,PaulChristiano,JanLeike,andRyan
tuning. InProceedingsofthe2021Conferenceon Lowe.2022. TrainingLanguageModelstoFollow
EmpiricalMethodsinNaturalLanguageProcessing, InstructionswithHumanFeedback. arXivpreprint
pages3045–3059,OnlineandPuntaCana,Domini- arXiv:2203.02155.
can Republic. Association for Computational Lin-
guistics. Baolin Peng, Michel Galley, Pengcheng He, Chris
Brockett, Lars Liden, Elnaz Nouri, Zhou Yu, Bill
Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Dolan,andJianfengGao.2022. GODEL:large-scale
Cao,andShuziNiu.2017. DailyDialog: Amanually pre-trainingforgoal-directeddialog. arXivpreprint
labelledmulti-turndialoguedataset. InProceedings arXiv:2206.11309.
oftheEighthInternationalJointConferenceonNat-
uralLanguageProcessing(Volume1: LongPapers), AlecRadford,JeffreyWu,RewonChild,DavidLuan,
pages986–995,Taipei,Taiwan.AsianFederationof DarioAmodei,IlyaSutskever,etal.2019. Language
NaturalLanguageProcessing. ModelsareUnsupervisedMultitaskLearners. Ope-
nAIblog,1(8):9.
ZekunLi,WenhuChen,ShiyangLi,HongWang,Jing
Qian,andXifengYan.2022. Controllabledialogue ColinRaffel,NoamShazeer,AdamRoberts,Katherine
simulation with in-context learning. In Findings Lee,SharanNarang,MichaelMatena,YanqiZhou,
of the Association for Computational Linguistics: WeiLi, andPeterJ Liu.2020. ExploringtheLim-
EMNLP2022,pages4330–4347,AbuDhabi,United itsofTransferLearningwithaUnifiedText-to-Text
ArabEmirates.AssociationforComputationalLin- Transformer. JournalofMachineLearningResearch,
guistics. 21:1–67.
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, HannahRashkin,AntoineBosselut,MaartenSap,Kevin
RuochenXu,andChenguangZhu.2023. GPTeval: Knight,andYejinChoi.2018. Modelingnaivepsy-
NLG Evaluation using GPT-4 with Better Human chologyofcharactersinsimplecommonsensestories.
Alignment. arXivpreprintarXiv:2303.16634. InProceedingsofthe56thAnnualMeetingoftheAs-
sociationforComputationalLinguistics(Volume1:
RaymondAMarandKeithOatley.2008. Thefunction
Long Papers), pages 2289–2299, Melbourne, Aus-
offictionistheabstractionandsimulationofsocial
tralia.AssociationforComputationalLinguistics.
experience. Perspectivesonpsychologicalscience,
3(3):173–192.
HannahRashkin,EricMichaelSmith,MargaretLi,and
Y-Lan Boureau. 2019. Towards empathetic open-
PhilipMMcCarthyandScottJarvis.2010. Mtld,vocd-
domainconversationmodels: Anewbenchmarkand
d,andhd-d: Avalidationstudyofsophisticatedap-
dataset. In Proceedings of the 57th Annual Meet-
proachestolexicaldiversityassessment. Behavior
ingoftheAssociationforComputationalLinguistics,
researchmethods,42(2):381–392.
pages 5370–5381, Florence, Italy. Association for
ShikibMehri,JinhoChoi,LuisFernandoD’Haro,Jan ComputationalLinguistics.
Deriu, Maxine Eskenazi, Milica Gasic, Kallirroi
RobReich,MehranSahami,andJeremyMWeinstein.
Georgila, Dilek Hakkani-Tur, Zekang Li, Verena
2021. Systemerror: Wherebigtechwentwrongand
Rieser,SamiraShaikh,DavidTraum,Yi-TingYeh,
howwecanreboot. Hodder&Stoughton.
ZhouYu,YizheZhang,andChenZhang.2022. Re-
portfromthensffuturedirectionsworkshoponauto-
AlanRitter,ColinCherry,andWilliamB.Dolan.2011.
maticevaluationofdialog: Researchdirectionsand
Data-drivenresponsegenerationinsocialmedia. In
challenges. arXivpreprintarXiv:2203.10012.
Proceedings of the 2011 Conference on Empirical
MethodsinNaturalLanguageProcessing,pages583–
RauniMyllyniemi.1986. Conversationasasystemof
593,Edinburgh,Scotland,UK.AssociationforCom-
socialinteraction. Language&Communication.
putationalLinguistics.
OpenAI.2022. Chatgpt: Optimizinglanguagemodels
fordialogue. AdamRoberts,HyungWonChung,AnselmLevskaya,
GauravMishra,JamesBradbury,DanielAndor,Sha-
JiaoOu,JinchaoZhang,YangFeng,andJieZhou.2022. ran Narang, Brian Lester, Colin Gaffney, Afroz
Counterfactual data augmentation via perspective Mohiuddin, Curtis Hawthorne, Aitor Lewkowycz,
transition for open-domain dialogues. In Proceed- Alex Salcianu, Marc van Zee, Jacob Austin, Se-
ingsofthe2022ConferenceonEmpiricalMethods bastian Goodman, Livio Baldini Soares, Haitang
Hu, Sasha Tsvyashchenko, Aakanksha Chowdh- EricSmith,OrionHsu,RebeccaQian,StephenRoller,
ery, Jasmijn Bastings, Jannis Bulian, Xavier Gar- Y-Lan Boureau, and Jason Weston. 2022. Human
cia, Jianmo Ni, Andrew Chen, Kathleen Kenealy, evaluationofconversationsisanopenproblem: com-
JonathanH.Clark,StephanLee,DanGarrette,James paring the sensitivity of various methods for eval-
Lee-Thorp, Colin Raffel, Noam Shazeer, Marvin uating dialogue agents. In Proceedings of the 4th
Ritter, Maarten Bosma, Alexandre Passos, Jeremy WorkshoponNLPforConversationalAI,pages77–
Maitin-Shepard,NoahFiedel,MarkOmernick,Bren- 97,Dublin,Ireland.AssociationforComputational
nan Saeta, Ryan Sepassi, Alexander Spiridonov, Linguistics.
JoshuaNewlan,andAndreaGesmundo.2022. Scal-
ingupmodelsanddatawitht5xandseqio. arXiv Eric Michael Smith and Adina Williams. 2021. Hi,
preprintarXiv:2203.17189. my name is martha: Using names to measure and
mitigatebiasingenerativedialoguemodels. arXiv
preprintarXiv:2109.03300.
Stephen Roller, Emily Dinan, Naman Goyal, Da Ju,
Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott,
Eric Michael Smith, Mary Williamson, Kurt Shuster,
EricMichaelSmith,Y-LanBoureau,andJasonWe-
JasonWeston,andY-LanBoureau.2020. Canyou
ston. 2021. Recipes for building an open-domain
putitalltogether: Evaluatingconversationalagents’
chatbot. In Proceedings of the 16th Conference of
ability to blend skills. In Proceedings of the 58th
theEuropeanChapteroftheAssociationforCompu-
AnnualMeetingoftheAssociationforComputational
tationalLinguistics: MainVolume,pages300–325,
Linguistics,pages2021–2030,Online.Association
Online.AssociationforComputationalLinguistics.
forComputationalLinguistics.
DavidERumelhart.1975. Notesonaschemaforstories. HugoTouvron,ThibautLavril,GautierIzacard,Xavier
InRepresentationandunderstanding,pages211–236. Martinet,Marie-AnneLachaux,TimothéeLacroix,
Elsevier. Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et al. 2023. Llama: Open and effi-
Victor Sanh, Albert Webson, Colin Raffel, Stephen cient foundation language models. arXiv preprint
Bach, Lintang Sutawika, Zaid Alyafeai, Antoine arXiv:2302.13971.
Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey,
NhatTran,MaliheAlikhani,andDianeLitman.2022.
et al. 2021. Multitask prompted training enables
How to ask for donations? learning user-specific
zero-shottaskgeneralization. InInternationalCon-
persuasivedialoguepoliciesthroughonlineinterac-
ferenceonLearningRepresentations.
tions. InProceedingsofthe30thACMConference
onUserModeling,AdaptationandPersonalization,
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan
pages12–22.
Le Bras, and Yejin Choi. 2019. Social IQa: Com-
monsense reasoning about social interactions. In Ben Wang. 2021. Mesh-Transformer-JAX: Model-
Proceedings of the 2019 Conference on Empirical Parallel Implementation of Transformer Lan-
Methods in Natural Language Processing and the guage Model with JAX. https://github.com/
9thInternationalJointConferenceonNaturalLan- kingoflolz/mesh-transformer-jax.
guageProcessing(EMNLP-IJCNLP),pages4463–
4473,HongKong,China.AssociationforComputa- LauraWeidinger,JohnMellor,MaribethRauh,Conor
tionalLinguistics. Griffin, Jonathan Uesato, Po-Sen Huang, Myra
Cheng,MiaGlaese,BorjaBalle,AtoosaKasirzadeh,
RogerCSchankandRobertPAbelson.1975. Scripts, et al. 2021. Ethical and social risks of harm from
Plans,andKnowledge. InIJCAI. languagemodels. arXivpreprintarXiv:2112.04359.
Peter West, Chandra Bhagavatula, Jack Hessel, Jena
AbigailSee,StephenRoller,DouweKiela,andJason
Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Weston. 2019. What makes a good conversation?
Sean Welleck, and Yejin Choi. 2022. Symbolic
howcontrollableattributesaffecthumanjudgments.
knowledgedistillation: fromgenerallanguagemod-
InProceedingsofthe2019ConferenceoftheNorth
elstocommonsensemodels. InProceedingsofthe
AmericanChapteroftheAssociationforComputa-
2022ConferenceoftheNorthAmericanChapterof
tionalLinguistics: HumanLanguageTechnologies,
theAssociationforComputationalLinguistics: Hu-
Volume1(LongandShortPapers),pages1702–1723,
manLanguageTechnologies,pages4602–4625,Seat-
Minneapolis,Minnesota.AssociationforComputa-
tle, United States. Association for Computational
tionalLinguistics.
Linguistics.
Noam Shazeer and Mitchell Stern. 2018. Adafactor: SaizhengZhang, EmilyDinan, JackUrbanek, Arthur
Adaptivelearningrateswithsublinearmemorycost. Szlam,DouweKiela,andJasonWeston.2018. Per-
In International Conference on Machine Learning. sonalizing dialogue agents: I have a dog, do you
PMLR. have pets too? In Proceedings of the 56th Annual
Meeting of the Association for Computational Lin-
EmilySheng,JoshArnold,ZhouYu,Kai-WeiChang, guistics(Volume1: LongPapers),pages2204–2213,
andNanyunPeng.2021. Revealingpersonabiasesin Melbourne,Australia.AssociationforComputational
dialoguesystems. arXivpreprintarXiv:2104.08728. Linguistics.
Chujie Zheng, Sahand Sabour, Jiaxin Wen, and Min-
lie Huang. 2023. AugESC: Large-scale data aug-
mentationforemotionalsupportconversationwith
pre-trainedlanguagemodels. InFindingsofACL.
PeiZhou,HyundongCho,PegahJandaghi,Dong-Ho
Lee, Bill Yuchen Lin, Jay Pujara, and Xiang Ren.
2022. Reflect,notreflex: Inference-basedcommon
groundimprovesdialogueresponsequality. InPro-
ceedingsofthe2022ConferenceonEmpiricalMeth-
odsinNaturalLanguageProcessing,pages10450–
10468,AbuDhabi,UnitedArabEmirates.Associa-
tionforComputationalLinguistics.
PeiZhou,KarthikGopalakrishnan,BehnamHedayat-
nia, Seokhwan Kim, Jay Pujara, Xiang Ren, Yang
Liu,andDilekHakkani-Tur.2021. Commonsense-
focuseddialoguesforresponsegeneration: Anem-
pirical study. In Proceedings of the 22nd Annual
MeetingoftheSpecialInterestGrouponDiscourse
andDialogue,pages121–132,SingaporeandOnline.
AssociationforComputationalLinguistics.
A Detailsof CO
3 Relation Templateforsentenceform
xReact [Head].NowPersonXfeels[Tail].
A.1 CommonsenseKnowledge→Narrative
xIntent [Head]becausePersonXwants[Tail].
Retrieving Social Commonsense Knowledge
xAttr PersonXis[Tail].[Head].
Weusethex-relationsfromAtomic10x (Westetal.,
xEffect [Head].NowPersonX[Tail].
2022),whicharetheinferencesofpeople’smental
states: xIntent, xWant, xReact, xAttr, and xWant [Head].NowPersonXwants[Tail].
xNeed. Table 3 summarizes the ratio of relations xNeed PersonX[Tailinpasttense].[Head].
includedinour SODAdataset. Weleaveotherrela-
tions(e.g.,isBefore,isAfter)forfuturework. Table8: Templatesforconvertingsymboliccommon-
senseknowledgetosentenceform.
TripleFormtoSentenceForm Table8liststhe
templatesforconvertingsymboliccommonsense
Relation Templateforbuildingvalidationquestions
knowledgetosentenceform.
xReact DoesPersonXfeel[Tail]after[Head]?
Sentence Form to Narrative We prompt xIntent DoesPersonXintend[Tail]when[Head]?
GPT-3.5 with “[sentence-form commonsense] xAttr Can PersonX be considered [Tail] when
Rewrite this story with more specific [Head]?
details in two or three sentences:”. We xEffect [Head]. Asaresult,PersonX[Tail]. Isthis
findlongnarrativestendtobedrivenfarawayfrom true?
theoriginalcommonsenseknowledge. Therefore, xWant DoesPersonXwant[Tail]after[Head]?
we set the length of the narrative to two or three
xNeed [Tailinpasttense].Isthistruewhen[Head]?
sentences.
We leverage text-davinci-002 GPT-3.5 for Table9: Templatesforconvertingsymboliccommon-
generating narratives. We set temperature to 0.9, senseknowledgetoquestionsforvalidation.
top-p to 0.95, frequency penalty to 1.0, presence
penaltyto0.6,andmaxtokensto1024.
B Detailsof SODA
A.2 Narrative→Conversation Table 10 and Table 11 show samples from our
dataset.
Inferring Conversation Participants We
prompt GPT-3.5 with “[narrative] The B.1 Post-processingtheConversations
following is a conversation in the scene
FilteringNon-humanSpeakers First,wecheck
between [PersonX’s name] and ...” to let it
whetherthespeakerprefixincludesthenamefrom
finish the partial prompt. This yields a plausible
our name base (§2.4). Next, we use lexical pat-
interlocutor for a given narrative (e.g., mom,
tern matching and identify words in speaker pre-
classmate, coworker, etc.); for the example story
fixesthatindicatehumans(e.g.,mom,dad,teacher,
withMadeleine,“hercoach”waspredicted.
Mrs., Mr.). Finally, for speaker prefixes that
We leverage the text-davinci-002 GPT-3.5
do not match the above patterns, we prompt the
model for identifying the speakers. We set tem-
text-davinci-002 GPT-3.5 model whether the
peratureto0,top-pto1.0,frequencypenaltyto0,
speakerishuman. Forexample,“Q: Is [speaker
presencepenaltyto0,andmaxtokensto16.
prefix] a person?\nA:".”
Generating Conversation Grounded in Narra- FilteringwithCommonsenseTriples Usinga
tive We again leverage the text-davinci-002 prompt, we ask two questions about the Head
GPT-3.5modelforgeneratingconversations. An event and also the Relation-Tail event for each
examplepromptis“[narrative] The following instance: (1) is the head of the triple repre-
is a long in-depth conversation happening sented in the narrative-conversation pair; and (2)
in the scene between Madeleine and her are the relation and tail? We prompt GPT-3.5
coach with multiple turns.\nMadeleine:”. with“[narrative]\nQ: [head question]\nA:”
Weusethesamehyperparametersettingasthenar- and “[conversation]\nQ: [relation-tail
rativegeneration. question]\nA:” Table 9 lists the templates for
SymbolicSocialCommonsenseKnowledge: SymbolicSocialCommonsenseKnowledge:
• Head:PersonXprovidesanotherservice • Head:PersonXtakesonalotofwork
• Relation:xIntent • Relation:xReact
• Tail:tobeahelpfulperson • Tail:pressured
Sentence-form Commonsense: Jabriel provides another Sentence-form Commonsense: Yamir takes on a lot of
servicebecauseJabrielwantstobeahelpfulperson. work.NowYamirfeelspressured.
Narrative: Narrative:
Jabrielprovidesaservicebytakingcareofpeople’spets Yamirisahighschoolstudentwhooftentakesontoomuch
whiletheyareoutoftown.Jabrielisahelpfulpersonwho work.Shefrequentlysignsupformoreextracurricularactiv-
lovesanimals,soshedecidedtostartthisbusiness.Shehas itiesthanshecanhandleandregularlyagreestodofavors
beentakingcareofpetsforthreeyearsandhasneverhad forherfriends,evenwhenshe’salreadyoverwhelmedwith
anyproblems. othercommitments.Asaresult,Yamirisconstantlystressed
Speakers:Jabriel,Client outandfeelslikeshecannevercatchup.
Speakers:Yamir,Lily
Conversation:
Jabriel:Hithere!Areyoulookingforsomeonetotakecare Conversation:
ofyourpetwhileyou’reoutoftown? Yamir: Ican’tbelieveIagreedtodothis. I’malreadyso
Client:Yes,Iam.I’mgoingonvacationforaweekandI behindoneverythingelse.
needsomeonetowatchmycat. Lily:What’swrong?Youseemreallystressedout.
Jabriel: That’s no problem at all! I love taking care of Yamir: Iam. IfeellikeIcannevercatchup. Everytime
animals,andIhaveexperiencewithcats. I’llbehappyto Iturnaround,there’ssomethingelsethatneedstobedone.
takecareofyourcatwhileyou’regone. Andit’sallbecauseIkeeptakingontoomuch.
Client:Thatsoundsgreat.Howmuchdoyoucharge? Lily:Whydoyoukeepdoingthat?
Jabriel:Icharge$20perday,plusanadditional$10perday Yamir:Idon’tknow.IguessIjustfeellikeifIdon’t,then
ifyouwantmetostayovernight. I’mnotreallydoingmypartorcontributingenough.Butit’s
Client:Soundsreasonable.I’lldefinitelyneedyoutostay justtoomuchsometimesanditmakesmesostressedout.
overnight,soitwillbe$30perday.Whencanyoustart? Lily: Well,maybeyouneedtostartsayingnomoreoften.
Jabriel: Anytimethatworksforyou! Justletmeknow Just because someone asks you to do something doesn’t
whenyou’llbeleavingandwhenyou’llbeback,andI’ll meanyouhavetosayyes.Youhavearighttosaynoandset
takecareofeverythinginbetween. yourownlimits.
Client:Alright,I’llbeleavingonSaturdayandI’llbeback Yamir:Yeah,maybeyou’reright...Ishouldstartsayingno
next Saturday. Can you come over on Friday evening to moreoften.It’sjustsohardthoughwhenpeoplearecounting
meetmycatandgeteverythingsetup? onmeandaskingforfavorsallthetime.ButmaybeifIstart
Jabriel:Soundsperfect.I’llseeyouonFridayat6pm. settingsomeboundaries,it’llhelpreducemystresslevelsin
thelongrun.Thanksfortalkingwithmeaboutthis,Lily-it
reallyhelpedputthingsintoperspective!"
Table10: Asamplefrom SODA.
Table11: Anothersamplefrom SODA.
building questions for commonsense validation.
Forexample,thecommonsenseknowledgetriple 3.5 on 100 human-annotated samples for com-
inTable1willaccompanyquestionsof“Madeleine monsensevalidation. Weaskthreehumanjudges
movesastepclosertothegoal,isthistrue?” and withthesamequestion-answerformatgiventothe
“Madeleine took the first step. Is this true when modelforeachtriple-narrative-conversationpair.
Madeleine moves a step closer to the goal?” We
formulatethisasathree-waymultiplechoiceques- B.2 Comparing SODAwith
tionandrankanswers(i.e.,yes,no,andunknown) Human-authoredDialogues
accordingtotheperplexityscoreusingconditional
Figure 4 shows the annotation page for workers
pointwise mutual information (Holtzman et al.,
evaluatingthedialoguequality.
2021). Weaskthequestionswithandwithoutthe
context(i.e.,thenarrativeandconversation). Table
IRBInformation Crowdworkingstudiesofstan-
9liststhetemplatesforbuildingquestionsforcom-
dard NLP corpora (involving no personal disclo-
monsensevalidation. Wefind66%,95%,and68%
sures)arenotrequiredbyourIRBtobereviewed
offilteredconversationsareidentifiedbyGPT-3.5
by them. While the authors of this work are not
ascontainingthefullcommonsensetriple,thehead
lawyersandthisisnotlegaladvice,thisopinionis
event, andtherelation-tailevent, respectively: in
basedonUnitedStatesfederalregulation45CFR
total,1,003,595conversationsareidentifiedasfully
46,underwhichthisstudyqualifiesasexempt. We
encapsulatingtheseedcommonsenseknowledge.
do not release crowdworker IDs, so annotations
Table13summarizestheperformanceofGPT- cannotbeback-tracedtoindividualworkers.
DailyDialog BlendedSkillTalk SODA Precision Recall F1-score
Emotion Ratio Emotion Ratio Emotion Ratio
Head
admiration 20.42 curiosity 17.86 curiosity 12.92
Yes 98.9 94.8 96.8
gratitude 18.84 admiration 13.16 admiration 11.23
No 00.0 00.0 00.0
curiosity 12.85 sadness 8.50 approval 10.24
approval 10.91 joy 5.32 gratitude 7.39 Unknown 16.7 100.0 28.6
joy 4.74 excitement 4.42 joy 6.38 Overall 96.1 93.0 94.2
excitement 3.61 surprise 4.34 disappointed 5.41
Head/wPMI
surprise 3.25 disappointed 4.34 confusion 4.68
love 3.06 fear 4.31 surprise 4.40 Yes 96.9 96.9 96.9
optimism 2.94 approval 4.19 realization 3.90 No 00.0 00.0 00.0
caring 2.23 optimism 3.95 caring 3.77
Unknown 00.0 00.0 00.0
remorse 2.07 realization 3.84 sadness 3.76
Overall 94.0 94.0 94.0
disapproval 1.95 annoyance 3.48 excitement 3.20
fear 1.82 love 2.97 remorse 2.81
Relation-Tail
sadness 1.77 confusion 2.54 disapproval 2.74
disappointed 1.47 caring 2.31 annoyance 2.35 Yes 89.2 76.7 82.5
annoyance 1.41 disgust 1.99 desire 2.31 No 21.4 42.9 28.6
confusion 1.23 nervousness 1.88 optimism 2.23 Unknown 8.3 14.3 10.5
realization 1.12 remorse 1.76 love 1.88 Overall 78.8 70.0 73.7
anger 0.97 anger 1.68 fear 1.81
amusement 0.92 embarrassed 1.44 anger 1.75 Relation-Tail/wPMI
desire 0.89 disapproval 1.41 nervousness 1.45
disgust 0.51 amusement 1.09 relief 0.99 Yes 92.2 68.6 78.7
nervousness 0.27 desire 1.09 embarrassed 0.82 No 21.4 42.9 28.6
embarrassed 0.22 pride 0.74 disgust 0.58 Unknown 16.7 85.7 27.9
pride 0.21 gratitude 0.66 pride 0.47 Overall 80.4 65.0 69.6
relief 0.21 relief 0.58 amusement 0.41
grief 0.00 grief 0.00 grief 0.00
Table13: Evaluationresultsofcommonsensevalidation
forshortquestion-answeringwithInstructGPTon100
Table12: Theratio(%)ofemotionsin10Kutterances
human-annotatedsamples.
from DailyDialog, BlendedSkillTalk, and SODA, la-
beledbythe27-emotion-typeclassifierfromGoEmo-
tions(Demszkyetal.,2020).
Converting ProsocialDialog to SODA format
We randomly sample names from our name
Analysis on Emotion Distribution To obtain database(§2.3)toconstructthesituationdescrip-
emotionalresponses,werandomlysample10Kut- tionsandperspectiveinstructionsforProsocialDia-
teranceswithemotionlabelsfromDailyDialog(Li log. Thesituationdescriptionsaremadefromthe
etal.,2017),utterancesinconversationswiththe RoTsinProsocialDialog(e.g.,“Cosmoistryingto
EmpatheticDialogue(Rashkinetal.,2019)theme gentlyconvinceafriendit’swrongtothinkallmen
forBlendedSkillTalk(Smithetal.,2020),andut- areviolent.”);theinstructionsarebuiltaswedid
terancesinconversationsgeneratedfromxReact for SODA(§4).
triplesfor SODA. WerunthefinetunedBERT-base
classifier(Demszkyetal.,2020)oneachutterance. D ExperimentDetails
Table12showsthefulldistributionacross27emo-
Automatic Evaluation via GPT-4 Inspired
tiontypesforeachdataset.
by Liu et al. (2023), we run automatic evalu-
Statistics of Human Evaluation A total of 74 ation on the overall quality of responses with
workersparticipatedincomparingdialogues,yield- GPT-4. We use the same head-to-head com-
ingaKrippendorf’salphaof0.25. Thisindicates parison setup from Table 5 and 6 with the
fairagreementsonthequalityjudgments. following prompt given to GPT-4: “You are
a response evaluator. Your task is
to choose the overall better response
C Detailsof COSMO
out of the two given the following
TrainingDetails COSMO-3B/COSMO-11B are context. You should consider naturalness,
trained using v3-32/v3-128 TPU accelerators specificity, naturalness, and
with batch size 256 (effective batch ≈ 780) consistency.\n\nContext:\n{CONTEXT}\n\n1)
for 110K/130K additional steps using Adafactor {RESPONSE}\n2) {RESPONSE}\n\nQuestion:
(Shazeer and Stern, 2018) with constant learning Which response is better in terms of
rate.001. overall quality?\nAnswer: Response ”.
DialogueContext: Model Natural Consistent Specific Overall
A:Ireallyneedtostarteatinghealthier. BlendedSkillTalk
B:Ihavetostarteatingbettertoo.
Koala-7B 26% 27% 35% 25%
A:Whatkindoffooddoyouusuallyeat?
COSMO-3B 74% 73% 65% 75%
B:Itrymybesttoeatonlyfruits,vegetables,andchicken.
Vicuna-7B 43% 47% 45% 46%
A:Isthatreallyallthatyoueat?
COSMO-3B 57% 53% 55% 54%
B:That’sbasicallyit.
A:Howdoyousticktoonlythosefoods? Table 16: Human evaluation results for head-to-head
comparisonofmodelresponsesunderzero-shotsetting
Ground-truthresponse:
with COSMO, Koala (Geng et al., 2023), and Vicuna
Actually,fruitsandveggiesarereallygoodforyou.
(Chiang et al., 2023). BlendedSkillTalk (Smith et al.,
DialoGPT:Ieatalotoffruitandveggies.Isticktoalotof 2020)isanunseendatasetforallthreemodels.
things.Idon’teatalotofjunkfood.
BlenderBot: Ieatalotoffruitandveggies. Itrytostay
awayfromprocessedfoods. resultsinTable5and6shouldbeconsideredmore
significant when assessing the overall quality of
GODEL:Igotothegymandeathealthyfood.
themodel,where COSMO alsooutperformsother
COSMO:IjusttrytomakesurethatI’mgettingenough models.
varietyinmydietsothatIdon’tgetsickofeatingthesame
thingallthetime.
Additional Human Evaluation on Blended-
SkillTalk Wealsocomparetheresponsequality
Table14: Theoriginalground-truthresponseandsam-
ple responses from DialoGPT, BlenderBot, GODEL,
ofCOSMO,Koala(Gengetal.,2023),andVicuna
andCOSMOtoacontextinDailyDialog. (Chiang et al., 2023) on BlendedSkillTalk (BST;
Smithetal.,2020),whichisanunseendatasetfor
all three models. We ask human judges to vote
Dataset&Models Overall
onwhichofthetwomodelresponsesarebetterin
DailyDialog termsofquality,basedonfourcriteriaasdescribed
COSMOvsGODEL 93%vs7%
in§5.2. Table16showsthat COSMO outperforms
bothmodelsinallfourcriteria,whilethedifference
COSMOvsBlenderBot 68%vs32%
COSMOvsKoala 65%vs35% betweenCOSMOandVicunaissmallercompared
COSMOvsVicuna 54%vs46% tothedifferencebetweenCOSMOandKoala. Re-
COSMOvsGroundTruth 52%vs48% sultsonDailyDialogcanbefoundinTable5.
BlendedSkillTalk
Prompts for GPT-3.5, ChatGPT, Koala, and
COSMOvsBlenderBot 66%vs34% Vicuna WepromptGPT-3.5withthefollowing
prompt: “You will be generating the next
SODA
turn of a given dialogue between two
COSMOvsBlenderBot 85%vs15% people. Your response should be natural
and specific. The dialogue is provided
Table15: Automaticevaluationresultsofhead-to-head
line-by-line.\n\ncontext:[narrative]
comparisononoverallqualityofmodels’responsesvia
\ndialogue:\n[dialogue].” For ChatGPT,
GPT-4.
Koala, andVicuna, weusethefollowingprompt:
“You will be generating the next turn
Table15showsthehead-to-headcomparisonre- of a given dialogue between two people.
sultsforresponsequalitybetweenmodels. Wefind Your response should usually be 1-2
theresultsaligncloselywiththosefromourhuman sentences. Alongside the dialogue
evaluation in §5. It should be noted that GPT-4 (which is provided line-by-line, where
tendstofavorGPT-generatedtextsoverthosewrit- a new-line means the speaker changed),
tenbyhumans, evenwhenhumanjudgesshowa you’ll be given some context about the
preference for the latter (Liu et al., 2023). As a two participants of the dialogue, e.g.,
result,thesescoresarelikelytobebiasedtowards their relationship, situation, etc.\n\n
COSMO, which is trained on texts generated by context:\n[narrative]\ndialogue:\n
GPT-3.5. Therefore,theoriginalhumanevaluation [dialogue]\nWhat is the most appropriate
next utterance (3 sentences max)?.” normsinproblematiccontexts(Kimetal.,2022a).
AbovedatasetsexceptforDailyDialogareallunder
Details of Human Evaluation A total of 77
the CC-BY-4.0 license. We use DailyDialog and
workers participated in comparing responses, re-
BlendedSkillTalk for comparing with our SODA
sulting in a Krippendorf’s alpha of 0.5. This in-
dataset,andProsocialDialogfortrainingCOSMO,
dicates good agreements on the response quality
whichisallcompatiblewiththelicense.
judgments. Figure5showstheannotationpagefor
workersevaluatingtheresponsequality.
E AdditionalRelatedWork
Human-authoredDialogueDatasets Existing
dialoguedatasetsgenerallyderivefromoneofthe
foursources: (1)Onlinelearningwebsitesandtext-
books (Li et al., 2017) for beginners which may
lackcomplexlanguageusage. (2)Movieanddrama
scripts(Danescu-Niculescu-MizilandLee,2011)
thatarelessnaturalcomparedtoday-to-dayscenar-
ios. (3)Crowdsourcing(Rashkinetal.,2019;Zhou
etal.,2021;Tranetal.,2022): potentiallyproneto
collectingresponsesthataresomewhatshortordull
duetoincentivemisalignmentbetweenresearchers
andcrowdworkers (Zhouetal.,2022). (4)Noisy
webinteraction,suchasRedditcomments(Baum-
gartneretal.,2020)andTwitter(Ritteretal.,2011);
while widely used in dialogue agent pretraining
stage due to their scale, these may represent dif-
ferent conversational frames compared to dyadic
conversations. Moreover, as these are unfiltered
conversations,theirusesurfacesacomplexsetof
ethicsandbiasconsiderations. SODA contributes
meaningfully to the suite of existing corpora via
improvedscale,quality,contextualization,anddi-
versecommonsenseknowledge.
F DialogueDatasetDescriptions
DailyDialog is a dataset of casual dialogue com-
piledfromEnglishlanguagelearningwebsites(CC-
BY-NC-SA-4.0;Lietal.,2017). PersonaChatisa
dialogue dataset of two speakers getting to know
one another based on provided personas (Zhang
etal.,2018). EmpatheticDialoguescontainsempa-
theticconversationsinwhichonespeakerdemon-
strates empathy for the other speaker’s emotions
(Rashkin et al., 2019). Wizard of Wikipedia con-
tainsconversationsbasedonWikipediabetweena
speaker eager to learn and an expert speaker (Di-
nanetal.,2018). BlendedSkillTalkconsistsofcon-
versations employing a variety of abilities – e.g.,
persona,empathy,knowledge(Smithetal.,2020).
ProsocialDialog contains conversations where a
speaker guides the interlocutor to follow social
Figure4: TheannotationpageforevaluatingdialoguesonAmazonMechanicalTurk.
Figure5: TheannotationpageforevaluatingresponsesonAmazonMechanicalTurk.
