 International Conference on Learning Representations (ICLR) 2014, Banff, Alberta, Canada.
https://doi.org/10.48550/arXiv.1312.6114
↩
Knoblauch, J., Jewson, J., & Damoulas, T. (2019). Generalized variational inference: Three arguments for
deriving new posteriors. arXiv. https://doi.org/10.48550/arXiv.1904.02063 ↩
Koller, D., & Friedman, N. (2009). Probabilistic graphical models: Principles and techniques. MIT press. ↩
Langley, P. (1989). Toward a unified science of machine learning. Machine Learning, 3(4), 253–259.
https://doi.org/10.1007/BF00116834 ↩
LeCun, Y. (2022). A path towards autonomous machine intelligence. OpenReview.
https://openreview.net/pdf?id=BZ5a1r-kVsf ↩
LeCun, Y., & Misra, I. (2021, March 4). Self-supervised learning: The dark matter of intelligence. Meta
Research. https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence.
66
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
↩
LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., & Jackel, L. D. (1989).
Backpropagation applied to handwritten zip code recognition. Neural Computation, 1(4), 541–551.
https://doi.org/10.1162/neco.1989.1.4.541 ↩
Lester, B., Al-Rfou, R., & Constant, N. (2021). The power of scale for parameter-efficient prompt tuning. In
M.-F. Moens, X. Huang, L. Specia, S. W.–t. Yih (Eds.), Proceedings of the 2021 Conference on Empirical
Methods in Natural Language Processing (pp. 3045–3059). http://doi.org/10.