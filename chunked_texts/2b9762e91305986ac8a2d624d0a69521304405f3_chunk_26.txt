ole Tajudeen,
information-theoretic framework for cross-lingual
Kevin Degila, Kelechi Ogueji, Kathleen Siminyu,
languagemodelpre-training. InProceedingsofthe
JuliaKreutzer,JasonWebster,JamiilToureAli,Jade
2021ConferenceoftheNorthAmericanChapterof
Abbott, IroroOrife, IgnatiusEzeani, IdrisAbdulka-
the Association for Computational Linguistics: Hu-
dirDangana,HermanKamper,HadyElsahar,Good-
manLanguageTechnologies,pages3576–3588,On-
nessDuru, GhollahKioko, MurhabaziEspoir, Elan
line.AssociationforComputationalLinguistics.
van Biljon, Daniel Whitenack, Christopher Onyefu-
luchi, Chris Chinenye Emezue, Bonaventure F. P.
Hyung Won Chung, Thibault Févry, Henry Tsai,
Dossou, Blessing Sibanda, Blessing Bassey, Ay-
Melvin Johnson, and Sebastian Ruder. 2021. Re-
odele Olabiyi, Arshath Ramkilowan, Alp Öktem,
thinking Embedding Coupling in Pre-trained Lan-
Adewale Akinfaderin, and Abdallah Bashir. 2020.
guageModels. InProceedingsofICLR2021.
Participatory research for low-resourced machine
translation: A case study in African languages. In
JonathanH.Clark,EunsolChoi,MichaelCollins,Dan
Findings of the Association for Computational Lin-
Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and
guistics: EMNLP2020,Online.
Jennimaria Palomaki. 2020. TyDi QA: A Bench-
mark for Information-Seeking Question Answering
Jinlan Fu, Pengfei Liu, Graham Neubig, and Mo Tab.
in Typologically Diverse Languages. In Transac-
2020. Interpretable Multi-dataset Evaluation for
tions of the Association of Computational Linguis-
Named Entity Recognition. In Proceedings of
tics.
EM