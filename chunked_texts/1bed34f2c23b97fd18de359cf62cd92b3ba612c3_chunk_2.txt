al.,2022)datasets, bothstemmingfromStack-
CODEX 12B. Both models show substantial
Overflow2 withbroadpracticalcodingqueries.
gaps between open and closed domains, but
WeanalyzeandhighlightthreeaspectsofODEX
CODEGEN gaps tend to decrease with model
size while CODEX gaps increase. We release (ยง3). First,ODEXhasbroaddomaincoverageof
ODEXtofacilitateresearchintoopen-domain 79libraries,with53.4%oftheproblemsemploy-
problemsforthecodegenerationcommunity.1 ing at least one library. Second, ODEX contains
queries in four different languages, with 439, 90,
164,and252samplesinEnglish,Spanish,Japanese,
1 Introduction
andRussian,asshowninFigure1. Third,ODEX
Evaluations of NL-to-code generation systems, addressesthreeuniquechallengesinopen-domain
especially for general-purpose programming lan- codeexecution: irreproducibleruns(Figure1 a ),
guages such as Python, have put an increasing
randomizedoutputs(Figure1 b ),andspecialized
emphasis on methods that execute code to verify
equivalencechecks(Figure2).
the results. The predominant approach for creat-
Weevaluatetwostate-of-the-artcodeLLMfam-
ing such test sets is to manually write test cases
ilies,CODEXandCODEGEN,onODEX(ยง5). Our
for canonical code solutions (Chen et al., 2021;
studyshowsthatlargermodelsizesandaugmented
Austin et al., 2021; Lai et al., 2022; Huang et al.,
training data improve execution accuracy. Mean-
2022). The correctness of model predictions is
while, we observe satisfactory multilingual capa-
thenevaluatedbyseeingifgeneratedcodepasses
bilities,despitethatneithermodelwasspecifically
the test cases (Chen et al., 2021). Compared to
designedformultilingualusage. However,wefind
execution-freemetricssuchastextmatchagainst
thatmodelsfacegreateryetvariedchallengeswith
referencesolutions,execution-basedmethodsmore