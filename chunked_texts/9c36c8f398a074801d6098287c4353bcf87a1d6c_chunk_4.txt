 allowing easier extensions to other value-
alignedjudgementwithexplicitvalueprovision.
alignedtasksindifferentdomains. Wefurtherin-
vestigatemodelperformanceusingdatagenerated
Prompt-basedLearning Recently,LLMshave
fromdifferentscalesandtypesofLLMs,andstudy
showngreatperformanceonprompt-basedlearning
theeffectofdatasizeforfine-tuning,andanalyze
(Brownetal.,2020;Chowdheryetal.,2022),which
the quality of the generated data. Moreover, we
doesn’trequirefine-tuning. Instead, themodelis
studythegeneralizationabilityof VA-MODELsby
directly fed a prompt that includes some exam-
testingitsperformanceonunseenvaluesets.
ples,andthemodelcangenerateresultsasifithas
“learned”. Studies on efficient prompt-learning/-
construction include Lu et al. (2021); Reynolds
Our contributions are as follows: 1) we intro-
andMcDonell(2021);Zhaoetal.(2021);Schick
duce the value-aligned classification task, where
andSchütze(2020). Weconsidertheliteraturefor
we first define human values externally and then
prompt-constructioninourmethodology.
use them at the instruction level in an in-context
learningparadigmandconstructvalue-alignedclas- KnowledgeDistillation Knowledgedistillation
sifierstomakepredictions;2)weproposetolever- isthetransferofknowledgefromteachertostudent
ageprompt-baseddatagenerationtodistillvalue- distribution (Hinton et al., 2015). Recent works
alignedknowledgefromLLMsforsmallerclassifi- haveattemptedtoperformdistillationfromLLMs
cationmodels;3)experimentalresultsindicatethat by prompting for text generation to show that it
ourapproachsignificantlyoutperformsstrongbase- outperforms existing text augmentation methods
lines,includingin-contextfew-shotlearningwith (Yooetal.,2021;Wangetal.,2022). (Westetal.,
LLMsandexistingtextaugmentationmethods;4) 2021)ret