 language, most akin to [9], [10] though we work in
2PaulG.AllenSchoolofComputerScienceandEngineering,University
ofWashington,Seattle,USA a fully end-to-end differentiable paradigm where embedded
9102
raM
02
]IA.sc[
1v90380.3091:viXra
Predictor
+
RNN
Dream Cell
Fig.2:Ateachtimestep,themodelreceivesanLSTMencodedlanguagevectorL(cid:126),theinitialworldstateW,andthecurrent
0
world state W. Using these, it predicts the next world state WË† and sub-goal G.
t t+1 t
languagerepresentationsarelearnedalongsidevisualencod- III. PROBLEMDESCRIPTION
ings of the world.
Given a natural language command and raw sensor read-
ings for a scene, the task is to issue a sequence of low level
Our work is also motivated by the Universal Planning
controls to a robotic arm that accomplish the intended task.
Networkswhichlearnanembeddingforimagesandaworld
Specification.A DREAMCELL takesintheinitialW
0
and
state vector used to generate motion plans to goals specified
currentW simulation-basedstateobservationsandanatural-
t
via a target image [11]. That work learns a distance metric
language sentence s to produce a sequence of intermediate,
fromthecurrentstateimagetothetargetimagewhichisused
latent-spacegoalsz,...,z forthispick-and-placetaskup
i i+h
to perform rollouts for training and inference. While learned
to horizon h. Each goal is a semantically meaningful break
genericrepresentationshavenotionsofagencyandplanning,
point in the execution, e.g., a completed grasp on the target.
the produced plans lack human interpretability, which may
DREAMCELLS make three predictions at every time step:
be important to modularity and generalization [12]. Neural
1) A sequence of subgoals predictions, representing the
approaches and scaling robotic learning within simulation
next high level actions out to some planning horizon;
have become common as they allow for end-to-end training
2) Asequenceofhiddenstaterepresentationsz,