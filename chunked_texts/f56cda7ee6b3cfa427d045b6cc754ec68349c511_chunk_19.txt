.’ = Plausibility, ‘Off.’ =
Offensiveness and ‘Dis.’ = Disagree stance. DAPT
Tovalidatethefindingsofourautomaticevaluation
referstoneutralstancecontrolwhileATCONrefersto
presentedabove,weconductin-househumaneval-
safeandneutralbothcontrol.
uationof4models: DGPTbaseline,Blenderbot,
DAPTneutralstancecontrolandATCONbothcon-
trol. WeexcludeGPT-3fromthisevaluationaswe andstanceclassifiersdon’tgeneralizewelltoun-
don’thaveaccesstoitsmodelparametersandcan’t seen dialogue model responses (Blender bot re-
fine-tune it for CTG. For every model response, sponses weren’t present in the classifier training
we investigate its plausibility {Yes, No}, stance data). Otherdiscrepanciesbetweenthehumanand
towards the last comment in the thread {Agree, automaticevaluationssuggestthatourstanceclas-
Disagree,Neutral},andoffensiveness{Yes,No}. sifieroverestimatesthe‘neutral’stanceandunder-
We recruit two annotators to evaluate model re- estimatesthe‘agree’stance. Aftersomemanualin-
sponsesforasampleof250offensivetestthreads. vestigation,weobservethatBlenderchatbotmostly
The Cohen’s Kappa and pairwise-agreement for generatesbenignempatheticresponsesbutagrees
the two annotators are κ = 0.40 and 77.9% for alotinoffensivecontextbyusingsentencestarters
plausibility, κ = 0.74 and 87.1% for stance and like “I know right?...” (examples in Figure 9).
κ = 0.76and92.3%foroffensiveness. Weresolve Blender chatbot also outperforms the CTG mod-
disagreementsbetweenannotatorsusinga3rdin- elsintermsofplausibility,likelyduetoitslarger
houseadjudicator. Theresultsoftheevaluationare models