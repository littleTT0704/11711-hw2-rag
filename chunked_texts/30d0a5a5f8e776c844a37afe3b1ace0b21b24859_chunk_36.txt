onHM3D[151]andfine-tunedfor29millionstepson
4.CommonApproaches RoboTHOR[51]. Habitat-Webusedbehaviorcloning
to train for 400 million steps for their 2021 Habitat
Thissectionpresentscommonapproachesusedby
Challenge entry. With the growing size of datasets,
the winners of the challenges. We discuss large-scale
andtheaddedperformancegainedbytrainingforor-
trainingbyscalingupdatasetsandcompute,leverag-
ders of magnitude longer, we suspect further scaling
ing visual pre-trained models such as CLIP, the use
computetoleadtobetterperformingagents.
ofinductivebiasessuchasmaps,goalembeddingsto
representdifferenttasks,andvisualanddynamicaug- 4.2.VisualPre-Training
mentation to make simulators more noisy and closer
toreality. Initial successes in deep reinforcement learning
were largely focused on graphically simplistic envi-
4.1.Large-ScaleTraining
ronments,e.g.Atarigames,forwhichcomplexvisual
processing was, in large part, unnecessary. For in-
Embodied AI is seeing the same trend as com-
stance,theseminalworkofMnihetal.[122]achieved
puter vision and natural language processing, where
human-level performance on dozens of Atari games
massive datasets and more computing power enable
usingusedamodelwithonlythreeconvolutionallay-
higher-performingmodels.
ers. Several initial works in embodied AI, in part
Massive datasets have been obtained by Proc-
due to computational constraints when training RL
THOR, which trains on 10K procedurally generated
agents, adopted this mindset; for instance, Savva et
houses [52]; HM3D, which captures 1K static scans
al. [167] trained models using a 3-layer image pro-
of real-world environments [151]; and Habitat-Web,
cessing CNN for Point Navigation. As embodied
whichbuildsanAmazonMechanicalTurktasktocol-
agents are, ostensibly, meant to be embodied in the
lect 80K imitation learning examples of humans per-
real-world, one might expected the they would ben-
forming ObjectNav in simulated environments [154].
efitfromimageprocessingarch