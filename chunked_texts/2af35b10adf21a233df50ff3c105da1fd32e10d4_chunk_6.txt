 theattentionmechanism,therebyallowingthelexicalvectorto
ordertoclassifyitsemotion.Wecomparethestatisticalpatterns focusonlyonthosepartsoftheaudiowhichwouldleadtothe
ofthemostattentedphonemesacrossactorandnon-actor. As highestclassificationaccuracy.Thislaysthebasisofthemodel
wewillseeinthefinalsectionsofourpaper, thesefactorsdo wehaveused,asshowninFigure2.
indeeddifferinastatisticallysignificantmanner, bringingthe
validityofconclusionsdrawnfromactedemotionalspeechasa
proxyfornaturalemotionintoquestion.
.
2. BackgroundWork
Therehasbeensomeworkdonetounderstandthedifferences
betweenactedandnaturalemotionalspeech. Theresultsfound
from these studies are somewhat contradictory to each other.
Studies like [13], which analyze acted and natural emotional
speechwiththehelpofhumanlistenershaveconcludedthatthe
listenersarenotabletodistinguishbetweenthetwocategories.
Theproblemisalsostudiedinthedomainoffalseexpression,
wherethetruthfulnessoftheexpressedemotionisstudied. It
alsoreachestheconclusionthathumansarelesslikelytodif-
ferentiatebetweenthetwo. Ontheotherhand,studieslike[4],
whichalsousehumanlisteners,concludethatabout78%oflis-
tenerswereabletodifferentiatebetweenthenaturalandacted
emotionwithonlyaudiocluesandevenmorecoulddifferenti-
atewhenprovidedwithaudio-visualcues.
The above studies primarily analyze the effect of acted
Figure2: Neuralnetworkmodelusedfortheemotionclassifi-
emotiononthelistener.Inourworkwedonotconsiderthelis-
cationwithattentionmechanism
tener(observerintheproposedNAOmodel)tobeavaliddis-
Sinceweneedboththeacousticandlexicalcontentofan 4.1.4. Characterizingcontent-dependentbias
utterance, to train the model, we require the transcription of
Itisalsopossibleforouranalysestobeinfluencedbyt