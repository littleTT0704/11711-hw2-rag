829.
HugoTouvron,MatthieuCord,AlexandreSablayrolles, HongyuZhu,MohamedAkrout,BojianZheng,Andrew
Gabriel Synnaeve, and Hervé Jégou. 2021. Going Pelegris,AmarPhanishayee,BiancaSchroeder,and
deeperwithimagetransformers. InProceedingsof Gennady Pekhimenko. 2018. Tbd: Benchmarking
the IEEE/CVF International Conference on Com- andanalyzingdeepneuralnetworktraining. arXiv
puterVision,pages32–42. preprintarXiv:1803.06905.
Hanrui Wang, Zhanghao Wu, Zhijian Liu, Han Cai, HongyuZhu,AmarPhanishayee,andGennadyPekhi-
LigengZhu,ChuangGan,andSongHan.2020a. Hat: menko. 2020. Daydream: Accurately estimat-
Hardware-awaretransformersforefficientnaturallan- ing the efficacy of optimizations for {DNN} train-
guageprocessing. arXivpreprintarXiv:2005.14187. ing. In2020USENIXAnnualTechnicalConference
(USENIXATC20),pages337–352.
SinongWang,BelindaZLi,MadianKhabsa,HanFang,
andHaoMa.2020b. Linformer: Self-attentionwith
A HardwarePlatforms
linearcomplexity. arXivpreprintarXiv:2006.04768.
Fulldetailsforthevarioushardwareplatformsand
YuWang,Gu-YeonWei,andDavidBrooks.2020c. A
systematicmethodologyforanalysisofdeeplearning GPUs used for evaluation in Section 4.3 are de-
hardware and software platforms. Proceedings of scribedinTable2.
MachineLearningandSystems,2:30–43.
B HardwareandUtilization
Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan
Wang,FeiSun,YimingWu,YuandongTian,Peter InTable3,weexamineGPUhardwareutilization
Vajda,Yangq