2019.StrategiesforPre-trainingGraphNeuralNetworks.In
2019. ThereAreManyConsistentExplanationsofUnlabeledData:WhyYou InternationalConferenceonLearningRepresentations.
ShouldAverage.InInternationalConferenceonLearningRepresentations. https: [24] HisashiKashima,KojiTsuda,andAkihiroInokuchi.2003.Marginalizedkernels
//openreview.net/forum?id=rkgKBhA5Y7 betweenlabeledgraphs.InProceedingsofthe20thinternationalconferenceon
[2] MikhailBelkinandParthaNiyogi.2002. Laplacianeigenmapsandspectral machinelearning(ICML-03).321–328.
techniquesforembeddingandclustering.InAdvancesinneuralinformation [25] KristianKersting,NilsM.Kriege,ChristopherMorris,PetraMutzel,andMarion
processingsystems.585–591. Neumann.2016.BenchmarkDataSetsforGraphKernels. http://graphkernels.
[3] DavidBerthelot,NicholasCarlini,IanGoodfellow,NicolasPapernot,AvitalOliver, cs.tu-dortmund.de
andColinARaffel.2019. Mixmatch:Aholisticapproachtosemi-supervised [26] PrannayKhosla,PiotrTeterwak,ChenWang,AaronSarna,YonglongTian,Phillip
learning.InAdvancesinNeuralInformationProcessingSystems.5049–5059. Isola,AaronMaschinot,CeLiu,andDilipKrishnan.2020.SupervisedContrastive
[4] PiotrBielak,TomaszKajdanowicz,andNiteshV.Chawla.2021. GraphBar- Learning.AdvancesinNeuralInformationProcessingSystems33(2020).
lowTwins:Aself-supervisedrepresentationlearningframeworkforgraphs. [27] ThomasN.KipfandMaxWelling.2017. Semi-SupervisedClassificationwith
arXiv:2106.02466[cs.LG] GraphConvolutionalNetworks.InInternationalConferenceonLearningRepre-