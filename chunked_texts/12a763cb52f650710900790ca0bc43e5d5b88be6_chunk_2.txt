ter-
toawidevarietyoftasks.
nalknowledgeisneededforcommonsensereason-
ing. Ononehand,asubstantialbodyofpriorwork In this paper, we investigate whether external
has reported that integrating external knowledge knowledge can be helpful for commonsense rea-
can help improve task performance (Mitra et al., soning, even on top of the largest state-of-the-art
2019;Bianetal.,2021,interalia),especiallyifthe pretrainedmodels(e.g. T5-11b(Raffeletal.,2019)
knowledgeishighquality(e.g. hand-craftedbyex- anditsvariants),withafocusonfourrecentcom-
perts). Ontheotherhand,recentleaderboardsare monsense benchmarks. To facilitate easier adap-
oftendominatedbylarge-scalepretrainedmodels tationwithanyzero-shotorfinetunedmodels,we
thatarefine-tunedonatargetbenchmark(Khashabi proposeanapproachthatdoesnotrequireaccess
et al., 2020; Lourie et al., 2021), suggesting that toastructuredknowledgebaseorjointfinetuning
thebenefitsofexternalknowledgemaywashaway forknowledgeintegration.
astheunderlyingmodelsincreaseinsizeandare Thekeyinsightbehindourmethod,Generated
pretrainedoneverlargeramountsofrawtext. Knowledge Prompting (sketched in Figure 1), is
Even if external knowledge is found to be ef- thatwecangenerateusefulknowledgefromalan-
fective on a particular task, flexibility remains a guagemodel,thenprovidetheknowledgeasanin-
fundamentalhurdletointegratingexternalknowl- putpromptthatisconcatenatedwithaquestion. To
3154
Proceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics
Volume1:LongPapers,pages3154-3169
May22-27,2022(cid:13)c2022AssociationforComputationalLinguistics
Dataset Question/Knowledge Prediction Score
thewordchildrenmeans[M]ormorekids. one 0.37|0.35
NumerSense
Thewordchildmeansone