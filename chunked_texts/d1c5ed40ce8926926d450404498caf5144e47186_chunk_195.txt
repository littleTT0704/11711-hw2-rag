 end-
to-end QA experiments with Watson, the expanded text corpora were also used to
retrieve supporting passages for answer scoring, and the added source content had an
impact on features that are based on search rankings and corpus statistics. Again,
the SE method significantly improved QA performance, increasing Watson’s accu-
racy by 7.6–12.9%. The gains in accuracy are larger than the improvements in search
recall, which indicates that source expansion facilitates answer scoring by increasing
the semantic redundancy of the information sources.
We have also shown that the SE approach does not require a search engine to
pre-select relevant content from the Web or other large document collections. Our
method is equally effective if text that is related to the topics of seed documents is
extracted directly from a locally stored corpus without using a retrieval system, and
9.1. SUMMARY 147
the search-based and extraction-based methods can be combined to further improve
QA results. By expanding seed corpora with related content from both web search
results and a local web crawl, we were able to improve Watson’s QA accuracy by 9.4–
19.8% on Jeopardy! and TREC datasets. In addition, we proposed an extension of
the SE algorithm to seed corpora in which there exists no injective mapping between
documents and topics that can be expanded. For instance, in newswire sources and
web crawls, multiple topics can be covered in a single document, or the same topic
may be discussed repeatedly in different documents. Such sources can be transformed
intotopic-orienteddocumentcollectionsbydiscoveringthemostimportanttopicsand
building pseudo-documents about them.
Note that the improvements in question answering performance were achieved
without retrieving more text at QA runtime. Search and candidate recall can always
be increased by retrieving additional or longer search results, but this often comes at
the expense of adding noise that hurts answer selection efficiency and effectiveness. It
may also seem that QA results always improve if larger information sources are used,
but we have seen that this is not always the case. For instance, just adding large, raw
web crawls is ineffective because the vast majority of web pages do not contain useful
information [Clarke et al., 2002], and even if a QA system could handle the added
noise, expensive parallel hardware would be