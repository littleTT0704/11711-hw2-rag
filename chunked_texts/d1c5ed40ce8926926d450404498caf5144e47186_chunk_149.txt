Wikipedia uses manually compiled variants of topics to automatically redirect users
who search for alternative forms of an article title. For instance, there are automatic
redirects for the queries Obama and President Obama to the article about the U.S.
president Barack Obama. We used these redirects as different surface forms of topics
in addition to the article titles when counting frequencies in ClueWeb09. In our copy
of Wikipedia there are about 3.5 million seed documents and 5.9 million redirects,
and we searched 12 TB of web data for occurrences of the topics. To support constant
time lookups, we split the article titles and variants into word tokens and stored them
in a prefix tree2. Then we tokenized the content of each document in the web crawl,
traversed the document and looked up token sequences of varying lengths in the tree.
If a sequence matched one of the Wikipedia titles or redirects, we incremented the
frequency count for the corresponding topic.
To confirm that the ranking of Wikipedia seeds by our estimates of their cover-
age in ClueWeb09 favors topics that are useful for question answering, we plotted
relevance curves for this ranking based on Jeopardy! and TREC datasets. The same
methodology was used as for popularity rankings in Section 6.2, except that a seed
document was judged as relevant if its title or any variant was the answer to a ques-
tion in the datasets. In Figures 7.1 and 7.2 we show the relevance curves for the two
QA tasks and compare them to random rankings, illustrated by straight lines. It can
be seen that the rankings by coverage are much more effective, but that there still
are relevant topics at low ranks, i.e. the curves continue to have positive slopes. Since
we no longer rely on web searches, we can expand large numbers of seeds without
worrying about search API restrictions or the data transfer volume. However, it is
still important to avoid irrelevant topics since the response time of a QA system in-
creases with the amount of data, and noise in the knowledge sources can hurt search
performance. Based on these considerations and the relevance curves, we decided to
expand up to 500,000 Wikipedia articles, and we also evaluated search recall using
fewer expanded documents.
2Also called a trie data structure.
110 CHAPTER 7. UNSTRUCTURED SOURCES
6