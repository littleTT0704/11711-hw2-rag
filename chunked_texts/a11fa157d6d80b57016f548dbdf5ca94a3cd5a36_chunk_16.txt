
evaluationacrosssettings,withtheROBERTA-LARGEasthe Table4:Theportionsofacceptedandrejectedtuplesinhuman
LM. evaluationacrossdifferentLMs,usingtheMULTI-PROMPTS
approach.
ered"accepted"ifatleasttwoannotatorsdeemit
tobetrueknowledge,and"rejected"ifatleasttwo severalsettingsontheHumanrelations: (1)Multi-
annotatorsrateitasfalse. Herewerefersportion Promptsreferstothethefullframeworkdescribed
ofacceptedtuplesasaccuracy. in§3whichusetheautomaticallycreateddiverse
The statistics of our resulting KGs are listed promptsinknowledgesearch. (2)Top-1Prompt:
in Table 2. Besides, we also put the results of Toablatetheeffectofensemblingmultipleprompts,
other paradigms of methods, including COMET weevaluatethevariantthatusesonlytheprompt
forKGcompletionandtext-miningbasedmethods withlargestweight(§3.1)forknowledgeextraction.
(Figure 1). Note that the results across different (3)HumanPrompt: Tofurtherunderstandtheef-
paradigms are generally not directly comparable fectiveness of the automatically created prompts,
duetovastlydifferentsettings. Yetwestillcollect weassessthevariantthatusestheinitialpromptof
the results together for reference purpose. From eachrelation. (4)AutoPrompt(Shinetal.,2020),
our RebertaNet with relation set "Auto", we are whichwasproposedtolearnpromptsbyoptimiz-
able to extract a reasonably large sets of knowl- ing the likelihood of tail entity prediction on the
edge (122K), by extracting knowledge with 487 trainingset. Tofitinoursetting,weadaptittoopti-
easy-to-collect "Auto" relations. The set of rela- mizethecompatibilityscore(Eq.1)ontheexample
tionisanorderofmagnitudelargerthantheprede- entity pairs. We omit other prompt tuning work
fined set of relations in both KG completion and (e.g.,Zhongetal.,2021;Qin