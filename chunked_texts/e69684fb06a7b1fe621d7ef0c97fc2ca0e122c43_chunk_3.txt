sc[
1v16221.8032:viXra
LLM-promptedsystemsposeusabilitychallenges. smaller. Wealsofindthatwecangenerateeffective
Practitioners have expressed concerns about the evaluation datasets; performance improvements
high serving cost and slow prediction time asso- onthesesyntheticclonesofrealbenchmarksalso
ciated with using LLMs (Park et al., 2022), and hold on their real counterparts. We believe that
thoseworkinginhigh-stakesdomainscannotrely Prompt2Modelcanservethefollowingpurposes
oncommercialLLMAPIsduetoprivacyconcerns. forthecommunity:
Forinstance,sharinguserdatawithLLMservice 1. A tool for quickly building small and com-
providers is illegal for many applications in the petent NLP systems: Prompt2Model can be
US(Sezginetal.,2022). directly used to produce task-specific models
that outperform LLMs in a few hours without
In this work, we present Prompt2Model, a
anymanualdataannotationorarchitecturede-
system that retains the ability to specify system
sign. Themethodbridgesthegapbetweenthe
behavior in a light-weight way through prompt-
proof-of-conceptLLMprototypingandtheprac-
ing, while still resulting in a deployable special-
ticaldeploymentofthemodel.
purpose model, maintaining all the advantages
2. A testbed for end-to-end, prompt-based
thereof. Prompt2Model is designed as an auto-
model training: Given Prompt2Model’s ex-
matedpipelinethatextractsessentialtaskinforma-
tensible design, it can offer a platform for ex-
tion from users’ prompts and then automatically
ploring new techniques in model distillation,
collects and synthesizes task-specific knowledge
datasetgeneration,syntheticevaluation,dataset
throughthreechannels:
retrieval, and model retrieval. Our platform
• Dataset retrieval: Whenever possible, we col-
allows studying these components using ex-
lect training data by retrieving task-relevant
trinsicdownstreammetrics,enablingempirical
annotated data (Färber and