esisalsonon-
30
trivial. Toelucidate,dialoguemodelcanspewof-
fensivelanguageeither1)directly-bydisrespect-
20 41.62
ingatarget-groupor2)contextually-byagreeing
withpreviousoffensiveutterances(Figure1). The
10 18.08
distributionoftheseoffensiveresponsesfromboth
12.89
9.88 9.26
dialoguemodelsandhumanreplycommentsispre- 5.36
0
sentedinFigure2. Comparedtohumans,dialogue Reddit user DGPT model GPT3 model
responses responses responses
modelresponsesareoveralllessoffensive,where
GPT-3 (389 out of 2,000) is more offensive than
Figure3: Responsestance“Agree”ratetowardsprevi-
DGPT(179outof2,000).
ousoffensivevssafecomments.
Agreement with Offensive vs Safe comments.
Wealsoplotthepercentageofresponseswiththe
ingourautomatictoxicityandstanceclassifiersis
“Agree”stancetowardspreviousoffensivevs. safe
presentedinTable3.
comments in Figure 3. Surprisingly, we find that
humans are more likely to agree with preceding
Target-GroupDistribution. InFigure4,wevi-
offensive comments (41.62%) compared to safe
sualize the distribution of target group frequen-
comments(12.89%). FurtheranalysisinAppendix
cies. WeseethatReddituserresponsesinthreads
Eshowsthisisaconsistentphenomenonbasedon
(i.e. comments) are offensive towards both de-
anautomatedanalysisof5millionthreadswritten
mographic groups (women, feminists, religious
over six months. We hypothesize that the higher
folks, LGBTQ folks etc.) and specific individuals
proportion of agreement observed in response to
(celebrity,Reddituser). Thismirrorsthediscrimi-
offensivecommentsmaybeexplainedbythehes-
nationthatpeoplereportfacinginreallife(RWJF,
itancy of Reddit users to engage with offensive
2017). Onthecontrary,dialoguemodels