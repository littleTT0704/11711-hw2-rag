 that classifies all
nuggets as irrelevant already achieves 94% accuracy on markup-based nuggets and
85% accuracy on sentence-level nuggets.
In the following, we present evaluation results on nuggets of both granularities
(Sentence and Markup) for different baseline strategies and statistical models:
• Baseline 1: Random. Text nuggets are ranked randomly. Note that each ran-
dom ranking has a different MAP and precision-recall curve, and we report the
average over all possible rankings of the nuggets. To simplify the calculations,
we treat each token as an independent text nugget than can be placed anywhere
in a ranking. Then at any given rank, the average of the precision values of all
possible token rankings is the same as the percentage of tokens in the dataset
that are relevant (28.48%).1
• Baseline 2: Round Robin. Selects the first nugget from all documents, followed
by the second nugget, and so forth. We expect this strategy to outperform the
random baseline since relevant text is often more concentrated at the top of
documents.
• Baseline 3: Search Rank. Preserves the ranking of the retrieved documents
by the search engine and the order of the text nuggets within the documents.
This is a much stronger baseline than random rankings since documents that
are ranked higher by the search engine typically contain more relevant nuggets.
Note that this baseline is the same for sentence-level nuggets and markup-based
nuggets since we do not alter the original order of the text nuggets.
• Baseline 4: Cosine Sim. The text nuggets are ranked by their cosine similarity
to the seed document. This is a special case of the maximal marginal relevance
(MMR) summarization algorithm [Carbonell and Goldstein, 1998, Goldstein
et al., 2000], using a parameter value of λ = 1.
MMRisoneofthemosteffectivealgorithmsformulti-documentsummarization.
It iteratively selects text passages with high “marginal relevance”, i.e. passages
that are relevant to a query and add novel information (see Section 2.4). The
parameter λ controls the tradeoff between relevance and novelty, and by setting
λ = 1 we select the most relevant nuggets regardless of their novelty. Thus we
do not penalize paraph