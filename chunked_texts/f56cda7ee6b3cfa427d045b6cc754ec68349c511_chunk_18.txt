.8 79.6
GPT-3 - 23.62.286.788 26.6 41.0 18.6 70.2
Blenderbot - 16.71.208.523 7.8 19.6 24.2 61.8
DAPT-[S] Offensive 8.61.362.856 4.0 16.0 18.4 76.4
DAPT-[S][N] Both 7.85.379.878 4.0 18.2 9.0 86.4
ATCON-[S] Offensive 8.63.364.851 9.4 29.6 22.4 72.2
ATCON-[N] Stance 8.03.380.874 4.2 17.4 15.0 80.8
ATCON-[S][N] Both 8.61.370.864 8.2 20.6 11.4 85.4
Reddituser - 12.84.374.879 16.6 29.8 21.0 74.8
Table 3: Results from automatic evaluation on 500 offensive threads from test set. [S] indicates safe control
attribute and [N] indicates neutral stance control attribute. Len. is the average response length by each model.
Dist-1and2areDistinct-1,2metricsrespectively.↓implieslowervaluesarepreferredwhile↑impliestheopposite.
ing less offensive responses. ATCON both con- Stance
Model Plaus. Off.
trol model also outperforms the DGPT baseline Agree Dis. Neutral
in %Off, and %Agree metrics but with smaller DGPT 65.2 21.2 7.2 71.6 26.0
Blender 91.2 26.0 14.4 59.6 13.6
marginsthatDAPTneutralstancecontrolmodel.
DAPT 77.2 17.2 8.4 74.4 18.4
Finally, our evaluation of Reddit user responses
ATCON 84.0 21.6 9.2 69.2 22.8
(last row in Table 3) also finds them to be highly
offensiveandagreeinginoffensivecontexts.14
Table4:Humanevaluationofbaselineandbestmodels
on 250 offensive test threads. All values in the table
6.3 Humanevaluation are percentages (%). ‘Plaus