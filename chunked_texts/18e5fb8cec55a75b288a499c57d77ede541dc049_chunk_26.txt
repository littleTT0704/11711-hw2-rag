,43–54.
Krishna, R.; Zhu, Y.; Groth, O.; Johnson, J.; Hata, K.; Petroni,F.;Rockta¨schel,T.;Lewis,P.;Bakhtin,A.;Wu,Y.;
Kravitz, J.; Chen, S.; Kalantidis, Y.; Li, L.-J.; Shamma, Miller, A. H.; and Riedel, S. 2019. Language models as
D.A.;etal.2017. Visualgenome:Connectinglanguageand knowledgebases? arXivpreprintarXiv:1909.01066.
visionusingcrowdsourceddenseimageannotations. Inter-
Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and
nationaljournalofcomputervision123(1):32–73.
Sutskever, I. 2019. Language Models are Unsupervised
Levine, Y.; Lenz, B.; Dagan, O.; Ram, O.; Padnos, D.; Multitask Learners. OpenAI URL https://openai.com/blog/
Sharir, O.; Shalev-Shwartz, S.; Shashua, A.; and Shoham, better-language-models/.
13514
Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016. Ye,Z.-X.;Chen,Q.;Wang,W.;andLing,Z.-H.2019.Align,
Squad: 100,000+ questions for machine comprehension of mask and select: A simple method for incorporating com-
text. arXivpreprintarXiv:1606.05250. monsense knowledge into language representation models.
arXivpreprintarXiv:1908.06725.
Reimers, N.; and Gurevych, I. 2020. Making Monolin-
gual Sentence Embeddings Multilingual using Knowledge Zellers, R.; Holtzman, A.; Bisk, Y.; Farhadi, A.; and Choi,
Distillation. arXiv preprint arXiv:2004.09813 URL http: Y. 2019. HellaSwag: Can a Machine Really Finish Your
//arx