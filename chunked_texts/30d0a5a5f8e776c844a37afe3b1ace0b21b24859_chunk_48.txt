 [95, 126] and
21
open-sourceinfrastructureforsim2robotdeployment available used during training. The use of large-
[1, 51, 187]. These advances have lowered the bar- scale training data has resulted in models that are
rier to entry for robotics, and enable the embodied increasingly more powerful and generalizable across
AIcommunitytoevaluatetheperformanceofvarious AI [6, 42, 147, 153]. Yet, most works in embodied
research algorithms both in simulation and on real- AI often suffer from massive overfitting to the train-
world robots. Currently, each approach is limited to ing scene datasets. For instance, in the RoboTHOR
aspecificsimulatororalimitedsetofrobotplatforms. andHabitatObjectNavchallengesalone, itisnotun-
A key future direction is for these translation tech- commontoobtainnear100%successonthe100orso
nologies to become ubiquitous interfaces, with sup- scenes seen during training while only obtaining 30-
port for any simulator or physical robot platform re- 50%successwhenevaluatingonunseenscenes.
quiredbytheresearcher. Early work in embodied AI either trained agents
Bycomparingtheperformanceofpoliciesinsimu- onhand-designedscenescreatedby3Dartists[227]or
lationandthereal-world,researchersareabletoiden- fromstatic3Dscansofreal-worldenvironments[26].
tify flaws in the simulator design that lead to poor However, there are several drawbacks for both ap-
sim2real transfer [1], and develop novel methods to proaches. Manually creating 3D scenes is incredibly
overcomethesim2realgap. Commonapproachesfor time intensive work and requires graphics experts to
bridgingthesim2realgapincludedomainrandomiza- create3Dassets,possiblymaketheminteractive,and
tion [10, 191], or domain adaptation, a technique in arrange the objects to construct scenes. It took 3D
whichdatafromasourcedomainisadaptedtomore artists about 32 hours to develop each house of the
closely resemble data from a target domain. Prior ArchitecTHORdataset[52],andresultsinpresent-day
worksleveragedGANtechniquestoadaptthe