 lan- the accompanying language instruction. ALFRED in-
guageunderstandingmodelswiththisbenchmark. volves interactions with objects, keeping track of state
1.Introduction changes,andreferencestopreviousinstructions.
A robot operating in human spaces must learn to con- nectinghumanlanguagetoactions, behaviors, andobjects
nect natural language to the world. This symbol ground- in interactive visual environments. Planner-based expert
ing [21] problem has largely focused on connecting lan- demonstrations are accompanied by both high- and low-
guagetostaticimages. However,robotsneedtounderstand level human language instructions in 120 indoor scenes in
task-oriented language, for example “Rinse off a mug and AI2-THOR2.0[26]. Thesedemonstrationsinvolvepartial
placeitinthecoffeemaker,”asillustratedinFigure1. observability, long action horizons, underspecified natural
Platformsfortranslatinglanguagetoactionhavebecome language,andirreversibleactions.
increasingly popular, spawning new test-beds [3, 12, 14,
ALFRED includes 25,743 English language directives
42]. Thesebenchmarksincludelanguage-drivennavigation
describing8,055expertdemonstrationsaveraging50steps
and embodied question answering, which have seen dra-
each, resulting in 428,322 image-action pairs. Motivated
matic improvements in modeling thanks to environments
by work in robotics on segmentation-based grasping [37],
like Matterport 3D [3, 11], AI2-THOR [26], and AI Habi-
agentsin ALFRED interactwithobjectsvisually,specify-
tat [45]. However, these datasets ignore complexities aris-
ing a pixelwise interaction mask of the target object. This
ingfromdescribingtask-orientedbehaviorswithobjects.
inference is more realistic than simple object class pre-
We introduce ALFRED, a new benchmark for con- diction, where localization is treated as a solved problem.
Existing beam-search [17, 48, 53] and backtracking solu-
1PaulG.AllenSchoolofComputerSci.&Eng.,Univ.ofWashington
tions[24,29]areinfeasib