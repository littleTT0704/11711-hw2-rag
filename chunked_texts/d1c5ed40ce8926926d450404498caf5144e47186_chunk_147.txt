ansionapproachbecause
it allows us to access information that is not available on the Web. For instance, we
can expand a seed corpus with confidential data from the intranet of a company or
other proprietary information sources. Similarly, source expansion can be applied to
domains for which existing search engines have insufficient coverage (e.g. financial
literature) or for which the information provided on web pages can be too unreliable
(e.g. the medical and legal domains). In addition, we can reduce network traffic and
circumvent restrictions of web search APIs regarding the number of queries that can
be issued per host in a given time period, and the maximum number of search results
accessible for each query.
107
108 CHAPTER 7. UNSTRUCTURED SOURCES
Examples of text corpora that can be stored locally and used for the extraction-
based source expansion approach include:
• General purpose web crawls that cover a wide range of different topics, or crawls
of websites about a particular knowledge domain (e.g. movies databases or po-
litical blogs and discussions).
• Pre-existing information sources that target a specialized domain (e.g. collec-
tions of scientific publications or product descriptions and manuals), or that fill
in gaps in the coverage of an open-domain QA system (e.g. world literature or
religious texts).
• News articles that were published during a specific time period (e.g. the 2007–
2010 financial crisis), or news about recent events that are not yet covered in
the knowledge sources used for QA.
Furthermore, multiple document collections can be combined and used as a large, un-
structured corpus of related content for the source expansion methodology described
in the following.
7.1.1 Approach
When expanding a seed corpus with information from a locally stored, unstructured
source, we first select seed documents about topics that have high coverage in that
source. Thenweextracttextnuggetsthatmentionthesetopicsandcompileaninitial,
noisy pseudo-document for each of the selected seeds. Finally, we remove irrelevant
and lexically redundant content by applying a modified configuration of the source
expansionpipelinefromChapter4. Insteadofretrievingwebpagesandsplittingthem
into text nuggets, we use the previously extracted nuggets as input for the statistical
relevance