 and g˜
θ
end
end
hypothesis “cats tend to have chubby faces” is good enough to classify all the
animals in her picture book, other hypotheses mapping ears or body-size to
labels are also predictive.
On the other hand, if she wants to differentiate all the “dogs” from “cats”
in the real world, she will have to rely on a complicated combination of the
features mentioned about. Our main motivation of this paper is as follows: this
complicated combination of these features is already illustrated in her picture
book, but she does not have to learn the true concept to do well in her finite
collection of animal pictures.
This disparity is officially known as “covariate shift” in domain adaptation
literature: the conditional distribution (i.e., the semantic of a cat) is the same
acrosseverydomain,butthemodelmaylearnsomethingelse(i.e.,chubbyfaces)
due to the variation of marginal distributions.
With this connection built, we now proceed to the theoretical discussion,
where we will constantly refer back to this “dog” vs. “cat” example.
Background As the large scale deep learning models, such as AlexNet or
ResNet, are notoriously hard to be analyzed statistically, we only consider a
simplified problem to argue for the theoretical strength of our method: we only
concern with the upper layer h(·;θtop) and illustrate that our algorithm helps
improve the generalization of h(·;θtop) when Z is fixed. Therefore, we can di-
rectly treat Z as the data (features). Also, for convenience, we overload θ to
denote θtop within the theoretical evidence section.
We expand our notation set for the theoretical analysis. As we study the
domain-agnosticcross-domainsetting,wenolongerworkwithi.i.d data.There-
fore, we use Z and Y to denote the collection of distributions of features and
labels respectively. Let Θ be a hypothesis class, where each hypothesis θ ∈ Θ
maps Z to Y. We use a set D (or S) to index Z, Y and θ. Therefore, θ(cid:63)(D)
Self-Challenging Improves Cross-