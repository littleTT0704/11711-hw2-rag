ummarizedasfollows: ten (3) a reference translation (typically created
byaprofessionalhumantranslator)isincludedas
• WeconfirmthefindingofKocmiandFeder-
additional information when assessing the candi-
mann(2023)thatLLMsarezero-shotstate-of-
date translation. This sub-problem is known as
the-artsystem-levelevaluators,butshowlow
reference-based evaluation(asopposedreference-
correlation with human judgment compared
lessevaluationorqualityestimation).
tolearned metricsatthesegment-level.
Upuntilrecently,humanevaluationofmachine
• We show that finetuning an LLM with hu- translationwascarriedoutpredominantlywiththe
manjudgmentmitigatesitslowsegment-level aim of assigning a single quality score to a can-
performance(particularlyforsmallerLLMs), didatetranslation. Consequently,learned metrics,
showingsimilarcorrelationswithhumanjudg- whichleveragecollectedhumanjudgmentdata,are
ment at both the system-level and segment- trainedforandevaluatedonthesametaskofscore
leveltostate-of-the-artlearnedmetrics. prediction(i.e.,assigningasinglequalityscoreto
acandidatetranslation),andcanachievehighcor- toautomaticallyscoretranslations. However,their
relationwithhuman-providedscores(Freitagetal., approachreliedonweakerencoder-onlyorencoder-
2022). decoderlanguagemodels,requiredsuperviseddata
However, framing machine translation evalu- towork,andoverallunderperformedothertopmet-
ation as a score prediction task is problematic: rics. WecompareagainsttheirMaTASemetricin
anyscoringorrankingoftranslationsisimplicitly ourexperiments. Luetal.(2023)showedthatdo-
basedonanidentificationoferrorsinthecandidate ingerroranalysis,apromptingtechniquesimilarto
translations,andaskingraterstosolelyprovidea AUTOMQM,couldleadtobetterChatGPT-based
singlescore