ontheMDD-UNSEEN
workscanbeframedaseitherextractiveQAorab-
testsetcomparedtothebaselineRAGmodel. Our
stractiveQA.Document-groundedconversational
submission (CMU-QA) stands 2nd and 3rd on the
questionansweringtaskslikeCoQA(Reddyetal.,
unseenandseenleaderboards1 respectively.
2019a)andDoc2Dial(Fengetal.,2020b)combine
the above two frameworks. This setting requires
1https://eval.ai/web/challenges/challenge-
∗Equalcontribution page/1437/leaderboard/3577
148
ProceedingsoftheSecondDialDocWorkshoponDocument-groundedDialogueandConversationalQuestionAnswering,pages148-154
May26,2022©2022AssociationforComputationalLinguistics
2 RelatedWorks ery passage is computationally infeasible. As a
compromise,re-rankingmethodssuchasthosein
TheMultiDoc2Dialsettingdrawsonrelatedtasks
Fajciketal.(2021)trainare-rankingmodulethat
likeopen-domainQAandconversationalQA.Con-
canjointlyembedthequeryandretrievedpassages.
sequently, we investigate techniques that have
Because the set of retrieved passages is signifi-
shownsuccessonthosetasks. ConversationalQA
cantly smaller than the whole corpus, re-ranking
tasks, which typically assume that the grounding
methods can model more complex relationships
document is provided, use transformer-based ar-
betweenthequeryandretrievedpassages,andsig-
chitectures;theleadingsubmissionstotheQuAC
nificantlyboostretrievalperformance.
andCoQAleaderboardsuseRoBERTa(Liuetal.,
Reader: Encoder-decoderbasedabstractiveread-
2019) and DeBERTa (He et al., 2020), respec-
ers have been widely used in QA tasks. RAG
tively. Retriever-readerarchitecturessuchasRAG
(Lewisetal.,2020b)usestheBART-largemodel
(Lewisetal.,2020b)have