 Models trained on this filtered dataset Giventhatcurrenthatespeechsystemstendtorely
achieve higher performance on OOD and adver- heavilyonthepresenceofNOI,OI,andONImen-
sariallyconstructedtestsets,comparedtotheorig- tions(§2.1)forlabelingtextastoxic,weusefalse
inalmodel,onseveraltextandimageclassification positiverate(FPR)overeachofthesecategoriesto
datasets. Thisindicatesareductioninspuriousbi- measurethedegreeofbiasinthemodel,following
asesinthefiltereddata. Hardt et al. (2016) and Xia et al. (2020). Specif-
ically, we report the FPR of a model on tweets
10TheNOIandOIbias-onlymodelsreach63%and67% containing NOI (FPR NOI), OI (FPR OI), and ONI
accuracy,respectively,whichisempiricallyhardfortheen-
(FPR ),aswelltheF correspondingtoeachof
sembletouse. Thisislikelyduetolowcoverageinthetrain ONI 1
setofthosecategories(4.43%NOIand4.25%OI). these classes. Intuitively, the lower the FPR ∗, the
3146
R ↓ R ↓ R ↓ Table 2 shows results for lexical bias reduc-
NOI OI ONI
tion using both debiased training approaches, as
Original 0.0445 0.2641 0.6718
well as models trained on datasets filtered us-
Random 0.0345 0.2603 0.6683
AFLite 0.0434 0.2458 0.6016 ing AFLite and all three regions from DataMaps.
DataMaps-Ambig. 0.0126 0.1968 0.5839 Bothdebiased trainingapproaches, LMIXIN-ONI
DataMaps-Hard 0.0081 0.1853 0.5849
DataMaps-Easy 0.0772 0.3661 0.7720
and LMIXIN-TOXTRIG, reduce FPR
ONI
as well
as FPR by a large amount. However