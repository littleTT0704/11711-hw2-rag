ference
Now we revisit another classical learning framework, Bayesian inference, and examine its intriguing
connections with the maximum entropy principle. Interestingly, the the maximum entropy principle can also
help to reformulate Bayesian inference as a constraint optimization problem, as for MLE.
Different from MLE, Bayesian approach for statistical inference treats the hypotheses (parameters θ) to be
inferred as random variables. Assuming a prior distribution π(θ) over the parameters, and considering a
probabilistic model that defines a conditional distribution p(x∣θ), the inference is based on Bayes’ theorem:
π(θ)∏ p(x∗∣θ)
p(θ∣D) = x∗∈D, (2.14)
p(D)
where p(θ∣D) is the posterior distribution after observing the data D (which we assume are i.i.d.); and
p(D) = ∫ π(θ)∏ p(x∗∣θ)dθ is the marginal likelihood.
θ x∗
Interestingly, the early work by Zellner (1988) showed the relations between Bayesian inference and maximum
entropy, by reformulating the statistical inference problem from the perspective of information processing, and
rediscovering Bayes’ theorem as the optimal information processing rule. More specifically, statistical
inference can be seen as a procedure of information processing, where the system receives input information in
the form of prior knowledge and data, and emits output information in the form of parameter estimates and
others. An efficient inference procedure should generate an output distribution such that the system retains all
input information and not inject any extraneous information. The learning objective is thus to minimize the
difference between the input and output information w.r.t. the output distribution:
m q(θin
)
−H(q(θ))+logp(D)−Eq(θ)[logπ(θ)+ ∑x∗∈Dlogp(x∗∣θ)
]
(2.15)
s.t. q(θ) ∈ P(Θ),
where the first two terms measure the output information in the output distribution q(θ) and marginal p(D