relations. Someof
Relations Weevaluateourframeworkwithsev- therelationsarenotstraightforward, makingthis
eral relation sets: (1) ConceptNet (Speer et al., relationsetmoredifficultthanotherones. 3
2017): Following Li et al. 2016, we filter the
4.2 ExtractingKnowledgeofDiverseNew
KG and use a set of 20 common relations (e.g.
Relations
HAS_SUBEVENT, MOTIVATED_BY_GOAL). The
initialpromptsfortheserelationsarefromtheCon- Our framework is applied to extract knowledge
ceptNetrepository,andwerandomlysample5ex- graphs from LMs with relations of ConceptNet,
ample entity pairs from the ConceptNet KG for Auto, and Human. The accuracy of the ex-
each relation. (2) LAMA (Petroni et al., 2019): tracted knowledge is then evaluated with hu-
Followingpreviousworks,weusetheT-RExsplit man annotation using Amazon Mechanical Turk
(41 relations from WikiPedia, such as capital_of, (MTurk). Each extracted knowledge tuple is la-
member_of). Foreachrelation,thehuman-written beled for correctness by three annotators using a
prompt provided in Petroni et al. 2019 is used as True/False/Unjudgeablejudge. Atupleisconsid-
theinitialpromptandwerandomlysample5exam-
3For reference, finetuned ROBERTA-LARGE achieves
pleentitypairsforeachrelation. (3)Human: We about50%accuracyontheoriginaldataset.
Methods Acc Rej SourceLMs Acc Rej
AUTOPROMPT 0.33 0.47 DISTILBERT 0.67 0.24
HUMANPROMPT 0.60 0.27 BERT-BASE 0.63 0.26
TOP-1PROMPT(Ours) 0.69 0.23 BERT-LARGE 0.70 0.22
MULTIPROMPTS(Ours) 0.73 0.20 ROBERTA-BASE 0.70 0.22
ROBERTA-LARGE 0.73 0.20
Table3:Theportionsofacceptedandrejectedtuplesinhuman