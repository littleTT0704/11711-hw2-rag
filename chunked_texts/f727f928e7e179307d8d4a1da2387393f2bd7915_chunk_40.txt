 SLAG condition where
train
Tibshirani,1994). Whenthereisasinglestatistic
r = r. Itiscriticaltothesuccessoflearned
train test
perdatapoint,likeMainInputUpdateSuccess,we
optimizers to train them to update points sequen-
formamatrixofshapen sforndatapointsand
× tially when this is a desired application. Further,
smodelseeds(wheretheseedwasusedforboth
sequentialupdatingwithsequencepredictiontasks
task model training and learned optimizer train-
istheonlysettingwhereweseelearnedoptimizers
ing). Wethenresamplerowsandcolumnsofthis
outperformbaselinesacrossallrelevantmetrics.
matrix10,000times,whichwassufficientforcon-
vergence. When we perform hypothesis tests for Choosingtraininglabelsforlearnedoptimizers.
thedifferenceinstatisticsbetweenconditions,we Inearlyexperiments,wefoundthatitisbeneficial
pairthedatapointsbyusingthesamerowsofthis tousealldatapoints(includingcorrectlypredicted
matrixateachstepofthebootstrap(i.e. weconduct points)asMainInputsduringtraining,ratherthan
pairedtests). Formetricsinvolvingmultipledata restricting training to only incorrectly predicted
points per Main Input, like paraphrases or other points. Westillfocusoncorrectingwrongoutputs
random data, we make a simplifying assumption at test time. But so we must select what label to
wherewedonotresamplethemultipledatapoints useduringoptimizertraining. TogetaHardLabel,
butjustcomputetheaveragemetricforthosedata we use the correct label for incorrectly predicted
points and treat that as the ground-truth statistics points,andforcorrectlypredictedpoints,wesim-
for the Main Input. We explored using a full 3- ply draw a label randomly from the labels in the
dimensionalbootstrap,whereweresampleamong training data. The alternative Beam Label condi-
theseextradatapointsbyconstructingamatrixof tionusesasamplefromthemodel’sbeamsearch
shape n s n, but it was quite slow and gave for a data point