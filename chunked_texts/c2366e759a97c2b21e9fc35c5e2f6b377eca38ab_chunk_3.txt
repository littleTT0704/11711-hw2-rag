ika Panda arm organizing 4 dishes into 2
drawers, following preference shown in a demonstration. The robot opens a top drawer, places
objectsinthetopdrawer,closesit,anddoesthesameforthebottomdrawer. Thehigh-levelpolicy
thatmakesdecisionsaboutwhentoopendrawers,whatobjectstopick,etcislearnedinsimulation
andtransferredzero-shottothereal-world.
user demonstration. Our experiments use a complex high-dimensional dishwasher loading envi-
ronment (Fig. 4) with several challenges: complex task structure, dynamically appearing objects
andhuman-specificpreferences. TTPsuccessfullylearnsthistaskfromsevenpreferenceswith80
demonstrationseach,andgeneralizestounseenscenesandpreferencesandoutperformscompetitive
baselines[23,24]. Finally,wetransferTTPtoarearrangementprobleminthereal-world,wherea
Frankaarmplacesdishesintwodrawers,usingasinglehumandemonstration(Fig. 1).
2 TransformerTaskPlanner(TTP)
We introduce TTP, a Transformer-based policy architecture for learning sequential manipulation
tasks. We assume low-level ‘generalized’ pick-place primitive actions that apply to both objects
likeplates,bowls,andalsotodishwasherdoor,racks,etc. TTPlearnsahigh-levelpolicyforpick-
placeinaccordancewiththetaskstructureandpreferenceshownindemonstrations. Thefollowing
sections are described with dishwasher-loading as an example, but our setup is applicable to most
long-horizonmanipulationtaskswith‘generalized’pick-place.
State-ActionRepresentations Weconsiderahigh-levelpolicythatinteractswiththeenvironment
atdiscretetimesteps. Ateverytimestept,wereceiveobservationo fromtheenvironmentwhichis
t
passedthroughaperceptionpipelinetoproduceasetofrigid-bodyinstances{x }n,corresponding
i i=1
tothenobjectscurrentlyvisible. Weexpressaninstanceas: x = {p,c,t},wherep isthepose
i i i i
of the object, c is