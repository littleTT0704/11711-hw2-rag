Xiaetal.(2020),debiasingledtodegener-
American English, white-aligned English, His-
atebehaviorduetothedatacollectionprocess,asdiscussed
panic, and other). In this study, we only focus inAppendixB.
3145
model to rely more on features unrelated to the DataMaps (Swayamdipta et al., 2020) show
biases. Once trained, the bias-only model is dis- the presence of distinct regions in a dataset—
carded,andonlythe“bias-free”fullmodelisused namely, easy, hard and ambiguous—defined with
forinference,followingClarketal.(2019). respect to a given model. These regions are
discovered based on the training dynamics of a
Bias-onlymodel Givenitseffectivenessonbag- model, determined by the model’s confidence in
of-words (BoW) features, we use an SVM classi- the true class, for each example, as well as the
fier as the lexical-bias-only model. For example, variability of this confidence, throughout train-
theTOXTRIG-onlymodelcountsthefrequencyof ing epochs. Swayamdipta et al. (2020) show that
TOXTRIGwordsineachtweet. Ourdialectal-bias- training exclusively on the hard and ambiguous
only model uses the probability of dialects (AAE, regions of the data results in high OOD perfor-
WAE,Hispanic,andother)obtainedfromadialect mance, indicating lower prevalance of spurious
detector (Blodgett et al., 2016) as features in a biases. The easy region is the largest in size
SVMclassifier. for RoBERTa; however, experiments showed that
training exclusively on these examples hurt OOD
Fullmodel Wefine-tuneaRoBERTa-largeclas-
generalization on different NLU tasks. Following
sifier(Liuetal.,2019),astate-of-the-artclassifier
this work, we create DataMaps-Easy, DataMaps-
for the toxicity detection task. See Appendix A.1
Ambiguous, and DataMaps-Hard subsets for our
formoremodelingdetails.
dataset.
