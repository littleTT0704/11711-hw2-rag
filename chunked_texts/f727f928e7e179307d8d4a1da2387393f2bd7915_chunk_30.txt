). SeeFig. 4foragraphofmemory
jectiveisoptimizedw.r.t. ϕwithAdamWthrough usedependingonr andk.
astandardprocedureofrandomlysamplingmini- Experiment runtimes. We now give runtimes
batcheswithoutreplacement(LoshchilovandHut- for experiments in the paper. Building the belief
ter, 2019). Within each batch, one datapoint is graphs takes 25 hours for FEVER (n = 10,444)
randomly selected as the Main Input, and the re- and 17.5 hours for LeapOfThought (n = 8642)
mainingpointsareusedas. Toobtainupdate onanNVIDIARTX2080GPU.Computingsum-
R
D
labels y n, we always use the opposite class marystatisticsforgraphstakes3hoursonFEVER
{ i∗ }i=1
inbinaryclassification. Forsequence-to-sequence and 3 hours for LeapOfThought for statistics be-
2724
Sequential Backprop Graph
Task Model
Optimizer Backprop
Stop Gradient
Figure3: Thebackpropagationgraphforsequentialmodelupdates.
sides Update-Transitivity. We compute Update- Dataset r K Objective
test
Transitivity for LeapOfThought with a subset of
1 5 Main
FEVER
4000points,whichtakes45hours. 10 1 Main
All other experiments are run on a NVIDIA 1 5 Main
LeapOfThought
V10032GBGPU.Trainingthetaskmodelstakes 10 1 Main
7 minutes for LeapOfThought, 45 minutes for 1 5 Main
zsRE
10 5 Main
FEVER,4hoursforzsRE,and10hoursforWiki-
data5m. Trainingthelearnedoptimizerwithr = 1 1 5 Main+Para
Wikidata5m
10 5 Main+Para
takes 2.3 hours for LeapOfThought, 5 hours for
FEVER, 9.5 hours for zsRE, and 16 hours for Table10: Finalhyperparametersandobjectivetermsof
Wikidata5m. Trainingthelearnedoptimizerwith thelearnedoptimizerforeachtask.
r = 10takes53minutesforLeapOfThought,