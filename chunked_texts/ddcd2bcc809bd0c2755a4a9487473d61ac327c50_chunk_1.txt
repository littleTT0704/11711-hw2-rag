Clever Hans or Neural Theory of Mind?
Stress Testing Social Reasoning in Large Language Models
NatalieShapira1 MoshLevy*1 SeyedHosseinAlavi*2,3 XuhuiZhou*4
YejinChoi5,6 YoavGoldberg1,5 MaartenSap4,5 VeredShwartz2,3
1 Bar-IlanUniversity 2 UniversityofBritishColumbia
3 VectorInstituteforAI 4 CarnegieMellonUniversity
5 AllenInstituteforArtificialIntelligence 6 UniversityofWashington
nd1234@gmail.com
Abstract TworecentpapersaddressedwhetherLargeLan-
guage Models (LLMs; Brown et al., 2020; Bom-
TheescalatingdebateonAI’scapabilitieswar-
masanietal.,2021;Zhaoetal.,2023)haveaToM,
rantsdevelopingreliablemetricstoassessma-
chine“intelligence.” Recently,manyanecdo- andcametooppositeconclusions: Sapetal.(2022)
talexampleswereusedtosuggestthatnewer shows they lack this ability and Kosinski (2023)
largelanguagemodels(LLMs)likeChatGPT claimsthisabilityhasemergedinthenewermod-
andGPT-4exhibitNeuralTheory-of-Mind(N- els spontaneously. The latter was criticized for
ToM);however,priorworkreachedconflicting
itsflawedmethodology(MarcusandDavis,2023).
conclusions regarding those abilities. We in-
Ullman(2023)furthershowedthatsimplechanges
vestigatetheextentofLLMs’N-ToMthrough
to the ToM questions break LLMs. But to para-
anextensiveevaluationon6tasksandfindthat
while LLMs exhibit certain N-ToM abilities, phrase the saying, hype gets halfway around the
this behavior is far from being robust. We world before rigorous experiments put on their
further examine the factors impacting perfor- boots; other researchers continue to spread the
manceonN-ToMtasksanddiscoverthatLLMs word about N-ToM, claiming that GPT-4 �