stothe‘entailment’label. Ifoneresponse
of N, we only have to compute 2N ELMo representations
entailstheother,weflagthemassimilar,evenifthereverse
ratherthanN2.
entailment is not true, because such a response is likely to
beafalsepositiveasadistractor.
The benefit of using ESIM+ELMo for this task is that
it can be made more efficient for the task of all-pairs sen-
Validatingthe λparameter Recallthatourhyperpa-
tence similarity. While much of the ESIM architecture in-
rameterλtradesoffbetweenmachineandhumandifficulty
volvescomputingattentionbetweenthetwotextsequences,
forourfinaldataset.Weshedmoreinsightonhowwechose
everything before the first attention can be precomputed.
theexactvalueforλinFigure13. Wetriedseveraldifferent
This provides a large speedup, particularly as computing
valuesofλandchoseλ = 0.1forQ → Aandλ = 0.01for
theELMorepresentationsisexpensive.Now,forafoldsize
QA → R, as at these thresholds human performance was
20Again,withobjecttagsreplacedwiththeclassname,andpersontags roughly 90%. For an easier dataset for both humans and
replacedbygenderneutralnames. machines,wewouldincreasethehyperparameter.
14
ycarucca
ycarucca
Dataset # Chance A Q+A S+Q+A
train
D. Language Priors and Annotation Artifacts
TVQA[46] 122,039 20.0 45.0 47.4 70.6♠
Discussion
MovieQA[75] 9,848 20.0 33.8 35.4 36.3♣
PororoQA[43]♥ 7,530 20.0 43.1 47.4
There has been much research in the last few years in
understandingwhat‘priors’datasetshave.21 Broadlyspeak- TGIFQA[39]♦ 73,179 20.0 45.8 72.5
ing,howwelldomodelsdoon VCR,aswellasothervisual VCRQ