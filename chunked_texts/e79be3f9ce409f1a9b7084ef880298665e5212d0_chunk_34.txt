Xiv:1906.05743, [52] JunXu,TaoMei,TingYao,andYongRui. Msr-vtt:Alarge
2019. 1,5,8 video description dataset for bridging video and language.
10
In2016IEEEConferenceonComputerVisionandPattern where D is the full set of corpus, which are the captions
Recognition(CVPR),pages5288–5296.IEEE,2016.1,2,5, inthetrainingsetforadataset;thedenominatorcountsthe
11 number of captions which contain a specific token. Based
[53] YoungjaeYu,JongseokKim,andGunheeKim. Ajointse- on Eq. 7, we can compute the idf for each token of inter-
quence fusion model for video question answering and re- est. Thesmallertheidf,themorefrequentitappearsinthe
trieval.InProceedingsoftheEuropeanConferenceonCom-
corpus. We do not compute the tf term since usually a to-
puterVision(ECCV),pages471–487,2018. 2,5,7
kenonlyappearsonceinasinglesentence. Thefulllistof
[54] Youngjae Yu, Hyungjin Ko, Jongwook Choi, and Gunhee
tokens and corresponding idfs can be found in Fig. 4. For
Kim. Videocaptioningandretrievalmodelswithsemantic
a given sentence, we first assign the computed idfs to its
attention. arXivpreprintarXiv:1610.02947,6(7),2016. 2
nounsandverbsandthennormalizetheidfs,whicharethen
[55] Youngjae Yu, Hyungjin Ko, Jongwook Choi, and Gunhee
usedtoweighthetoken-levelcontrastivelosses.
Kim. End-to-endconceptworddetectionforvideocaption-
ing,retrieval,andquestionanswering. InProceedingsofthe
B.Contributionofthreecontrastivelosses
IEEEConferenceonComputerVisionandPatternRecogni-
tion,pages3165–3173,2017. 2
[56