emeth-
deformable-transformer[71]toconducttemporalfusion,while ods for fair comparison. Let t =1/FPS denote
stream stream
other settings are similar to VisTR [60]. Although it achieves the streaming time of each frame and t =1/FPS
model model
animpressiveresult,weconsideritmainlyduetotheadoption denote the average model processing time for each frame. For
of a stronger deformable transformer. We also compare our online methods, the final latency of each frame is
method against the state-of-the-art VIS methods on Youtube-
VIS 2021 in Table II. Since Youtube-VIS-2021 is a newly Latency online =t stream+t model
introduced dataset, there are only a few methods for compari-
Forofflinemethods,weneedtowaittilltheN -thframeofthe
son. Our method achieves the best performance among online f
clip comes, where N is the frame number of the processed
methods. f
clip. The latency of the last frame (the whole clip) is
Qualitative result. We compare the qualitative result of our
method against CrossVIS [68] on Youtube-VIS-2019 val set Latency =t ∗N +t ∗N
offline stream f model f
segamI
SIVssorC
sruO
segamI
SIVssorC
sruO
lluF
desserpmoC
9
Method Backbone AP AP50 AP75 AR1 AR10 Ref.Frame AP AP50 AP75 AR1 AR10
MaskTrack ResNet-50 28.6 48.9 29.6 26.5 33.8 0 37.3 58.4 40.1 37.6 43.0
SipMask-VIS ResNet-50 31.7 52.5 34.0 30.8 37.8 1 40.8 63.4 43.5 42.4 46.7
CrossVIS ResNet-50 34.2 54.4 37.9 30.4 38.2 2 40.4 63.8 42.3 40.5 47.0
CrossVIS ResNet-101 35.2 56.3 36.4 33.9 40.6 3 40.7 64.8 44.0 39.2 45.5
