-off, yielding both
highquantityandqualityofpseudo-labelsduringtraining. Extensiveexperimentsdemonstratethe
effectivenessofourmethodonvarioustasks. Wehopemoreworkscanbeinspiredinthisdirection,
suchasdesigningbetterweightingfunctionsthatcandiscriminatecorrectpseudo-labelsbetter.
9
etaRrorrE
)%(etaRrorrE )%(etaRrorrE )%(etaRrorrE
PublishedasaconferencepaperatICLR2023
REFERENCES
EricArazo,DiegoOrtego,PaulAlbert,NoelEO’Connor,andKevinMcGuinness. Pseudo-labeling
andconfirmationbiasindeepsemi-supervisedlearning. In2020InternationalJointConference
onNeuralNetworks(IJCNN),pp.1–8.IEEE,2020.
David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and
ColinRaffel. Remixmatch: Semi-supervisedlearningwithdistributionmatchingandaugmenta-
tionanchoring. InInternationalConferenceonLearningRepresentations,2019a.
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A
Raffel. Mixmatch: Aholisticapproachtosemi-supervisedlearning. AdvancesinNeuralInfor-
mationProcessingSystems,32,2019b.
DavidBerthelot, RebeccaRoelofs, KihyukSohn,NicholasCarlini,andAlexKurakin. Adamatch:
Aunifiedapproachtosemi-supervisedlearninganddomainadaptation. ICLR,2021.
OlivierChapelle,BernhardScho¨lkopf,andAlexanderZien(eds.). Semi-SupervisedLearning. The
MITPress,2006.
BaixuChen,JunguangJiang,XimeiWang,JianminWang,andMingshengLong. Debiasedpseudo
labelinginself-training. arXivpreprintarXiv:2202.07136,2022.
XiaokangChen,Yuhui