estoanhourlyrateof$9.05. We fortrainingandevaluations(Wanetal.,2014);Ac-
require workers to be English-speaking, with the tivityNet(CabaHeilbronetal.,2015), apopular
mTurkMasterqualificationandalifetimeapproval benchmarkforhumanactivityunderstanding,uses
rateofover90%. thesame203activitiesacrossdifferentsplits;Yang
To sample examples to annotate, we first ob- etal.(2021b)trainsastepinferencemodelwitha
tain all the steps corresponding to the same trainingsetthatsharesthesamegoalswiththetest
1000 goals as we did in subsection 6.1. To set.
evaluate the DEBERTA-ULâ€™s ability to predict This data split is meaningful on its own. We
unlinkable,werandomlysample500stepspre- canviewtheoriginalqueriesasinitialschemasfor
dictedasunlinkableandanother500predicted complexprocedures. Thenweinducemoregener-
as otherwise. Then, for these 1000 steps, we ob- alizableschemasbymatchingthemwithschema
tain linked goal predictions of our three models: instantiations(inourcase,thevideosthatdisplay
200
100
0
100
200
Figure4: ThefullversionofFigure3
the procedures). We evaluate the quality of the C ExperimentReproducibility
induced schemas by matching them with unseen
CandidateGoalRetrieval Thedetailedparam-
instantiations. The large-scale DARPA KAIROS
eter information of SP can be found in S5.1
project13adoptedasimilarsetup,whichwebelieve
in (Wieting et al., 2021). Encoding all steps and
indicatesitsgreatinteresttothecommunity.
goals in wikiHow took around two hours on a
In terms of the scale of the video retrieval
2080Ti (12GB) GPU. For SBERT, the encoding
dataset, though we only select 1000 goals from
tookaroundanhouronav100GPU(32GB).
23k goalsfromHowto1M,therearealready 150k
Reranking We used the transformers li-
videos in total while widely-used video datasets
brary