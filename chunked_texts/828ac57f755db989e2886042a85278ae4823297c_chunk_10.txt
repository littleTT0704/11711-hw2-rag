annotatedinfine-grainedclips.Inthesetasks,givenavideo quence modeling task [5] is as good as LSTM. Note that
clip, questions about the previous or next clip need to be we trained our model with LSTM as well, but it performs
answered. Note that for tasks of describing the past and worsethantheonewithGRU.WithGRU,wecanachieve
future, only the current clip is given and the model has to mAP of 24.9% on MEDTest 14 100Ex classification task,
reasontemporalstructuresbasedthegivenclip. Werestrict whilewecanonlyget20.4%withLSTM.Wesuspectthat
thepastandfuturetobenottoofarawayfromthecurrent itisbecauseLSTMwithmoreparametersismoreproneto
clipandtypicallywechoosethecliprightbeforeorafterthe overfitthanGRU.
givenone,wherethetimeintervalislessthan10seconds. Gated Recurrent Unit. Denote f1,f2,...,fN as the
i i i
Foreachtask,weintroducetwolevelsofquestions. For framesinavideov,whereN isthenumberofframessam-
i
simplicity,wedenoteourtasksasPast-Easy,Present-Easy, pledfromthevideo. Ateachstept,theencodergeneratesa
Future-Easy, Past-Hard, Present-Hard and Future-Hard. hiddenstateht,whichcanberegardedastherepresentation
i
We create three splits for each task and videos are divided of sequence f1,f2,...,ft. Thus the state of hN encodes
i i i i
intotraining,validationandtestingsets. thewholesequenceofframes. StatesinGRU[4]arecalcu-
4
latedas(droppingthevideosubscriptiforsimplicity): Unsupervised visual context learning
9'
rt =σ(W xt+W ht−1) (1)
xr hr
Reconstruct
zt =σ(W xt+W ht−1) (2) 8' future
xz hz
(Model III)
h¯t =tanh(W