 In [60],
Table1:Acomparisonofvideo-languagepretrainingmeth-
the authors further extract objects from the video clips.
odsregardingcontrastivelearningstrategies. “Earlystage”
In[31,14], theauthorsusecollaborativeexpertstoextract
and“Laterstage”meancomputingthelossbeforeandafter
featuresfromaudio,scene,OCR,face,speech,etc.
multi-modal fusion, respectively. “Cascade” means using
•Languagerepresentations.Thereareprimarilyfourvari-
cascadehardnegativesampling.
ants: 1)GoogleNewspretrainedword2vec(w2v)[36]used
in [31, 35, 34]; 2) LSTM or Bidirectional LSTM [19];
whereλ istheweightoftoken-levelloss(0.5bydefault). 3) pretrained BERT [10] used in [41, 60, 33, 14] and 4)
t
Duringinference, wemakethepredictionbysummingthe OpenAI-GPT[38]usedin[31].
alignmentscoresfromallthethreescoringfunctions. Inthispaper,weuseapretrainedBERT-basemodelfor
language representation as in [60, 33]. For video features,
following [35, 34, 33], we extract 2D CNN features using
4.Experimentalsetup
Resnet-152 (R-152) pretrained on ImageNet [9]. For 3D
CNN features, we use I3D (with Resnext-101 backbone)
4.1.Datasets
pretrainedonKinetics-400[23]andS3D[51]pretrainedon
Inourexperiments, wetrainandevaluateourmodelon Howto100M[34]. Theoff-the-shelfpretrainedweightsare
thefollowingestablishedbenchmarks: providedby[16]and[34]. Forsimplicity,wedenotethem
byI3D-X101andS3D-HMinthefollowing.
•YouCook2[58]consistsof2kvideosaboutroutinecook-
Another discrepancy among different methods is the
ing activities of 89 recipes. Each video contains multiple
