 for the main
Based on the description of each category, we
experimentandprovideananalysisontheeffects
manuallycomposetwoopposingvalues–onemak-
ofthesizeandtypesofLLMs.
ing the content sexist (value) and another mak-
ing the content non-sexist (counter-value). For
Generated Content Extraction & Processing instance, any Role Stereotyping contents will be
Thegeneratedcontentisgeneratedinsuccessionaf- considered to be sexist based on the value “Men
terthepromptasnaturaltext,andextractedthrough andwomenareequallycapableforanyrole,”but
patternmatching. Wegatherallextractedcontent can also be considered to be non-sexist with the
toconstructasynthetictrainingsetforteachingthe differentvalue“Menandwomenarebiologically
smaller models in the next step, and process the different; hence certain roles are more appropri-
generated data as follows. Firstly, we keep only ate for women.” A full list of values and counter
uniquesamplesbydroppingallduplicates. Then, values is available in Appendix A.1. In total, we
weremoveexactcopiesofthefew-shotexamples consider 19 categories of sexism and two corre-
usedintheprompts. Finally,anycontentlessthan sponding values (value, counter-value) for each
threewordsisfilteredoutasitislessinformative. category,translatedinto38(19×2)humanvalues.
Test set We use the original multi-label sexism construct VA-ALBERT, VA-ROBERTA and VA-
content (human-labeled, non-synthetic) for creat- BART,respectively. RoBERTahasbeenprovedto
ingatestsetforthevalue-alignedjudgementtask, berobustinvariousNLPtasksandBARTshows
excludingthatusedforprompt-constructioninthe comparable performance to RoBERTa on GLUE
training data generation. Originally, each item tasks.
of content is labelled with one/multiple sexism
5.2.2 Baselines
categories. For our task setup, we translate the
data into the form of triplet {content, value, la- To