Contrast
ğº
!
Encoder Projector Predictor â„!(ğ‘§ ")
Mini-Batch
ğº â€² ğ‘§ â€²
! ğ‘“ ğ‘” â„!
ğº!!!
!
ğº â„ (ğ‘§ )
"! $
ğº
"
ğº â€² EMA ğ‘§ â€²
" Update "
ğº # ğº ğ‘“!! ğ‘”!! â„ (ğ‘§ )
#! #
ğº â€² ğ‘§ â€²
# #
Figure1:OverviewofIGSD.Illustrationofourframeworkinthecasewhereweaugmentinputgraphsğº oncetogetğºâ€²for
onlyoneforwardpass.Blueandredarrowsdenotecontrastonpositiveandnegativepairsrespectively.
4.2 Self-supervisedLearningwithIGSD whichiscrucial[10]butunachievableinmostcontext-instance
InIGSD,tocontrasttheanchorğº withothergraphinstancesğº contrastivelearningmodelssincesubgraphsaregenerallyhard
ğ‘– ğ‘—
(i.e.negativesamples),weemploythefollowingself-supervised toassignlabelsto.Besides,withthislossweareabletofine-tune
InfoNCEobjective[37]: ourmodeleffectivelyusingself-trainingwherepseudo-labelsare
assignediterativelytounlabeleddata.
Lself-sup =âˆ’Eğºğ‘–âˆ¼Gï£® ï£¯ ï£¯
ï£¯ ï£¯
ï£¯log
exp(cid:16) âˆ’Lğ‘–c,o ğ‘–n(cid:17)
+ex (cid:205)p
ğ‘
ğ‘—(cid:16) =âˆ’
âˆ’
11L Iğ‘–c ğ‘–,o ğ‘– â‰ n ğ‘—(cid:17)
Â·exp(cid:16) âˆ’Lğ‘–c,o
ğ‘—n(cid: