othe
matte and the combined column includes the combination
trimap input. In addition to all these cases, our model and
ofanarbitrarybackgroundimageandtheextractedsubject
allothermodelsaresensitivetothebackgroundoftheinput
byusingthepredictedalphamatte.
imageaccordingtothefindingsofourdetailedexperiments.
It indicates that the alpha matte prediction performance of We also performed a user study and asked 30 different
themodelsforthesamesubjectcanconsiderablychangeac- participants to compare all results according to the quality
cordingtothebackgroundoftheinputimage.Theillumina- oftheimagestomeasurethemattingperformance.Weused
tionconditions, thecolordistribution, andtheexistenceof randomlyselectedsampleimagesfromallfourbenchmark
multiple subjects on the image affect the alpha matte pre- test sets. We present the results in Table 2. We have five
diction performance. For the PPM-100 dataset, since the differentlevelsofscorewhicharemuchbetter,better,same,
Score MODNet BGM-V2 FBA MGM Loss MSE
Muchbetter 41.55% 10.45% 4.23% 8.25% L +L 7.24
cGAN alpha
Better 29.22% 32.67% 16.61% 30.27% L +L +L 3.78
cGAN per alpha
Same 19.15% 39.86% 52.44% 41.02% L +L +L +L 1.76
cGAN per alpha border
Worse 8.11% 16.33% 22.47% 18.20% L +L +L +L +L 1.06
cGAN per alpha border ac
Muchworse 1.94% 0.69% 3.58% 2.26% α 3.14
α,F 1.06
Table 2. User study using all three benchmarks. We compared
our model with MODNet [24], BGM-V2 [29], FBA [13], and Table 3. Ablation study for the loss functions. We repeated the
MGM[51].Thescoresdemonstratehowmuchourresultisbetter trainingofthealphamattegenerationnetworkusingacombina-
orworsethantheotherresults. tionofdifferentlossfunctionsandwepresentM