whenaddingzero,one,oralltestcasesinprompts.
Coding Queries vs. Programming Challenges
Some works stem from coding contest web-
NumberofTestCasesintheDocstring Includ-
sites(Hendrycksetal.,2021;Lietal.,2022),but
ingtestcasesininputsaddsexecutionhintsofthe
GitHub Jupyter Notebooks (Agashe et al., 2019;
expected functionality of the solution, and hence
Huangetal.,2022)andStackOverflow(SO)(Yin
mayimproveexecutionaccuracy. Wetestthishy-
etal.,2018;Wangetal.,2022;Laietal.,2022)pro-
pothesisbyexperimentingwithpromptsthathave
videmorenaturalandpracticalcodingqueries. We
varyingnumbersoftestcases. Besidesthedefault
preserve this naturalness and incorporate various
setting with zero tests, we compare adding one
NLsettingstoassistprogrammersworldwide.
randomtestcaseandallannotatedtestcases.
Figure11(right)showsthatinjectingasfewas
Execution-basedEvaluation Evaluationbyex-
oneexemplartestcasesignificantlyimprovesthe
ecutionhaslongbeenusedforSQL(Zhongetal.,
executionaccuracy,yetaddingmorecaseshaslittle
2017) or logical forms (Dong and Lapata, 2016).
bonus. Thispotentiallyimpliesthesufficiencyof
Many datasets have begun to support Python ex-
onetestcasetoshowthemainfunctionality.
ecution via test cases, however focus on built-in
functions (Chen et al., 2021; Austin et al., 2021;
Number of Evaluation Test Cases Execution
Hendrycks et al., 2021) or specific domains (Lai
results could be more reliable if using more test
etal.,2022;Huangetal.,2022). Ourtestcases,in
casesforevaluation. However,thereisatrade-off
contrast,coverdiverselibrariesintheopendomain.
between evaluation effectiveness and annotation
efficiency,duetothehighcostofhumaneffort. To
9 Conclusion
studythistradeoff,weobserve