atmorethan16words.
A.3.Moviescovered
Anadditionalinformativestatisticisthecountsofunique
Our dataset also covers a broad range of movies - over
answersandrationalesinthedataset,whichweplotinFig-
2000inall,mostlyviaMovieClips(Figure9). Wenotethat
ure 7. As shown, almost every answer and rationale is
sincewesplitthedatasetbymovie, thevalidationandtest
unique.
setscoveracompletelydisjointsetofmovies,whichforces
amodeltogeneralize. Foreachmovieimage,workersask
A.2.Objectscovered
2.6questionsonaverage(Figure10),thoughtheexactnum-
On average, there are roughly two objects mentioned bervaries-bydesign,workersaskmorequestionsformore
over a question, answer, and rationale. Most of these ob- interestingimages.
jects are people (Figure 8), though other types of COCO
A.4.Inferencetypes
objectsarecommontoo[49]. Objectssuchas‘chair,’‘tie,’
and‘cup’areoftendetected,however,theseobjectsvaryin It is challenging to accurately categorize commonsense
terms of scene importance: even though more ties exist in and cognition-level phenomena in the dataset. One ap-
thedatathancars,workersrefertocarsmoreintheirques- proachthatwepresentedinFigure2istocategorizeques-
tions, answers, and rationales. Some objects, such as hair tions by type: to estimate this over the entire training set,
driersandsnowboards,arerarelydetected. weusedaseveralpatterns,whichweshowinTable4. Still,
9
FDC
selpmaxE
person
Type Freq. Patterns chair
tie
cup
Explanation 38% why,howcome,howdoes bottle
book
Activity 24% doing,looking,event,playing,preparing car
diningtable
Temporal 13% happened,before,after,earlier,later,next wineglass
pottedplant
Mental 8% feeling,thinking,saying,love,upset,ang