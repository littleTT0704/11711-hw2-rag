.
tionanda3Drepresentationoftheworldasinput,andout-
Laterinthesametask,theagentwillbeaskedtorotatea puts where the chosen block should be moved. The model
blockandplaceitbetweenthetwostacks.Wepresenthere canbebrokendownintothreeprimarycomponents:
just a few excerpts wherein the same action is described in 1. LanguageEncodingforBlockandOperationprediction
fivedifferentways.
2. Applyingaspatialoperation
t7 t8
3. Predictingacoordinateinspace.
Our overall model architecture is shown in Figure 3. By
keeping the model modular we can both control the bottle-
necksthatlearningmustuseforrepresentationandprovide
ourselves post hoc access to interpretable scene and action
representations(exploredfurtherininterpretabilitysection).
1 RotateSRItotheright... Withoutthese,themodelallowssentencesandoperationsto
2 rotateit45degreesclockwise...
berepresentedbyarbitraryN-dimensionalvectors.
3 onlyhalfofonerotationsoitscornerspoint
whereitsedgesdid...
4 thelogofacesthetoprightcornerofthescreen... LanguageEncoder
5 SpinSRIslightlytotherightandthensetit
Asiscommon,weusebidirectionalLSTMs(Hochreiterand
inthemiddleofthe4stacks
Schmidhuber 1997; Schuster and Paliwal 1997) to encode
Tocompletetheseinstructionsrequiresunderstandingan- the input sentence. We use two LSTMs: one for predicting
gles, a new set of verbs (rotate, spin,...), and references blocks to attend to, one for choosing the operations to ap-
totheblock’spreviousorientation.Thefinalexample,indi- ply.BothLSTMsshareavocabularyembeddingmatrix,but
catesthataspinisnecessary,butassumesthegoalofhaving have no other means of communication. We experimented
5031
with using a single LSTM as well as conditioning one on Giventheaforementionedargumentattentionmap(tensor
theother,butfounditdegradedperformance. AofsizeB×D×H ×W ×1,