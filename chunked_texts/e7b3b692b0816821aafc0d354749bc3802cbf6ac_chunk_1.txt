PublishedasaconferencepaperatICLR2023
COMPUTATIONAL LANGUAGE ACQUISITION WITH
THEORY OF MIND
AndyLiu HaoZhu,EmmyLiu,YonatanBisk,GrahamNeubig
HarveyMuddCollege LanguageTechnologiesInstitute
Claremont,CA,USA CarnegieMellonUniversity
{ajliu}@g.hmc.edu Pittsburgh,PA,USA
{zhuhao, mengyan3, ybisk, gneubig}@cs.}cmu.edu
ABSTRACT
Unlike current state-of-the-art language models, young children actively acquire
languagethroughinteractionswiththeirsurroundingenvironmentandcaretakers.
Onemechanismthathasbeenarguedtobecriticaltolanguagelearningistheabil-
itytoinferthementalstatesofotheragentsinsocialenvironments,coinedTheory
of Mind (ToM) by Premack & Woodruff (1978). Drawing inspiration from the
modernoperationalizedversionsofToMimplementedinRabinowitzetal.(2018)
andZhuetal.(2021),webuildlanguage-learningagentsequippedwithToM,and
measureitseffectsonthelearningprocess. WemodelToMbygivingthespeaker
agent an internal listener model that is trained alongside the speaker and used
to rerank potential utterances. We experiment with varying task difficulty, hy-
pothesizingthatmodelswillacquiremorecomplexlanguagetoadapttostronger
environmental pressures. We find that training speakers with a highly weighted
ToMlistenercomponentleadstoperformancegainsinourimagereferentialgame
setting. Wealsofindsomeevidencethatincreasingtaskdifficultyinthetraining
processresultsinmorefluentandpreciseutterancesinevaluation. Thissuggests
the potential utility of further incorporating ToM, as well as other insights from
childlanguageacquisition,intocomputationalmodelsoflanguageacquisition1.
1 INTRODUCTION
Humanlanguagesarefundamentallyshapedbysocial-communicativegoalsinthegroundedworld.
Moderntheoriesfromdevelopmentalpsychologyoftenattributehumansâ€™uniqueabilitytoquickly
acquireandadaptlanguagetotheirabilityto