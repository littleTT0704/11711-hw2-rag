tracking.
dreas et al. (2017) explored associating each task de-
scription to a modular sub-policy. Later works extend
2. Related Work theaboveapproachbyusingasingleconditionalpolicy
(Mei et al., 2016), or by matching sub-tasks to tem-
Language Conditioned Policies A considerable
plates(Ohetal.,2017). Recentworkshaveshownthat
portion of prior work studies imitation learning (Tellex
LLMs are proficient high-level planners (Huang et al.,
et al., 2011; Mei et al., 2016; Nair et al., 2022; Stepput-
2022a; Ahn et al., 2022; Lin et al., 2022), and therefore
tis et al., 2020; Jang et al., 2022; Shridhar et al., 2022;
motivatesustorevisittheideaofhierarchicaltaskplan-
Plan, Eliminate, and Track
ning with progress tracking. To our knowledge, PET
is the first work combining a zero-shot subtask-level
LLM planner and zero-shot LLM progress tracker with
a low-level conditional sub-task policy.
TextGames Text-basedgamesarecomplex,interac-
tive simulations where the game state and action space
are in natural lanugage. They are fertile ground for
language-focused machine learning research. In addi-
tiontolanguageunderstanding,successfulplayrequires
skills like memory and planning, exploration (trial and
error), and common sense. The AlfWorld (Shridhar
et al., 2020b) simulator extends a common text-based
game simulator, TextWorld Cˆot´e et al. (2018a), to
create text-based analogs of each ALFRED scene.
Figure 2. Plan Module (Sub-task Generation). 5 full exam-
ples are chosen from the training set based on RoBERTa
Agents for Large Action Space He et al. (2015)
embeddingsimilaritywiththetaskquerydescription. Then
learns representation for state and actions with two
the examples are concatenated with the task query to get
different models and computes the Q function as the the prompt. Finally, we prompt the LLM to generate the
inner product of the representations. While this could desired sub-tasks.
generalize