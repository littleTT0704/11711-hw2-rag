) 1+c(cid:112) β¯ (1 λ∗)(∆+2L) γT 1+cβ¯
gen ≤ stab (β¯,ρ)1 − N(cid:48)
(cid:47) (cid:0) ∆)1+cλ1
∗β∗(cid:18) γT(cid:19)1− cλ∗β1
∗+1 ThisisEquation1fromSection4
N(cid:48)
(13)
Ingoingfromthefirstlinetothesecondweconsiderthesettingwhere∆ 2L. Thisisacasewhere
(cid:29)
theauxiliarytaskissufficientlydifferentfromtheprimarytask. Someobservationsaboutthissetting:
1. Smaller∆impliesauxiliarytaskissimilartomaintaskandleadstoimprovingthebound.
2. DependenceoftheboundonN(cid:48)isabitmorenuanced. NotethatincreasingN(cid:48)increases
γ unlesswereduceλ appropriately. Rememberthatλ istherateatwhichwesample
e e
theprimarytask. Thus,ifweaddmoreauxiliarydatabutstillsampletheprimarytaskatthe
originalrate,thenweareeffectivelyignoringtheextraauxiliarydata.
3. Itmightbetemptingtoassumethatwecangetarbitraryimprovementsinthissettingby
settingλ =0. However,notethatwhilstthismightreducethegeneralizationerror,it
e
meansthatweareseeingnoneoftheend-taskwhichwouldresultinlargeincreaseinthe
trainingerror
4. Note that (β¯ = λ∗β∗ β ) always. So we get improvements on the dependence on T
e
≤
comparedtoTheoremE.2.
5. Wecanoptimizeλ,λ tominimize(cid:15)auxdyn.
e a stab
22
