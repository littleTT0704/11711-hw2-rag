 with Canary, we observe it is on 0%
Coherency Engaged Respect Prosociality Overall
parwithInstructGPT-3onoverallandevenbetter
onprosociality. AlthoughInstructGPT-3hasun- Figure5: Resultsofhead-to-headcomparisonbetween
dergonemuchmoreadditionaltrainingthanGPT-3 modelswithandwithoutCanaryon PROSOCIALDIA-
(Ouyangetal.,2022),Canarycaneffectivelyclose
LOGviahumanjudgements(ยง6.2).
thegapbetweenthetwomodels.
7 RelatedWork
70%
Instruct GPT-3 Tie GPT-3
60%
Most existing dialogue safety work has focused
50%
ondetectingproblematiccontexts,oftenusingbi-
40%
naryorternarylabels(e.g.,Dinanetal.,2019;Xu 30%
et al., 2020). Baheti et al. (2021) develop classi- 20%
fierstodetectwhenanagentagreeswithtoxiccon- 10%
tent. Dinanetal.(2022)createasuiteofclassifiers 0%
Coherency Engaged Respect Prosociality Overall
to assess safety concerns. Sun et al. (2022) col-
70%
lectfine-grainedcontextandutterance-levelsafety Instruct GPT-3 Tie GPT-3 + Canary
60%
labels. Other works leverage these safety labels
50%
to make conversational agents generate better re-
40%
sponses (Madotto et al., 2021; Thoppilan et al., 30%
2022;Perezetal.,2022). 20%
More recently, several works have introduced 10%
0%
strategies to respond to problematic context with
Coherency Engaged Respect Prosociality Overall
cannednon-sequitars(Xuetal.,2021),controlfor
Figure 6: Results of head-to-head comparisons be-
steering away from toxicity (Baheti et al., 2021),
tween Instruct GPT-3 vs. GPT-3 and Instruct GPT-3
and apologies (Ung et al., 2021). In contrast, we
vs. GPT-3 with