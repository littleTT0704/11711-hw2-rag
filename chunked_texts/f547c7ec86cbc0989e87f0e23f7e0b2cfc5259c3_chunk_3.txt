ConferenceonSpokenLanguageTranslation(IWSLT2023),pages389–396
July13-14,2023 c2023AssociationforComputationalLinguistics
(cid:13)
fedintothemodel. Astranslationqualitytendsto with the <eos> token, the algorithm allows gen-
diminishtowardtheendoftheunfinishedsource, erating a hypothesis with a score lower than the
anonlinepolicyisemployedtocontrolthelatency- unreliablescoreifitwasseenduringthedecoding
quality tradeoff in the generated output. Popular ofpreviousblocks.
online policies include wait-k (Ma et al., 2019), Finally, the algorithm removes two instead of
shared prefix (Nguyen et al., 2020), hold-n and one token in the current beam (see Line 20). Re-
local agreement (Liu et al., 2020). In Polák et al. moving thelasttwotokensmitigates theissue of
(2022),weshowedthatthetradeoffcouldbecon- low-qualitytranslationtowardtheendofthecon-
trolledbyvaryingthechunklength. text.1
To generate the translation, a standard beam
searchistypicallyapplied(Sutskeveretal.,2014). 2.2 RethinkingOnlinePoliciesfor
Whilethisdecodingalgorithmenablesthemodel Attention-basedSTModels
to generate a complete translation for the current
Whiletheimprovedincrementalblockwisebeam
input,italsosuffersfromovergeneration(i.e.,hallu-
searchimprovestheperformance,itstillrequiresa
cinatingtokensbeyondsoundspresentintheinput
strongonlinepolicysuchashold-norlocalagree-
segment)andlow-qualitytranslationstowardsthe
ment (Liu et al., 2020). A common property of
endofthesourcecontext(Dongetal.,2020;Polák
these online policies is that they require multiple
etal.,2022).
re-generations of the output translation. For ex-
To tackle this issue, we adopt an improved in-
ample, the local agreement policy must generate
cremental blockwise beam search (Polák et al.,
eachtoken