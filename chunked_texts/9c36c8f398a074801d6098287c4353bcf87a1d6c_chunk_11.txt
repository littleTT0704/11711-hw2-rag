Sexist’}
asthebackbonemodelsforafaircomparisonwith
and {content, counter-value, ‘Non-Sexist’}. So,
our VA-MODELs.
eachcontentitemhasaduplicatebutispairedwith
differentvaluesandvalue-alignedjudgements. To Nlpaug-Models Nlpaug(Ma,2019)issemantic
preventthemodelfromonlylearningtwovalueand augmentationmethodusingBERT-baseembedding.
labelassociations,wesyntheticallymaketheclass We conduct augmentation with prompt construc-
‘NA’byassigningirrelevantvalues/counter-values tion examples by insertion and substitution. For
tothecontent(e.g.,assigningthevalueofPayGap each examples, we make 10 augmented samples
to a content of Role Stereotyping so the label is (five insertions and five substitutions). Then, we
‘NA’).Intotal,thereare10,722samples,including fine-tunethebaseversionsofALBERT,BARTand
the prompt construction samples. We split them RoBERTaonthesemanticallyaugmenteddataand
intotrainingandvalidationsetswitharatioof4:1. prompt-constructionexamplessowecanevaluate
theeffectivenessoftheprompt-basedaugmentation
Building VA-MODELs We finetune smaller
inourmethod.
modelswiththegeneratedvalue-alignedtraining
data. We build VA-MODELs to incorporate ex- 5.3 Experimentalsetup
plicithumanvaluestomakejudgementsforvalue-
Evaluationmetric Weevaluateourexperiments
alignedsexismclassificationfollowingSection4.2.
with both F1 score and accuracy. For the main
For the smaller models, we take base versions
results,wereportallaccuracy,weightedF1-score
of ALBERT (12M params.) (Lan et al., 2019),
(W-F1),precisionandrecall.
RoBERTa (125M params.) (Liu et al., 2019) and
BART (110M params.) (Lewis et al., 2019) to 2Weuseprompt-basedfew-shotlearningwithOPT-175