it(§5.2).
etal.,2020). Forrule-of-thumb(RoT)generation,
wecompareCanarywithfourfine-tunedmodels:
GPT-2,NormTransformer(Forbesetal.,2020),Di- Model
Prosocial Engaged Respectful Coherent Overall
aloGPT(Zhangetal.,2020),andT5-large. Were-
Prost(Responseonly) 12.9 12.7 10.9 12.7 21.9
portBLEU-4andF1scoresofmodeloutputs,and Tie 69.8 70.7 79.3 71.6 48.3
Prost(RoT&Response) 17.1 16.4 9.7 15.6 29.6
also the perplexity of gold RoTs for each model.
GPT-3 9.3 12.7 11.0 3.1 10.7
FurtherdetailsareinAppendixC.1andC.2.
Tie 27.3 37.2 65.4 54.4 14.1
Results. Table2showsthesafetyclassification Prost(RoT&Response) 63.4 50.1 23.7 42.5 75.2
accuracyandRoTgenerationresultsofbaselines InstructGPT-3 11.9 21.3 12.2 6.9 20.2
Tie 36.2 36.5 69.1 65.2 20.7
and the three variants of Canary (§4.1). Canary Prost(RoT&Response) 51.9 42.3 18.8 27.9 59.1
(i.e., T5 with additional social norm knowledge)
Table 4: Results of head-to-head human evaluation
generally performs better than the vanilla T5 di-
between dialogue agents on response generation for
rectly trained on our dataset. The Delphi-based
PROSOCIALDIALOG(inpercentages;§5.2).
Canaryoutperformsallmodels. Thisshows that
Delphi’sknowledgeoncommonpatternsofhuman
moralsenseforshortsnippetsisusefulfordown-
Evaluation metrics. We conduct both auto-
stream tasks of determining problematic content
matic and human evaluations for measuring the
andgeneratingRoT