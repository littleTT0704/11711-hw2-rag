-32 ViT-S-P2-32
w/o Pretrain w/o Pretrain
0.2 ViT-S-P2-32 0.2 ViT-S-P2-32
0.0 0.0
0k 25k 50k 75k 100k 0k 25k 50k 75k 100k
Iter. Iter.
(a)Testaccuracy. (b)Pseudo-labelaccuracy.
Figure2: Pre-trainingablationonCIFAR-400with400labels. Testandpseudo-labelaccuracyare
comparedwithWRN-28-8withoutpre-training,pre-trainedWRN-28-8,pre-trainedViT-S-P16-224,
ViT-S-P2-32withoutpre-training,andpre-trainedViT-S-P2-32.
Table8: FinalranksofSSLalgorithms. NotethattherankforCVtaskshereisdifferentfromthe
onesinTable5becauseweignoreMixMatchandReMixMatchheretoremovetheeffectsoftheir
missingranksinNLPandAudio.
Π-Model Pseudo-Labeling MeanTeacher VAT UDA FixMatch Dash CoMatch CRMatch FlexMatch AdaMatch SimMatch
CV 10 9 12 11 6 5 8 7 1 4 2 3
NLP 12 11 10 8 9 7 6 3 2 5 4 1
Audio 12 10 11 9 7 3 8 6 5 4 1 2
Rankmax−Rankmin 2 2 2 3 3 4 2 4 4 1 3 2
Table9: ThistableshowshowmanytimesanSSLalgorithmisworsethansupervisedtraining,where
thenumbersoftotalsettingsare9,10,and9forCV,NLP,andAudiorespectively.
Π-Model Pseudo-Labeling MeanTeacher VAT MixMatch ReMixMatch UDA FixMatch Dash CoMatch CRMatch FlexMatch AdaMatch SimMatch
CV 2 1 3 1 4 0 0 0 0 2 0 0 0 0
NLP 9 7 5 3 - - 2 1 1 0 0 1 0 0
Audio 7 5 6 4 - - 0 0 1 2 0 0 0 0
usingViTwithoutpre-trainingperformstheworstamongdifferentbackbones. Thereasoncanbe
thatViTisdatahungry