- MOdelthatcanconverseinawiderangeofsocial
sentedinTable4. SODA exhibitsamorebalanced situations. COSMOcantakeinsituationnarrative,
distributionofemotionswhilemaintainingsimilar along with dialogue history, and generate a next
rankingswithotherhuman-authoreddialogues. utteranceaccordingtoagivenrole.
Cost & Time-Efficient Compared to dialogue Training COSMO We use several structured
crowdsourcing, collecting SODA via our contex- components of SODA during training: (1) the
tualization framework is significantly more time contextual narrative n (§2.3), (2) the perspec-
andcostefficient. WithGPT-3.5text-davinci-002, tive/speaker instruction i (e.g., “Imagine you are
to go from a commonsense triple to a dialogue Madeleineandspeaktohercoach”)builtwiththe
costsabout$0.02,and10queriestakelessthan2 inferred conversation participants (§2.4), and (3)
minutes,countingourfullfiltrationpipeline. the dialogue context c. The model is trained to
generateatargetresponser whengivenn,i,and
3.3 DoWeNeedContextualization?
c – i.e., p(r|n,i,c). We do so in a sequence-to-
To isolate the effect of contextualization (vs. sequencefashion,concatenatingn,i,cwithasep-
straightforward sampling from a large language arator<SEP>toserveasinput. cismadeupofthe
model),wecompareSODAwithdialoguesnaively previousconversationutterancesconcatenatedwith
sampledfromGPT-3.5withoutanygivencontext. aturnindicator<TURN>.
Wesample100dialoguesusingthesamehyperpa- Because conversational models often agree to
rametersandthebasicfilteringstepsin CO,but toxic or unethical behavior (Baheti et al., 2021),
3
with the following prompt: “The following is foradditionaltrainingdata,weincludeProsocial-
a long in-depth conversation between two Dialog (Kim et al.,