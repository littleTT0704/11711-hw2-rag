aswanietal.,
asencodinginformationsharedbythetranslation 2017)encoder-decodermodel,wherethesentence
pairinthesharedvariableresultsinonlyasingle embeddingsareusedintwoplaces: ateachlayer
penaltyfromtheKLloss,whileencodingtheinfor- ofthedecoderinplaceofcross-attentionandinthe
mationseparatelyinthelanguage-specificvariables computationofthelogits.
Inference Networks
Li Inference Net
q E(z nl ci.| Ex mi; bϕ s.) SL pan
.
g Lu aa yg ee rμ s- li,Σlj Latent Space Generative Model
KL between prior and approximate
Lan eg mu ba eg de
d
e in nc go sder
Merging
posteriors
Language decoder
p(x li|z sem,z li;θ)
X i Semantic Inference Net operation Semantic 𝒩(μli,Σli) embeddings concat Decoder X li
Input q(z sem|x li,x lj;ϕ) μsem,Σsem E zn sc eod ming
translation pair Concatenate
f ao fnr r d ola mln j sg pau oma og lp e oles fd l i Enc. Embs. S Lem aya en rt sic merge latens t d a v em e ccp otl doe erd s and tR rae nc oo slfn a s i tnt ir opu nuc tt p i ao in r
translations pairs 𝒩(μsem,Σsem)
concat Decoder
X j
q(z lj|x
lj;Lj
ϕ
In )ference Ne μt
li,Σlj
𝒩(μlj,Σlj)
p(x lj|z sem,z lj;θ)
X lj
Language-
Enc. Embs. Sp. Layers
Figure2: ThecomputationgraphforthevariationallowerboundusedtotrainVMSST.Thetextforlanguagesl
i
andl,withtheirrespectivelanguage