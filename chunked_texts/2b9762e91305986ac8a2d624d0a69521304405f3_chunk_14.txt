atedtrainingdataofalllanguages(includingthe
definedattributesandperformanceisbrokendown originalEnglishdata)jointly.
overdifferentattributevalues. Wedefinenewtask- Humanperformance Weusethehumanperfor-
specificattributesforthefourtasktypesaswellas mance estimates from XTREME for the retained
task-independentattributes(seeAppendixK). tasks. For XCOPA we average the proportion of
Metadata We additionally would like to enable annotatedlabelsdisagreeingwiththemajorityla-
practitioners to rank submissions based on other belacrossalllanguages(Pontietal.,2020). Weare
information. Tothisend,weaskeachsubmission not able to obtain human performance estimates
to XTREME-R for relevant metadata such as the for the new retrieval tasks as identifying a trans-
numberofparameters,theamountofpre-training lationamongalargenumberofcandidatesistoo
data, etc. We will show this information in an time-consumingforahumantoperform.
interactive leaderboard (see Appendix H for the
metadataofcurrentXTREMEsubmissions). 4.2 Results
We show the main results in Table 4. As in
4 Experiments
priorwork,XLM-RLargegenerallyoutperforms
mBERT.Fine-tuninghelpssignificantlyonTatoeba
Training and evaluation setup XTREME-R fo-
cusesonzero-shotcross-lingualtransferfromEn- 5WeareunabletoproducetranslationsforQuechua.
Classification Structuredprediction Questionanswering Lang.-agnosticretrieval Retrieval
Model Avg
XNLI XCOPA UD-POS WikiANN-NER XQuAD MLQA TyDiQA-GoldP Mewsli-X LAReQA Tatoeba
Metrics Acc. Acc. F1 F1 F1/EM F1/EM F1/EM mAP@20 mAP@20 Acc.
Cross-lingualzero-shottransfer(modelsaretrainedonEnglishdata)
mBERT 54.1 66.5 56.1 70.9 62.7 65.1/50.4 61.3/44.1 58.4/43.7 38.6 21.6 43.