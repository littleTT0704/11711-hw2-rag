constituteonlyasmallsubsetofperturbationsthathumanvisionisinvariantto,therefore
weevaluatetheR-Bluronsomeothercommontypesofimagecorruptionsthathumansarelargely
invarianttobutDNNsarenot. Atthispoint,wealsoincludetheadversariallytrainedResNet(AT)in
theevaluationtomeasurehowwelltherobustnessendowedbyadversarialtraininggeneralizesto
other,non-adversarial,corruptions,andcompareitwithbiologicallymotivatedmethods. Wesampled
2images/classfromImagenetand5images/classfromEcoset. Thenweappliedthe17ofthe193
common(non-adversarial)corruptionsproposedin[HendrycksandDietterich,2019]at5different
severity levels to generate 85 corrupted versions of each image leading to corrupted versions of
ImagenetandEcosetcontaining170Kand240Kimages,respectively.
Table1showstheaccuracyachievedbythemodelsonEcosetandImagenetunderadversarialand
non-adversarialperturbations. Asexpected,AT achievedthehighestaccuracyonwhiteboxattacks
byvirtueofbeingtrainedondataperturbedwithattacksverysimilartoAPGD.AfterAT,themost
adversarially robust model is R-Blur, followed by VOneBlock. We see that R-Blur is the most
accuratemodelonnon-adversarialcommoncorruptions,followedbyVOneBlock,whichsupportsour
hypothesisthattherobustnessofbiologicallymotivatedmethodsingeneral,andR-Blurinparticular,
ishighlygeneralizable. Incontrast,theaccuracyofAT oncommoncorruptionsisalmostthesameas
thatoftheunmodifiedResNet,indicatingthattherobustnessofAT doesnotgeneralizewell.
3.3 AblationStudy
Having established that R-Blur indeed improves the robustness of image recognition model, we
examine, by way of ablation, how much each component of R-Blur contributes towards this im-
provementasshowninFigure8. Themostsignificantcontributort