 reinforce-
by giving multiple examples, and then a final in- mentlearning(RL)fromacandidatepool.
putexample,wherethemodelisexpectedtopre-
5.2 High-qualityReasoningChains
dicttheoutput. However,suchstandardfew-shot
promptings,inwhichtheLLMisgivenin-context Earlychainofthoughtwork(e.g.,Weietal.(2022))
examplesofinputâ€“outputpairsinfrontoftest-time mainlyreliesonasinglehuman-annotatedreason-
examples,havenotyetprovedsufficienttoachieve ingchainasaprompt. However,manuallycreating
high performance on challenging tasks such as reasoningchainshastwodisadvantages. First,as
mathematicalreasoning(Raeetal.,2021). tasksbecomemorecomplex,currentmodelsmay
Chain-of-thoughtprompting(CoT)(Weietal., notbesufficienttolearntoperformallnecessary
2022)leveragesintermediatenaturallanguagera- reasoningstepsandcannoteasilygeneralizetodif-
tionalesaspromptstoenableLLMstofirstgenerate ferent tasks. Second, a single decoding process
reasoning chains and then predict an answer for isvulnerabletoincorrectinferencesteps,leading
aninputquestion. Forexample,aCoTpromptfor to an incorrect prediction as the final answer. To
solvingthemathwordproblemcouldbe address this limitation, recent studies mainly fo-
Engine ICL Rationale Rationale
Models Postmethod
(bestperformed) source type source
Few-shot-CoT(Weietal.,2022) PaLM(540B) Random Language Hand-crafted -
Self-Consistency-CoT(Wangetal.,2023) Codex(175B) Random Language Hand-crafted Self-consistency
Least-to-mostCoT(Zhouetal.,2023) Codex(175B) Random Language Hand-crafted -
PromptPG-CoT(Luetal.,2022b) GPT-3(175B) RL Language Hand-crafted -
Retrieval-CoT(Zhangetal.,2023) GPT-3(175B) Retrival Language Auto-generated -
Auto-CoT(