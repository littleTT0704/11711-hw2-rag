T intheteacherblockbeforeconducting
GroundTruth Element-wise Multiplication R Reshape t t=1
themultimodalinteraction.Similartostudentblock,thefinal
CC F z z outputofteacherblockisdenotedas{f ttch}T t=1.Notethat
the teacher block does not share weights with the student
Visual Feature ğ‘“!"% #$ Visual Featureğ¹ blockandthegradientofteacherblockistruncatedtoavoid
Multimodal z influencingtheencoder.
Attention z R
Sem Embed. ğ‘”&â€™( ğ¹&â€™(
Multimodal z
ğœ‘!â†¦# S (Ttu ed ace hn et rF Fea et au tr ue reğ‘“! ğ‘“&!!!, +-"% # "% #$ $) WEn ec uo sd ee sr
eparateencoderstoextractvisualandacousticfea-
Attention z
Loc. Embed. ğ‘”)*+ ğ¹)*+ tures.
Figure4:IllustrationofACFblockusedinthe(label-guided)
multimodalfusionprocess.Studentblock:Thevisualfea-
ture{f }T isfirstflattenedandaddedwithpositionalen-
t t=1
coding then conducts multimodal attention with acoustic F Transformer
semanticembeddinggsem andlocationembeddinggloc re- P
spectively.Afterthat,weformapixel-wiseweightingfrom Frame ğ¼! Visual Featureğ‘“!"
Backbone
fusedfeatureFloctomodulateFsem.Theoutputofstudent
Addition F Flatten P Positional Encoding
block is denoted as {fstu}T. Teacher block: Different
t t=1
fromstudentblock,weconcatenateground-truthmaskwith Figure5:Single-framevisualfeatureextraction.TheER
the visual feature {f t}T t=1 to help the network learn better frame I t is first processed by a backbone and then the ex-
representationinthemultimodalfusion.Sinceteacherblock tracted features are fed to a transformer to capture spatial
