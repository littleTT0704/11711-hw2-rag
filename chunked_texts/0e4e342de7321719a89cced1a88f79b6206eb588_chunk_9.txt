}wherew i ∈ kens and textual tokens r qv ⊕r v ⊕r q. In the self-attention
RCin×Cout×N×N,andeachcandidatekernelrepresentsapar-
layers of the transformer encoders, the regression token r
qv
ticularsetoffeaturestobeextracted.Astextquerieswithdif- can learn from all the textual and visual tokens as well as
ferentsemanticmeaningsmayrequiredifferentcombinations therelationshipsbetweenthem. Therefore,itscorresponding
ofthesesetsoffeatures,thecandidatekernelsareaggregated outputafterinteractionf representstheglobalinformation
qv
according to an attention weight α = [α 1,...,α K] ∈ RK×1 encodedinthequery-imagepair. f
qv
islaterpassedintothe
computedfromthequerytokenf query. Theattentionweight predictionheadasthegroundingrepresentation.
α is calculated by projecting f query into a K-dimensional To showthe power of ourquery-conditioned convolution,
vectorusinganon-linearprojectionandasoftmaxlayer: weremovetheoptionalfusionmoduleintheVGQCpipeline
as shown in Figure 2(b). After deriving the query-aware
α=Softmax(ϕ (f )) (1)
Cq(cid:55)→K query visual features f(cid:48) from the backbone, a regression token
v
aw gh ge rr ee gϕ atC eq d(cid:55)→ cK on( v·) oi ls uta ion non k- eli rn ne ea lr Wtran ∈sfo Rrm Ca inti ×o Cn of uu tn ×c Nti ×on N.T ishe
a
r siq tv io∈ nalR eC nv c× o1 dii ns ga Ppp be en fd oe rd ei bn eif nro gn pt ao sf seϕ dC iv n(cid:48)(cid:55)→ toC tv h( ef tv(cid:48) r) anw sfit oh rmpo er-
encoders.