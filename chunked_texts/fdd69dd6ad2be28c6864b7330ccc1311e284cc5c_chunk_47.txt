1.37 38.74±0.60
MeanTeacher 35.85±1.95 19.62±3.28 33.37±0.06
VAT 40.63±2.68 29.94±1.87 35.84±0.36
UDA 18.15±5.70 12.09±1.26 29.28±0.20
FixMatch 17.19±3.46 12.57±1.28 28.88±0.22
Dash 18.04±1.21 12.98±1.27 28.69±0.39
CoMatch 13.65±1.42 10.17±0.68 37.71±0.31
CRMatch 30.28±1.64 22.39±1.41 29.22±0.21
FlexMatch 10.46±1.20 9.06±1.80 30.19±0.51
SimMatch 11.19±1.01 10.65±1.64 28.55±0.13
D ResultswithDifferentPre-trainedBackbones
Inthissection,weverifyUSBwithdifferentpre-trainedbackbones. Differentpre-trainedbackbones
doaffecttheperformanceofSSLalgorithms,whichmakesitimportanttoreportresultswithmultiple
backbones. Wewillcontinuouslyupdateresultswithdifferentbackbonesathttps://github.com/
microsoft/Semi-supervised-learning. HerewereportseveralresultsinTable12,Table13,
and Table 14. Across the tasks, there is a pretty clear distinction between the performance of
algorithmsinthefirsthalfoftherankinglistandthesecondhalfoftherankinglist. Whileswitching
outbackbonesdoesnotchangethemembershipofthesetwohalves,itdoesseemliketherelative
orderingswithinthetophalfcanindeedvaryabit.
To compare different backbones on CV tasks, we fine-tune pre-trained public Swin-Transformer
[123] with USB. We keep all hyper-parameters the same as in Table 15, and mainly evaluate on
EuroSAT(32)andSemi-Aves(224). ForEuroSAT,wechangetheinputimagesizeofthepre-trained
Swin-Sfrom224to