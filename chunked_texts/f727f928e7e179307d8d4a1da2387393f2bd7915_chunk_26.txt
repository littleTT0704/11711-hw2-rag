CNLP),
judgement. HAL. pages2463–2473,HongKong,China.Association
forComputationalLinguistics.
Benjamin Heinzerling and Kentaro Inui. 2021. Lan-
guagemodelsasknowledgebases: Onentityrepre- AdamRoberts,ColinRaffel,andNoamShazeer.2020.
sentations,storagecapacity,andparaphrasedqueries. Howmuchknowledgecanyoupackintotheparam-
InProceedingsofthe16thConferenceoftheEuro- eters of a language model? In Proceedings of the
peanChapteroftheAssociationforComputational 2020ConferenceonEmpiricalMethodsinNatural
Linguistics: MainVolume,pages1772–1791,Online. LanguageProcessing(EMNLP),pages5418–5426,
AssociationforComputationalLinguistics. Online.AssociationforComputationalLinguistics.
Nora Kassner, Oyvind Tafjord, Hinrich Schütze, and Anna Rogers, Olga Kovaleva, and Anna Rumshisky.
PeterClark.2021. Beliefbank: Addingmemorytoa 2020. AprimerinBERTology:Whatweknowabout
pre-trainedlanguagemodelforasystematicnotion howBERTworks. TransactionsoftheAssociation
ofbelief. arXivpreprintarXiv:2109.14723. forComputationalLinguistics,8:842–866.
Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gri- EricSchwitzgebel.2019. Belief. InEdwardN.Zalta,
bovskaya, Devang Agrawal, Adam Liska, Tayfun editor,TheStanfordEncyclopediaofPhilosophy,Fall
Terzi,MaiGimenez,CypriendeMassond’Autume, 2019edition.MetaphysicsResearchLab,Stanford
SebastianRuder,DaniYogatama,etal.2021. Mind University.
thegap: Assessingtemporalgeneralizationinneural
languagemodels. InNeurIPS. AntonSinitsin,VsevolodPlokhotnyuk,DmitriyPyrkin,
Ser