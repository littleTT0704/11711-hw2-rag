
from each instance comes from a movie, while the object
tionales,weappliedAdversarialMatching,turningrawdata
detectorwastrainedtodetectobjectsintheCOCOdataset
into a multiple choice task. We also tokenized the text
[49]. Workers ask challenging high-level questions cover-
spans.
ing a wide variety of cognition-level phenomena. Then,
Was the raw data saved in addition to the cleaned
workers provide a rationale: one to several sentences ex-
data? Yes - the raw data is the correct answers (and as
plaining how they came at their decision. The rationale
suchisasubsetofthe‘cleaned’data).
pointstodetailsintheimage,aswellasbackgroundknowl-
Does this dataset collection/preprocessing procedure
edge about how the world works. Each instance contains
achieve the initial motivation? At this point, we think
one correct answer and three incorrect counterfactual an-
so. Our dataset is challenging for existing VQA systems,
swers, along with one correct rationale and three incorrect
buteasyforhumans.
rationales.
Doesthedatarelyonexternalresources? No,every-
G.5.DatasetDistribution
thingisincluded.
Are there recommended data splits or evaluation How is the dataset distributed? VCR is freely avail-
measures? We release the training and validation sets, ableforresearchuseatvisualcommonsense.com.
as well as the test set without labels. For the test set, re-
G.6.LegalandEthicalConsiderations
searchers can submit their predictions to a public leader-
board. Evaluation is fairly straightforward as our task is
Were workers told what the dataset would be used
multiple choice, but we will also release an evaluation
foranddidtheyconsent? Yes-theinstructionssaidthat
script.
workersanswerswouldbeusedinadataset. Wetriedtobe
asupfrontaspossibletoworkers.Workersalsoconsentedto
G.3.DataCollectionProcess
havetheirresponsesusedinthiswaythroughtheAmazon
Howwasthedatacollected? Weusedmovieimages, MechanicalTurkParticipationAgreement.
withobjectsdetectedusingMaskRCNN[24,