 the data distribution p d(t), and, following the configurations of supervised MLE
(Section 4.1.1), set f = f data, α = 1, β = ϵ, and the uncertainty measure H to be the Shannon entropy. As
28
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
a result, the solution of q in Equation 3.2 reduces to the data distribution q(t) = p (t). The learning of the
d
model thus reduces to minimizing the divergence between the model and data distributions:
minD(p d,p θ),
(5.1)
θ
which is a common objective shared by many ML algorithms depending on how the divergence function is
specialized. Thus, in this setting, the divergence function directly determines the learning objective. In the
following sections, we will see other richer influences of D in combination with other SE components.
We next discuss some of the common choices for the divergence function, which opens up the door to recover
and generalize more learning algorithms besides those discussed earlier, such as the generative adversarial
learning (e.g., GANs; Goodfellow et al., 2014) that is widely used to simulate complex distributions (e.g.,
natural image distributions).
5.1. Cross Entropy and Kullback–Leibler (KL) Divergence
The diverse algorithms discussed in Section 4 have all been based on the cross entropy as the divergence
function in SE, namely,
D(q,p θ) =−Eq [logp θ]. (5.2)
A nice advantage of using the cross entropy is the close-form solution of q in the teacher-student procedure, as
shown in Equation 3.3, which makes the optimization and analysis easier.
In the case where the uncertainty function is the Shannon entropy H(q) = −Eq[logq] (as is commonly
assumed in this article), one could alternatively see the above algorithms as using the KL divergence for D, by
noticing that KL(q,p θ) = Eq[logq]−Eq[logp θ]. That is, given specific balancing weights (α 0,β 0),
the divergence and uncertainty terms in SE can be rearranged as:
α 0Eq[log