 model about
tions from five KGs: ATOMIC, ConceptNet,
generalcommonsenseregardlessofthetaskathand(Peters
WordNet, VisualGenome (Krishna et al. 2017), and
etal.2019;Levineetal.2020;Liuetal.2020;Zhangetal.
Wikidata (Vrandecˇic´ and Kro¨tzsch 2014), found in the
2019; Talmor et al. 2020). This line of work resembles our
Commonsense Knowledge Graph (CSKG) (Ilievski
approach of including background knowledge in a general,
et al. 2020). Notably, ATOMIC differs from the other KGs
task-agnosticway;however,itstillreliesonthetasktraining
in two ways: 1) its relations have a different focus than
dataandhasgenerallynotbeentestedinazero-shotregime.
thoseoftheothersources;and2)itsnodelabelsarelonger
and formalized as templates. Due to these considerations,
GeneratingCommonsenseQuestionsandAnswers
wepreparetwosetsofQAsets:onebasedonATOMICand
RichardsonandSabharwal(2019)uselinksinWordNetto
onebasedontheremainingfourknowledgesources.Figure
generate question-answer pairs, then leverage the resulting
1illustratesourquestiongenerationpipeline.
dataset to evaluate language models. Petroni et al. (2019)
prompttheskillsoflanguagemodelsbysentencesinsteadof Data partitions ATOMIC expresses pre- and post-states
questions, generated from sources like ConceptNet and foreventsandtheirparticipantswithninerelations.Itshead
SQuAD(Rajpurkaretal.2016).Previousworkshavegener- nodes are events, whereas the tail nodes are either events
atedsyntheticQAsetstocomplementexistingtrainingdata. or attributes. Its nodes have two particularities: 1) irrele-
Yeetal.(2019)proposedan‘align-mask-select’methodto vant parts of the node text are replaced with blanks (‘ ’);
and2)referencestofictionalagentsareindicatedwithspe-
2https://github