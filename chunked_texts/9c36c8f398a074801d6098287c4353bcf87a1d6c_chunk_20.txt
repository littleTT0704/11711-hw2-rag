 Ilya Sutskever, and Dario Amodei.
pletesetofhumanvaluedefinitions. Thus,explor- 2020. Language models are few-shot learners. In
AdvancesinNeuralInformationProcessingSystems,
ing the value-aligned task in different languages
volume 33, pages 1877â€“1901. Curran Associates,
other than English is a promising research direc- Inc.
tion.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Our main experimental results are based on a
Maarten Bosma, Gaurav Mishra, Adam Roberts,
175Bparametermodel,whichrequireslargeGPU
Paul Barham, Hyung Won Chung, Charles Sutton,
resourcesoraccessthroughanAPI.Thismayhin- Sebastian Gehrmann, et al. 2022. Palm: Scaling
derotherresearchersfromreproducingexperimen- language modeling with pathways. arXiv preprint
arXiv:2204.02311.
talresults. Additionally,weexploreddifferentsizes
of LLM including 1B and 6B models, which do
PaulFChristiano,JanLeike,TomBrown,MiljanMar-
notrequirelargeGPUresources,andshowedthey tic, Shane Legg, and Dario Amodei. 2017. Deep
canachievecomparableresults. Wehopetheycan reinforcementlearningfromhumanpreferences. In
AdvancesinNeuralInformationProcessingSystems,
bepossiblealternativeoptionsforresearcherswho
volume30.CurranAssociates,Inc.
maynothaveaccessto100B+models.
Althoughsexismisasuitablecasestudyforus Virginia Dignum. 2017. Responsible artificial intelli-
toinvestigatethefeasibilityofthevaluealignment gence: designing ai for human values. Daffodil In-
ternationalUniversity.
taskaswehaveshownthroughoutthiswork,itis
stillonedomain. Furtherexpansiontodifferentdo- Denis Emelin, Ronan Le Bras, Jena D Hwang,
mainsorvalue-alignedclassificationtaskssuchas Maxwell Forbes, and Yejin Choi. 2020. Moral
stories: Situated reasoning about norms, intents,
thedetection