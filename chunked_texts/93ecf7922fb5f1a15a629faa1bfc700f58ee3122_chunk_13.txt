en- Besides, MGM [51] requires a segmentation mask as our
dentsetup. Thetrainingandtestsubjectshavealreadybeen alphamattegenerationnetwork.
listedforthecorrespondingdatasets. Quantitative evaluation Experimental results are
Evaluation We used mean squared error (MSE), mean showninTable1. Weevaluatedallmodelsunderthesame
absolute error (MAE), sum of absolute difference (SAM), conditions, e.g., using background image and resolution.
gradient (Grad), and connectivity (Conn) metrics to evalu- According to the experimental results presented in Table
ateourmodelasintheliterature.Forcomparison,wechose 1, our model surpassed the performance of MODNet and
publicly available SOTA methods, namely MODNet [24], MGM,whichdonotuseanyadditionalinputs,onfourdif-
BGM-V2[29],FBA[13],MGM[51]andwetestedthemon ferentbenchmarks. Othermethodsinthetable—BGM-V2
thetestsetsinordertoperformafaircomparisonsincedif- andFBA—benefitfromadditionalinputsuchastheback-
ferentbackgroundsmaychangethemodels’performances. ground of the input image and a trimap. These additional
Input GT Ours BGM-V2 FBA MODNet MGM
Figure2.Qualitativecomparison.RowsrepresentAIM,D646,PM85datasets,respectively.
inputs make the task easier and more accurate results are imagesarereal-worldimages,therearenobackgroundim-
likely to be obtained, since the background image is the ages without the subject. Therefore, we could not test the
same one as the original input image, and trimap identi- BGM-V2modelonthisdataset.
fiesmostoftheareaontheimageasforegroundandback-
Qualitative evaluation In Figure 2, we present our re-
ground. On the AIM dataset, our model is found superior
sults, input image, ground truth, and the outputs of the
to the BGM-V2 in all metrics. However, the FBA method
other models for three benchmark datasets; AIM, D646,
achievest