.5. An exact surface-
ness,acrossallprogramminglanguages. However form-matchingmetricsuchaschrFwouldassigna
in almost all languages, performance reaches its lowsimilarityscoretothiscodepair,astheyonly
maximum before the last layer, and decreases at sharethetokenx. However, CodeBERTScoreas-
thefollowinglayers. Thissuggeststhathigherlay- signsnon-zeroscorestoeachtokenwithmeaning-
ersencodethesemanticinformationofeachtoken ful alignments, such as matching [sq,rt] with
more accurately, but the final layers may be more [_0,5],sinceasquarerootisthe0.5-thpower.
task-specific. These observations are consistent Additionally, we study the robustness of Code-
with Tenney et al. (2019), who found that lower BERTScore to adversarial perturbations. We
layers in BERT tend to process shallow informa- found that token-based metrics such as chrF are
0.8
os
math
0.7
.
.
0.6
r
sq
0.5
md
rt 0.4
ir
( 0.3
(
0.2
x
folder
0.1
) )
0.0
sh util. r mt ree ( folder ) x _** _0. 5
(a) (b)
Figure 6: Heatmaps of the similarity scores between two pieces of code that achieve the same goal. Figure 6(a)
shows the similarity scores between os.rmdir(folder) and shutil.rmtree(folder). Figure 6(b)
showsthesimilarityscoresbetweenmath.sqrt(x)andx ** 0.5.
muchmorepronetomatchingtrivialtokensrather correlatewellwithexecutionaccuracy.
thantokensthatpreservethesemanticmeaningof
Execution-based Metrics To alleviate previous
thecode. ExamplescanbefoundinAppendixE.
issues,execution-basedevaluationcountsagener-
Additional discussion and experiments regard-
ated code snippet as correct if it produces the re-
ing the distinguishability of CodeBERTScore are
quired outputs when run with