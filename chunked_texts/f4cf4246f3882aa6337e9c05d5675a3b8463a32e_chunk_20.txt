objectclassinstances. materialformore.
6.4.Humanevaluation
7.Conclusions
Weobtainedahumanevaluationof100randomlysam-
pled directives from the unseen test fold. The experiment
WeintroducedALFRED,abenchmarkforlearningto
involved 5 participants who completed 20 tasks each us-
map natural language instructions and egocentric vision to
ing a keyboard-and-mouse interface. Before the experi-
sequencesofactions. ALFREDmovesusclosertoacom-
ment, the participants were allowed to familiarize them-
munity goal of language-driven robots capable of naviga-
selves with AI2-THOR. The action-space and task restric-
tionandinteraction. Theenvironmentdynamicsandinter-
tionswereidenticaltothatofthebaselinemodels. Overall,
action mask predictions required in ALFRED narrow the
theparticipantsobtainedahighsuccessrateof91%,while
gap between what is required of agents in simulation and
takingslightlylongerthantheexpertwith86%path-length
robotsoperatingintherealworld[37].
weighted success rate. This indicates that the directives in
We use ALFRED to evaluate a sequence-to-sequence
ALFREDarewell-alignedwiththedemonstrations.
model with progress monitoring, shown to be effective in
othervision-and-languagenavigationtasks[28]. Whilethis
6.5.Sub-GoalPerformance
model is relatively competent at accomplishing some sub-
We also examine performance of the SEQ2SEQ model goals (e.g. operating microwaves is similar across Heat &
onindividualsub-goalsin ALFRED.Forthisexperiment, Place tasks), the overall task success rates are poor. The
weusetheexperttrajectorytomovetheagentthroughthe long horizon of ALFRED tasks poses a significant chal-
episodeuptothesub-task.Then,theagentbeginsinference lengewithsub-problemsincludingvisualsemanticnaviga-
basedonthelanguagedirectiveandcurrentvisualframe. tion, object detection, referring expression grounding, and
action grounding. These challenges may be approachable
Table 4 presents path-length weighted success scores
bymodel