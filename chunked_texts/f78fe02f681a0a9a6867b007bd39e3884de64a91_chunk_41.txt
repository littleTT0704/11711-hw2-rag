(Smithetal.,2020),andut- areviolent.”);theinstructionsarebuiltaswedid
terancesinconversationsgeneratedfromxReact for SODA(§4).
triplesfor SODA. WerunthefinetunedBERT-base
classifier(Demszkyetal.,2020)oneachutterance. D ExperimentDetails
Table12showsthefulldistributionacross27emo-
Automatic Evaluation via GPT-4 Inspired
tiontypesforeachdataset.
by Liu et al. (2023), we run automatic evalu-
Statistics of Human Evaluation A total of 74 ation on the overall quality of responses with
workersparticipatedincomparingdialogues,yield- GPT-4. We use the same head-to-head com-
ingaKrippendorf’salphaof0.25. Thisindicates parison setup from Table 5 and 6 with the
fairagreementsonthequalityjudgments. following prompt given to GPT-4: “You are
a response evaluator. Your task is
to choose the overall better response
C Detailsof COSMO
out of the two given the following
TrainingDetails COSMO-3B/COSMO-11B are context. You should consider naturalness,
trained using v3-32/v3-128 TPU accelerators specificity, naturalness, and
with batch size 256 (effective batch ≈ 780) consistency.\n\nContext:\n{CONTEXT}\n\n1)
for 110K/130K additional steps using Adafactor {RESPONSE}\n2) {RESPONSE}\n\nQuestion:
(Shazeer and Stern, 2018) with constant learning Which response is better in terms of
rate.001. overall quality?\nAnswer: Response ”.
DialogueContext: Model Natural Consistent Specific Overall
A:Ireallyneedtostarteatinghealthier. BlendedSkillTalk
B:Ihavetostarteatingbettertoo.
Koala-7B 26% 27% 35% 25%
A:Whatkindoffooddoyouusuallyeat?
COSMO-3B 74% 73% 65% 75%
B:Itrymybesttoeatonlyfruits,vegetables,and