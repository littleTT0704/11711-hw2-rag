desires
"necessary")
add_edge("food", "has context", "necessary")
add_edge("necessary", "not desires", "banned")
Banned
add_edge("millions", "desires", "food")
Figure4: Anexplanationgraph(left)andthecorrespondingPythoncode(right)
StCA(↑) SeCA(↑) G-BS(↑) GED(↓) EA(↑)
T5 (150) 12.56 6.03 9.54 91.06 7.77
fine-tuned
T5 (1500) 38.19 21.86 29.37 73.09 23.41
T5 (2500) 43.22 29.65 33.71 69.14 26.38
CURIE(30) 5.03 1.26 3.95 96.74 2.60
few-shot DAVINCI(30) 23.62 10.80 18.46 83.83 11.84
COCOGEN(30) 45.20 23.74 34.68 68.76 23.58
Table 4: Results for EXPLAGRAPHS (eval split). COCOGEN with only 30 examples outperforms the T5 model
whichwasfine-tunedon1500examples,acrossallmetrics.
each edge is added as an add_edge(source, stance. A high EA implies that each edge in
edge_type, destination) function call. thegeneratedoutputcontainsuniquesemantic
Wealsolistthestartingnodesinalistinstantiated information,andremovinganyedgewillhurt.
with a begin variable (Figure 4). Given a test
example,weconstructtheinputuntilthelineof# Results Table4showsthatCOCOGENwithonly
Edgesandletamodelcompletetheremaining. 30 examples outperforms the T5 model that was
fine-tunedusing1500examples,acrossallmetrics.
Metrics WeusethemetricsdefinedbySahaetal. Further, COCOGEN outperforms the NL-LLMs
(2021) (see Section 6 of Saha et al. (2021) for DAVINCIandCURIEwithatext-promptacrossall
a detailed description of the mechanisms used to metricsbyabout50