 array of phenomena. Above are two categories of example QA pairs. Left are examples that
requireknowledgeofbasicpropertiesoftheobjects(flexibility,curvature,andbeingporous),whileontheRightbothanswers
maybetechnicallycorrectbutoneismoreconvenientandpreferable.
The dataset is further cleaned of basic artifacts using the annotation,helpsremindannotatorsaboutthelessprototyp-
AFLite algorithm introduced in (Sakaguchi et al. 2020; icalusesofeverydayobjects.
Sapetal.2019)whichisanimprovementonadversarialfil- Second, and equally important, is that instructions build
tering(Zellersetal.2018;2019b). ononeanother.ThismeansthatanyQApairinspiredbyan
Throughout this work we first detail the construction of instructable will be more likely to explicitly state assump-
ournewbenchmarkforphysicalcommonsense.Second,we tions about what preconditions need to be met to start the
show that popular approaches to large-scale language pre- taskandwhatpostconditionsdefinesuccess.
training, while highly successful on many abstract tasks,
fail to perform well when a physical model of the world is Collectingdatathroughgoal-solutionpairs
required. Finally, our goal is to elicit further research into
UnliketraditionalQAtasks,wedefineourdatasetinterms
buildinglanguagerepresentationsthatcapturedetailsofthe
ofGoalandSolutionpairs(seeFigure2forexampleGoal-
real world. To these ends, we perform error and corpora
Solutionpairsandtypesofphysicalreasoning).TheGoalin
analysestoprovideinsightsforfuturework.
mostcasescanbeviewedasindicatingapost-conditionand
thesolutionsindicatetheprocedureforaccomplishingthis.
Dataset
Themoredetailedthegoal,theeasieritisforannotatorsto
write both correct and incorrect solutions. As noted above,
We introduce a new dataset, PIQA, for benchmarking
thesecondcomponentofourannotationdesignisreminding
progress in physical commonsense understanding. The un-
people to think creatively. We initially experimented with
derlyingtaskismultiplechoicequestionanswering:givena
question q