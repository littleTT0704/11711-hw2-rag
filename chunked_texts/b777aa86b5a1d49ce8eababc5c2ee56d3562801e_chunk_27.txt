
arXiv:2207.10551. ume35,pages14138–14148.
YiTay,MostafaDehghani,JinfengRao,WilliamFedus, SergeyZagoruykoandNikosKomodakis.2016. Wide
SamiraAbnar,HyungWonChung,SharanNarang, residualnetworks. arXivpreprintarXiv:1605.07146.
DaniYogatama,AshishVaswani,andDonaldMet-
XiangyuZhang,XinyuZhou,MengxiaoLin,andJian
zler. 2021. Scale efficiently: Insights from pre-
Sun.2018. Shufflenet: Anextremelyefficientcon-
trainingandfine-tuningtransformers. arXivpreprint
volutional neural network for mobile devices. In
arXiv:2109.10686.
Proceedings of the IEEE conference on computer
visionandpatternrecognition,pages6848–6856.
Ann Taylor, Mitchell Marcus, and Beatrice Santorini.
2003. Thepenntreebank: anoverview. Treebanks:
DaquanZhou,BingyiKang,XiaojieJin,LinjieYang,
Buildingandusingparsedcorpora,pages5–22.
XiaochenLian,ZihangJiang,QibinHou,andJiashi
Feng.2021. Deepvit: Towardsdeepervisiontrans-
SeiyaTokui,KentaOono,ShoheiHido,andJustinClay-
former. arXivpreprintarXiv:2103.11886.
ton.2015. Chainer: anext-generationopensource
frameworkfordeeplearning. InProceedingsofwork- Xiyou Zhou, Zhiyu Chen, Xiaoyong Jin, and
shoponmachinelearningsystems(LearningSys)in William Yang Wang. 2020. Hulk: An en-
thetwenty-ninthannualconferenceonneuralinfor- ergy efficiency benchmark platform for responsi-
mationprocessingsystems(NIPS),volume5,pages ble natural language processing. arXiv preprint
1–6. arXiv:2002.05