-Warmup-2xDecay(0.1) 5e-4 4
VOneBlock 256 0.1 25 C-Warmup-2xDecay(0.1) 5e-4 4
G-Noise 256 0.1 25 C-Warmup-2xDecay(0.1) 5e-4 4
Imagenet ResNet 256 0.2 25 L-Warmup-Decay(0.2) 5e-4 2
AT 256 0.2 25 L-Warmup-Decay(0.2) 5e-4 4
R-Warp 256 0.1 25 L-Warmup-Decay(0.2) 5e-4 4
R-Blur 256 0.1 25 C-Warmup-2xDecay(0.1) 5e-4 4
VOneBlock 256 0.1 25 C-Warmup-2xDecay(0.1) 5e-4 4
G-Noise 256 0.1 25 C-Warmup-2xDecay(0.1) 5e-4 4
Table3: Theconfigurationsusedtotrainthemodelsusedinourevaluation. L-Warmup-Decay(f)
representsaschedulethatlinearlywarmsupanddecaysthelearningrateandf representsthefraction
ofiterationsdevotedtowarmup. C-Warmup-2xDecay(0.1)issimilarexceptthatthewarmupand
decayfollowacosinefunction,andtherearetwodecayphases. Boththeschedulersareimplemented
usingtorch.optim.lr_scheduler.OneCycleLRfromPytorch.
H HardwareDetails
WetrainedourmodelsoncomputeclusterswithNvidiaGeForce2080TiandV100GPUs. Mostof
theImagenetandEcosetmodelsweretrainedandevaluatedontheV100s,whiletheCIFAR-10and
Ecoset-10modelsweretrainedandevaluatedonthe2080Tiâ€™s.
19
