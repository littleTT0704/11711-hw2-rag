withAAE,showingonlysmall tion. Our findings suggest that instead of solely
improvements in fairness. Based on those results, relying on development of automatic debiasing
wedonotexploreadversarialmethods, optingin- for existing, imperfect datasets, future work fo-
stead for ensemble-based methods of predefined cusprimarilyonthequalityoftheunderlyingdata
bias reduction. In contemporary work, Mozafari for hate speech detection, such as accounting for
etal.(2020)useare-weightingmechanism,which speaker identity and dialect. Indeed, such efforts
shows some effects in debiasing racial bias. We couldactasanimportantsteptowardsmakingsys-
leave it for future work to evaluate this method tems less discriminatory, and hence safe and us-
in our setting. In contrast to all previous work, able.
our experiments alsomeasure the effectiveness of
bias-agnosticmethods. Acknowledgments
OtherGeneralDebiasingMethods Severalap- We thank the anonymous reviewers and Laura
proaches for debiasing NLU tasks have been pro- Vianna for helpful comments on this work. This
posedlately. Someapproachesrelyonadversarial research was supported in part by NSF grants
training to remove protected attributes (e.g. gen- 1813153and1714566.
der or race), from a model’s internal representa-
tions (Zhang et al., 2018; Wang et al., 2019; Xia
References
et al., 2020). Other approaches include confi-
dence regularization (Utama et al., 2020), as well Su Lin Blodgett, Solon Barocas, Hal Daume´, III, and
as other product of expert approaches (He et al., Hanna Wallach. 2020. Language (technology) is
power: Acriticalsurveyof“bias”inNLP. InProc.
2019; Karimi Mahabadi et al., 2020) similar to
ofACL.
the debiased training approach from Clark et al.
(2019),whichistheonlydebiasedtrainingweem- Su Lin Blodgett, Lisa Green, and Brendan O’Connor.
ployduetoitsrelativelystrongperformance. 2016. Demographicdialectalvariationinsocialme-
d