
thatknowledge-seekingassistiveconversationsdif-
Redditthreadsand5Minstructionandgroundeddi-
ferfromnaturalsocialconversations.
aloguedatasets. KoalaandVicunaaremodelsthat
In addition, we compare the responses from
finetunedLLaMA(Touvronetal.,2023),whichis
anopen-sourceLLM,usingdialoguedatafromthe
COSMO and 200 ground-truth responses in Dai-
lyDialogwhichwereoriginallywrittenbyhumans.
web. Theyarebothknowntoachievecomparable
performancetoChatGPT(OpenAI,2022),which
Surprisingly, human judges prefer COSMO’s re-
sponses even over the original gold responses in
isamodelfinetunedforconversationalinteraction
thedataset,suggestingthatdialoguemodelstrained
based on GPT-3.5 – i.e., our teacher model. We
alsocompareCOSMOwithGPT-3.5andChatGPT;
onSODAcanleadtohighgeneralizabilityandnat-
uralness,evenforunseenconversations. Table14
promptingdetailsareinAppendixD.
intheAppendixshowstheground-truthresponse
Evaluation Metrics We perform head-to-head andresponsesfromeachmodelforagivencontext.
comparison between two responses, each from a
differentagent. Wesample100testexamplesran- 5.2 One-sidedOut-of-domainSetting
domlyfromdatasetsandaskthreehumanjudges Foranevenhardersetting,weevaluateCOSMOvs.
on Amazon Mechanical Turk to select the better BlenderBotonthedatasetBlenderBotwastrained
responsebetweenthetwointermsoffourdistinct on: BlendedSkillTalk (BST; Smith et al., 2020).
criteria (Mehri et al., 2022): (1) naturalness, (2) Table6(top)showsthehead-to-headcomparison
consistency,(3)specificity,and(4)overall. resultsoftheresponsesfromCOSMOandBlender-
Bot(f