boundary.
mulation. Wefirstidentifythefundamentalreasonbehindthequantity-qualitytrade-offisthelack
ofsophisticatedassumptionimposedbytheweightingfunctiononthedistributionofpseudo-labels.
Especially,confidencethresholdingcanberegardedasastepfunctionassigningbinaryweightsac-
cordingtosamples’confidence,whichassumespseudo-labelswithconfidenceabovethethreshold
areequallycorrectwhileothersarewrong. Basedontheanalysis, weproposeSoftMatchtoover-
comethetrade-offbymaintaininghighquantityandhighqualityofpseudo-labelsduringtraining.
AtruncatedGaussianfunctionisderivedfromourassumptiononthemarginaldistributiontofitthe
confidence distribution, which assigns lower weights to possibly correct pseudo-labels according
to the deviation of their confidence from the mean of Gaussian. The parameters of the Gaussian
functionareestimatedusingthehistoricalpredictionsfromthemodelduringtraining. Furthermore,
weproposeUniformAlignmenttoresolvetheimbalanceissueinpseudo-labels,resultingfromdif-
ferentlearningdifficultiesofdifferentclasses. Itfurtherconsolidatesthequantityofpseudo-labels
whilemaintainingtheirquality.Onthetwo-moonexample,asshowninFig.1(c)andFig.1(b),Soft-
Matchachievesadistinctivelybetteraccuracyofpseudo-labelswhileretainingaconsistentlyhigher
utilization ratio of them during training, therefore, leading to a better-learned decision boundary
as shown in Fig. 1(d). We demonstrate that SoftMatch achieves a new state-of-the-art on a wide
rangeofimageandtextclassificationtasks. WefurthervalidatetherobustnessofSoftMatchagainst
long-taileddistributionbyevaluatingimbalancedclassificationtasks.
Ourcontributionscanbesummarizedas:
• Wedemonstratetheimportanceoftheunifiedweightingfunctionbyformallydefiningthe
quantityandqualityofpseudo-labels,andthetrade-offbetweenthem. Weidentifythatthe
inherenttrade-offinpreviousmethodsmainlystems