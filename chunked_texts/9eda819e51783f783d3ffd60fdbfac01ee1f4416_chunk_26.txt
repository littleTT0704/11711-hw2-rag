andPe-
ter Liu. 2020. Pegasus: Pre-training with extracted
gap-sentencesforabstractivesummarization. InIn-
ternationalConferenceonMachineLearning,pages
11328–11339.PMLR.
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q
Weinberger,andYoavArtzi.2019. Bertscore: Eval-
uating text generation with bert. arXiv preprint
arXiv:1904.09675.
Mengjie Zhao, Yi Zhu, Ehsan Shareghi, Ivan Vulic´,
RoiReichart,AnnaKorhonen,andHinrichSchu¨tze.
2021. A closer look at few-shot crosslingual trans-
fer: Thechoiceofshotsmatters. InProceedingsof
the59thAnnualMeetingoftheAssociationforCom-
putational Linguistics and the 11th International
A SupplementaryMaterial
A.1 Hyper-parameters
InTable2,wereportthehyper-parametersusedin
Sec.3.1.
A.2 AdditionalResults
Table3supplementsFig.4inSec.3.3.
learningrate epoch batchsize gradacc prefixlength innerdim beamsize lengthpenalty
prefix-tuning
fewshotsetting 3.00e-4 20 2 1 20 800 4 0.6
notfewshotsetting,low-resource 2.00e-4 15 8 1 200 800 4 0.6
notfewshotsetting,notlow-resource 2.00e-4 15 16 4 200 800 4 0.6
adapter-tuning
fewshotsetting 1.00e-3 20 2 1 - 1200 4 0.6
notfewshotsetting,low-resource 1.00e-3 15 8 1 - 1200 4 0.6
notfewshotsetting,notlow-resource 1.00e-3 15 16 4 - 1200 4 0.6
PLMfine-tuning
fewshotsetting 5.00e-4 20 2 1 - - 4 0.6
notfewshotsetting,low-resource 5.00e-4 15 8 1 - - 4 0.6
notfewshotsetting,notlow-resource 5.00e-4 15 16 4 - - 4 0.6
Table