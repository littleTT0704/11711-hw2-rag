extensiveanalysisandexperimentation,inwhichwealso
testedanumberofhypothesesthatdidnotturnouttohaveasignificanteffect. Additionaldetailsofthese
hypothesesaredetailedinAppendixE,andwehopethattheymayprovideideasforfutureimprovementsof
retrieval-basedLMs.
EnsembleofDistanceMetrics Wehypothesizedthattheensembleoftwodistancemetrics: thestandard
innerproductdistance(whichtheLMuses)andtheL2distance(whichthekNNcomponentuses),isthekey
totheimprovement. However,wefoundthatsimilargainscanbeachievedusingtheinner-productmetricfor
theretrievedkNN.MoredetailscanbefoundinAppendixE.1.
EnsemblingofTwoModels WehypothesizedthatthekNNcomponentmerelyprovidesanothermodel
forensembling. TheimprovementfromkNN-LMispurelyduetotheensemblingeffectofdifferentmodels.
However,wefoundthatkNN-LM’simprovementisorthogonaltoensemblingwithadifferentbaseLM.More
detailscanbefoundinAppendixE.5.
Sparsification Themask-to-k(·)usedbykNNretrievalinducessparsityinthedistributionoverthevocab-
ulary,duetoasmallk(typically1024)comparedtothesizeofthevocabularyV (33Kinourexperiments
10
and260KintheoriginalsettingsofKhandelwaletal.(2020b)). WehypothesizedthatkNN-LMincreases
theprobabilityofthetop-kentrieswhiletaking“probabilitymass”fromthelongtailofunlikelywordtypes.
However,wecouldnotgainanybenefitssolelyfromsparsifyingtheoutputprobabilityofastandardLMand
interpolatingitwiththeoriginalLM.MoredetailscanbefoundinAppendixE.2.
StolenProbabilities Thestolenprobabilitieseffect(Demeteretal.,2020)referstothesituationwherethe
outputembeddingsofanLMarelearnedsuchthatsomewordsaregeometricallyplacedinsidetheconve