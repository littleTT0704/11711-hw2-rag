 its ability to improve a variety
dictions that are highly confident but incorrect (see Figure
of self-training methods. Specifically, our approach
1). Forinstance,ifthesourcedomainimagesusuallyhave
achieves 1.2%-2.9% (GTA) and 2.2%-4.4% (SYN-
brightregions(highintensityoftheRGBchannels)forthe
THIA)relativeimprovementsoverthreedifferentself-
skyclass,thenbrightregionsintargetdomainimagesmight
training baselines. Interestingly, we observe that reg-
be predicted as the sky with high confidence, irrespective
ularisationimprovesperformanceonboth“stuff”and
oftheactualsemanticlabel. Sincehighlyconfidentpredic-
“things” classes, somewhat normalising the effects of
tionsqualifyaspseudo-labels,trainingthemodelonpoten-
classwisestatistics.
tially noisy predictions can ultimately lead to sub-optimal
performance in the target domain. Thus, in this work, we • Further, our regularised self-training method
seek to reduce the heavy reliance of self-training methods achieves state-of-the-art mIoU of 54.2% in GTA
on photometric cues for predicting pixel-wise semantic la- → Cityscapes settings and improves classwise
bels. IoUsbyupto4.8%overbestpriorresults.
Tothatend,weproposetoincorporateauxiliarymodal-
2.RelatedWork
ity information such as depth maps that can provide struc-
turalcues[11,24,51,53],complementarytothephotometric Unsuperviseddomainadaptation. Unsuperviseddomain
cues. Semantic segmentation datasets are usually accom- adaptation (UDA) is of particular importance in complex
panied by depth maps that can be easily acquired in prac- structured-prediction problems, such as semantic segmen-
tice[12,39].Sincena¨ıvefusionoffeaturesthatareextracted tation in autonomous driving, where the domain gap be-
fromdepthinformationcanalsointroducenuisance[24,51], tweenasourcedomain(e.g.,anurbandrivingdataset)and
an important