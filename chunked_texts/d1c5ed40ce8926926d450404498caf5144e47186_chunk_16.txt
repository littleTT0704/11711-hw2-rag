
ferent strategies for selecting relevant information for source expansion (Chapter 5)
and demonstrate the effectiveness of our approach in task-based evaluations on QA
data (Chapter 6). We show that SE significantly and consistently improves the per-
formance of Watson [Ferrucci et al., 2010], one of the most effective QA systems to
date, yielding gains of 4.2%–8.6% in search recall and 7.6%–12.9% in QA accuracy on
large sets of questions drawn from the Jeopardy! TV show and TREC evaluations.
Similarly, our method improves search recall of the OpenEphyra3 open-source QA
system by 4.0%–13.7% on large TREC datasets. Suggestions for other applications
of source expansion are made when we discuss areas for future research at the end of
the thesis (Chapter 9).
1.2 Approach
The input to our source expansion (SE) algorithm is a topic-oriented seed corpus, i.e.
a document collection in which each document contains information about a distinct
topic. Each of these seed documents can be expanded with additional information
about the same topic and reformulations of information that is already covered in the
following four-stage pipeline (further described in Chapter 4):
1. Retrieve content that is related to the topic of the seed document from a large
external source (e.g. the Web or a locally stored text corpus).
2. Extract self-contained nuggets of text from the retrieved content (e.g. para-
graphs or sentences).
3. Estimate the relevance of the text nuggets with regard to the topic of the seed
document using a statistical model.
3http://sourceforge.net/projects/openephyra/
4 CHAPTER 1. INTRODUCTION
4. Compile a new pseudo-document from the most relevant nuggets, excluding
lexically redundant text.
This procedure can be repeated for each document in the seed corpus, yielding an
expanded corpus with increased coverage and semantic redundancy. The expanded
corpus can be leveraged as an additional source by an information retrieval or extrac-
tion system. In question answering, the corpus can be indexed and used to retrieve
content that is related to a given question for answer extraction, or to gather addi-
tional supporting evidence for candidate answers in an answer