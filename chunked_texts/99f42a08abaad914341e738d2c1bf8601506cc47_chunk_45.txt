 for SphereFace-R v1, since it
nations of them. To efficiently evaluate SFN, we adopt the enablesthegradientpropagationforlargemargin(m> π in
θ
combination of m and s that leads to the best performance Eq. 11). Here we use the best-performing hyperparameters
inSection6.2.2andfixthemthroughouttheSFNexperiment from our previous experiments. In fact, the consistent im-
sothatwecanfocusonhowtwillaffecttheperformance. provements can also be obtained from CGD with the other
eulaV
noitcnuF
evitcejbO
eulaV
noitcnuF
evitcejbO
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 13
TABLE11
EvaluationonMegaFace,IJB-BandIJB-C.WeuseSFNet-64asthebackbonearchitectureandMS-Celeb-1Masthetrainingsetforallthe
comparedmethods.Resultsarein%andhighernumberindicatesbetterperformance.
MegaFace IJB-B IJB-C
(refined) 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR
Method FN m s t Iden. Veri. 1e-6 1e-5 1e-4 top1 1e-2 1e-1 1e-6 1e-5 1e-4 top1 1e-2 1e-1
NormFace[9] HFN - 30 - 89.24 90.76 40.56 75.30 90.22 92.49 64.62 88.19 70.17 85.88 92.69 93.70 77.97 89.81
CosFace[3],[4] HFN 0.35 64 - 98.05 98.45 37.82 82.99 94.20 94.69 70.61 93.03 78.01 92.29 95.87 95.91 84.59 94.53
ArcFace[5] HFN 0.5 64 - 98.45 98.39 41.02 86.16