ilartotheobjec-
tiveabove,wecombinetheseintoasinglelearningobjectivefortheentirespeakernetwork.
4 INTRODUCING TOM MODELING
We incorporate into the speaker architecture an LSTM-based ToM listener. This listener model is
trainedalongsideoftherestofthespeakernetworktolearnthe“mentalstate”oftheactuallistener–
theneuralnetworkparametersthatallowittobestreplicatetheprobabilitiesthatthelistenerwould
assign to image-utterance pairs. It uses a similar architecture to the actual listener, combining its
ownlearnedsentenceembeddingsfromanLSTMnetworkwithpretrainedimageembeddingsusing
ResNet. Inotherwords,ourToMlistenerseekstolearnthesentenceembeddingmodelθ that
ToM
willmaximizetheprobabilitiesassignedtothelistener’schoicegivenanutterance.
θ =argmaxP (u |xˆ)∝exp(θT (u )·ResNet(xˆ)) (6)
ToM ToM i ToM i
θ
WeintroduceToMintothespeakermodelbyhavingourspeakersamplecandidateutterancesand
rerankthemwiththehelpoftheToMlistener.OurToMspeakerfirstsamplesN candidateutterances
U ={u(i)}N fromitsdistribution. Next,wegenerateaspeakerandalistenerscoreforeach:
i=1
(cid:89)
P (u)∝ P(u |u,u,...u,x) (7)
speaker i 1 2 i−1
i
P (x|u)∝exp(LSTMT(u)Resnet(x)) (8)
ToM
4
PublishedasaconferencepaperatICLR2023
Here,theprobabilityP(u |u,u,...u,x)iscomputedaccordingto1. Wethencombinethese
i 1 2 i−1
scoresusingalistenerweighthyperparameterw togettheoverallscoreassignedtoeachutterance.
l
Finally,weselectthebestutterance,ub