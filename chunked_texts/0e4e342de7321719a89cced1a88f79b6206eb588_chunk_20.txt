utter,2017] Ilya Loshchilov and Frank
work,2018. Hutter. Decoupled weight decay regularization. arXiv
[Chenetal.,2020] Yinpeng Chen, Xiyang Dai, Mengchen preprintarXiv:1711.05101,2017.
Liu, Dongdong Chen, Lu Yuan, and Zicheng Liu. Dy- [Maoetal.,2016] JunhuaMao,JonathanHuang,Alexander
namicconvolution: Attentionoverconvolutionkernels. In Toshev, Oana Camburu, Alan Yuille, and Kevin Murphy.
CVPR,2020. Generationandcomprehensionofunambiguousobjectde-
[Chenetal.,2021] Feilong Chen, Fandong Meng, Xiuyi scriptions. InCVPR,pages11â€“20,2016.
Chen, Peng Li, and Jie Zhou. Multimodal incremental [Nagarajaetal.,2016] Varun K. Nagaraja, Vlad I. Morariu,
transformerwithvisualgroundingforvisualdialoguegen- andLarryS.Davis. Modelingcontextbetweenobjectsfor
eration. InACL-IJCNLP,August2021. referringexpressionunderstanding,2016.
[Dengetal.,2021] JiajunDeng,ZhengyuanYang,Tianlang [Nagranietal.,2021] Arsha Nagrani, Shan Yang, Anurag
Chen,WengangZhou,andHouqiangLi.Transvg:End-to-
Arnab,ArenJansen,CordeliaSchmid,andChenSun. At-
endvisualgroundingwithtransformers.InICCV,October
tention bottlenecks for multimodal fusion. Advances in
2021.
NeuralInformationProcessingSystems,34,2021.
[Devlinetal.,2019] Jacob Devlin, Ming-Wei Chang, Ken-
[Rezatofighietal.,2019] Hamid Rezatofighi, Nathan Tsoi,
ton Lee, and Kristina Toutanova. Bert: Pre-training of
JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio
deep bidirectional transformers for language understand-