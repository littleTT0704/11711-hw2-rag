ario Amodei. 2020.
Language models are few-shot learners. ArXiv,
Ethical considerations In this work, the har-
abs/2005.14165.
vested knowledge is automatically generated by
LMs. Wewouldliketonotethatthelanguagemod-
NicolaDeCao,WilkerAziz,andIvanTitov.2021. Edit-
els could possibly generate unethical knowledge ingfactualknowledgeinlanguagemodels.
tuples, same with the risks of other applications
using language models for generation. We hope JiangjieChen,RuiXu,ZiquanFu,WeiShi,Zhongqiao
Li, Xinbo Zhang, Changzhi Sun, Lei Li, Yanghua
that the knowledge extraction study could offer
Xiao,andHaoZhou.2022. E-kar: Abenchmarkfor
techniques to better interpret and understand the
rationalizingnaturallanguageanalogicalreasoning.
language models, and in turn foster the future re- arXivpreprintarXiv:2203.08480.
searchoflanguagemodelethics. Sincetheknowl-
edgegraphonlyconsistssimplephrases,wethink Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
KristinaToutanova.2019. Bert: Pre-trainingofdeep
filtering sensitive words would be effective. No
bidirectionaltransformersforlanguageunderstand-
foreseeablenegativesocietalimpactsarecausedby
ing. InNAACL-HLT(1).
themethoditself.
Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-
lashaRavichander, EduardHovy, HinrichSchütze,
References andYoavGoldberg.2021. Measuringandimproving
consistencyinpretrainedlanguagemodels. Transac-
BadrAlKhamissi,MillicentLi,AsliCelikyilmaz,Mona tionsoftheAssociationforComputationalLinguis-
Diab,andMarjanGhazvininejad.2022. Areviewon tics,9:1012–1031.