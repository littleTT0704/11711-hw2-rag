econductedthemainexperimentwith Intheprompt,theboldwordswillbereplacedby
it. WealsodidinvestigationwiththeGPT-Jurassic theactualdata. Thefirstsentenceisthefew-shot
6B model. Interestingly, the GPT-Jurassic mod- example and we repeat it N times by randomly
elsshowedbetterperformancewithdataprompted selectingfivesamplesforeachlabelcategory. The
withprompttemplate#2,whichwasdifferentfrom secondsentenceisthetestsample,andthemodel
OPT-175B.Thismayhaveresultedfromthediffer- will generate the corresponding label in the text.
enttrainingobjectivesandpre-trainingresources Duringgeneration,wesettop-p0.9andgenerate
of the models. Although the overall structure of labelsfivetimes. Finally,wecalculatetheaverage
ourmethodologyismodelagnostic,thereshould scoresamongtheresults.
besomeexplorationmadeonprompttemplatecon-
D Vocabularyoverlapsofgenerated
structiondependentonmodels.
trainingdataamongsexismcategories
TheexperimentalresultsareshowninTable5.
Figure 6 presents the vocabulary overlaps of the
VA-ROBERTA value-aligned training data generated from OPT-
Acc. Prec. Rec. W-F1
w/prompttype
175amongthesexismcategories. Wecalculatethe
1 73.91% 73.91% 75.14% 74.31% vocabulary overlaps for each sexism category of
2 72.71% 72.71% 75.22% 73.34%
thegenerateddata.
3 71.25% 71.25% 75.48% 72.06%
4 69.75% 69.75% 74.12% 70.60%
E PerCategoryResults
5 72.07% 72.07% 73.82% 72.61%
Figure 7 presents the evaluation results of VA-
Table5: Evaluationresultsof VA-ROBERTA trained
BART for each sexism category on the test set.
on OPT-175B generated data with different prompt
types. Weprompted120datasamplespercategories.
C ExperimentalDetails
Hyperparameters For hyper-parameters, we
performagrid