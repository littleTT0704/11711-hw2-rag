
inmp3format. Tosegmentandalignittoutterancelevel,we
followedtheCMUWildernessproject’s[11]segmentationand Toanswerthequestionsabove,forbothcreatedandfound
alignmentprocess. AlignmentforNewTestamentdata,which data, we divided each into splits of 25 min, 50 min and 101
is ≈ 20 hours of speech, took a maximum of 5 days per lan- min (the largest amount of created data was 102 minutes for
guageona16-CPUmachine.Table1showstheresultingutter- bothlanguages. Asmentionedpreviously,toallowthosewith
ances. lessexperienceinspeechtechnologytoexpandAfricanVoices
tootherlanguages, webuiltTTSsystemsusingFestvoxtools
Table1: Datafromfoundsources. [8]duetotheirrelativeaccessibilityastheydonotrequireex-
**Dataisnotreleased pensivecomputeresources.
Language source No.utterances hrs
Luo Open.Bible 11263 15.92 4.1. ResultsandAnalysis
Lingala Open.Bible 12957 27.52
Forobjectiveevaluation,weusedthemeanMelCepstralDis-
Kikuyu Open.Bible 10877 17.72 tortion (MCD) score [27].6 Table 2 shows the results of the
Yoruba Open.Bible 10978 18.04
automaticevaluation.
Hausa-M CommonVoice 518 0.62
Hausa-F CommonVoice 1938 2.3 Table2: ObjectiveevaluationusingMCD(lowerisbetter).
Luganda CommonVoice 2942 4.52
Lang Source 25 50 101
Ibibio LLSTI 125 0.32
Kiswahili LLSTI 426 0.53 Found 4.73 4.73 4.65
Luo
Wolof ALFFA 1000 1.2 Created 6.49 6.45 6.37
Fongbe ALFFA 542 0.33 Found 4.67 4.40 4.37
Suba
Suba** Bible.is 11971 24.82 Created 5.15 4.58 4.80
3.3. FoundDataSources We conducted human evaluation, specifically preference
andtranscriptiontests, toob