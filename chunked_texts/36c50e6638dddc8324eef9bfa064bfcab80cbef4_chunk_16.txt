LEU-4 F1 PPL
(Rolleretal.,2021). Moreover,itshowsbetterper-
BADclassifier 72.2 72.1 – – –
formance than other pre-trained dialogue agents
BERT 73.1 72.8 – – –
across various dialogue datasets (see Table 8 in NormTransformer – – 10.2 36.1 8.6
DialoGPT – – 10.0 32.1 8.7
Appendix). MoredetailsareinAppendixB.2.
GPT-2 69.3 68.4 9.6 32.3 8.8
T5 72.4 73.4 16.1 38.9 5.9
5 Experimentson PROSOCIALDIALOG
Canary(SocialChemistry) 73.5 73.1 16.3 39.2 5.4
Canary(MIC) 74.1 74.0 16.2 41.2 5.3
WefirstevaluateCanaryondeterminingdialogue Canary(Delphi) 77.9 77.1 16.5 43.3 5.3
safetyandgeneratingrules-of-thumb(§5.1). Next,
Table 2: Dialogue safety classification accuracy
we evaluate Prost on generating prosocial re-
(%) and rules-of-thumb generation results (§5.1) on
sponsesbothquantitativelyandqualitatively(§5.2).
PROSOCIALDIALOG. PPLdenotesperplexity.
5.1 DialogueSafetyClassification&
Rule-of-thumbGeneration Model BLEU-4 F1 Perplexity
Baselines and evaluation metrics. We compare Prost(Responseonly) 3.98 30.30 6.31
Prost(RoT&Response) 4.13 31.13 6.22
theaccuracyofCanarywithfourfine-tunedmod-
Prost(Responsew/goldRoT) 4.51 32.78 6.16
els for dialogue safety classification: BERT (De-
vlinetal.,2019),BADclassifier(Xuetal.,2021), Table 3: Response generation results on PROSOCIAL-
GPT-2(Radfordetal.,2019),andT5-large(Raffel DIALOGtestspl