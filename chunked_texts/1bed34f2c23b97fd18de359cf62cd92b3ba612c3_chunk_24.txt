 of the Association for Compu-
tationalLinguistics,pages311–318.
Hammond Pearce, Baleegh Ahmad, Benjamin Tan,
Brendan Dolan-Gavitt, and Ramesh Karri. 2021.
An empirical cybersecurity evaluation of github
copilot’s code contributions. arXiv preprint
arXiv:2108.09293.
Maja Popovic´. 2015. chrF: character n-gram F-score
forautomaticMTevaluation. InProceedingsofthe
Tenth Workshop on Statistical Machine Translation,
pages 392–395, Lisbon, Portugal. Association for
ComputationalLinguistics.
Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie
Liu,DuyuTang,NeelSundaresan,MingZhou,Am-
brosio Blanco, and Shuai Ma. 2020. Codebleu: a
method for automatic evaluation of code synthesis.
arXivpreprintarXiv:2009.10297.
Michele Tufano, Dawn Drain, Alexey Svyatkovskiy,
Shao Kun Deng, and Neel Sundaresan. 2020. Unit
testcasegenerationwithtransformersandfocalcon-
text. arXivpreprintarXiv:2009.05617.
MortezaVerdi,AshkanSami,JafarAkhondali,Foutse
Khomh, Gias Uddin, and Alireza Karami Motlagh.
2020. An empirical study of c++ vulnerabilities in
crowd-sourced code examples. IEEE Transactions
onSoftwareEngineering.
EricWallace,TonyZhao,ShiFeng,andSameerSingh.
2021. Concealeddatapoisoningattacksonnlpmod-
els. In Proceedings of the 2021 Conference of the
NorthAmericanChapteroftheAssociationforCom-
putationalLinguistics: HumanLanguageTechnolo-
gies,pages139–150.
Zhiruo Wang, Grace Cuenca, Shuyan Zhou, Frank F
Xu,andGrahamNeubig.2022. Mconala: Abench-
markforcodegenerationfrommultiplenaturallan-
guages. arXivpreprintarXiv:2203