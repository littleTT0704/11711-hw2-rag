 function be L where the
2
Thissectioncontainsthedetailsoftheproposedapproachfor
aim is to minimise the difference between T-F representation
SED, segmentation mapping network g 1, classification map- {xˆ}T and predicted time-frequency representation{x¯}T
i i=1 i i=1
pingnetworkg,andtheauxiliarytime-frequencyreconstruc-
2 ofaudioclip. IfthelearnableparametersareW=[w,w,w ]
2 4
tionauxiliarytask.Thearchitectureisdepictedinfigure1
and w,w,w corresponding to g(.),g (.),g (.) respectively,
2 4 2 4
thentheoptimisationproblemcanbeframedintermsofthese
3.1. Self-supervisedLearningformulationforSED weightsWoveralldatapointsas:
eL ae ct hth xe
i
r ∈aw Rau isdi ao fb rae mr eep ir nes te hn ete ad udb iy
o
cX lip.= W{ ex ei} xT i tr= a1 ctw tih mer ee
-
m WinL 1(P,y|w,w 4)+αL 2({x¯ i}T i=1,{xˆ i}T i=1|w,w 2) (3)
frequency features for each audio, let them be represented by Theparameteralpha(α)accountsforscaledifferencebetween
Xˆ = {xˆ i}T i=1 where each xˆ i ∈ Rd, d ∈ Z corresponds to lossesL 1andL 2. Ithelpsinadjustingthecontributionofaux-
frame in the audio clip. In practice, d are the number of mel iliarytaskrelativetotheprimarytaskinlearningweights.
bins obtained after computing the spectrogram. As per MIL
formulation,wecanrepresenteachsampleindatasetasabag 3.2. Sharedencoderandauxiliarytaskdecodernetwork
B =({xˆ }T,y)|N wherey∈RC istheweaklabel,Nare
j i i=1 j=0 Thesegmentation