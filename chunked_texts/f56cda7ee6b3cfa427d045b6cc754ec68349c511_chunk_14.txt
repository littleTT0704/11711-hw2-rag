-
Dems mess up major cities, Offensive to menting our training set with SBIC data shows
USER: republicans mess up other democrats and
countries. Both suck republicans furtherimprovementinallthemetrics. However,
but hillaryand Trump are both eventhebestmodelachieves0.714F onallutter-
Offensive to 1
ğŸ¤–BOT: trash... voting for Jill Stein, Neither
much better choice celebrity ances,showingthatthetaskischallenging. Classi-
ficationmodelsperformworseondialoguemodel
Figure5:Examplesofdialoguemodelgeneratedoffen-
responseswithinourdataset,astheycanbeincoher-
sivepersonalattackswithoutexplicitbadwords.
entbutdistributionallysimilartonaturallanguage.
Tocorroborate,thebestmodel,DGPT+,gets0.673
ative loss for well classified instances. In our ex- F 1 on GPT-3 responses and 0.489 F 1 on DGPT
periments,thehyperparametersÎ² andÎ³ aresetto responses.
0.9999and1.0,respectively.
Stance classification models struggle to per-
form well as evidenced by low F1 scores on de-
5.3 Evaluation
tecting â€˜Agreeâ€™ and â€˜Disagreeâ€™ stance. As found
Wedivide TOXICHAT intotrain,dev,andtestsets inpriorworkonstancedetection(Yuetal.,2020),
using a 70-15-15 ratio. Identifying offensive re- stancealignmentischallengingbecauseitiscontex-
ply utterances (u,i â‰¥ 2) is challenging since it tual,nuanced,anddoesnâ€™tneedhighword-overlap
i
may require understanding the entire thread con- toconveyimplicitagreement/disagreement. Forin-
text. Hence,weevaluateOffensivetaskusing stance,asarcasticallywordedquestion,likeâ€œOhre-
offensivelabelF scorefor(1)allutterances,(2) ally?â€,canalsoshowindirectdisagreement. Train-
1
firstutterance,and(3)replyutterancesinthethread. ingwithweight