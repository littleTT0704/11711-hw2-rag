 2017) uses the term (1âˆ’p m)Î³ to reduce the rel-
AllStancePairs AdjacentStancePairs
Agree Disagree Neutral Macro Agree Disagree Neutral Macro
NBOW(wCE).183.000.894.359.206.000.851.352
BERT(wCE).244.193.903.447.302.230.871.468
DGPT(wCE).385.200.901.496.456.179.856.497
DGPT(CB ).349.319.916.528.414.353.874.547
foc
Table1: TestsetStancelabelandmacroF scoresforallutterancepairsandadjacentutterancepairs.
1
allu firstu replyu 5.4 ResultsandAnalysis
NBOW(CE).399.311.423
BERT(CE).608.598.610
DGPT(CE).691.737.674 We present the test set evaluation results of
DGPT+(CE).714.741.704 Stance and Offensive tasks in Table 1 and
2, respectively. We observe similar trends as test
Table 2: Test set Offensive F scores for all utter-
1 inthedevsetevaluationmetricspresentedinTable
ances,firstutterancesandreplyutterancesinallthreads.
6 and7 inthe Appendix. The DGPTmodel with
DGPT+ indicates DGPT model trained on our dataset
fullthreadcontextoutperformsBERTandNBOW
augmentedwithinstancesfromSBIC(Sapetal.,2020).
modelswhichlacktheglobalcontext.
Examples of personal attack by dialog model
I thought "Anti-Feminism" Offensive to For the Offensive task, DGPT classifier
USER: meant you wanted to see other achieves higher accuracy for detecting offensive-
Feminist BURN to the ground.
nessinthefirstutterance(firstuF )comparedto
Well, the thing is that we don't Offensive to 1
ðŸ¤–BOT: want to burn anything to the Disagree comment BERT.Thissuggeststhatpretrainingonin-domain
ground. The only thing we author
want to burn is your bullshit. Redditcommentsimprovestheperformance. Aug