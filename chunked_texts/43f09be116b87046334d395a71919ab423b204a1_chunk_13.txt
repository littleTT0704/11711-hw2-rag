 32.3% ✓
ON i2b2 20.8% 5.3 AugmentedSilverMentions
ONGenrei ONGenrej (8.1%,47.9%) ✓
Tofurtherreduceannotationburden,weaugment
Table3:Summaryofsource-targetconfigurationsinourex-
periments. We experiment with transfer between domains the set of annotated mentions over the target do-
withcommonordifferingannotationstyle,whereannotation
main. Wetrainamentiondetectoroverasubsetof
stylecandictatewhetherornottherearesingletonsannotated
goldannotatedtarget-domain. Then, weuseitto
ordomain-specificmentionstoannotateforexample.
tagsilvermentionsovertheremainingunlabeled
documents,andusethesesilvermentionlabelsin
domain with coreference annotations optimizing
computingMD.
T
onlythecoreferencelossCL. Then,wecontinue
S
trainingwithCL ontargetdomainexamples. 5.4 CoreferenceEvaluationConfiguration
T
We additionally experiment with an alterna-
Inadditiontothemostcommoncoreferencemet-
tivebaseline(high-prec. c2fCL S,CL T,MD T)in rics MUC,B3,CEAF, we average across link-
whichcoreferenceannotationsarereusedtoopti-
ϕ4
based metric LEA in our score. We also evalu-
mizeourMDoverthetargetdomain. Thisallows
ateeachmodelwithandwithoutsingletons,since
forfullutilizationthetargetdomainannotations.
including singletons in the system output can ar-
tificially inflate coreference metrics (Kübler and
Proposed: high-prec. c2f(CL,MD,MLM )
S T T
Zhekova,2011). Whenevaluatingwithsingletons,
Weusethesamemodelarchitectureandpre-trained
we keep singletons (if they exist) in both the sys-
encoder as the baseline, but also incorporate the
temandGOLDclusters. Whenevaluatingwithout
joint training objective CL+MD. We optimize
singletons,wedrops