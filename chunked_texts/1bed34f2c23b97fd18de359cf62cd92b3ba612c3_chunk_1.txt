Execution-Based Evaluation for Open-Domain Code Generation
ZhiruoWang♠,ShuyanZhou♠,DanielFried♠,GrahamNeubig♠♣
♠LanguageTechnologiesInstitute,CarnegieMellonUniversity
♣InspiredCognition
{zhiruow,shuyanzh,dfried,gneubig}@cs.cmu.edu
Abstract However, most resources with execution sup-
port only apply to closed-domain code, that only
To extend the scope of coding queries to
use Python built-in functions (Chen et al., 2021;
more realistic settings, we propose ODEX,
Hendrycksetal.,2021;Austinetal.,2021;Lietal.,
the first Open-Domain EXecution-based natu-
2022;Haluptzoketal.,2022)orspecificlibrariesin
ral language (NL) to Python code generation
dataset. ODEX has 945 NL-Code pairs span- datasciencedomains(Laietal.,2022;Huangetal.,
ning 79 diverse libraries, along with 1,707 2022). Thisfocusonclosed-domainproblemsdi-
human-written test cases for execution. Our vergessubstantiallyfromnaturalopen-domainpro-
NL-CodepairsareharvestedfromStackOver- gram usage covering a diverse range of libraries
flow forums to encourage natural and practi-
andfunctionalities(Yinetal.,2018;Agasheetal.,
calcodingqueries.Moreover,ODEXsupports
2019; Wang et al., 2022). To enable execution-
four natural languages as intents, in English,
basedevaluationforcodingqueriesusinglibraries,
Spanish, Japanese, and Russian. ODEX un-
we present ODEX, an Open-Domain EXecution-
veils intriguing behavioral differences among
top-performing code language models (LM). based dataset (§2). We build ODEX by creating
While CODEX achieves better overall results, 1,707 test cases for 945 NL-Code pairs from the
CODEGEN improves effectively via scaling – CoNaLa(Yinetal.,2018)andMCoNaLa(Wang
CODEGEN 6.1B performs comparably with
et