generalizationofthe
MED dataset [1] (exclude MEDTest 13 and MEDTest 14 neural network. We initialized h0 for encoder with zeros,
videos) which consists of 35,805 videos with duration of
while weights in input transformation layer are initialized
over 1,300 hours. The reason to choose MED dataset as
with a uniform distribution in [-0.01, 0.01] and recurrent
a source for temporal context learning is that videos in
weights are with uniform distribution in [-0.05, 0.05]. We
MED dataset have much longer duration, containing com-
setthemini-batchsizeto64andclipgradientelement-wise
plexandprofoundevents,actionsandobjectsforlearning. at 1 × 10−4. Frame sequences from different videos are
Wecollectdataapartfromourtargettaskdatasetsastolearn
sampled in each mini-batch. The network is optimized by
morepowerfulmodelandpractically,itisdifficulttotraina
RMSprop[35], whichscalesthegradientbyarunningav-
modelfromscratchinsuchasmalldatasetlikeTACoSwith
erageofgradientnorm. ThemodelistrainedbytheTorch
only 127 cooking videos. As frames in video are of high
library[6]onasingleNVIDIATeslaK20GPUandittakes
correlations in short range, we sample frames at the frame
about one day for the models to converge and finish the
rate of 1 fps. We use time span of 30 seconds and set the
training.
unrolllengthT to30forthepresentmodel(ModelI),15for
Inference.Atinferencetime,wefeedtheConvNetfeatures
bothpastmodel(ModelII)andfuturemodel(ModelIII).
extracted from GoogLeNet to the encoder, and obtain the
As for the input to GRU model, we use ConvNet fea-
videofeaturesfromhiddenstates. Foreachvideoclip, we
tures extracted from GoogLeNet [34] with Batch Normal- initializedh0 tozeros, andpassthecurrenthiddenstateto
ization [14] of dimension 1,024 which was trained from
thenextstepuntillastinput. Wethenaveragehiddenstates
scratchwithImageNet2012dat