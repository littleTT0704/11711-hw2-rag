emi-automatedpipelinetogenerate
apathologyVQAdatasetfrompathologytextbooks
A Experimentalsetup
andonlinedigitallibraries. Wemanuallycheckthe
Table3showsdatasetsplitstatistics. Weimplement automatically-generatedquestion-answerpairsto
the methods using PyTorch and perform training fix grammar errors. The automated pipeline con-
onfourGTX1080TiGPUs. sistsoftwosteps: (1)extractingpathologyimages
Webasicallyfollowtheoriginalmodelconfigu- andtheircaptionsfromelectronicpathologytext-
rationsusedin(TanandBansal,2019), (Kimetal., booksandthePathologyEducationInformational
2018),and(Yangetal.,2016). Dataaugmentation Resource(PEIR)DigitalLibrary3 website;(2)gen-
is applied to images, including shifting, scaling, eratingquestions-answerpairsfromcaptions.
andshearing. Fromquestionsandanswersinthe
B.1 ExtractingPathologyImagesand
PathVQAdataset,wecreateavocabularyof4,631
Captions
wordsthathavethehighestfrequencies.
Given a pathology textbook that is in the PDF
In Method 1, we use the default hyperparam-
format and available online publicly, we use
eter settings in (Tan and Bansal, 2019). For the
two third-party tools PyPDF24 and PDFMiner5
textencoder, thehiddensizewassetto768. The
to extract images and the associated captions
image features were extracted from the outputs
therefrom. PyPDF2 provides APIs to access
oftheFaster-RCNNnetwork,whichispretrained
on BCCD2 – a medical dataset containing blood the “Resources” object in each PDF page where
the “XObject” gives information about images.
cells photos, as well as on Visual Genome (Kr-
PDFMiner allows one to obtain text along with
ishnaetal.,2017). Theinitiallearningratewasset
its exact location in a page. To extract image
to 5e-5 with the Adam (Kingma and Ba, 2014a)
captions from text in each page,