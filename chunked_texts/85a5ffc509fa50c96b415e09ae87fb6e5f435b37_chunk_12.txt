 in labeling time and cost is justifiable to a
showsanexamplewherethemodelexplainsanim-
degree (echoing our intend of pushing people to
plicitlytoxic statementas harmlessand misleads
“think slow”). However, we do hope future work
content moderators (39.8% in MODEL-EXPL vs.
could look more into potential ways to improve
55.4%in NO-EXPL).
performancewhilereducingtimethrough,e.g.,se-
Onapositivenote,expert-writtenexplanations
lectively introducing explanations on hard exam-
still improve moderator performance over base-
ples(Laietal.,2023). Thisapproachcouldaidin
lines, highlighting the potential of our frame-
scalingourframeworkforeverydayuse,wherethe
work with higher quality explanations and serv-
delicatebalancebetweenswiftannotationandcare-
ing as a proof-of-concept of BIASX, while moti-
ful moderation is more prominent. On the other
vating future work to explore methods to gener-
hand,ourstudyfollowsasetofprescriptivemod-
ate higher-quality explanations using techniques
eration guidelines (Rottger et al., 2022), written
such as chain-of-thought (Camburu et al., 2018;
based on the researchers’ definitions of toxicity.
Weietal.,2022)andself-consistency(Wangetal.,
Whiletheyaresimilartoactualplatforms’termsof
2023)prompting.
serviceandmoderationrules,theymaynotreflect
5 ConclusionandFutureWork thenormsofallonlinecommunities. Customized
labeling might be essential to accommodate for
In this work, we propose BIASX, a collaborative
platform needs. We are excited to see more ex-
frameworkthatprovidesAI-generatedexplanations
plorationsaroundouralreadypromisingproof-of-
toassistusersincontentmoderation,withtheob-
concept.
jectiveofenablingmoderatorstothinkmorethor-
oughly about their decisions. In an online user
6 Limitations,EthicalConsiderations&
study,wefindthatbyaddingexplanations,humans
BroaderImpact
per