ubemapseverelydestroysthespatialrelationship strongabilityoftransformer(Vaswanietal.2017)tomodel
betweeneachfacewhichobstaclestheglobalunderstanding thecomplexrelationship,ithasachievedpromisingresultin
oftheframe. VSOD(Liuetal.2021;Renetal.2021b).
In this paper, we purpose a framework for audio-visual
salient object detection in panoramic scenarios. Consider- PanoramicSaliencyDetection
ing the rich spatial and semantic information encoded in Saliencydetectionaimstopredicttheregionofhumaneye
theambisonicaudios,wefirstuseapretrainedacousticen- fixation in the video. For image-level saliency prediction
coder to extract location and semantic embeddings of 3D (Cheng et al. 2018; Suzuki and Yamanaka 2018),(Cheng
soundsources,andthenintroduceaudio-visualcontextfu- etal.2018)proposeacubepaddingoperationtoprojectthe
sion(ACF)blockstoenhancethevisualfeaturesbyacoustic panoramic frame to a cube with fewer distortions on each
cues.Ideally,the3Dlocationofsoundsourcesshouldbeuti- face.(Zhu,Zhai,andMin2018)firstmaptheERframeto
lizedasground-truthtofinetunetheacousticnetworkwhile aspherethenpredictthesaliencyfromeachviewport.For
itisverydifficulttoobtainforcommonpanoramicvideos. video-levelsaliencyprediction(Chengetal.2018;Nguyen,
Totacklethisproblem,inspiredbylabel-guideddistillation Yan,andNahrstedt2018),Nguyenetal.(Nguyen,Yan,and
(Zhangetal.2022),theground-truthlabelofsalientobjectis Nahrstedt2018;Zhangetal.2018)proposesamethodthat
employedinthemultimodalfusionbyenforcingconsistency leveragesCNNandLSTMforsaliencyprediction.In(Zhang
betweenteacher(equippedwithlabel)andstudentbranch.By et al. 2018), spherical CNN is introduced to directly han-
learningbetteraudio-visualcorrespondence,w