.,2021;Oliveretal.,2018). The
mainchallengeofSSLliesinhowtoeffectivelyexploittheinformationofunlabeleddatatoimprove
themodel’sgeneralizationperformance(Chapelleetal.,2006). Amongtheefforts,pseudo-labeling
(Lee et al., 2013; Arazo et al., 2020) with confidence thresholding (Xie et al., 2020; Sohn et al.,
2020;Xuetal.,2021b;Zhangetal.,2021)ishighly-successfulandwidely-adopted.
The core idea of threshold-based pseudo-labeling (Xie et al., 2020; Sohn et al., 2020; Xu et al.,
2021b; Zhang et al., 2021) is to train the model with pseudo-label whose prediction confidence is
above a hard threshold, with the others being simply ignored. However, such a mechanism inher-
ently exhibits the quantity-quality trade-off, which undermines the learning process. On the one
hand, ahighconfidencethresholdasexploitedinFixMatch(Sohnetal.,2020)ensuresthequality
ofthepseudo-labels. However,itdiscardsaconsiderablenumberofunconfidentyetcorrectpseudo-
labels. AsanexampleshowninFig.1(a),around71%correctpseudo-labelsareexcludedfrom
thetraining. Ontheotherhand,dynamicallygrowingthreshold(Xuetal.,2021b;Berthelotetal.,
2021),orclass-wisethreshold(Zhangetal.,2021)encouragestheutilizationofmorepseudo-labels
butinevitablyfullyenrollserroneouspseudo-labelsthatmaymisleadtraining.Asanexampleshown
by FlexMatch (Zhang et al., 2021) in Fig. 1(a), about 16% of the utilized pseudo-labels are in-
correct. Insummary,thequantity-qualitytrade-offwithaconfidencethresholdlimitstheunlabeled
datautilization,whichmayhinderthemodel’sgeneralizationperformance.
Inthiswork,weformallydefinethequantityandqualityofpseudo-labelsinSSLands