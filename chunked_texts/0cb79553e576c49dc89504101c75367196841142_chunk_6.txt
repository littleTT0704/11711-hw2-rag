
MARCO 0.145 0.958 43.54 0.141 0.954 39.10
Original 0.351 – 58.46 0.344 – 88.79
CondBERT 0.202 0.961 69.51 0.190 0.961 131.12
SBF
ParaGeDi 0.186 0.921 179.88 0.192 0.923 99.96
MARCO 0.176 0.947 54.86 0.186 0.946 48.75
Original 0.563 – 205.73 0.578 – 220.42
Dyna CondBERT 0.288 0.954 190.51 0.293 0.950 200.20
Hate ParaGeDi 0.332 0.918 217.78 0.323 0.912 240.17
MARCO 0.274 0.939 110.50 0.277 0.936 128.84
Table1: AutomaticevaluationsondetoxifiedgenerationsonMAgr,SBF,andDynaHateforMARCO,ParaGeDi
andCondBERTacrossalldatasetsandsplits,MARCOachievesthelowesttoxicity,bestfluency,andsecond-best
BERTScore,whileCondBERTachievesthehighestBERTScore. Boldindicatesthebestmetric,andunderline
indicatesthesecond-bestmetricineachcolumnforeachdataset.
theyareindeedtoxic–toautoregressivelyproduce anti-expert than with the expert, the original to-
arewriteggiventheoriginalandmaskedsentences ken is most likely toxic and will be replaced in
w and wm. We transform the DEXPERTS (Liu the rewrite. On the other hand, if the differences
et al., 2021) framework, which leverages a PoE betweentheexpertandanti-expertarenotenough
to steer a model away from toxic generations by toswaythebasemodel,theoriginaltokenismost
ensemblingtokenprobabilities,toenablerewriting likelynon-toxicandwillbere-addedintherewrite.
byusingAE-LMs.
We obtain the next-token unnormalized log- 4 DetoxificationExperiments&Results