halftheperplexityimprovement,ormorethan
6.5%relativeimprovementcomparedtothebaseLM.
2
2 FormalizingandGeneralizingkNN-LM
kNN-LM(Khandelwaletal.,2020b)isalinearinterpolationbetweenabaseLMandakNNmodel. Givena
setofcontextsc andtheircorrespondingnexttokenw asapair(c,w )∈D,kNN-LMscreateadatastore
i i i i
(K,V)={(k,v )},asasetofkey-valuepairs:
i i
(K,V)={(f(c ),w )|(c,w )∈D} (1)
i i i i
Duringinference,theparametriccomponentoftheLMgeneratestheoutputdistributionp (w |c ;θ)over
LM t t
thenexttokensandproducesthecorrespondingcontextrepresentationf(c ),giventhetestinputcontextc.
t t
Thenthenon-parametriccomponentoftheLMqueriesthedatastorewiththef(c )representationtoretrieve
t
itsk-nearestneighborsN accordingtoadistancefunctiond(·,·). Next,thekNN-LMcomputesaprobability
distributionovertheseneighborsusingthesoftmaxoftheirnegativedistances,andaggregatestheprobability
massforeachvocabularyitemacrossallofitsoccurrencesintheretrievedtargets:
(cid:88)
p (w |c )∝ 1 exp(−d(k,f(c ))) (2)
kNN t t wt=vi i t
(ki,vi)∈N
Finally,thisdistributionisinterpolatedwiththeparametricLMdistributionp toproducethefinalkNN-LM
LM
distribution:
p(w |c ;θ)=(1−λ)p (w |c ;θ)+λp (w |c ) (3)
t t LM t t kNN t t
where λ is a scalar that controls the weights of the interpolation between two components, with higher λ
puttingmore