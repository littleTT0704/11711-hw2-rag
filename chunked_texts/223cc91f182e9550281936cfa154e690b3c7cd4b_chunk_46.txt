
in the sense that the auxiliary distribution q has a closed-form solution:1 at each iteration n,
q(n+1)(t) =p θ(n)(t)exp{f ϕ(n)(t)} / Z, (6.5)
where Z is the normalization factor. As shown in (Wu et al., 2020), the particular form of solution results in a
new variant of GANs that enables more stable optimization of the experience function (discriminator) f.
ϕ
Concretely, the discriminator f can now be optimized with importance reweighting:
ϕ
m ϕax−Et∼q(n+1) [f ϕ(t)]+Et∼p
d
[f ϕ(t)]
1 (6.6)
=− ZE t∼p(n)[exp{f ϕ(n)(t)}⋅f ϕ(t) ]+Et∼pd [f ϕ(t)],
θ
33
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
where importance sampling is used to estimate the expectation under
q(n+1),
using the generator
p(n)
as the
θ
proposal distribution. Compared to the vanilla and Wasserstein GANs above, the fake samples from the
generator are now weighted by the exponentiated discriminator score exp{f (t)} when used to update the
ϕ(n)
discriminator. Intuitively, the mechanism assigns higher weights to samples that can fool the discriminator
better, while low-quality samples are downplayed to avoid degrading the discriminator performance during
training.
Besides the generative adversarial learning, in Section 4 we briefly mentioned that many of the conventional
experience can also benefit from the idea of introducing adaptive or learnable components, for example, data
instances with automatically induced data weights or learned augmentation policies (Section 4.1.4). We discuss
more in Section 9.2 about how the unified SE as the basis can effortlessly derive efficient approaches for joint
model and experience optimization.
6.1.2. Online Experience From the Environment
Another form of dynamic experience comes from the changing environments, such as the data stream in online
learning (Sh