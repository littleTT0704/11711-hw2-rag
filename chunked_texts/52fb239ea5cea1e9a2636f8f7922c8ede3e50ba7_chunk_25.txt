-task
Data Answer(%F1) Program(%F1)
Neo Multi ∆ Neo Multi ∆ modelintheprogram-synthesissetting.
100% 28.4 32.3 +4.0 80.0 82.4 +2.5
40% 20.0 21.1 +1.2 75.2 70.3 -4.9 Mathability. Amongthetasksinthemathcate-
20% 15.8 18.4 +2.6 66.3 67.1 +0.8
gory,BHA¯SKARAexcelsinbasicmath,linearalge-
bra,andin-domainstatistics. Onthesetasks,itper-
Table 5: Here we show the results of fine-tuning
bothGPT-Neo-2.7B(Neo)andBHA¯SKARA(Multi)on formsequalorbettertoCodex. Ontheotherhand,
100%,40%,and20%oftheheld-outdatafrom L¯ILA- BHA¯SKARAstrugglesinadvancedmathandgeom-
OOD.TheMultialmostalwaysoutperformsNeo(the etry,withmediocreperformanceinmultiplication-
∆columnshowsthemargin). division, number theory, and calculus. Codex
showsanalogoustrends,exceptforperformingvery
0.6 Zero-shot Few-shot(3)
Model Dimension
GPT3 w/oInst w/Inst w/oInst w/Inst
0.5
Codex
Mathability 0.120 0.123 0.311 0.306
0.4 Language 0.124 0.131 0.352 0.350
Format 0.241 0.257 0.555 0.540
0.3 Knowledge 0.108 0.112 0.367 0.363
0.2 Average 0.148 0.156 0.396 0.390
0.1
Table 6: The IID scores for GPT-3 models with and
withoutinstructionprompting(Inst). Instructionhelps
0 1 3 max
slightlyinzero-shotsetting,butnotinfew-shotsetting.
Number of few-shot examples
Figure3: AverageF1scoresofGPT-3andCodexwith
differentnumbersoffew-shotexamplesin