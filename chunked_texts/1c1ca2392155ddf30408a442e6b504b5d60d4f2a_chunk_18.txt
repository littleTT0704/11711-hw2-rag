-base,BERT-large(Devlinetal.,
2019),RoBERTa-large(Liuetal.,2019),ALBERT-xxlarge(Lanetal.,2020),Delphi(Jiangetal.,
2021),3 whichistrainedonthe1.7MethicaljudgementsfromCommonsenseNormBank(CNB)
(Jiangetal.,2021),Delphi++,whichistrainedonCNBaswellas200Kextrasituationsprovided
by Delphi demo,4 GPT-3 (Brown et al., 2020), and InstructGPT (Ouyang et al., 2022). We also
includearandombaselineandabaselinethatalwayspredicts“no”(whichisthemajorityclass)for
allscenarios. Wereportallmodels’experimentaldetailssuchasthemodelparametersandprompt
templatesinAppendixB.1.
Metrics. Following the practice of Hendrycks et al. (2021b), we use the binary classification
evaluation metrics, where the two classes are permissible (1) and not permissible (0). We use
weightedF1scoreandaccuracyasourevaluationmetrics. SincethegoalofourMoralExceptQA
taskistoevaluatethemoralflexibilityofLLMs, wealsoreportthepercentageoftheerrorsthat
areduetodogmaticallyfollowingtheruleandpredicting“notpermissible,” i.e., #falsenegatives =
#allfalsesamples
#falsenegatives whichwedenoteastheconservativityscore(Cons.).
#falsenegatives+#falsepositives
Inadditiontofollowingthepreviouslyestablishedstandardusingbinaryclassificationformoral
judgments(Hendrycksetal.,2021b;Jiangetal.,2021),wealsocomplementthiswithamoresubtle
measure,whichcomparesmodelperformancetotheprobabilityofhumansubjectssayingthatthe
actionismorallypermissible. Wecomparethehumanprobabilitydatatothemodel’sprobability
distribution(implementationdetailsatAppendixB.1)usingmeanabsoluteerror(MAE)foreach
question,