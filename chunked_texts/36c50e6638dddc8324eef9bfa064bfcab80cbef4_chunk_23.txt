 Canary on PROSOCIALDIALOG via
directly address the task of responding to unsafe
humanjudgements(§6.2).
content through adataset of conversations where
a speaker disagrees with problematic utterances,
usingsafetylabelsandsocialnorms(RoTs). Tothe
bestofourknowledge,thisisthefirstlarge-scale
situationsrequiringhumanintervention(e.g.,emer-
multi-turndialoguedatasetfocusingonprosocial
gency)fromthoserequiringcarefulresponses(e.g.,
feedbacktounethicalandtoxiccontexts.
biased,unethical). ExperimentsshowedProst,di-
alogue agent trainedon our dataset, can navigate
8 Conclusion
problematiccontextsinamoreprosocialmanner.
Weintroduced PROSOCIALDIALOG,alarge-scale We also trained a dialogue safety model Canary
English dialogue dataset providing constructive thatoutputsrelevantrules-of-thumbwhenthecon-
feedbackforprosocialbehaviorsalignedwithcom- text is detected to be not casual. Human evalua-
monsensesocialrules(i.e.,rules-of-thumb)across tionshowedCanarycansignificantlyimprovethe
diverseproblematiccontexts. Weproposedanew prosocialityandoverallqualityoflargelanguage
three-tier dialogue safety schema to differentiate models’responsestoobjectionablecontexts.
9 SocietalandEthicalConsiderations culturesortimes,theoutputscanbesociallyunac-
ceptableinsomecases.
Precautions taken during dataset construction.
We also like to note that our RoT set does not
Since PROSOCIALDIALOG aims to include vari-
represent all general social rules in US, rather it
ousproblematiccontexts,wetakeextensivesafety
should be considered as a subset of those. Note,
precautions to protect our workers from possible
ourannotatorsareallfromasingleonlineplatform,
psychologicalharms. AlthoughweleverageGPT-
i.e.,AmazonMechanicalTurk(MTurk). Although
3 to generate the problematic utterances, simply
wethoroughlyverifyourdialoguesseveraltimes
beingexposedtothemforannot