 T-explainer parameters (Equation 5). Importantly, our
frameworkdoesnotmodifytheteacher,asourgoalistoexplainamodelwithoutchangingitsoriginal
behavior. Noticethatwealsosimplifytheproblembyconsideringthemoretractablesimulationloss
L siminsteadofthesimulabilitymetricSIM(S θ∗,T)aspartoftheobjectivefortheouteroptimization.
3
Now, if we assume the explainers E and E are differentiable, we can use gradient-based
φT φS
optimization[Finnetal.,2017]tooptimizeboththestudent(withitsexplainer)andtheT-explainer.
Inparticular,weuseexplicitdifferentiationtosolvethisoptimizationproblem. Tocomputegradients
forφ,wehavetodifferentiatethroughagradientoperation,whichrequiresHessian-vectorproducts,
T
anoperationsupportedbymostmoderndeeplearningframeworks[Bradburyetal.,2018,Grefenstette
et al., 2019]. However, explicitly computing gradients for φ through a large number of inner
T
optimizationstepsiscomputationallyintractable. Tocircumventthisproblem,typicallytheinner
optimizationisrunforonlyacoupleofstepsoratruncated gradientiscomputed[Shabanetal.,
2019]. Inthiswork,wetaketheapproachoftakingasingleinneroptimizationstepandlearningthe
studentandS-explainerjointlywiththeT-explainerwithoutresettingthestudent[Deryetal.,2021].
Ateachstep,weupdatethestudentandS-explainerparametersasfollows:
(cid:104) (cid:105)
θt+1 =θt−η ∇ E L (S,E,T,E,x) (6)
INN θ (x,y)∼Dˆ
train
student θt φt
S
φt
T
(cid:104) (cid:105)
φt+1 =φt −η ∇ E L (S,E,T,E,x). (7