outputforaninput,while
updatedmodelgivesthesamenewprediction
(2) satisfying other objectives like minimizing
asitdoesforx (averagedacrossx ).
i i
changesinpredictionsforotherdata. Mitchelletal.
(2021)focusonscalinguptheunderlyinghypernet- 3. Retain Rate (All Data): The proportion of
workarchitecture, whichisacomplementarybut theupdatedmodel’spredictionswhichareun-
orthogonalresearchdirectionthatisnotthefocus changedforalldatabesidestheMainInput.
of this paper. In a different approach, Kassner
etal.(2021)“update”modelbeliefsbyaddingin 4. ∆-Acc(AllData): Thechangeinaccuracyon
relevantinformationtotheinputattesttime. But allotherdatabesidestheMainInput.
thisapproachdoesnotchangethemodelweights
Inpractice,RetainRate(AllData)and∆-Accare
and hence does not influence model outputs
computedwithrandomsubsetsofadataset,since
on all other potentially relevant inputs. Lastly,
thesemustbecomputedaftereverybeliefupdate.
Meng et al. (2022) provide a specialized method
Weaddtwometricstothoseusedinpastwork:
focused on rank-one updates to MLP matrices in
Transformer-based LMs, but they do not address 5. Update Success Rate (Entailed Data): The
the problem of updating multiple model beliefs newmodel’saccuracyondatathatislogically
and do not measure model consistency under entailedbythenewMainInputprediction.
entailment or unintended corruption of local
6. RetainRate(LocalNeutral): Theproportion
neutralbeliefs(metrics(5)and(6)inSec. 3).
oftheupdatedmodel’spredictionswhichare
Visualizing factual beliefs in language models.
unchangedfordatathatissimilartotheMain
Wedonotknowofanypriorworkonvisualizing
Inputbutstilllogicallyneutral.
dependenciesbetweenfactualbeliefsinlanguage
models,althoughourapproachisnotablyinspired We use Update Success Rate (Entailed Data) to
