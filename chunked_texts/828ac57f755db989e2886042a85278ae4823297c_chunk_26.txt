9].
[14] S.IoffeandC.Szegedy. Batchnormalization: Accelerating
deepnetworktrainingbyreducinginternalcovariateshift.In
6.Conclusion
ICML,2015. 1,5
Unlike video captioning tasks which generate a generic [15] A. Karpathy and L. Fei-Fei. Deep visual-semantic align-
andsingledescriptionforavideoclip,weintroduceanap- ments for generating image descriptions. In CVPR, 2015.
proach of temporal structure modeling for video question 2
answering. Weutilizeanencoder-decodermodeltrainedin [16] R.Kiros,Y.Zhu,R.Salakhutdinov,R.S.Zemel,A.Torralba,
an unsupervised way for visual context learning and pro- R. Urtasun, and S. Fidler. Skip-thought vectors. In NIPS,
pose a dual-channel learning to ranking method to answer 2015. 5,6
questions. The proposed method is capable of modeling [17] D.KleinandC.D.Manning.Accurateunlexicalizedparsing.
videotemporalstructureinalongertimerange. Weevalu- InACL,2003. 3
ateourapproachonthreedatasetswhichhavealargenum- [18] A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet
berofvideos.Thenewapproachoutperformsthecompared classification with deep convolutional neural networks. In
baselines,andachievesencouragingquestionansweringre- NIPS,2012. 1
sults. [19] G.Kulkarni,V.Premraj,S.Dhar,S.Li,Y.Choi,A.C.Berg,
and T. L. Berg. Baby talk: Understanding and generating
References imagedescriptions. InCVPR,2011. 2
[20] R. Lebret, P. O. Pinheiro, and R. Collobert. Phrase-based
[1] TRECVID MED 14. http://nist.gov/itl/iad/ image