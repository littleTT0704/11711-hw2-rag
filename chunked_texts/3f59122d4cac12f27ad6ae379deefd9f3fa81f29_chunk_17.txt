
RoboticsandAutomation(ICRA),2018.
VII. CONCLUSIONS [15] A.ByravanandD.Fox,“Se3-nets:Learningrigidbodymotionusing
deep neural networks,” in Robotics and Automation (ICRA), 2017
We present an approach for inferring interpretable plans
IEEEInternationalConferenceon. IEEE,2017,pp.173–180.
from natural language and raw sensor input using prospec- [16] C. Finn and S. Levine, “Deep visual foresight for planning robot
tion. Our DREAMCELL architecture predicts future world motion,”inRoboticsandAutomation(ICRA),2017IEEEInternational
Conferenceon. IEEE,2017,pp.2786–2793.
statesfromlanguageandrawsensorobservations,facilitating
[17] T. Weber, S. Racanie`re, D. P. Reichert, L. Buesing, A. Guez, D. J.
highlevelplaninferencethatcanbeconvertedintolow-level Rezende,A.P.Badia,O.Vinyals,N.Heess,Y.Lietal.,“Imagination-
execution.Prospectionenablesend-to-endplaninferencethat augmented agents for deep reinforcement learning,” arXiv preprint
arXiv:1707.06203,2017.
is agnostic to the nature of sensory input and low-level
[18] A.Bosselut,L.Omer,A.Holtzmann,C.Ennis,D.Fox,andY.Choi,
controller modules. In the future, using this architecture to “Simulatingactiondynamicswithneuralprocessnetworks,”Interna-
bootstrap language understanding for execution on a real tionalConferenceonLearningRepresentations,2018.
[19] I. Lenz, R. A. Knepper, and A. Saxena, “DeepMPC: Learning deep
robot using sim-to-real transfer techniques could facilitate
latentfeaturesformodelpredictivecontrol.”inRobotics:Scienceand
end-to-end control on a physical platform. Systems,2015.
[20] R. Pascanu