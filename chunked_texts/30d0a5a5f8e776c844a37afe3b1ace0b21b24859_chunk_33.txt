,
directives describing 8K expert demonstrations av-
andistrainedwithbehaviorcloning(nDTW:0.3086).
eraging 50 steps each, resulting in >428K image-
In the first year, teams failed to surpass the perfor-
action pairs. Motivated by work in robotics on
mance of this baseline. However, a significant im-
segmentation-based grasping, agents in ALFRED in-
provementinSOTAwasattainedin2022;thetopsub-
teractwithobjectsvisually, specifyingapixelwisein-
mission(Reborn[8])producedannDTWof0.5543—
teraction mask of the target object. This inference
an 80% relative improvement over the baseline. This
is more realistic than simple object class prediction,
was enabled by an effective hierarchy of waypoint
wherelocalizationistreatedasasolvedproblem. Ex-
11https://ai.google.com/research/rxr/habitat istingbeam-searchandbacktrackingsolutionsarein-
15
feasibleduetothelargeractionandstatespaces,long 3.3.3 InteractiveInstructionFollowingwithDialog
horizon,andinabilitytoundocertainactions. Agents
Task-driven Embodied Agents that Chat (TEACh) is
are evaluated on their ability to achieve directives in
adatasetofover3,000human–human,interactivedi-
both seen and unseen rooms. Evaluation metrics in-
alogues and demonstrations of household task com-
clude: success rate (SR), success weighted by path-
pletion in the AI2-THOR simulator. Robots operat-
length(SPL),andGoal-Conditionsuccesswhichmea-
ing in human spaces must be able to engage in such
surescompletedsubtasks.
naturallanguageinteractionwithpeople,bothunder-
Currentstate-of-the-artapproachesinALFREDuse standing and executing instructions and using con-
spatial-semantic mapping [21, 119] to explore and versation[159,190]toresolveambiguity[131]andre-
build persistent representations of the environment coverfrommistakes. ACommanderwithaccesstoor-
before grounding instructions. These representations acle information about a task communicates in n