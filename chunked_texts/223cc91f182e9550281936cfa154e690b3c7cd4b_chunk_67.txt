 search spaces. The standard
equation that defines a structured algorithmic space would similarly suggest opportunities for automatic search
or optimization of learning algorithms, which is expected to be more efficient than direct search on the
programming code space (Real et al., 2020). We briefly discussed in Section 9 how new algorithms can
mechanically be created by composing experience and/or other algorithmic components together. It would be
significant to have an automated engine that further streamlines the process. For example, once a new advance
is made to reinforcement learning, the engine would automatically amplify the progress and deliver enhanced
functionalities of learning data manipulation and adapting knowledge constraints. Similarly, domain experts
can simply input a variety of experiences available into their own problems, and expect an algorithm to be
automatically composed to learn the target model they want. The sophisticated algorithm manipulation and
creation would greatly simplify machine learning workflow in practice and boost the accessibility of ML to
much broader users.
From Maxwell’s equations to General Relativity, and to quantum mechanics and Standard Model, “Physics is
the study of symmetry,” remarked physicist Phil Anderson (1972). The end goal of physics research seems to
be clear—a ‘theory of everything’ that fully explains and links together all physical aspects. The ‘end goal’ of
ML/AI is surely much more elusive. Yet the unifying way of thinking would be incredibly valuable, to
continuously unleash the extensive power of current vibrant research, to produce more principled
understanding, and to build more versatile AI solutions.
Disclosure Statement
Zhiting Hu and Eric P. Xing have no financial or non-financial disclosures to share for this article.
50
Harvard Data Science Review • Issue 4.4, Fall 2022 Toward a 'Standard Model' of Machine Learning
References
Abdolmaleki, A., Springenberg, J. T., Tassa, Y., Munos, R., Heess, N., & Riedmiller, M. (2018, April 30–May
3). Maximum a posteriori policy optimisation [Poster presentation]. 6th International Conference on Learning
Representations, Vancouver, BC, Canada. https://openreview.net/pdf?id=S1ANxQW0b
Altun, Y., & Smola, A. (2006). Unifying divergence minimization and statistical inference via convex duality.
