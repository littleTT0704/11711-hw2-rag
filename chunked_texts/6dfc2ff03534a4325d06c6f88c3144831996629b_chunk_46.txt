okensequences.20
WetrainedthismodelonfreelyavailableNLPcorpora. 0.6
We used the SNLI formalism [8], in which two sentences
arean‘entailment’ifthefirstentailsthesecond,‘contradic- 0.4
tion’ifthefirstiscontradictedbythesecond,and‘neutral’
Relevance Model
otherwise. We combined data from SNLI and MultiNLI 0.2
Worker
[82] as training data. Additionally, we found that even af-
0.0
tertrainingonthesecorpora,themodelwouldstrugglewith
3 2 1
paraphrases,sowealsotranslatedSNLIsentencesfromEn- 10 10 10
glishtoGermanandbackusingtheNematusmachinetrans-
lation system [81, 73]. These sentences served as extra
paraphrase data and were assigned the ‘entailment’ label.
Figure 13: Tuning the λ hyperparameter. Workers were
WealsousedrandomlysampledsentencepairsfromSNLI
askedtosolve100datasetexamplesfromthevalidationset,
asadditional‘neutral’trainingdata. WeheldouttheSNLI
asgivenbyAdversarialMatchingforeachconsideredvalue
validationsettodeterminewhentostoptraining. Weused
ofλ. Weusedtheseresultstopickreasonablevaluesforthe
standardhyperparametersforESIM+ELMoasgivenbythe
hyperparametersuchthatthetaskwasdifficultfortheques-
AllenNLPlibrary[22].
tionrelevancemodelP,whilesimpleforhumanworkers.
Given the trained model P, we defined the similarity rel
nli Wechoseλ=0.1forQ→ Aandλ=0.01forQA→R.
model as the maximum entailment probability for either
wayoforderingthetworesponses:
(cid:110) (cid:111)
P (r,r )=max P (ent|r,r ),P (ent|r,r), (3)
sim i j nli i j nli j i
where‘ent’refer