 ReportedT5-base 18.00 9.73 23.40
size=4 4,240 250 747 60 180 ReportedT5-Large 30.60 15.84 31.80
size=5 3,391 250 750 60 180 OurBART-base 28.30 15.07 30.35
OurBART-large 30.20 15.72 31.20
Table2:StatisticsofCommonGendatasetsplits. OurT5-base 31.00 16.37 32.05
OurT5-large 33.60 17.02 33.45
initialanalysis(§3.1)ofbaselinegenerationsshowsseveralis- Table 3: Comparing dev performance of our re-
O
suesrelatedtocommonsense,specificity,andfluency.Wehy- implementedmodelstothoseinLinetal.(2020).Boldrep-
pothesizethatthesecanbeaddressedthroughimagecaptions resents where we reach/exceed reported numbers. Results
(§3.2).Imagesrepresentingeverydayscenariosarecommon- averagedovertwoseedsforourmodels.Linetal.(2020)did
place,andtypicallylogicalandgroundedincommonsense. notreportBART-base.SeeAppendixAforallmetrics.
Captioning models can also normally produce decent cap-
tionsforeverydayimages,whichcanbeusedtoguideand
enhancethegenerationprocess.SeeTable1forexamples. tam,LawrenceZitnick,andParikh2015),SPICE(Anderson
Expoundingonthis,weuseapretrainedimagecaptioning etal.2016),andcoverage(cov).These(otherthancov)as-
modelonMSCOCOcaptions(Linetal.2014)tocaptionthe sesssimilaritybetweenhumanreferencesandgenerations.
topretrievedimagesforeachconceptset(§4.1,4.2).Weuse Inparticular,CIDErcapturesacombinationofsentencesim-
thesecaptionsasadditionalinformationtoaugmentinputs ilarity,grammaticality,saliency,importance,andaccuracy.
toourgenerationmodels(§4.3).Extensiveevaluation(§6) SPICEmapstextstosemanticscenegraphsand