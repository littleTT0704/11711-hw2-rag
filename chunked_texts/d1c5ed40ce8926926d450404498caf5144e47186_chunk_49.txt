
Ephyra 0.206 0.140 0.189 0.181
TREC 16
Median 0.131 0.085 0.118 0.108
Table 3.4: Evaluation results for Ephyra in the TREC 15 and 16 evaluations.
3. Semantic parsing. Asemanticparserandontologiesareusedtogenerateshallow
semantic representations of questions and sentences retrieved from the sources.
Thesemanticrepresentationsareessentiallypredicate-argumentstructuresaug-
mented with named entity information and related terms. Candidate answers
are extracted from sentences that match the semantic structure of the question.
Ephyra has been evaluated in the TREC 15 and 16 question answering tracks
[Dang et al., 2006, 2007]. In Table 3.4 we show evaluation results for different ques-
tion types and compare Ephyra to the median over all TREC participants. More re-
cently, Ephyra was released as open source software to the research community. The
open source version OpenEphyra is lightweight and platform-independent, and can
be downloaded from SourceForge4. OpenEphyra has been used by other researchers
as a framework for experiments with new QA algorithms [Bilotti and Nyberg, 2008,
Banerjee and Han, 2009], and it served as the basis for participations in cross-lingual
QA evaluations [van Zaanen, 2008, Dornescu et al., 2008]. In an internal evaluation
on 444 factoid questions from the TREC 11 dataset (excluding questions with no
known answers), OpenEphyra had an accuracy of 49%.
3.4.2 Watson and the DeepQA Architecture
Watson [Ferrucci et al., 2010] is a state-of-the-art question answering system devel-
oped at IBM Research for the Jeopardy! challenge. The system is based on IBMâ€™s
DeepQA architecture, a flexible QA framework that facilitates the development of
general and reusable QA technologies. The goal of the DeepQA effort is to achieve
high-performing results across a wide range of question types and domains that are
reproducible by the research community.
Figure 3.2 gives an overview of the DeepQA architecture. DeepQA differs from
common TREC systems such as Ephyra in many respects [Ferrucci et