 eralreasons. First,thestepitselfmightbesofine-
pair. Concretely,wefollowtheformulationofWu grained that further instructions are unnecessary
etal.(2019)toconstructtheinputofeachstep-goal (e.g. Go to a store). Second, although wikiHow
pairas: spansawiderangeofcomplexprocedures,itisfar
[CLS]ctx[ST]step[ED]goal[SEP] from comprehensive. Some goals simply do not
existinwikiHow.
where [ST] and [ED] are two reserved tokens
Hence, we design a mechanism to predict
in the vocabulary of a pretrained model, which
whetherastepislinkableornotexplicitly. More
markthelocationofthestepofinterest. ctxisthe
specifically,weaddaspecialtokenunlinkable,
context for a step (e.g., its surrounding steps or
itsgoal)thatcouldprovideadditionalinformation. 4 https://cutt.ly/oTx5gMM. BERTScoremeasuresthe
semantic similarity between a pair of texts, similar to the
3www.bing.com objectiveofourreranking.
takenfromthereservedvocabularyofapretrained Model R@1 R@10 R@30
model,asaplaceholder“goal”tothetop-k candi-
SP 35.8 64.4 72.5
dategoallistC(s),andthisplaceholderistreated SBERT 30.6 53.3 63.4
BM25(goalonly) 30.5 51.6 61.1
as the gold-standard answer if the step is deter-
BM25(article) 9.3 35.3 49.2
mined to be unlinkable. The similarity score be- BingSearch 28.0 47.9 -
tween a step and this placeholder goal follows
BERT 50.7 69.4 -
Equation 1 and sim (s,unlinkable) is set to
1 DEBERTA 55.4 71.9 -
the lowest first-stage similarity score among the −surr 54.3 71.6 -
−goal 55.0 71.5 -
candidategoalsretrievedbythefirst-stagemodel.
−