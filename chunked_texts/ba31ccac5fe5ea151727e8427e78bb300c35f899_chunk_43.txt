the al-
2007;SmithandSmith,2007;McDonaldandSatta,
gorithms for CRF-styled models (Lafferty et al.,
2007).
2001). Foraninputinstancex(forexample,asen-
tence), the model assigns a globally normalized Learningwithincompleteannotations. Follow-
probabilitytoeachpossibleoutputstructuredob- ing previous works (Tsuboi et al., 2008; Li et al.,
jecty (forexample,atagsequenceoraparsetree) 2016; Greenberg et al., 2018), for the instances
inthetargetspaceY: with incomplete annotations, we utilize the loga-
rithm of the marginal likelihood as the learning
exps(y|x)
p(y|x) = objective:
(cid:80) exps(y′|x)
y′∈Y
(cid:80) (cid:88)
exp s(f|x) L = −log p(y|x)
f∈y
=
(cid:80) y′∈Y(cid:80) f′∈y′s(f′|x) y∈YC
(cid:88) exps(y|x)
Here,s(y|x)denotestheun-normalizedrawscores = −log (cid:80)
exps(y|x)
assignedtoy,whichisfurtherfactorizedintothe y∈YC y∈Y
(cid:88)
sumofthesub-structurescoress(f|x).16 Inplain = −log exps(y|x)+logZ(x)
likelihoodtrainingforCRF,wetakethenegative
y∈YC
log-probabilityasthetrainingobjective:
Here,Y denotestheconstrainedsetoftheoutput
C
L = −logp(y|x) objectsthatagreewiththeexistingpartialannota-
= −s(y|x)+log (cid:88) exps(y′|x) tions. Inthisobjectivefunction,theseconditemis
exactlythesameasinstandardCRF,whilethefirst
y′∈Y
one