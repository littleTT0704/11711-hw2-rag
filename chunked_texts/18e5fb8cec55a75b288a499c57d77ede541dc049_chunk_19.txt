
dure,weobtainedthreejudgmentsforeachquestion.
ComparisonofQAGenerationStrategies Theinter-annotatoragreementonselectingthecorrectan-
Table3showstheresultswithdifferentsamplingstrategies, swer is 0.62 using Fleiss Kappa score, which is substan-
thus addressing H5. The best performing adversarial algo- tial agreement. The Kripendorf alpha (Krippendorff 2004)
rithm, Adv-answer, yields comparable accuracy to the ran- for rating question difficulty is 0.35, which is fair agree-
domstrategy,revealingthatdistractorssampledwithamore ment. The results of the baseline LMs and human perfor-
sophisticated strategy are not necessarily more informative mance (Table 5) show that the ATOMIC subset presents a
for the LMs. Adv-question and Adv-filter typically lead to harder challenge for both models, as well as for humans.
declines in accuracy. Considering Adv-question, this could Overall,theresultssupportourhypothesisH7:thesynthetic
be due to the similarity of the distractors to the question, questionsarerelativelyeasyforhumanstosolveandmuch
whichmightguidethemodeltolearntopickthemostdis- harderformodels.However,theannotationpointedtosev-
similarcandidateasthecorrectanswer,whichisanartifact eraldirectionsforimprovingthesyntheticQAsets.Anum-
of our question generation and cannot be expected to work ber of questions generated from ATOMIC are ungrammat-
wellfordownstreamtasks. Ourmanualinspectionofthere- ical, which makes them harder to understand, while some
mainingquestionspreferedbyAdv-filterindicatesthatmany questionsfromCWWVwereratedasunfair.Forexample,all
questionsareunfair,assomedistractorsarealsocorrectan- answer options for the question A person can are valid: (a)
swers,whichisaconsequenceoftheincompletenessofthe cost several thousand dollars (b) expressing boredom (c)
KGs. Adv-filterprioritizesthesequestionsastheyareâ€œdif- check snow level.