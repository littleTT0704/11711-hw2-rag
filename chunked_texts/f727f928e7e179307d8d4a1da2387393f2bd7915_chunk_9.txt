 Wecompute θ = θ(k)+ − g (x,yˆ,y,θ(k+j))
∗ ϕ i i i∗
themetricsusingdataofthekindshowninTable1.
j=0
X
Evaluation procedure. To date, methods have = Update(x i,yˆ i,y i∗,θ(k);ϕ,K)
been evaluated on the basis of their ability to
takingK smallstepsfrominitialparametersθ(k).
change model predictions for all data. Moreover,
thedesiredlabels y n onsequenceprediction De Cao et al. (2021) use such a loop at test time;
{ i∗ }i=1 we incorporate the loop into training to align the
taskshaveeachbeenselectedfromthemodel’spre-
trainandtest-timedistributions.
dictivebeamsearch(DeCaoetal.,2021;Mitchell
et al., 2021). We propose for evaluation to focus Learnedoptimizertraining. Thetrainingobjec-
onamorevaluablebutdifficultsetting: changing tive for KNOWLEDGEEDITOR includes differen-
thepredictionsonincorrectpointstobecorrect. tiabletermscorrespondingtoUpdateSuccessfor
theMainInputandparaphrases,aswellasRetain
Sequential updates. The standard evaluation in
Rate for all other data. We also consider terms
pastworkistoupdateasinglemodelbelief,evalu-
forUpdateSuccessonentaileddataandtheLocal
atethenewmodel,thenrollbacktheupdatebefore
Neutral Retain Rate, when this is possible given
repeating the process for each test point. We ob-
availabledata. Theoverallobjectiverequiressev-
tainsequentialversionsofallmetricsbyapplyingr
eralkindsofadditionaldataforeachpoint,which
modelupdatesinarowbeforecheckingthemetrics,
wedenoteby forotherrandomdata, for
meaningtherearefloor(n/r)measurementsfora R LN
D D
localneutraldata, forentaileddata,and for
test set of n points. We consider it important to E P
D D
paraphr