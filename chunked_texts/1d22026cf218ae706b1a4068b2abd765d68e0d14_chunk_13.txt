a
minimum-meansquareerrorshort-timespectralampli- Watanabe,S.,Hori,T.,Karita,S.,Hayashi,T.,Nishitoba,J.,
tudeestimator. IEEETransactionsonAcoustics,Speech, Unno,Y.,EnriqueYaltaSoplin,N.,Heymann,J.,Wiesner,
and Signal Processing, 32(6):1109–1121, 1984. doi: M.,Chen,N.,Renduchintala,A.,andOchiai,T. ESPnet:
10.1109/TASSP.1984.1164453. End-to-end speech processing toolkit. In Proceedings
of Interspeech, pp. 2207–2211, 2018. doi: 10.21437/
Gong, S., Dai, Y., Ji, J., Wang, J., and Sun, H. Emo- Interspeech.2018-1456. URLhttp://dx.doi.org/
tion analysis of telephone complaints from customer 10.21437/Interspeech.2018-1456.
based on affective computing. Computational In-
Xia,Y.,Chen,L.-W.,Rudnicky,A.,andStern,R.M. Tem-
telligence and Neuroscience, 2015. doi: 10.1155/
poral context in speech emotion recognition. In Proc.
2015/506905. URLhttps://www.ncbi.nlm.nih.
Interspeech,volume2021,pp.3370–3374,2021.
gov/pmc/articles/PMC4655047/.
Hsu, W.-N., Bolte, B., Tsai, Y.-H. H., Lakhotia, K.,
Salakhutdinov, R., and Mohamed, A. Hubert: Self-
supervised speech representation learning by masked
predictionofhiddenunits. IEEE/ACMTransactionson
Audio,Speech,andLanguageProcessing,29:3451–3460,
2021.
Kwasny, D. and Hemmerling, D. Joint gender and age
estimationbasedonspeechsignalsusingx-vectorsand
transferlearning,2020. URL