engeinmostrecentQAdatasetshasbeenthathuman-
writtenanswerscontainunexpectedbutdistinctbiasesthat
Wepresent,anewtaskthatchallengesvisionsys-
VCR
modelscaneasilyexploit. Oftenthesebiasesaresopromi-
tems to holistically and cognitively understand the con-
nent so that models can select the right answers without
tent of an image. For instance, in Figure 1, we need
evenlookingatthequestions[28,61,72].
to understand the activities ([person3 ] is delivering
Thus, we present Adversarial Matching, a novel QA
food), the roles of people ([person1 ] is a customer
assignmentalgorithmthatallowsforrobustmultiple-choice
who previously ordered food), the mental states of people
datasetcreationatscale.Thekeyideaistorecycleeachcor-
rectanswerforaquestionexactlythreetimes—asaneg- ([person1 ] wantstoeat),andthelikelyeventsbefore
ative answer for three other questions. Each answer thus andafterthescene([person3 ] willservethepancakes
has the same probability (25%) of being correct: this re- next). Ourtaskcoversthesecategoriesandmore: adistri-
solves the issue of answer-only biases, and disincentivizes butionoftheinferencesrequiredisinFigure2.
machines from always selecting the most generic answer. Visualunderstandingrequiresnotonlyansweringques-
Weformulatetheanswerrecyclingproblemasaconstrained tionscorrectly,butdoingsofortherightreasons. Wethus
optimization based on the relevance and entailment scores require a model to give a rationale that explains why its
between each candidate negative answer and the gold an- answer is true. Our questions, answers, and rationales are
swer, as measured by state-of-the-art natural language in- writteninamixtureofrichnaturallanguageaswellasde-
ferencemodels[10,57,15]. Aneatfeatureofourrecycling tection tags, like ‘[person2 ]’: this helps to provide
algorithm is a knob that can control the tradeoff between anunambiguous