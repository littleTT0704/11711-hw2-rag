otherand
wecantrainindividualmodels:questionanswering(Q→A)
the image context. For each position i in the response, we
willdefinetheattendedqueryrepresentationasqˆ iusingthe 8Ourcodeisalsoavailableonlineatvisualcommonsense.com.
5
Q→A QA→R Q→AR Model Q→ A QA→R Q→ AR
Model Val Test Val Test Val Test
R2C 63.8 67.2 43.1
Chance 25.0 25.0 25.0 25.0 6.2 6.2
Noquery 48.3 43.5 21.5
BERT 53.8 53.9 64.1 64.5 34.8 35.0 Noreasoningmodule 63.6 65.7 42.2
BERT(responseonly) 27.6 27.7 26.3 26.2 7.6 7.3 Novisionrepresentation 53.1 63.2 33.8
ESIM+ELMo 45.8 45.9 55.0 55.1 25.3 25.6
GloVerepresentations 46.4 38.3 18.3
LSTM+ELMo 28.1 28.3 28.7 28.5 8.3 8.4
Table 2: Ablations for R2C, over the validation set. ‘No
RevisitedVQA[38] 39.4 40.5 34.0 33.7 13.5 13.8
query’ tests the importance of integrating the query dur-
BottomUpTopDown[4] 42.8 44.1 25.1 25.1 10.7 11.0
MLB[42] 45.5 46.2 36.1 36.8 17.0 17.2
ingcontextualization;removingthisreducesQ→ARperfor-
MUTAN[6] 44.4 45.5 32.0 32.2 14.6 14.6 manceby20%. In‘noreasoning’,theLSTMinthereason-
ingstageisremoved;thishurtsperformancebyroughly1%.
R2C 63.8 65.1 67.2 67.3 43.1 44.0
Removing the visual features during grounding, or using
Human 91.0 93.0