TheThirty-SixthAAAIConferenceonArtificialIntelligence(AAAI-22)
Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense in
Text Generation Models
StevenY.Feng1,KevinLu2,ZhuofuTao3,MaliheAlikhani4,TerukoMitamura1,EduardHovy1,
VarunGangal1
1LanguageTechnologiesInstitute,CarnegieMellonUniversity2UniversityofWaterloo
3UniversityofCalifornia,LosAngeles4SchoolofComputingandInformation,UniversityofPittsburgh
syfeng@cs.cmu.edu,kevin.lu1@uwaterloo.ca,z24tao@g.ucla.edu,malihe@pitt.edu
teruko@cs.cmu.edu,hovy@cs.cmu.edu,vgangal@cs.cmu.edu
Abstract {stand,hold,umbrella,street} {food,eat,hand,bird}
Weinvestigatetheuseofmultimodalinformationcontained
inimagesasaneffectivemethodforenhancingthecommon-
senseofTransformermodelsfortextgeneration.Weperform
experimentsusingBARTandT5onconcept-to-textgenera-
tion,specificallythetaskofgenerativecommonsensereason-
ing,orCommonGen.WecallourapproachVisCTG:Visually baseline:Aholdsanumbrellawhilestandingonthestreet baseline:handofabirdeatingfood
GroundedConcept-to-TextGeneration.VisCTGinvolvescap- Vca isp Ct: Ta Gw :o Am wan omw aa nlk si tn ag ndd sow onn aa ss tt rr ee ee tt hh oo ll dd ii nn gg aa nn uu mm bb rr ee ll ll aa. capt V: ia sCpe Trs Go :n Aho bl id ri dng eaa tssm foa ol dlb fri ord min at hh ae nir d.hand
tioningimagesrepresentingappropriateeverydayscenarios, {cat,bed,pet,lay} {fence,jump,horse,rider}
andusing