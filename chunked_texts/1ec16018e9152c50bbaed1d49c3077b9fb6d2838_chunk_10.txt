)MeanReciprocalRank(â†‘)
arepartoftheknownevidence.
Figure 1: Alignment of GPT-2 (left) and GPT-Neo
Probes Needed (Zhong et al., 2019; Yin et al., (right)explanationstoknownevidenceaccordingtodot
2021b). We measure the number of tokens we product(top),probesneeded(middle),meanreciprocal
needtoprobe,basedontheexplanation,tofind rank(bottom)averagedoverlinguisticparadigms.
S
atokenthatisintheknownevidence. Thiscorre-
spondstotherankingofthefirsttokenx suchthat
i 4.3 Results
G = 1aftersortingtokensbydescendingsaliency.
i
WeuseGPT-2(Radfordetal.,2019)andGPT-Neo
Mean Reciprocal Rank (MRR). We calculate (Blacketal.,2021)toextractexplanations. GPT-
the average of the inverse of the rank of the first 2isalargeautoregressivetransformer-basedLM
tokenthatispartoftheknownevidenceiftheto- with 1.5 billion parameters and trained on 8 mil-
kens are sorted in descending saliency. This also lionwebpages. GPT-NeoisasimilarLMwith2.7
corresponds to the average of the inverse of the billion parameters and trained on The Pile (Gao
probesneededforeachsentenceevaluated. et al., 2020) containing 825.18GB of largely En-
187
glishtext. Inadditiontotheexplanationmethods GPT-2 GPT-Neo
4 GI: r=0.84 4
describedabove,wealsosetuparandombaseline GN: r=0.73
as a comparison, where we create a vector of the 3 E: r=0.62 3
same size as explanations with values randomly
2
sampledfromauniformdistributionover[0,1). 2 GI: r=0.56
1 GN: r=0.41
InFigure1,wecanseethatoverall,contrastive
1 E: r=-0.51
explanationshaveahigheralignment