
base(Wangetal.,2021). Modelswiththesubscript“off-shelf”aretheoff-the-shelfmodels,andthe
othermodelswerefinetunedwiththeobjectiveinEquation3. Thelastcolumnisthebestmodel
(RoBERTafortldrandCodeT5forCoNaLa)trainedwithouttheweaksupervisioncorpus.
n BM25 RoBERTa RoBERTa CodeT5 CodeT5 Bestw/oweaksup.
off-shelf off-shelf
1 32.81 17.53 30.03 10.45 18.10 28.30
5 51.73 37.89 52.50 20.26 38.52 50.50
tldr
10 59.86 46.80 60.33 25.73 51.03 59.84
20 62.01 56.11 64.30 33.65 57.26 62.30
1 3.01 4.46 13.49 4.60 16.54 10.51
5 7.16 7.58 26.38 8.63 42.35 21.15
CoNaLa
10 9.73 10.93 34.86 12.25 55.81 29.34
20 11.46 13.89 45.46 18.46 66.79 42.21
24%intldr.Thatis,oneofthereasonsthatretrievingdocumentationhelpsgeneratingaccuratecode
isthatdocumentationbridgesthegapbetweenthe“intentterminology”andthe“codeterminology”.
6.2 ABLATIONSTUDY
We compared different configurations of the retriever, to gather more insights for effective
DocPrompting. Table4showsacomparisonbetweendifferentretrieversandtheirsetups. First,the
performanceofBM25variesamongdatasets: Intldr,BM25matchestherecalloftraineddense
retrievers;howeverinCoNaLa,BM25achievesonlyrecall@10of9.73%,andstrongdenseretrievers
such as the encoder of CodeT5 achieve recall@10 of 55.81. We hypothesize that this difference
betweendatasetsstemsfromthewaysthesedatasetswerecreated: tldrintentswerewrittenbased
onexisting