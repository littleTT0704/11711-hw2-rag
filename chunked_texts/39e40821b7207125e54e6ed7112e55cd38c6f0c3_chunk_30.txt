 TST learns an thesamegraphcouldTheannotationsweredone
embeddingfunctionf suchthatforapairofexam- separately: thesamegraphcouldhavemorerele-
ples(x,y )and(x,y ),ify ∼ y ⟹ f(x ) ∼ vantnodes(higherrelevance)butmaynotbecor-
i i j j i j i
f(x ). For a new x, f(x) is used to retrieve the rect. Theidentityofthemodelthatgeneratedeach
j
closestexamplesfromD. graph(COCOGENorDAVINCI)wasshuffledand
unknowntotheevaluators.
We follow Poesia et al. (2021), and train a
TheresultsinTable11indicatethathumaneval-
knowledge-similaritytuner(KST). Weusempnet-
uation is closely correlated with the automated
5https://github.com/VHellendoorn/
metrics: for EXPLAGRAPHS,annotatorsfoundthe
Code-LMs#evaluation
6https://github.com/markriedl/ 7https://huggingface.co/microsoft/
WikiPlots mpnet-base
ISO GED Avg(d) Avg(∣V∣) Avg(∣E∣) BLEU ROUGE-L BLEURT
G 1.0 0.0 1.84 7.41 6.8 - - - -
COCOGEN+002(15) 0.53 2.1 1.79 7.44 6.7 25.24 38.28 -0.26
COCOGEN+002(15)+KST 0.52 1.99 1.8 7.45 6.7 25.4 38.4 -0.25
Table8: KSTonPROSCRIPTgeneration: Dynamicallycreatingapromptleadstomarginalimprovements.
StCA(↑) SeCA(↑) G-BS(↑) GED(↓) EA(↑)
COCOGEN+002 45.2 23.74 34.68 68.76 23.58
COCOGEN+002+KST 37.47 18.46 29.41 73.76 19.15
Table9