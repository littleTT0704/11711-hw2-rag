.06
L0 JTw/RTN 50.81 45.67 60.09 58.91 63.83 81.71 65.37 52.02 59.80
L12 JTw/RTN 64.41 50.2 73.83 63.87 68.7 85.88 71.92 58.6 67.18
Table11: ExperimentresultsforNERonXLM-R,JointTraining(JT)withRTN.(Allwith5kEnglishexamples)
Source Method qu cdo ilo xmf mhr mi tk gn average
(1) - target 58.44 26.77 63.39 32.06 53.66 82.90 52.53 46.01 51.97
JT 60.25 35.29 73.06 43.45 60.17 86.29 60.09 57.80 59.55
(2) English
MetaXL 63.76 38.63 76.36 45.14 60.63 88.96 64.81 54.13 61.55
Table12: NERresultsonmBERTwhereweuse5kEnglishexamplesasauxiliarydataandplaceRTNafter12th
layer.
NER(average) SA(tel) SA(fa)
#en JT MetaXL ∆ #en JT MetaXL ∆ #en JT MetaXL ∆
5k 59.55 61.55 +2.00 100 75.12 77.36 +2.24 100 74.25 75.78 +1.53
10k 62.36 63.66 +1.30 1k 74.76 76.39 +1.63 1k 74.71 75.58 +0.87
20k 62.39 63.38 +0.99 5k 74.07 78.15 +4.08 5k 74.81 76.69 +1.88
Table 13: F1 on various source language transfer data sizes on mBERT. # en denotes the number of English
examplesusedfortransfer. ∆denotestheimprovementofMetaXLoverthejointtrainingbaseline.
