asGPT-3.5-TurboandGPT-4demonstrate
tobecarefultoavoidprovidingincorrectanswers
improved performance in handling samples that
and,asaresult,generatelongerphrases. Withthat
involve false belief and transparent access (i.e.,
said,aswearguein§4.2,aLLMexhibitingrobust
thecontaineristransparent). Furthermore,nearly
N-ToMabilityshouldbeabletoanswerquestions
allmodelssincetext-davinci-002exhibitstrong
correctlyregardlessoftheprobingmethod.
performanceontruebelief samples. However,both
GPT-3.5-TurboandGPT-4experienceasubstantial
5.3 AreSpuriousCorrelationsaTrend?
decline in performance compared to their earlier
counterpartswhenitcomestotransparentaccess, In the previous experiment §5.2, we saw that the
latelabel(e.g.,theprotagonististheonewhowrote datasetscontainbothdifficultandeasyquestions.
7
isevenbelowthemajoritybaseline). Wealsocre-
atedAdv-CSFB,anewToMbenchmarkdesigned
touncoverwhetherLLMssolveToMquestionsfor
the right reasons, or merely rely on surface cues
andshallowheuristics.
So... DoLLMshaveToM? Ourresultsshowthat
whilesomedatasetshavebeensuccessfullysolved,
othersremainchallengingforLLMs. Thus,mod-
Figure4: ToMi’saccuracieswithdifferentsplitsofthe els do not have robust N-ToM abilities. These
dataset. While GPT-3.5 (the best-performing model)
findings are inconsistent with Kosinski (2023),
achievesatotalof0.7accuracyscore(seeFigure1),it
who claimed that ToM has emerged in LLMs as
achievesonly0.46onthesubsetquestions“falsebelief”.
abyproductoftheirdevelopment,aclaimfurther
echoed by Bubeck et al. (2023). We argue that
theseconclusionswereover-generalizedbased