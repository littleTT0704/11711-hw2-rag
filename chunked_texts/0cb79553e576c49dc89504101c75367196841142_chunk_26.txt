3×3×5×3 = 135
hyperparametercombinations,duetodatasetsize,
B.3 EvaluationMetrics
before choosing a final set to use on our test set.
In total, we rewrite approximately 240,000 texts. Toxicity To evaluate toxicity, we use the Per-
Since100generationstakeabout30seconds,we spective API, a publicly hosted toxicity classi-
useapproximately20GPUhours. fier trained on the Jigsaw corpus. Given a text,
themodeloutputsascalartoxicityscorebetween
Baselines Both of our baselines are available 0 and 1 inclusive. The model, which is lo-
onhttps://github.com/s-nlp/detoxasJupyterNote- cated at https://www.perspectiveapi.com/, is con-
books. WeadaptthemtoPythonfiles,runnablevia tinually updated and may change output over
thecommandline. Thereisnolicenseavailable. time. We query it in June, 2022, following
the API Terms of Service and intended use at evaluation. Theinterfaceforthisisthesameasour
https://developers.google.com/terms/. maintaskshowninFigure3,butwithsixsentences
insteadofone. Annotatorswhoansweratleastfive
Fluency We assess fluency by calculating the
outofsixquestionscorrectlyareapprovedandcan
perplexity of a text with an external, pretrained
work on the main task. We list the six examples
languagemodel. WeuseGPT2-base(Radfordetal.,
andcorrectanswersinTable11.
2019),foundathttps://huggingface.co/gpt2,with
Wepaidamedianwageof$8/hforthequalifi-
117Mparameters,anduseitundertheMITlicense
cationandthemaintask,whichisabovethemini-
anditsintendeduse.
mumwageandafairvalueforUSAandCanada.
We run this metric with a single NVIDIA
RTX6000GPU,whichtakesapproximately5sec- E DecodingwithProductofExperts
onds per 100 examples. With an estimate of
Hinton (2002) introduce the Product of Experts
450,000 texts processed, our usage for this met-
