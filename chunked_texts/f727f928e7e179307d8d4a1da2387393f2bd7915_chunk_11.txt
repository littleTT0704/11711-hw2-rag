 zsRE 69.5(1.1) - -
AdamW(LoshchilovandHutter,2019). Toobtain Wikidata5m 25.8(0.5) - -
update labels y n, we always use the oppo-
{ i∗ }i=1 Table2: Beliefmetricresultsacrossdatasets.
siteclassinbinaryclassification. Forsequence-to-
sequence tasks, we use the correct label when yˆ
i ParaphraseConsistency
↑
isincorrect,andwhenyˆ iscorrect,werandomly
i Dataset ModelIncorrect ModelCorrect
select another label from the training data. This
zsRE 61.39(1.33) 91.82(1.17)
choice is in contrast to De Cao et al. (2021) and
Wikidata5m 24.55(0.48) 37.20(2.06)
Mitchell et al. (2021), who use samples from the
Table3: Paraphraseconsistencybythecorrectnessof
modelbeamsearchasupdatelabelsforallpoints.
themodelpredictionontheMainInput.
SLAGobjective. Topreparetheupdatemethodfor
a sequential-update setting, we consider training fact. Wefilterthedatasothatthecontextfactsare
g ϕ to update multiple datapoints in a row. Using unique,thenshuffletheresulting14,939pointsinto
theper-datapointlossinEq. 1,weobtainourSe- train/dev/testsplitswith60/10/30%ofthedata.
quential,Local,andGeneralizing(SLAG)lossfor
InordertogetLocalNeutraldata,weconstruct
asetofr MainInputs = x,yˆ,y r as
D { i i i∗ }i=1 (4)asequencepredictiontaskusingWikidata5m,
r arelationalknowledgebasewithover20million
LSequential(ϕ; D,θ t)= L(ϕ;x i,yˆ i,y i∗,θ t+i) (2) triplets (Wang et al., 2021). Each input consists