? They're dead
anyway. Why bother? 6 I don't think it's too much to ask to call 911 if you watch someone
overdose on something. It's really importantto look out for others
by doing things like that.
(a) (b)
Figure 1: (a) Sample responses from existing state-of-the-art conversational models (Brown et al., 2020; Roller
etal.,2021;Zhangetal.,2022)toaproblematiccontext. (b)AnexampledialoguefromPROSOCIALDIALOG. At
each turn, the task is to (1) first determine dialogue safety labels (§3.3), (2) then infer relevant rules-of-Thumb
(RoTs)forproblematiccontexts,and(3)finallygenerateconstructivefeedbackbasedonRoTs(§3.2).
Weoperationalizethisprosocialintentwithcom- appropriate responses than other state-of-the-art
monsensesocialrulesorrules-of-thumb(RoTs),as languageanddialoguemodelswhenfacingprob-
responses should be grounded in communicative lematiccontexts(§5.2and§6.1). Empiricalresults
intents or goals (Clark and Brennan, 1991). For also demonstrate that Canary effectively guides
example, utterance 6 in Figure 1b is grounded in large-scalepre-trainedlanguagemodelstogener-
theprosocialintenttoremindtheotherofthesocial ate significantly more prosocial responses under
responsibility,“Youshouldlookoutforothers.” zero-shotsettings(§6.2).
To create PROSOCIALDIALOG, we set up a
2 ProsocialityandReceptivenessin
human-AI collaborative data creation framework
ConversationalAgents
(Figure 2), where GPT-3 generates the poten-
tiallyunsafeutterances,andcrowdworkersprovide We tackle the challenges of designing a chatbot
prosocialresponsestothem. Thisapproachallows thatcanrespondprosocially,safely,andethically
us to circumvent two substantial challenges: (1) toproblematicinputsbyincorporatingthreediffer-
therearenoavailablelarge-