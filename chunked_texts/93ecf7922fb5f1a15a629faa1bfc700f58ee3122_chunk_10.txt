GGmodeltoobtainfeaturesforthegeneratedim-
empirically realized that discriminator converged too fast.
age and the real image. We followed a similar pipeline as
Wetrainedthealphagenerationnetworkwithbatchsizeof
in [19] to decide the layers to extract features. After that,
oneasusingoneimageineachbatchcausesbetterconver-
wecalculatedaweightedsumoftheL1distancesbetween
gence [13]. Besides, we utilized Adam optimizer [25] for
featuresofthepredictedalphamatteandthegroundtruthal-
the training of both models. We trained the discriminator
phamatteforallextractedfeatures. Besides,weappliedthe
onestepforeveryfivestepsforthegeneratortraining.
samelossforgeneratedforegroundsubjectandgroundtruth
foregroundsubjectthatweobtainedbymultiplyingthein-
4.ExperimentalResults
putimagewithpredictedalphamatteandgroundtruthalpha
matte,respectively. Then,wefollowedthesamestrategyto DatasetsInordertotrainourmodel, weusedthecom-
extractfeaturesandcalculatetheperceptualloss. binationofAdobeImageMatting(AIM)[49]andDistinc-
For the alpha loss, we followed a different strategy and tions (D646) [36] datasets to employ more data as well as
calculatedtheL1distancebetweenthepixelsthathaveonly increasethediversity.Sincewefocusedontheportraitmat-
oneorzerovaluesinthepixeldomaininsteadofcalculating ting problem, we selected all images that contain persons
L1 distance between all pixels. The remaining pixels that for the training and test by following the same strategy in
haveneitheronenorzerovaluesareconsideredbydefining the portrait matting literature. In the end, there are 201
anotherlossbasedonL1distance. Thus,wepenalizedthe subjects in the AIM dataset and 363 subjects in the D646
Method Input Dataset MSE MAE SAD Grad Conn
BGM-V2[29] Image,background AIM 2.12 8.62 9.04 8.32 9.21
FBA[13] Image,tr