Uncovering Temporal Context for Video Question and Answering
LinchaoZhu§ ZhongwenXu† YiYang† AlexanderG.Hauptmann§
§SCS,CarnegieMellonUniversity
†QCIS,UniversityofTechnologySydney
{zhulinchao7,zhongwen.s.xu,yee.i.yang}@gmail.com alex@cs.cmu.edu
Abstract Task 2: Infer the past
He took out_-
In this work, we introduce Video Question Answering A.mango
in temporal domain to infer the past, describe the present B.knife
C.soda
andpredictthefuture. Wepresentanencoder-decoderap-
proach using Recurrent Neural Networks to learn tempo-
ralstructuresofvideosandintroduceadual-channelrank- Task 1: Describe the present
ing loss to answer multiple-choice questions. We explore He slices
approaches for finer understanding of video content using A.cucumber
question form of “fill-in-the-blank”, and managed to col- B.bowl
C.onion
lect 109,895 video clips with duration over 1,000 hours
D.bean
from TACoS, MPII-MD, MEDTest 14 datasets, while the
corresponding 390,744 questions are generated from an- Task 3: Predict the future'--
--
notations. Extensiveexperimentsdemonstratethatourap-
He _ cucumber on plate.
proachsignificantlyoutperformsthecomparedbaselines. A.throws -
B.places
C.wipes
D.rinses
1.Introduction
Figure1. Questionsandanswersaboutthepast,thepresentand
Current research into image analysis is gradually going thefuture.Oursystemincludesthreesubtasks,whichareinferring
beyond recognition [18] and detection [11]. There are in- the past, describing the present, and predicting the future, while
creasinginterestsindeeperunderstandingofvisualcontent onlythecurrentframesareobservable.Bestviewedincolor.
by jointly modeling image and natural language. As Con-
volutionalNeuralNetworks(ConvNets)haveraisedthe