rievescommonsenseknowledgesymbol-
wesystematicallystudyfactorsthatimpactprompt- icallyinatextformfromGPT-3fordownstream
baseddatagenerationandhighlightresearchques- taskswithhelpofsmallerfilteringclassifiers. We
tionsandchallengesinthevalue-alignedjudgement distill value-specific knowledge, not all abilities
taskthroughthoroughanalysis. of general language model, from LLMs through
value-alignedtrainingdatagenerationfortraining
smallervalue-alignedclassifiers. Thisreducesthe
costofhumanlabelingandalsoenablesbuilding
smallermodelsspecializedforvalue-alignedjudg-
menttask.
3 Value-AlignedJudgementTask
3.1 TaskDescription
Asanefforttoalignmachineswithhumanvalues, Figure 2: Illustration of the construction of our pro-
ourtaskfocusesonteachingthemodelthatdiffer- posed VA-MODEL. Using LLMs, we first create syn-
ent values can lead to different judgements even thetic value-aligned training data. Then, we transfer
given the same content. The task is formulated theknowledgeintosmallermodelsbyfine-tuningthem
onthedata,soValueAlignedModelscanmakevalue-
as follows. A model needs to make a judgement
alignedjudgements.
Y oncontentC basedonanexplicithumanvalue
V
V. In this work, “value” refers to any qualities,
standardsofbehavior,orbeliefsthatindividualsor
derstanding of sexism has been emphasized (Jha
societieshold,andisexpressedinnaturallanguage
andMamidi,2017;Sharifiradetal.,2018;Parikh
phrasesorsentences. Thesetofvaluesisexternally
et al., 2019). This aligns with our motivation for
definedbyahumanuserofthesystemorfromex-
explicit value-aligned judgement. Lastly, values
istingrelevantliteratureonmoralphilosophy,and
related to sexism are complicated, involving reli-
is independent of the development of algorithms.
gious,cultural,andpersonalbeliefsorvalues. We
Thedistinctionfromtheexistingvalue-alignedclas-
thusbelieveitisataskwithenough