 Language Detection. In
CommonsenseStories. InNAACL. NAACL.
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car- Hilary Silver. 1994. Social exclusion and social soli-
roll L Wainwright, Pamela Mishkin, Chong Zhang, darity: Threeparadigms. Int’lLab.Rev.,133:531.
SandhiniAgarwal, KatarinaSlama, AlexRay, etal.
2022. Training Language Models to Follow In- Eric Michael Smith, Mary Williamson, Kurt Shuster,
structions with Human Feedback. arXiv preprint Jason Weston, and Y-Lan Boureau. 2020. Can
arXiv:2203.02155. You Put it All Together: Evaluating Conversational
Agents’AbilitytoBlendSkills. InACL.
JamesWPennebaker,RyanLBoyd,KaylaJordan,and
Kate Blackburn. 2015. The Development and Psy- Miriah Steiger, Timir J Bharucha, Sukrit Venkatagiri,
chometric Properties of LIWC2015. Technical re- MartinJRiedl,andMatthewLease.2021. Thepsy-
port. chological Well-Being of content moderators: The
emotional labor of commercial moderation and av-
EthanPerez,SaffronHuang,FrancisSong,TrevorCai,
enuesforimprovingsupport. InCHI.
Roman Ring, John Aslanides, Amelia Glaese, Nat
McAleese, and Geoffrey Irving. 2022. Red Team-
Chloe Rose Stuart-Ulin. 2018. Microsoft’s politically
ingLanguageModelswithLanguageModels. arXiv
correct chatbot is even worse than its racist one.
preprintarXiv:2202.03286.
https://qz.com/1340990/microsofts-politically-
correct-chat-bot-is-even-worse-than-its-
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
racist-one/. Accessed: 2022-4-28.
Dario Amodei, Ilya Sutskever, et al. 2019. Lan-
guageModelsareUnsupervisedMultit