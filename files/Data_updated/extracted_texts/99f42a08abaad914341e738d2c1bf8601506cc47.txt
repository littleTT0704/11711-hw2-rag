IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 1
SphereFace Revived:
Unifying Hyperspherical Face Recognition
Weiyang Liu*, Yandong Wen*, Bhiksha Raj, Fellow, IEEE, Rita Singh, Adrian Weller
Abstract—Thispaperaddressesthedeepfacerecognitionproblemunderanopen-setprotocol,whereidealfacefeaturesare
expectedtohavesmallermaximalintra-classdistancethanminimalinter-classdistanceunderasuitablychosenmetricspace.Tothis
end,hypersphericalfacerecognition,asapromisinglineofresearch,hasattractedincreasingattentionandgraduallybecomeamajor
focusinfacerecognitionresearch.Asoneoftheearliestworksinhypersphericalfacerecognition,SphereFaceexplicitlyproposedto
learnfaceembeddingswithlargeinter-classangularmargin.However,SphereFacestillsuffersfromseveretraininginstabilitywhich
limitsitsapplicationinpractice.Inordertoaddressthisproblem,weintroduceaunifiedframeworktounderstandlargeangularmargin
inhypersphericalfacerecognition.Underthisframework,weextendthestudyofSphereFaceandproposeanimprovedvariantwith
substantiallybettertrainingstability–SphereFace-R.Specifically,weproposetwonovelwaystoimplementthemultiplicativemargin,
andstudySphereFace-Runderthreedifferentfeaturenormalizationschemes(nofeaturenormalization,hardfeaturenormalization
andsoftfeaturenormalization).Wealsoproposeanimplementationstrategy–“characteristicgradientdetachment”–tostabilize
training.ExtensiveexperimentsonSphereFace-Rshowthatitisconsistentlybetterthanorcompetitivewithstate-of-the-artmethods.
IndexTerms—Hypersphere,facerecognition,angularmargin,lossfunction
(cid:70)
1 INTRODUCTION
RECENT years have witnessed the tremendous success tive on a hypersphere [8]. Hyperspherical FR essentially
of deep face recognition (FR). Owing to the rapid focuses on answering the question: How to effectively and
developmentindiscriminativelossfunctions[1],[2],[3],[4], stablyincorporatelargeangularmargintofaceembeddings?
[5]thatpromotelargeinter-classfeaturemargin,theperfor- Large-margin softmax [1] is one of the first methods to
mance of deep FR has dramatically improved. These loss incorporatelargeangularmargintodeeplylearnedfeatures.
functions share a common goal to project deeply learned The core idea is to use a monotonically decreasing lower
face embeddings onto a hypersphere and incorporate large bound function ψ(θ (x,Wy)) to replace the target angular
geodesic inter-class margins. We call this series of deep FR activation cos(θ (x,Wy)) in the softmax-based loss function,
methodshypersphericalfacerecognition. where θ (x,Wy) denotes the angle between deep feature x
PreviousdeepFRmethods[6],[7]typicallytrainneural andtheclassifierofthetargetclassW y (y isthelabelofx).
networks by classifying identities in a training set. Such a The intuition is that the function ψ(θ (x,Wy)) will make the
training target largely deviates from the open-set testing angleθ (x,Wy) smallerinordertoachievethesamevalueof
(i.e., to determine whether two face images belong to the cos(θ (x,Wy)).Suchadesignwillencouragethedeepfeatures
sameperson)intwoaspects:(i)similaritymeasurediffersin to have large inter-class margins on the unit hypersphere.
trainingandtesting;(ii)open-settestingmustsolveametric Most popular hyperspherical FR methods [2], [3], [4], [5]
learningproblem[2]wherethegoalistolearnlarge-margin adoptthisdesignprinciple.
features,whiletrainingaimstosolveaclosed-setclassifica- Built upon [1], SphereFace [2] takes one step further
tion problem where the goal is to learn separable features. by explicitly constraining decision boundaries on the hy-
Motivatedbythemismatchbetweentrainingandtestingin persphere and simultaneously incorporating angular mar-
deep FR, hyperspherical FR aims to bridge the gap by (i) gins. Inspired by SphereFace, there is a series of work [3],
constraining the face embeddings on the hypersphere (i.e., [4], [5] that design alternative lower bound target func-
using cosine similarity for both training and testing), and tion ψ(θ (x,Wy)) to achieve angular margin. Based on how
(ii)incorporatinglargegeodesicmarginonthehypersphere. ψ(θ (x,Wy)) is constructed, loss functions in hyperspherical
Another motivation for hyperspherical FR comes from the FR can be divided into additive margin [3], [4], [5] and
observation that deep features are intrinsically discrimina- multiplicative margin [1], [2]. As a representative multiplica-
tive margin method, SphereFace renders promising geo-
metric insights. However, in contrast to additive margin,
• W.LiuandA.WellerarewiththeDepartmentofEngineering,University
SphereFace is known to be highly non-trivial to train, typi-
of Cambridge, United Kingdom. W. Liu is also with the Max Planck
Institute for Intelligent Systems, Tu¨bingen, Germany. A. Weller is also callyrequiringanumberofbellsandwhistlestostabilizeits
withTheAlanTuringInstitute,London,UnitedKingdom. training,whichlimitsitspotentialapplication.
E-mail:wl396@cam.ac.uk,aw665@cam.ac.uk Inordertoaddressthisshortcoming,wetakeadetourby
• Y.Wen,B.RajandR.SingharewiththeDepartmentofElectricaland
firstidentifyinganintrinsicconnectionthatbridgesdifferent
ComputerEngineering,CarnegieMellonUniversity,UnitedStates.
E-mail:yandongw@andrew.cmu.edu,{bhiksha,rsingh}@cs.cmu.edu margindesigns[1],[2],[3],[4],[5],[9]inhypersphericalFR.
• *W.LiuandY.Wenhavecontributedequallytothiswork. We formulate this connection with a unified large-margin
Acceptedforpublicationon1March2022 framework for hyperspherical FR. In this framework, we
2202
raM
61
]VC.sc[
3v56550.9012:viXra
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 2
summarize a general principle for any loss function to forhypersphericalFRmethodstoimprovethetrain-
achievelargeangularmargin.Followingthisprinciple,most ingstabilityandgeneralizability.
existing hyperspherical FR methods can be viewed as spe- • Toevaluatetheusefulnessoffeaturemagnitude,we
cial instantiations. This framework helps us gain a deeper comprehensively study SphereFace-R under three
understandingofhypersphericalFR,andservesasaportal differentFNschemes:NFN,HFNandSFN.
todesignnewlossfunctions. • Our paper comes with an easy-to-use codebase to
Under this unified framework, we extend our previous facilitate future research.1 It serves as a platform to
study of SphereFace [2] by proposing alternative yet effec- evaluatehypersphericalFRmethodsfairly.
tive ways to implement the multiplicative margin with im-
proved training stability and better empirical performance.
2 RELATED WORK
Specifically, the original realization of multiplicative mar- Deep face recognition. Deep face recognition has been an
gin in SphereFace is exact only when the angle between activeresearchareainthepastdecades.[6],[7],[11]address
the feature and the target classifier is sufficiently small. open-set FR using a convolutional neural network (CNN)
Whenthisangleislarge,themultiplicativemarginbecomes supervised by softmax-based loss, which essentially views
approximate and the original intuition no longer holds. open-setFRasamulti-classclassificationproblem.[12]com-
Motivated by this, we propose two novel variants that can bines contrastive loss and softmax loss to jointly supervise
exactly implement the intuition of multiplicative margin the CNN training, greatly boosting performance. [13] uses
for all possible angles. Along with the new multiplicative triplet loss and feature normalization to learn a unified
margins, we also propose a novel implementation strategy face embedding. After training on nearly 200 million face
which we call characteristic gradient detachment (CGD) that images, they achieve state-of-the-art performance. Inspired
helps to stabilize training and improve generalization. We by linear discriminant analysis, [14] propose center loss for
termourimprovedapproachSphereFace-R. CNNs and obtain promising performance. Prior to hyper-
Another significant difference between SphereFace and spherical FR, well-performing deep FR methods [13], [15],
otherhypersphericalFRmethods[3],[4],[5],[9]iswhether [16] were mostly built on either contrastive loss or triplet
feature normalization (FN) is performed. Based on the loss, validating the importance of solving open-set FR as a
empirical observation in [2], [8], we notice that feature metriclearningproblem[2].ThedevelopmentofdeepFRis
magnitude still contains some information such as image also closely related to deep metric learning [17], [18], [19],
quality. However, whether the information encoded in fea- [20],[21],[22],[23],[24],[25],[26],[27],[28].
ture magnitude is useful for FR remains an open question. Hypersphericalfacerecognition.Asamajorlineofresearch
Toaddressthis,weconsiderthreeschemeshere:nofeature indeepFR,hypersphericalFR[2],[3],[4],[5],[9],[10],[26],
normalization (NFN), hard feature normalization (HFN) [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39],
and soft feature normalization (SFN). HFN is identical to [40], [41], [42], [43], [44], [45], [46] has become increasingly
thepopularfeaturenormalizationusedin[3],[4],[5],[9].In popularinrecentyearsduetoitseffectiveness.[1]proposes
contrast,SFNformulatesthefeaturenormalizationobjective the initial framework of learning deep features with large
into a regularization term and optimizes it jointly with angular margin. Built upon this framework, SphereFace [2]
the neural network. Unlike HFN, SFN will take feature normalizes the classifier weights and explicitly models the
magnitude into account when training the neural network. decision boundary on the hypersphere. Feature normaliza-
This shares a similar spirit with [10]. While both FN-free tion [9], [29], [30] has also been introduced to facilitate the
learning and HFN can be viewed as limiting cases of SFN, learning of large angular margin face embeddings. To im-
SFN effectively unifies both approaches and serves as an provetrainingstability,CosFace[3],[4]andArcFace[5]pro-
interpolationbetweenthem.Weconductasystematicstudy pose to use additive angular margin to replace the original
toevaluatetheeffectivenessofallthreeFNstrategies. multiplicative margin in SphereFace and obtain impressive
Ourcontributionscanbesummarizedasfollows: performance.[36]and[37]consideradaptiveschemestoset
the radius of the hypersphere and the margin parameter,
• Wepresentaunifiedframeworktounderstandlarge respectively. [26], [40] study hyperspherical FR by taking
angular margin in hyperspherical FR. This frame-
theeasy-hardsamplebalanceintoconsideration.
workeffectivelyexplainshowandwhyangularmar-
Hypersphericallearning.Beyondfacerecognition,theidea
gin can be incorporated in SphereFace and further
of learning a representation on the hypersphere is also
summarizes a general principle for loss functions
showngenerallyusefulinadiversesetofapplications,such
to introduce large angular margin. Moreover, most
asfew-shotrecognition[47],[48],[49],[50],[51],deepmetric
of the current hyperspherical FR methods can be
learning [25], [52], self-supervised learning [53], [54], [55],
viewedasspecialinstantiationsofthisframework.
[56], generative models [57], [58], geometric learning [59],
• Under the unified framework, we substantially ex-
[60],[61],personre-identification[26],[62],[63],[64],speech
tend our previous work on SphereFace [2] by ad-
processing [65], [66], [67], [68] and text processing [69]. It
dressingtraininginstabilityandimprovingempirical
hasbeenwidelyobservedthatconstrainingtheembedding
performance. Compared to the original SphereFace,
spaceonahypersphereisbeneficialtogeneralizability.
SphereFace-R uses a more intuitive way to incor-
In contrast to hyperspherical FR methods that use an
porate the multiplicative margin and yields more
additive margin, SphereFace-R is built upon our previous
stable training, more clear geometric interpretation
work[1],[2]andadoptsamultiplicativemarginapproach.
andsuperiorgeneralization.
• WeproposeCGD,agenericimplementationmethod 1.SeeProjectOpenSphere:https://opensphere.world/.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 3
TABLE1
InstantiationsoftheUnifiedHypersphericalFaceRecognitionFramework.Grayregiondenotesourcontribution.
Method FeatureMagnitude Non-targetFunctionη(θ) TargetFunctionψ(θ) ∆(θ)(showninFig.1)
NormFace[9] HFN cos(θ) cos(θ) 0
CosFace[3],[4] HFN cos(θ) cos(θ)−m m
ArcFace[5] HFN cos(θ) cos(θ+m) cos(θ)−cos(θ+m)
SphereFace NFN[2]/HFN/SFN cos(θ) (−1)kcos(mθ)−2k,θ∈[kπ,(k+1)π],k∈N cos(θ)−(−1)kcos(mθ)+2k
m m
SphereFace-Rv1 NFN/HFN/SFN cos(θ) cos(min{m,π}·θ) cos(θ)−cos(min{m,π}·θ)
θ θ
SphereFace-Rv2 NFN/HFN/SFN cos(θ) cos(θ) cos(θ)−cos(θ)
m m
3 A UNIFIED LARGE-MARGIN LEARNING FRAME- As long as we guarantee that ∆(θ) is larger than zero,
WORK FOR HYPERSPHERICAL FACE RECOGNITION then the objective function in Eq. (3) will define a task that
can inherently introduce large angular margin. To see how
To gain deeper insights towards large angular margin, we
∆(θ)interactswiththelossfunction,wecanrewriteEq.(3)
presentaunifiedframeworkforhypersphericalFR.Tostart
inthefollowingmathematicallyequivalentform:
with,weconsiderthestandardsoftmaxcross-entropyloss:
(cid:18) exp(W(cid:62)x+b ) (cid:19) L =log(cid:16) 1+(cid:88) exp(cid:0) (cid:107)x(cid:107)(η(θ )−ψ(θ ))(cid:1)(cid:17)
L s =−log (cid:80)K i=1exp(y W i(cid:62)x+y b i) (1) g (cid:16) (cid:88)i(cid:54)=y (cid:0) i y (cid:1)(cid:17) (5)
where x ∈ Rd denotes the deep feature (the input of the =log 1+ exp (cid:107)x(cid:107)(η(θ i)−η(θ y)+∆(θ y))
classifier layer), y is its ground truth label, K is the total i(cid:54)=y
number of classes, W i ∈ Rd is the weights of the i-th which essentially aims to minimize η(θ i)−η(θ y)+∆(θ y).
classifier and b i is the bias for the i-th class. Note that here The term η(θ i)−η(θ y) represents the difference of classi-
weconsiderthecaseofasingleinputsampleforsimplicity; fication confidence, and the characteristic function ∆(θ y)
weonlyneedtoaveragethelossobjectivesifweconsidera controls the angular margin. When ∆(θ y) = 0 and η(·) is
mini-batchofinputsamples.Sincetheclass-dependentbias thecosinefunction,Eq.(5)reducestothestandardsoftmax
term is not informative in open-set evaluation, we follow loss with weight normalization. ∆(θ y) = 0 indicates that
the common practice to remove it [2]. Then we normalize no angular margin has been introduced. When ∆(θ y) > 0,
theclassifierweightstoone(i.e.,(cid:107)W i(cid:107) = 1,∀i)andrewrite this leads to large angular margin because it makes the
theobjectivefunctionasfollows: classification more stringent (i.e., the neural network will
(cid:18) exp(cid:0) (cid:107)x(cid:107)cos(θ )(cid:1) (cid:19) learn to make θ y smaller in order to reach the same loss
y
L s =−log (cid:80)K
exp((cid:107)x(cid:107)cos(θ ))
(2) valueasthecaseof∆(θ y)=0).Itisalsoworthmentioning
i=1 i thatwhen∆(θ y)<0,Eq.(5)definesaneasiertaskthanthe
whereθ i denotestheanglebetweendeepfeaturexandthe standardclassificationproblemandispotentiallyusefulfor
i-th classifier W i. By considering a generic angular activa- robust learning against noisy images or labels. Our paper
tion rather than the cosine function, we have the following focusesonthecaseof∆(θ y)>0.
generalizedobjectivefunction: We note that there exist scenarios where large angular
(cid:18) exp(cid:0) (cid:107)x(cid:107)ψ(θ )(cid:1) (cid:19) margin can still be achieved even if ∆(θ y) is smaller than
y
L g =−log (cid:0) (cid:1) (cid:80) (3) zeroinsomerangeofθ y ∈[0,θ].Forexample,∆(θ y)forAr-
exp (cid:107)x(cid:107)ψ(θ ) + exp((cid:107)x(cid:107)η(θ ))
y i(cid:54)=y i cFacecanbesmallerthanzerowhenθ yisclosetoπ.ArcFace
whereψ(θ y)istheangularactivationfunctionforthetarget canstillintroduceangularmarginbecausethecasewhereθ
y
class (i.e., ground truth label) and η(θ i),i (cid:54)= y denotes is close to π hardly happens with real data distribution, as
the angular activation function for the i-th non-target class verified by [5]. Nonetheless, the characteristic function for
(the labels excluding the ground truth one). Similar to the ArcFace still approximately satisfies our principle, since it
cosine function, both ψ(θ) and η(θ) are generally required is larger than zero with most θ y ∈ [0,θ]. Therefore, as long
tobemonotonicallydecreasingforθ ∈ [0,π].Afterlooking as the characteristic function ∆(θ y) is larger than zero for
into different hyperspherical FR methods, we summarize a the angles where θ y is densely distributed in practice (i.e.,
simpleyetgenericprincipleforanysoftmaxlossinorderto E θy∆(θ y) > 0), it will typically suffice to produce effective
learnembeddingswithlargeangularmargin. angular margin. Our principle in fact serves as a sufficient
conditiontointroduceangularmargin.Itisgenerallybetter
Toachievelargeangularmargin,thegenericprincipleis to use our principle as the guideline for designing new
tomakeψ(θ)alwayssmallerthanη(θ)in(0,π],namely angular margin losses, because the empirical distribution
of the target angle θ y could vary under difference circum-
∆(θ)=η(θ)−ψ(θ)>0 (4)
stances(e.g.,networkarchitectures,datasets,optimizers).
where we define ∆(θ) as the characteristic function We now discuss in depth why ∆(θ y) > 0 is able
for large angular margin. ∆(θ) determines most of the to introduce large angular margin. For ease of illustra-
tion, we consider the binary case where the first class
properties about theangular margin, such as thesize of
is the target class. In this case, we only need to discuss
themargin,itslearningstability,etc.
η(θ 2)−η(θ 1)+∆(θ 1).If∆(θ 1)=0,thedecisionboundary
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 4
0.7 0.7
2.5 2.5
0.6 0.6 (1) -(2) > (1) 00 .. 45 0.5 2 ( (1 1) ) - -( (2 2) ) < = ( (1 1) ) 2 s s s= = =0 1 1. .5 5
0.3 0.4 1.5 1.5 s=2
NormFace s=2.5
0.2 CosineFace 0.3 0.1 A Sprc hF era ec Fe ace 1 1 Easy Samples
0.2
-0.10 0.1 S S Sp p ph h he e er r re e eF F Fa a ac c ce e e- -R R v v1 2 0.5 0.5 Hard Samples
-0.2 0 0 0
0 0.5 1 1.5 2 2.5 3 0 0.5 1 1.5 2 2.5 3 0 1 2 3 4 5 0 0.5 1 1.5 2 2.5 3
Angle Angle Feature Magnitude s Angle 1
(a) Comparison between SphereFace (b) Comparison between SphereFace (a) Loss value vs. feature magnitude (b) Loss value vs. angle
and existing methods and SphereFace-R v1/v2 under different angular scenarios under different feature magnitude
Fig.1.(a)∆(θ)forcurrentrepresentativehypersphericalFRmethods. Fig.2.(a)Howthelossvaluechangesasfeaturemagnitudesincreases
(b)∆(θ)ofSphereFaceandSphereFace-R.Wesetmto0.4,0.5,1.4, underdifferentangularscenariosinEq.(7).Forthisfigure,weconsider
1.4and1.4forCosFace,ArcFace,SphereFace,SphereFace-Rv1and thebinarycasewhereθ1 = π/3(y = 1)andθ2 = π/2.Bothη(·)and
SphereFace-Rv2,respectively. ψ(·)arecosinefunction.(b)HowthelosscurveofEq.(6)variesunder
different feature magnitude s. For this figure, we consider the binary
casewherey=1andθ2=π/2.
for the first class is η(θ 2)−η(θ 1) = 0 which is equivalent
to θ 1 = θ 2. When θ 1 < θ 2, the sample x will be classified ical discriminativeness. By normalizing the feature magni-
to the first class. If ∆(θ 1) > 0 and η(·) is monotonically tudetoaprescribedpositiveconstants,Eq.(5)becomes
decreasing, then the decision boundary for the first class (cid:16) (cid:88) (cid:0) (cid:1)(cid:17)
becomes η(θ 2)−η(θ 1)+∆(θ 1) = 0 which is equivalent to L s =log 1+ exp s·(η(θ i)−η(θ y)+∆(θ y)) (6)
θ 1+m(θ 1)=θ 2wherem(·)denotessomepositivefunction i(cid:54)=y
(the specific form of m(·) is determined by η(·) and ∆(·), wheresisauniversalvalueinsteadoftheoriginalinstance-
but it stays positive as long as ∆(·) is always positive). dependent (cid:107)x(cid:107). There are two advantages of feature nor-
Therefore, now we need to make θ 1+m(θ 1) < θ 2 in order malization.First,itcaneffectivelyavoidpotentialbadlocal
to classify x to the first class, and the decision boundary minima. Second, it can help the loss function to better
forthefirstclassbecomesmorestringentthantheprevious balanceeasyandhardtrainingsamples.
case.Theneuralnetworkhastolearnsmallerθ 1 inorderto Forthefirstaspect,weconsiderEq.(6)inasimplebinary
correctly classify x and smaller θ 1 implies a more compact classification scenario (class 1 is the ground truth label for
representation for the first class. The same reasoning also thedeepfeaturex,i.e.,y = 1).Thelossvaluecaneasilygo
applies to the case where x belongs to the second class to zero once the deep feature x lies in the correct decision
(i.e., the second class is the target class). As a result, if we region,asdemonstratedinthefollowingequation:
can successfully train a neural network to correctly classify (cid:16) (cid:0) (cid:1)(cid:17)
training samples with these more stringent classification lim log 1+exp s·(η(θ 2)−η(θ 1)+∆(θ 1))
s→+∞
c mri at re gr ii na, fo∆ r( tθ h1 e) le> arn0 ec dan dee ef pfe fc et aiv tue rly es.produce large angular   0 if η(θ 1)−η(θ 2)>∆(θ 1) (7)
Importantly,currentpopularhypersphericalFRmethods
=

+− ∞log 21 i if
f
η η( (θ θ1 1) )− −η η( (θ θ2 2) )<= ∆∆ ((θ θ1 1)
)
can be viewed as special cases under this unified frame-
work, as shown in Table 1 (first four rows). To intuitively whereη(θ 1)−η(θ 2)>∆(θ 1)meansthatxcanbecorrectly
understand different variants of angular margin, we also classified,η(θ 1)−η(θ 2)=∆(θ 1)meansthatxexactlylieson
compare their characteristic functions ∆(θ) in Fig. 1(a). thedecisionboundaryandη(θ 1)−η(θ 2)<∆(θ 1)meansthat
One can observe that different hyperspherical FR methods xcannotbecorrectlyclassified.Theresultsimplythatwhen
yield different large-margin characteristic functions. Each xcanbecorrectlyclassified,atrivialsolutiontoreduceloss
characteristicfunctiondetermineshowahypersphericalFR to zero is to simply increase s. However, increasing s does
method performs and therefore it is of great significance not help the neural network learn angularly discriminative
to design a suitable characteristic function. Specifically, the face embeddings and results in bad local minima. Because
characteristic function ∆(θ) clearly reveals the induced an- (cid:107)x(cid:107) can be viewed as an instance-dependent learnable s,
gular margin for samples with different recognition hard- the neural network without feature normalization is likely
ness (larger θ y typically implies a harder sample). Instead tosimplyincrease(cid:107)x(cid:107)afterθ 1passesthedecisionboundary.
ofastaticcharacteristicfunction,designingadynamicchar- Therefore,usingaconstantscanpreventthistrivialwayof
acteristic function could be beneficial [37], [40]. It is also reducing loss value and eliminate these bad local minima.
possibletolearnthecharacteristicfunctioninadata-driven We also plot how the loss value changes as s increases in
andautomaticfashion,asexploredin[70],[71]. Fig. 2(a). The same argument can easily generalize to the
Besidesthecharacteristicfunction∆(·),thefeaturemag- multi-classscenario,asshownin
nitude (cid:107)x(cid:107) in Eq. (5) also plays a non-negligible role in (cid:16) (cid:88) (cid:0) (cid:1)(cid:17)
lim log 1+ exp s(η(θ )−η(θ )+∆(θ ))
i y y
learninglargeangularmargin.TheoriginalSphereFaceap- s→+∞
i(cid:54)=y
proach preserves the feature magnitude in training, since (cid:26) (8)
the feature magnitude does not affect the angular decision =
0 if ∀i(cid:54)=y, η(θ y)−η(θ i)>∆(θ y)
boundary. [3], [4], [5], [9], [29] show that normalizing the
+∞ if ∃i(cid:54)=y, η(θ y)−η(θ i)<∆(θ y)
featuremagnitudetoaconstants(e.g.,makingx←s x in where s has a large influence on the loss value. For the
(cid:107)x(cid:107)
Eq.(5))canstabilizetrainingandalsoimprovehyperspher- multi-class scenario, the neural network can trivially in-
)( noitcnuF
citsiretcarahC
)( noitcnuF
citsiretcarahC
eulaV noitcnuF
evitcejbO
eulaV noitcnuF
evitcejbO
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 5
c ar llea is (cid:54)=es yt .o Inm tein reim sti iz ne glt yh ,e thlo isss ao lsn oce exη p(θ lay i) n−
s
wη( hθ yi) t> he∆ st( aθ ny d) af ro dr θ1=θ2 Classifier W1
softmax loss cannot learn deep features with large angular
W1 W2 Classifier W2
Angular Margin
margin. Empirically the standard softmax loss tends to in-
creasesinsteadofminimizingthetargetangleoncethedeep Decision boundary for Class 1
x
featurexfallsintothecorrectdecisionboundary,leadingto Decision boundary for Class 2
separablefeaturesratherthanlarge-marginfeatures.Large-
θ1 θ2
Samples from Class 1
θ12
marginlossestakeadvantageofthisphenomenonandmake Samples from Class 2
(a) No Angular Margin
thedecisionboundaryasymmetricfordifferentclasses(i.e.,
η(θ) (cid:54)= ψ(θ)). Then the classification of x (i.e., forcing
ψ(θ y) > η(θ i),∀i (cid:54)= y) naturally becomes equivalent to 2sin- 1( 2 s in m ( θ 2 12 ) ) m
learninglarge-margindeepfeatures. W1 W2 W1 W2
Forthesecondaspect,weuseanexampletodemonstrate
howthefeaturemagnitudescanbalancetheeasyandhard
samples. We compare the loss function under different s
in Fig. 2(b). By adjusting s, the loss function in Eq. (6)
has different sensitivity for samples with different target cos(θ1)−m=cos(θ2) cos(θ1)=cos(θ2)−m θ1+m=θ2 θ1=θ2+m
angle θ y. Intuitively, samples with large target angle are CosFace ArcFace
considered to be hard, while samples with small target (b) Additive Angular Margin
angle are viewed as easy. Therefore, feature magnitude s
c wa hn ica hlso seb rva ela sn ace roth lee sl io mss ilav ral tu oe hf ao rr dea ss ay ma pn led mha inrd ingsa [m 21p ]le is n, m m− +1 1θ12 mm +−1 1θ12
W1 W2 W1 W2
deep metric learning. From Fig. 2(b), one can observe that
largersputsmorefocusonthehardsamples,sincetheloss
ratio between hard and easy samples increases. Finding a
goodsessentiallycanbeviewedassearchingforasuitable
balance between easy and hard samples in hyperspherical mθ1=θ2 θ1=mθ2 θ1=θ2/m θ1/m=θ2
FRmethods,e.g.,[3],[4],[5],[9]. SphereFace, SphereFace-R v1 SphereFace-R v2
Tosummarize,Eq.(6)essentiallythrowsawaytheinfor-
(c) Multiplicative Angular Margin
mationencodedinthefeaturemagnitudex.Despitethetwo
major advantages that ease the training of hyperspherical Fig. 3. An intuitive comparison among no angular margin (e.g., [9],
FR methods, it remains an open problem whether it is [30]), additive angular margin (CosFace [3], [4] and ArcFace [5])
andmultiplicativeangularmargin(SphereFace,SphereFace-Rv1and
beneficialtocombinefeaturemagnitudetotraining.Feature
SphereFace-Rv2).
magnitude is closely related to image quality and semantic
ambiguity [8], [72], and such information intuitively seems
useful to distinguish different faces. However, training activation function. SphereFace adopts the same paradigm
hyperspherical FR methods without feature normalization byconstructingthefollowingtargetangularfunctionψ(θ):
generallyyieldsinferiortrainingstabilityandgeneralization (cid:20)kπ (k+1)π(cid:21)
performanceinpractice.Inordertoexplorewhetherfeature ψ(θ)=(−1)kcos(mθ)−2k, θ ∈ , (9)
m m
magnitudeisindeedhelpfulornot,weconsidertoconstrain
thefeaturemagnitudeviaasoftregularizationinSection4.2. where k ∈ [0,m − 1] and k is an integer. After ensuring
This serves as an interpolation between no feature normal- η(θ)=cos(θ)andEq.(9),Eq.(5)becomestheobjectivefunc-
ization and hard feature normalization, and can take the tion for the original SphereFace, as summarized in Table 1.
featuremagnitudeintoaccountduringtraining. The original SphereFace requires m to be an integer, which
is in fact unnecessary. m can be any positive value larger
4 SPHEREFACE-R: BETTER AND MORE STABLE than 1. In order to improve training stability, our original
SphereFace minimizes its objective function (with m = 4)
Inthissection,weelaboratethedesignofSphereFace-Rand
jointly with a standard softmax loss, which approximately
introduce two novel variants that perform well in practice.
yields an effective m as 1.4. Therefore, the target angular
Sharing the same geometric interpretation as SphereFace,
functionintheoriginalSphereFacecanbesimplifiedto
SphereFace-R yields improved training stability and supe-
rior open-set generalizability. We start by revisiting the de- (cid:26) cos(mθ) if 0≤θ ≤ π
signoftheoriginalSphereFaceandthenproposealternative ψ(θ)= −cos(mθ)−2 if π <θ ≤m π (10)
m
waystoimplementthemultiplicativemargininSection4.1.
whereweusuallyusem ∈ [1,2].Onecaneasilyverifythat
In Section 4.2, we discuss different feature normalization
the characteristic function ∆(θ) is always larger than zero
schemes.Finally,welistafewimportantopenproblemsfor
with θ ∈ (0,π], so it satisfies the general principle to intro-
hypersphericalFRinSection4.3.
duce large angular margin. Fig. 3 intuitively compares no
angularmargin,additiveangularmarginandmultiplicative
4.1 RethinkingMultiplicativeAngularMargin
angular margin. The intuition of multiplicative margin can
AshasbeenshowninTable1,alltheprevioushyperspher- be understood from a simple binary classification example
ical FR methods focus on designing a good target angular (withtwoclassifiersW 1 andW 2).WeconsiderEq.(3)with
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 6
η(θ) = cos(θ) and ψ(θ) = cos(θ). For a sample x, we need exactly the same as SphereFace and perfectly implements
torequirecos(θ 1)>cos(θ 2)tocorrectlyclassifyx.Butwhat the multiplicative margin. For θ ∈ [ mπ,π], we consider a
if we instead require cos(mθ 1) > cos(θ 2) where m > 1 new multiplicative margin parameter m(cid:48) and the target
in order to correctly classify x? It is essentially making the angular function becomes ψ(θ) = cos(m(cid:48)θ). In order to
decision more stringent than previous, because we require (i) make m(cid:48) as large as possible and (ii) make ψ(θ) a
a lower bound2 of cos(θ 1) to be larger than cos(θ 2). The monotonic decreasing function where m(cid:48)θ does not exceed
decision boundary for class 1 is cos(mθ 1) = cos(θ 2). Simi- π, we propose an adaptive decreasing strategy for m(cid:48):
larly, if we require cos(mθ 2) > cos(θ 1) to correctly classify m(cid:48) = π θ. Combining pieces, we end up with a dynamic
samples from class 2, the decision boundary for class 2 multiplicative margin parameter m(cid:48) = min{m,π}. The
θ
is cos(mθ 2) = cos(θ 1). Suppose all training samples are non-target angular function is the same as SphereFace,
correctly classified, such asymmetric decision boundaries i.e., η(θ) = cos(θ). Therefore, the multiplicative margin is
will naturally produce an angular margin of size m m− +11θ 12 implementedthroughψ(θ)=η(m(cid:48)θ).Thecurveofthecor-
where θ 12 denotes the angle between W 1 and W 2. From respondingcharacteristicfunction∆(·)isgiveninFig.1(b).
angular perspective, correctly classifying x from identity 1 More interestingly, we can observe that SphereFace-R v1
requires θ 1<θ m2, while correctly classifying x from identity incorporates less angular margin to samples that are too
2requiresθ 2<θ m1.Ifm > 1,bothdecisioncriteriaaremore easy or too hard (i.e., the target angle is around 0 or π)
difficulttoachievethanthevanillacasewithoutanyangular and combines the largest angular margin to samples with
margin(i.e.,θ 1 <θ 2 andθ 2 <θ 1). medium hardness. We also compare SphereFace-R v1 with
WecanobservethatEq.(10)canexactlymatchtheintu- theotherhypersphericalFRmethodsinTable1.
ition of multiplicative margin only when θ ∈ [0, π]. When Despite the well implemented multiplicative margin in
m
θ ∈ (π,π], the same argument however will no longer Eq.(11),thereisstillaconstraintontheeffectivemultiplica-
m
hold.Althoughsuchaheuristicdesigncanstillempirically tive margin parameter m(cid:48), i.e., m(cid:48) ≤ π. Moreover, we have
θ
achieve large angular margin and work reasonably well, it
noconsistentm(cid:48)inEq.(11)forsampleswithdifferenttarget
may inevitably be less interpretable and also contribute to angle.Itindicatesthatforanarbitrarysamplewhosetarget
the training instability. The key to multiplicative angular angle is within [0,π], SphereFace-R v1 can not guarantee
margin is to guarantee that the equation ψ(θ) = η(mθ) the same m(cid:48). To address this limitation, we propose to
(m > 1) always holds for θ ∈ [0,π]. In order to better im- implement the multiplicative margin from the perspective
plement the intuition of multiplicative margin, we propose of the non-target angular function rather than the target
twodifferentapproaches,i.e.,designingeitheranewtarget angularfunction,leadingtoSphereFace-Rv2.
angularfunctionψ(θ)oranewnon-targetfunctionη(θ).In
Section4.1.1,wefirstfollowtheoriginalideaofSphereFace 4.1.2 SphereFace-Rv2:OnDesigningη(θ)
tore-designatargetangularfunctionψ(θ)whichcanbetter Weconsiderhowtodesignthenon-targetangularfunction
reflecttheintuitionofmultiplicativemargin.InSection4.1.2, η(θ) based on the intuition of multiplicative margin. To
wetakeadifferentapproachbydesigninganewη(θ)which achieveψ(θ) = η(mθ)withoutchangingthetargetangular
hasamuchsimplerformyetcanexactlymatchtheintuition function ψ(θ), we can naturally arrive at the following
of multiplicative margin for θ ∈ [0,π]. Section 4.1.3 pro- desirednon-targetangularfunctionη(θ):
poses a useful implementation method to further stabilize (cid:18) θ (cid:19) (cid:18) θ (cid:19)
training.Section4.1.4givesimplicationsanddiscussions. η(θ)=ψ =cos (12)
m m
4.1.1 SphereFace-Rv1:OnDesigningψ(θ) where m is a prescribed positive constant and ψ(θ) =
Following the conventional way to design an angular mar- cos(θ).ComparedtoEq.(11)inSphereFace-Rv1,Eq.(12)is
gin loss [2], [3], [4], [5], we first focus on constructing much simpler and more importantly, satisfies the property
a target angular function ψ(θ) based on the intuition of ofψ(θ) = η(mθ)forθ ∈ [0,π]withastaticm.Whilebeing
multiplicative margin. For θ ∈ [0, π], we can simply extremely simple and conceptually appealing, SphereFace-
m
use ψ(θ) = cos(mθ) which is a monotonically decreasing R v2 can also exactly incorporate a static multiplicative
function in [0, π] and exactly implements the multiplica- angular margin. In contrast, SphereFace-R v1 is unable to
m
tive angular margin. When θ > π, SphereFace constructs induce a static multiplicative margin with m > 1 and can
m
a surrogate monotonically decreasing function to replace only incorporate a dynamic multiplicative margin where
cos(mθ), as specified in Eq. (10). However, this design of the effective margin parameter has to be close to 1 if θ is
ψ(θ) in [π,π] does not follow the original intuition of near π. More importantly, unlike SphereFace-R v1, there is
m
multiplicative margin and may be sub-optimal. In order to no constraint for the size of the induced angular margin in
betterimplementmultiplicativemarginintheentiredomain SphereFace-Rv2andwecanuseanydesirablem≥1.
of[0,π],weproposethefollowingtargetangularfunction: From the corresponding characteristic function given in
(cid:16) (cid:110) π(cid:111) (cid:17) Fig. 1(b), we can see that SphereFace-R v2 incorporates the
ψ(θ)=cos min m, ·θ (11)
θ smallest angular margin to easiest samples and the largest
where m is usually a prescribed positive constant. Eq. (11) angular margin to samples with medium hardness. Unlike
remains a monotonic function in [0,π] and can be viewed SphereFace-Rv1thatintroducesverysmallangularmargin
to hard samples, SphereFace-R v2 combines much larger
asincorporatinglargeangularmarginwithadynamicmul-
tiplicative parameter min{m,π}. For θ ∈ [0, π], Eq. (11) is angular margin to these samples. Therefore, SphereFace-R
θ m
v1 and SphereFace-R v2 put different efforts on optimizing
2.Theinequalitycos(θ1)>cos(mθ1)holdsifθ1∈[0, mπ],m>1. hardsamplesandmayyielddifferentgeneralizability.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 7
To the best of our knowledge, SphereFace-R v2 is the 0.7
very first method that introduces large angular margin 0.6 Original ()
throughnon-targetangularfunctions.SphereFace-Rv2eas- in the forward pass 0.5
ily addresses the difficult problem of incorporating a static (0)
Step approximation of ()
0.4
multiplicativemarginbysimplyswitchingthedesignfocus in the backward pass 0.3
fromtargetfunctiontonon-targetfunction.Webelievethat () 0.2
CGD of () ()
this method provides an important and novel perspective 0.1 CGD of ()
ondesigninglargeangularmarginlosses. 0
0−δ 0 0+δ
Angle
0 0.5 1 A1 n. g5
le
2 2.5 3
4.1.3 CharacteristicGradientDetachment (a) Illustration of CGD (b) CGD for SphereFace
In order to further stabilize training and improve per-
0.6 0.6
formance, we introduce a simple and generic method –
0.5 0.5
characteristic gradient detachment for implementing our
0.4 0.4
multiplicative margin. In general, the shape of the char-
acteristic function ∆(θ) determines the training stability 0.3 0.3
()
and the convergence property. Empirically, we find that 0.2 0.2 CGD of ()
()
a characteristic function with simpler backward gradient 0.1 CGD of () 0.1
computation typically leads to better training stability. For 0 0
0 0.5 1 1.5 2 2.5 3 0 0.5 1 1.5 2 2.5 3
example, CosFace [3], [4] yields strong empirical training Angle Angle
(c) CGD for SphereFace-R v1 (d) CGD for SphereFace-R v2
stability and its characteristic function is simply a positive
constant with backward gradient as 0. Inspired by such
an observation, we aim to simplify the backward gradient Fig.4.AnillustrationofthebackwardactivationofCGDforSphereFace
(m = 1.4),SphereFace-Rv1(m = 1.4)andSphereFace-Rv2(m =
computation for the characteristic function. To gain more
1.4).ThegreencurvesdemonstratetheeffectofCGDinthebackward
intuitions, we first use Taylor expansion to decompose the propagation, and the forward computation still follows the red curves
characteristic function in the target angular function at an (i.e.,∆(θ))withoutanyapproximation.
arbitraryangleθ
0
∈(0,π)withasmallangledeviationδθ:
ψ(θ +δθ)=η(θ +δθ)−∆(θ +δθ)
0 0 0 propagation. This essentially means that we only need to
=η(θ
+δθ)−(cid:0)
∆(θ )+
∆(cid:48)(θ 0)
δθ+
compute the characteristic function in the forward pass
0 0 1! (13) and completely ignore it in the backward propagation. In
∆(n)(θ ) order to avoid computing the gradient of the characteristic
···+ 0 (δθ)n+R (δθ)(cid:1)
n! n function, we substitute Eq. (16) into the first line of Eq. (5)
andfinallyobtainthefollowinglossfunction:
where ∆(n)(θ) denotes the n-th order derivative of ∆(θ)
andR n(δθ)denotesthehigherorderinfinitesimalof(δθ)n. L
v1
=log(cid:16) 1+(cid:88) exp(cid:0) (cid:107)x(cid:107)(η(θ i)−η(θ y)+Detach(∆(θ y)))(cid:1)(cid:17)
When the characteristic function is more complex, then its
i(cid:54)=y
Taylor expansion needs to have more terms to accurately
which can be generally used for the cases where the tar-
representit.Thisleadstomorecomplexbackwardgradient
get angular function is modified, such as SphereFace and
computation. Motivated by the observation that simpler
SphereFace-Rv1.Inthebackwardpass,CGDapproximates
gradientcomputationoftenleadstobettertrainingstability,
thecharacteristicfunctionofthemultiplicativemarginwith
we propose to make an approximation to the characteristic
apiece-wisefunctionconsistingofmanyconstantfunctions,
functionbyremovingsomehigherordertermsinitsTaylor
asillustratedinFig.4.Equivalently,CGDcanalsobeviewed
expansion. Generally, we can remove any higher order
as a step function approximation to the characteristic func-
Taylorexpansiontermsandityieldsdifferentbackwardgra-
tion in the backward pass. We note that the approxima-
dients.Particularly,wedrawinspirationsfromtheconstant
tion in CGD only exists in the backward direction and
characteristicfunctionadoptedinCosFace,andusethezero-
orderapproximationfor∆(θ 0+δθ)inEq.(13): the forward computation is always identical to the CGD-
free scenario. From a different perspective, CGD can be
ψ(θ 0+δθ)≈η(θ 0+δθ)−∆(θ 0) (14) understood as interpreting the multiplicative margin with
a dynamic CosFace-style additive margin (i.e., the effective
whichismuchsimplerandrobusttocomputeandgivesthe
followingapproximategradientforψ(θ)atθ 0: margin parameter for the additive margin is dynamically
dependentontheinputtargetangleinCGDratherthanbe-
ψ(θ +δθ)−ψ(θ )
ψ(cid:48)(θ 0)= δl θi →m
0
0
δθ
0 ≈η(cid:48)(θ 0) (15) i Sn pg hest ra et Fic aci en aC no dsF Sa pc he e). reT Fh ae ced -i Rsc vu 1s ,si so in nca eb to hv ee ya ap rp eli mes odto ifb yo inth
g
which naturally leads to the proposed CGD where we thetargetangularfunction.Asaconcreteexample,applying
can simply apply gradient detachment to the characteristic CGDtoSphereFace-Rv1yieldsthetargetangularfunction:
function ∆(θ). Specifically, we stop the gradient of the ψ(θ)=cos(θ)−Detach(cos(θ)−cos(min{m,π}·θ))whose
θ
characteristicfunctionwithadetachmentoperator: gradientisidenticaltoCosFace.
For SphereFace-R v2 that modifies the non-target angu-
ψ(θ)=η(θ)−Detach(∆(θ)) (16)
lar function, the derivation is similar except that we focus
where Detach(·) denotes the detachment operator that al- on approximating the gradient of the non-target function
lowsforwardcomputationbutstopsthebackwardgradient η(θ) instead of the target function ψ(θ). Therefore, we can
)(
noitcnuF
citsiretcarahC
)(
noitcnuF
citsiretcarahC
)(
noitcnuF
citsiretcarahC
)(
noitcnuF
citsiretcarahC
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 8
similarly apply gradient detachment to the characteristic parameter varies depending on the training sample), while
functioninthenon-targetangularfunction: SphereFace-R v2 implements a static one (i.e., the effective
margin parameter stays the same for all training samples).
η(θ)=ψ(θ)+Detach(∆(θ)). (17)
Moreover,SphereFaceandSphereFace-Rusedifferenteffec-
AfterputtingEq.(17)intothefirstlineofEq.(5),weendup tivemarginparametersforsampleswithdifferenthardness.
with the following general loss function for the cases that Both SphereFace and SphereFace-R strictly satisfy the gen-
modifythenon-targetfunction: eral principle in Eq. (4) to achieve large angular margin,
validatingtheeffectivenessofourproposedprinciple.
(cid:16) (cid:88) (cid:0) (cid:1)(cid:17)
L v2 =log 1+ exp (cid:107)x(cid:107)(ψ(θ i)−ψ(θ y)+Detach(∆(θ i))) Jointlydesigningtargetandnon-targetfunctions.Because
i(cid:54)=y SphereFace-Rv1focusesonthetargetangularfunctionand
SphereFace-Rv2focusesonthenon-targetangularfunction,
from which we can see that the key is to detach the gra-
itisnaturaltoconsidertosimultaneouslydesignthetarget
dients of the characteristic function. Therefore, applying
andnon-targetangularfunctions.Forexample,Eq.(11)and
CGD to SphereFace-R v2 yields the non-target function:
η(θ) = cos(θ)+Detach(cos(θ)−cos(θ)). The essence of Eq.(12)canbeeasilyusedtogetherandtheresultingcharac-
m
teristicfunctionissimplythecombinationofboth.Morein-
CGDistoavoidcomputingthegradientofthecharacteristic
terestingly,itisnotnecessaryforbothtargetandnon-target
function in the backward pass. As a simple generalization,
functionstousethecosine-baseddesign.Wecansimplyuse
we can consider higher-order Taylor approximation to the
a linear function as the target and non-target functions, as
characteristicfunctioninsteadofthezero-orderapproxima-
proposed in [31]. It can effectively alleviate some design
tion.SinceCGDalreadyyieldssatisfactorytrainingstability
constraints caused by the periodicity of cosine function.
andempiricalperformance,wewillsticktoitforsimplicity.
Jointly designing the target and non-target functions can
In fact, CGD serves as a generally useful tool for im-
greatlyenlargethesearchspaceofthecharacteristicfunction
plementingnewtypesofangularmarginandisnotlimited
andmayleadtoabettermultiplicativemarginloss.
to SphereFace and SphereFace-R. For the backward prop-
agation, CGD can approximate the characteristic function Beyond additive and multiplicative margin. There are
induced by any angular margin with a dynamic additive many more alternative types of angular margin other than
margin,andeffectivelystabilizethetraining. the additive and multiplicative ones. For example, we can
also use the exponential function to achieve ∆(θ) > 0.
4.1.4 ImplicationsandDiscussions Specifically, we use η(θ) = cos(2θ) and ψ(θ) = cosm(2θ),
where m > 1 is the margin parameter and larger m gives
Comparisonbetweenadditiveandmultiplicativemargin.
larger angular margin. Alternatively, we can also combine
WhileTable1providesadetailedcomparisonbetweenaddi-
additiveandmultiplicativemarginasη(θ)=cos(θ),ψ(θ)=
tive and multiplicative margin, the fundamental difference
between them is on a conceptual level. Additive margin
cos(m 1θ+m 2)−m 3.Itremainsanopenproblemtodesign
asimpleyetwell-performingangularmargin.
is introduced by adding or subtracting a parameter to the
target function so that the characteristic function ∆(θ) can
be larger than zero in most cases. Specifically, this param- 4.2 FeatureMagnitude
eter can be either inside [5] or outside [3], [4] the cosine SphereFace [2] originally does not use feature normaliza-
function. In contrast, multiplicative margin is achieved by tion, because the feature magnitude does not affect the
multiplyingaparametertothetargetornon-targetfunction angulardecisionboundary.[3],[4],[5],[9]showthatfeature
so that ∆(θ) is larger than zero. It is also possible that a normalizationcaneasethedifficultyofminimizingangular
multiplicativemarginlossandanadditivemarginlosslead margin losses and greatly improve the training stability.
tothesamecharacteristicfunction,andtheymaybetechni- Despitebeingeffectivetostabilizetraining,featurenormal-
callythesameloss.Therefore,theirdifferenceisdetermined izationinevitablylosesusefulinformationaboutindividual
bythespecificintuitionthatguidesthelossdesign. samples (e.g., image quality). Existing hyperspherical FR
Generality of multiplicative margin.SphereFace-Rv1and methods either preserve the feature magnitude in the loss
v2demonstratetwodifferentstrategiestoincorporatemul- function [1], [2], [32] or normalize the feature magnitude
tiplicative angular margin, showing the existence of many to constant s [9], [30]. To explore whether feature magni-
feasible designs to achieve multiplicative margin. In fact, tude can be beneficial to generalization, we systematically
theexactformofthelossfunctionisnotcrucialandthecore study SphereFace and SphereFace-R under NFN and HFN.
of multiplicative margin lies in the spirit of multiplying a Moreover,weconsiderasoftfeaturenormalizationmethod
factortoensurethecharacteristicfunctiontobelargerthan which effectively unifies NFN and HFN and serves as an
zero.Followingsuchaspirit,therearelikelymanypotential interpolationbetweenboth.
lossdesignsthatcanworkaswellasours. Hard feature normalization. HFN becomes a default com-
Comparison between SphereFace and SphereFace-R. It is ponent in current hyperspherical FR methods [3], [4], [5],
easy to see that SphereFace employs a surrogate character- [26], [40]. By normalizing the feature x to a constant s, the
istic function to implement the multiplicative margin and objective function value will merely depend on the angles
does not follow the intuition of multiplicative margin for between x and the classifiers W i,∀i. In order to perform
θ ∈ [π,π]wherem > 1.Incontrast,bothSphereFace-Rv1 suchahardnormalizationonthefeaturex,weparameterize
m
andv2exactlyfollowtheintuitionofmultiplicativemargin theoriginalxinEq.(5)withs x andarriveatEq.(6).Since
(cid:107)x(cid:107)
in the entire domain of [0,π]. SphereFace-R v1 implements sisaprescribedconstant,itisequivalenttonormalizingall
a dynamic multiplicative margin (i.e., the effective margin thefeaturestoahyperspherewithradiuss.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 9
Softfeaturenormalizationasaninterpolation.Weconsider
thesoftfeaturenormalizationthatinterpolatesbetweenFN- 60 60
freelearningandHFN.Specifically,besidestheoriginalloss, 40 40
20 20
we combine an additional regularization term to constrain Q0 Q 0
-20 -20
thefeaturemagnitude: -40 -40
-60
(cid:13) (cid:13)2 3 3
wheretisahyperpL aS rF aN m= etet r· t(cid:13) h(cid:107) ax t(cid:107) co− nts r(cid:13) olstheregularizat( i1 o8 n) (a2 θ )i No1 rmali0 zed0 Softm1
ax
θ (y s=32
0)
3 2 θi (b1
)
Sph0 er0
eFace
(1 s=3θ 0y )2 3
strengthandsisaprescribedfeaturemagnitudethatserves
asimilarroletoHFN.Whent = 0,SFNreducestoFN-free
learning. When t = +∞, SFN reduces to HFN. Therefore, 50 100
50
SFN can be viewed as an interpolation between FN-free Q0 Q0
learningandHFN.SFNhasalsobeenstudiedin[10].
-50 -50
SFN can make use of the instance-level information -100
3 3
encoded in feature magnitude during training while still 2 3 2 3
encouraging a feature normalization effects. Moreover, the θi 1 0 0 1 θy 2 θi 1 0 0 1 θy 2
difference between SFN and HFN can be viewed as using (c) SphereFace-R v1 (s=40) (d) SphereFace-R v2 (s=60)
different optimization techniques to constrain the feature
Fig.5.Acomparisonoflosscharacteristicsamongnormalizedsoftmax,
norm to a prescribed constant. HFN has the flavor of pro-
SphereFace,SphereFace-Rv1andSphereFace-Rv2.
jectedgradientdescentwherethesolutionwillbeprojected
tothefeasibleregiontosatisfysomeconstraint.Incontrast,
SFN is essentially a Lagrangian relaxation of the original of similarity score as S(x 1,x 2) = g((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))·cos(θ 1,2)
problem where the feature norm is constrained. Therefore, where x 1,x 2 are deep features of two input samples, θ 1,2
their empirical performance could be quite different in istheanglebetweenx
1
andx 2,andg((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))denotes
practice,eveniftheysharethesameoptimizationtarget. a function with the norm of x 1 and x 2 as input. We may
Dynamicfeaturemagnitude.IncontrasttoHFNthatusesa requirethefunctiong((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))tohaveafewproperties:
staticfeaturemagnitude,bothFN-freelearningandSFNcan (i) permutation invariance: g((cid:107)x 1(cid:107),(cid:107)x 2(cid:107)) = g((cid:107)x 2(cid:107),(cid:107)x 1(cid:107))
beviewedasadynamic(data-dependent)waytocontrolthe and (ii) adjustable magnitude augmentation. As a concrete
featuremagnitude.Moreover,thereexistmanyotherstrate- example,wecoulduseg((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))=(cid:107)x 1(cid:107)t·(cid:107)x 2(cid:107)t where
gies that can dynamically control the feature magnitude to t adjusts the augmentation strength of feature magnitude.
improvetheempiricalperformance,suchas[36]. g((cid:107)x 1(cid:107),(cid:107)x 2(cid:107))=1reducestothecosinesimilarityscore.In
general,howtodesignagoodg isnotclearandremainsto
4.3 DiscussionsandOpenProblems beexploredinfutureendeavours.
Optimal design of characteristic function. It is clear that
thecharacteristicfunctionisthekeytolargeangularmargin, 5 A UNIFIED CHARACTERIZATION OF LOSS FUNC-
but is there an optimal characteristic function? The answer TIONS IN HYPERSPHERICAL FACE RECOGNITION
to this question remains open. We argue that the optimal
design of characteristic function should be dynamic and In this section, we take a closer look at what characterizes
depends on the specific dataset, the network architecture, hyperspherical face recognition. As our unified framework
the optimizer, the stage of training (i.e., the weights of the in Section 3 discusses, a feature normalization strategy, a
network), etc. Current studies on hyperspherical FR still (non-)target angular function and a characteristic function
focuses on a static characteristic function. [70], [71] explore can fully determine the loss function of a hyperspherical
an automatic way to learn a characteristic function from FR method. Particularly, the characteristic function ∆(·)
data,butthoselearnedcharacteristicfunctionsarestillstatic controls the property of the induced angular margin (e.g.,
onesanddonotleadtoasignificantperformancegain.[45] size,trainingstability).Itdoesnotconsiderthefeaturemag-
combines the sample quality to hyperspherical FR through nitude and only focuses on the difference between target
a customized characteristic function that is dependent on and non-target function. Here we take a step further by
the feature magnitude. How to design or learn a better showing a unified way to characterize the loss function as
characteristicfunctionthatisdynamicallydependentonthe awhole.Specifically,wehavethefollowinggeneralformof
data and also easy to optimize remains a huge challenge. thelossfunctionforhypersphericalFR:
Moreover, the underlying mechanism that determines the (cid:16) (cid:88) (cid:0) (cid:1)(cid:17)
L =log 1+ exp s·(η(θ )−η(θ )+∆(θ ))
performanceofacharacteristicfunctionstaysamysteryand s i y y
needstobeunderstoodbothempiricallyandtheoretically. i(cid:54)=y (cid:124) :=Q(θy(cid:123) ,(cid:122) θi,s,m) (cid:125) (19)
Making better use of feature magnitude. In this paper, (cid:16) (cid:88) (cid:0) (cid:1)(cid:17)
=log 1+ exp Q(θ ,θ ,s,m)
y i
we have not considered to incorporate feature magnitude
i(cid:54)=y
to testing and still stick to the cosine similarity for com-
paringpairs.However,itremainsaninterestingopenprob- where we define Q(θ y,θ i,s,m) as the loss characteristics
lem whether it will be more beneficial to combine feature thatfullydeterminehowthelossfunctionbehaves.Wecom-
magnitude back to the similarity score (especially FN-free parethelosscharacteristicsamongnormalizedsoftmax[9],
learning or SFN is used). We consider a generalized form SphereFace and two variants of SphereFace-R in Fig. 5.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 10
Although we show that the loss characteristics can fully TABLE2
determine the loss function, the underlying mechanisms Statisticsfortheuseddatasets.
of how the loss characteristics can affect the performance Dataset #ofID #ofimages Split
arelargelyunclearandremaintobeinvestigated.Typically,
VGGFace2[76] 8.6K 3.1M train
s and m jointly specify the loss characteristics, and their
MS-Celeb-1M[77] 86K 5.8M train
roles could be partially coupled, which is also empirically
LFW[78] 5,749 13,233 validation
observedinourablationstudy.
AgeDB-30[79] 568 16,488 validation
From a back-propagation perspective, we have the gra-
CALFW[80] 5,749 11,652 validation
dientofL
s
(w.r.t.eitherxorW i,∀i)as
CPLFW[81] 5,749 12,174 validation
L(cid:48) s=(cid:88) 1+(cid:80)exp(Q ex( pθ (y Q,θ (i θ,s ,, θm ,) s) ,m))·Q(cid:48)(θ y,θ i,s,m) (20) C VF GP G[ F8 a2 c]
e2 test[76]
5 50 00
0
7 1, 70 30 k0 v va al li id da at ti io on
n
i(cid:54)=y i(cid:54)=y y i
IJB-B[83] 1,845 76.8K test
where Q(cid:48)(θ y,θ i,s,m) denotes the gradient of loss charac- IJB-C[84] 3,531 148.8K test
teristics. Quite interestingly, if we apply CGD to Eq. (19), MegaFace(probe)[85] 530 3,530 test
then Q(cid:48)(θ y,θ i,s,m) for all hyperspherical FR methods will MegaFace(distractor)[86] 690K 1M test
immediately become identical to that of the normalized
softmax loss [9]. The only critical difference lies in the
TABLE3
weighting factor ρ i = 1+(cid:80)e ix (cid:54)=p y(Q ex( pθ (y Q,θ (i θ, ys, ,m θi) ,s) ,m)) in Eq. (20), VaryingmfornofeaturenormalizationonVGGFace2(%).
where Q(θ y,θ i,s,m) varies for different loss functions in m SphereFace SphereFace-Rv1 SphereFace-Rv2
the forward pass. This finding suggests that once CGD is
1.1 53.09 55.18 52.71
applied, the gradient of every loss function in hyperspher-
1.2 55.36 55.97 56.08
ical FR can be viewed as a particular weighting strategy
1.3 55.32 51.11 50.19
to combine Q(cid:48)(θ y,θ i,s,m) of different i (cid:54)= y. In other
1.4 44.95 43.04 37.78
words,onlytheweightingfactorsρ i,∀iinthegradientL(cid:48)
s
=
1.5 34.23 31.54 30.94
(cid:80) i(cid:54)=yρ i ·Q(cid:48)(θ y,θ i,s,m) will differ for different loss func-
tions. Therefore, the design space for loss functions can be
areenabledwhenNFNandSFNareused.WeuseSFNet-20
switchedfromfindingQ(θ y,θ i,s,m)tofindingaweighting
andSFNet-64intheablationandexploration,whileSFNet-
strategyforcombiningthegradientsQ(cid:48)(θ y,θ i,s,m),∀i(cid:54)=y.
64 and IResNet-100 are adopted in large-scale benchmarks
Such a gradient weighting perspective reveals that search-
toachievestate-of-the-artperformance.
ingforsuitablemandmisequivalenttodesigningagood
Training. The training images are horizontally flipped for
gradient weighting strategy. This may open a brand new
dataaugmentation.Wetrainallthemodelsontwopopular
gatetogaindeeperunderstandingstowardshyperspherical
training dataset: VGGFace2 [76] (3.1M images from 8.6K
FR. Moreover, we believe that our novel loss characteriza-
IDs) and MS-Celeb-1M (5.8M images from 86K IDs, also
tionreformulationinEq.(19)andEq.(20)mayinspiremore
calledMS1M-V2,thecleanedversionofMS-Celeb-1Mused
effectivedesignsforlossfunctionsinhypersphericalFR.
in [5]). Detailed statistics of these datasets are given in
Table 2. In our experiments, all the models are optimized
6 EXPERIMENTS AND RESULTS using stochastic gradient descent with momentum 0.9. For
In this section, we present comprehensive experiments to VGGFace2, we train on 2 GPUs for 80k iterations, with a
explorethepropertiesoftheSphereFacefamily.Experimen- learning rate of 0.1 which is decreased by 10 at the 40k
tal setup is introduced in Section 6.1. We perform ablation and 60k iteration. For MS-Celeb-1M, we train on 4 GPUs
studies in Section 6.2 and Section 6.3 to investigate differ- for240kiterations.Thelearningrateisinitializedas0.1and
ent variants of SphereFace and their hyperparameters. In decreasedby10attheiterationof100k,180k,and220k.
Section 6.4, we evaluate our methods on the large-scale Testing.Westrictlyfollowthespecificprotocolprovidedin
benchmarksandcomparetoohterstate-of-artmethods. each dataset for evaluation. Table 2 shows the statistics of
the testing sets. Given a face image, we extract two 512-
6.1 ImplementationDetails dimensional embeddings from the original image and its
horizontally flipped version, respectively. The final embed-
Preprocessing.Eachfaceimageiscroppedbasedonthefive
dingisobtainedbyaveragingthetwo.Thescoringmethod
facelandmarks(i.e.,lefteye,righteye,nasaltip,leftmouth
is cosine similarity. The nearest neighbor classifier and
corner, and right mouth corner) detected by MTCNN [73]
thresholdingareusedforfaceidentificationandverification,
and RetinaFace [74] using similarity transformation. The
respectively. To reduce the randomness, 5 models from the
sizeofthecroppedimageissetto112×112,andeachRGB
last10kiterationswillbeusedintestingandtheiraveraged
pixel([0,255])isnormalizedto[−1,1].
resultsarereported.Specifically,weevaluatethemodelsat
CNNs.TheSphereFaceNetworks(SFNets)thatareinitially
the iteration of 72k, 74k, 76k, 78k and 80k for VGGFace2,
proposedin[2]areusedasthebackboneinourexperiments.
and232k,234k,236k,238kand240kforMS-Celeb-1M.
Slightly different from [2], we equip SFNets with batch
normalization(BN)[75]tofacilitatethemodeloptimization.
6.2 AblationandExplorationonVGGFace2
For better comparison to existing methods, we also evalu-
ate our models with IResNet-100 [5] which is a 100-layer The validation set is a combination of multiple datasets,
modifiedResNet.TheaffineparametersinthelastBNlayer including LFW, AgeDB-30, CALFW, CPLFW, CFP-FP, CFP-
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 11
TABLE4
GridsearchingformandswithhardfeaturenormalizationonVGGFace2.Resultsarein%andhighernumberindicatesbetterperformance.
s s s
20 30 40 50 60 20 30 40 50 60 30 40 50 60 70
m m m
1.1 51.97 53.28 55.50 53.78 52.06 1.1 50.88 57.10 54.12 51.84 53.37 1.1 54.62 54.69 50.52 52.56 51.33
1.2 53.16 61.37 57.22 54.85 56.12 1.2 49.68 57.21 56.30 51.99 52.17 1.2 55.59 60.75 58.30 54.55 56.88
1.3 48.28 60.08 60.89 60.37 57.09 1.3 45.35 59.15 56.23 56.92 55.02 1.3 44.12 55.67 61.07 57.34 57.15
1.4 42.32 58.63 59.30 57.39 53.94 1.4 45.83 53.38 58.05 55.79 56.15 1.4 35.01 48.42 59.31 62.72 58.12
1.5 37.20 58.04 59.35 54.74 53.43 1.5 35.91 55.00 60.45 58.29 58.95 1.5 32.71 42.50 46.98 55.54 56.81
1.6 38.62 47.81 53.53 49.77 53.30 1.6 33.40 47.70 53.75 52.28 50.92 1.6 25.90 30.83 42.88 49.83 51.40
(a)VaryingmandsforSphereFace. (b)VaryingmandsforSphereFace-Rv1. (c)VaryingmandsforSphereFace-Rv2.
TABLE5 TABLE7
VaryingtforsoftfeaturenormalizationonVGGFace2(%). VaryingmwithnofeaturenormalizationonMS-Celeb-1M(%).
SphereFace SphereFace-Rv1 SphereFace-Rv2 m SphereFace SphereFace-Rv1 SphereFace-Rv2
t
(m=1.2,s=30) (m=1.5,s=40) (m=1.4,s=60) 1.0 76.50 75.12 78.98
0.05 57.08 39.43 55.53 1.1 79.89 82.52 79.94
0.1 62.40 43.96 60.61 1.2 49.64 84.66 84.78
0.2 61.24 54.40 60.30 1.3 - 0.33 69.95
0.5 58.68 61.37 61.21
TABLE8
1.0 57.10 60.59 58.34
VaryingmwithhardfeaturenormalizationonMS-Celeb-1M(%).
TABLE6
SphereFace SphereFace-Rv1 SphereFace-Rv2
AblationofCGDfordifferentFNstrategiesonVGGFace2(%). m
s=32 s=64 s=32 s=64 s=64 s=96
SphereFace SphereFace-Rv1 SphereFace-Rv2 1.4 87.32 - 89.42 - 86.88 -
FN CGD
(m=1.2,s=30) (m=1.5,s=40) (m=1.4,s=60) 1.5 88.82 - 90.19 - 91.58 -
(cid:55) 47.91 49.92 49.41 1.6 88.97 89.15 90.78 86.24 88.74 88.48
NFN
(cid:51) 55.36 55.97 56.08 1.7 91.03 89.30 89.79 88.89 88.80 89.36
(cid:55) 46.02 28.78 36.61 1.8 89.83 90.53 88.53 88.89 88.54 88.98
HFN
(cid:51) 61.37 60.45 62.72 1.9 - 89.58 - 89.61 - 89.71
(cid:55) 47.81 25.26 40.52 2.0 - 88.50 - 87.52 - 89.01
SFN
(cid:51) 62.40 61.37 61.21
TABLE9
VaryingtwithsoftfeaturenormalizationonMS-Celeb-1M(%).
FF,andVGG2-FP.Thestatisticsofthesedatasetsaresumma-
SphereFace SphereFace-Rv1 SphereFace-Rv2
rizedinTable2.Intotal,thereare43,000testingpairs(21,500 t t
(m=1.7,s=32) (m=1.6,s=32) (m=1.5,s=64)
positive pairs, and 21,500 negative pairs). The performance
0.6 54.30 81.27 0.1 78.18
of a model is measured by the area under the ROC curve
0.8 85.40 81.24 0.2 86.10
(AUC). Since it is important for a face recognition system 1.0 87.70 87.19 0.4 83.34
to avoid false positives, we use AUC-x [87] as the metric, 1.2 85.00 87.15 0.6 85.50
which integrates up to false positive rate of x (x ∈ [0,1]). 1.4 78.52 83.67 0.8 81.75
Wefindthatx=0.0005achievesthebesttrade-offbetween
stability and effectiveness. Since VGGFace2 is a relatively
well, due to the increased difficulty in optimization. In our
small training set (8.6K subjects [76]), we use the SFNet-20 experiments, m = 1.2 achieves the best trade-off between
modelasthebackboneinthissection.
featurediscriminativenessandoptimizationdifficulty,lead-
ingtothebestperformanceforalltypesofmargins.
6.2.1 NoFeatureNormalization
We start by exploring SphereFace and SphereFace-R with- 6.2.2 HardFeatureNormalization
out feature normalization. Since there is only one effective HFNintroducesanadditionalhyperparameterstotheloss
hyperparameter (i.e., the margin m), it is easy to find the function, which controls the norm of the deep features. To
optimal setting. We compare SphereFace, SphereFace-R v1 show how m and s affect the performance, we perform a
and SphereFace-R v2, and they represent different types of grid search by varying these two hyperparameters for all
margins as shown in Table 1. Note that SphereFace with threetypesofmarginsincludingSphereFace,SphereFace-R
NFN is the same as the original SphereFace [2] (with addi- v1andSphereFace-Rv2.TheresultsaregiveninTable4.
tional CGD). Our methods are equivalent to the standard We have several observations. First, there usually exists
softmax cross-entropy loss when m = 1.0. We vary m an optimal margin hyperparameter m that leads to the
from1.1to1.5andreportthecorrespondingAUC-0.0005in best performance for each scale s. If m is smaller than
Table3.Itcanbeobservedthatsmallmargin(e.g.,1.1)results the optimal value, the performance is usually improved as
ininferiorperformance,becausethelearnedfeaturesarenot m increases. If m is greater than the optimal value, the
sufficientlydiscriminative.Ontheotherhand,incorporating performance is usually decreased as m increases. Second,
a margin that is too large can not produce good results as for larger s, the corresponding optimal m will also tend to
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 12
TABLE10
EvaluationonMegaFace,IJB-BandIJB-C.WeuseSFNet-20asthebackbonearchitectureandVGGFace2asthetrainingsetforallthecompared
methods.Resultsarein%andhighernumberindicatesbetterperformance.
MegaFace IJB-B IJB-C
(refined) 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR
Method FN m s t Iden. Veri. 1e-6 1e-5 1e-4 top1 1e-2 1e-1 1e-6 1e-5 1e-4 top1 1e-2 1e-1
NormFace[9] HFN 0.35 40 - 76.81 82.18 32.53 68.20 82.24 91.17 58.85 78.99 65.64 76.31 86.15 92.09 70.60 81.43
CosFace[3],[4] HFN 0.35 40 - 81.38 85.73 40.77 73.66 85.51 91.96 67.97 82.77 70.43 80.21 88.75 93.09 75.36 84.90
ArcFace[5] HFN 0.4 40 - 83.80 87.98 40.15 76.52 87.50 92.26 70.25 85.02 74.32 82.49 90.17 93.79 78.22 86.71
CircleLoss[26] HFN 0.25 256 - 83.00 86.28 36.56 72.81 86.51 91.41 65.58 83.73 69.69 80.66 89.67 92.96 75.41 85.63
CurricularFace[40] HFN 0.25 40 - 88.32 91.82 22.16 63.35 88.23 92.66 47.59 84.93 35.54 76.49 91.10 93.73 54.13 85.77
SphereFace[2] NFN 1.2 - - 85.55 90.03 40.52 74.89 86.81 92.86 67.79 84.19 71.95 81.46 89.69 94.20 76.20 85.85
SphereFace-Rv1 NFN 1.2 - - 85.63 90.70 35.42 73.87 86.59 92.92 66.75 83.95 71.60 81.80 89.67 94.12 76.29 85.92
SphereFace-Rv2 NFN 1.2 - - 85.02 89.24 39.17 73.80 86.36 92.85 67.60 83.66 70.96 80.61 89.32 93.95 75.30 85.04
SphereFace HFN 1.2 30 - 85.44 90.12 40.11 75.44 87.43 92.97 67.70 84.87 73.79 83.02 90.37 94.19 78.18 86.90
SphereFace-Rv1 HFN 1.5 40 - 83.39 87.42 39.39 75.78 86.82 92.53 68.92 84.43 72.39 82.33 89.83 93.85 77.96 86.39
SphereFace-Rv2 HFN 1.4 60 - 85.15 89.35 36.68 76.61 87.81 92.85 70.21 85.50 74.94 83.51 90.45 94.06 78.80 87.24
SphereFace SFN 1.2 30 0.1 86.06 90.59 39.55 76.00 87.63 93.14 68.37 85.21 74.59 83.34 90.59 94.27 78.93 87.12
SphereFace-Rv1 SFN 1.5 40 0.5 89.17 91.95 42.38 80.24 88.88 93.45 73.55 87.24 77.61 85.93 91.59 94.65 82.09 89.01
SphereFace-Rv2 SFN 1.4 60 0.5 89.10 91.75 44.20 78.91 88.86 93.12 70.84 87.15 75.91 85.63 91.38 94.31 81.04 88.54
be larger. For example, in Table 4(b), the optimal margin 10 10
mis monotonouslyincreased from1.1 to1.5 forthe scales NFN NFN
rangingfrom20to60.Theperformanceisaffectedbyboths 7.5 HFN 7.5 HFN
SFN SFN
andminacoupledmanner.Thesamepatternalsoappears
in Table 4(a) and (c). Third, a wide range of s could lead 5 5
toasatisfyingperformance,aslongasmisproperlytuned.
2.5 2.5
For example, in Table 4(a), the corresponding AUC-0.0005
remains a relatively high value ([57.09,61.37]) while the
0 0
scalesvariesfrom30to60.Wenotethattheseobservations 0 20k 40k 60k 80k 0 80k 160k 240k
areconsistentacrossalltypesofmultiplicativemargin. Number of Iterations Number of Iterations
(a) Training SFNet-20 on VGGFace2 (b) Training SFNet-64 on MS-Celeb-1M
Hyperparameter tuning strategy. With the aforementioned
observations, we summarize a simple yet effective strategy
Fig.6.TrainingobjectiveofSphereFace-Rv2withNFN,HFNandSFN
to search suitable hyperparameters for HFN. First, we uni- on (a) VGGFace2 and (b) MS-Celeb-1M. For SFN, we only plot the
formly pick the scale parameter s with a relatively large softmax-basedlossandthefeaturenormregularizationisnotplotted.
gap, e.g., 20 or 30. The approximate range of s can follow
the common setting in many existing approaches [2], [5].
Second,wefindtheoptimalmarginparametermforeachs WegivetheAUC-0.0005inTable5.SphereFaceachieves
62.4% with SFN and 61.37% with HFN. SphereFace-R
withauniformsearch.IthasbeenshowninTable4thatthe
range of m depends on the specific s we use. For larger s, v1 achieves 61.37% with SFN and 60.45% with HFN.
itsoptimalmistypicallylargeraswell.Asausefulpractice, SphereFace-Rv2achieves61.21%withSFNand62.72%with
weshouldgraduallysearchlargerm,assincreases.Finally, HFN.OurexperimentsshowthatthatSFNgenerallyyields
we choose the scale s and the margin m that lead to the comparableorevenbetterresultsthanHFNwithaproperly
chosentwhenourmodelsaretrainedonVGGFace2.
best performance on the validation set. We find that such
a simple hyperparameter searching is generally useful and
6.2.4 CharacteristicGradientDetachment
can be applied to tuning different kinds of hyperspherical
FRmethodsinpractice. InTable6,wecomparethemodelstrainedwithorwithout
CGD. Except the usage of CGD, the experiments are per-
6.2.3 SoftFeatureNormalization formed with exactly the same experimental settings (e.g.,
SFN is a soft regularization to constrain the feature norm dataset, architecture, training setup etc). We have evalu-
and can be considered as a trade-off between NFN and ated CGD on all three FN strategies (i.e., NFN, HFN and
HFN. SFN has a weighting hyperparameter t controlling SFN). The results show that CGD significantly improves
the contribution of feature norm regularization term. Since the results in all scenarios, which validates the importance
therearethreehyper-parameters,i.e.,m,s,andt,itistime- of simplifying the gradient of the characteristic function.
consuming and infeasible to enumerate all possible combi- CGD works particularly well for SphereFace-R v1, since it
nations of them. To efficiently evaluate SFN, we adopt the enablesthegradientpropagationforlargemargin(m> π in
θ
combination of m and s that leads to the best performance Eq. 11). Here we use the best-performing hyperparameters
inSection6.2.2andfixthemthroughouttheSFNexperiment from our previous experiments. In fact, the consistent im-
sothatwecanfocusonhowtwillaffecttheperformance. provements can also be obtained from CGD with the other
eulaV
noitcnuF
evitcejbO
eulaV
noitcnuF
evitcejbO
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 13
TABLE11
EvaluationonMegaFace,IJB-BandIJB-C.WeuseSFNet-64asthebackbonearchitectureandMS-Celeb-1Masthetrainingsetforallthe
comparedmethods.Resultsarein%andhighernumberindicatesbetterperformance.
MegaFace IJB-B IJB-C
(refined) 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR
Method FN m s t Iden. Veri. 1e-6 1e-5 1e-4 top1 1e-2 1e-1 1e-6 1e-5 1e-4 top1 1e-2 1e-1
NormFace[9] HFN - 30 - 89.24 90.76 40.56 75.30 90.22 92.49 64.62 88.19 70.17 85.88 92.69 93.70 77.97 89.81
CosFace[3],[4] HFN 0.35 64 - 98.05 98.45 37.82 82.99 94.20 94.69 70.61 93.03 78.01 92.29 95.87 95.91 84.59 94.53
ArcFace[5] HFN 0.5 64 - 98.45 98.39 41.02 86.16 94.82 94.88 77.92 93.79 84.47 93.25 96.25 96.12 88.80 95.08
CircleLoss[26] HFN 0.25 256 - 98.29 98.67 41.65 82.76 94.09 94.64 74.63 92.83 81.18 91.59 95.83 95.77 84.56 94.15
CurricularFace[40] HFN 0.5 64 - 98.43 98.62 43.76 85.55 94.61 94.82 76.01 93.37 83.35 92.95 96.11 96.04 87.88 94.76
SphereFace[2] NFN 1.1 - - 93.04 94.37 37.78 69.99 88.70 91.98 60.43 86.28 62.10 83.03 91.74 93.30 71.45 88.11
SphereFace-Rv1 NFN 1.2 - - 93.75 94.80 44.83 83.07 92.12 93.56 70.59 90.80 77.72 89.78 94.14 94.94 84.55 92.23
SphereFace-Rv2 NFN 1.2 - - 94.74 95.51 47.82 82.82 92.15 93.51 72.38 90.91 76.14 89.85 94.17 94.94 84.58 92.17
SphereFace HFN 1.7 32 - 98.16 98.46 48.83 86.66 94.36 94.84 76.35 93.20 83.57 92.79 95.82 96.07 87.74 94.47
SphereFace-Rv1 HFN 1.6 32 - 98.03 98.30 48.84 88.16 94.31 94.98 79.18 93.23 85.65 93.17 95.72 96.07 89.94 94.55
SphereFace-Rv2 HFN 1.5 64 - 98.04 98.48 45.77 86.52 94.08 94.70 74.13 93.13 82.07 92.61 95.63 95.92 88.00 94.32
SphereFace SFN 1.7 32 1.0 97.84 98.28 44.42 85.89 94.13 94.84 77.37 93.14 83.05 92.25 95.67 95.95 87.72 94.19
SphereFace-Rv1 SFN 1.6 32 1.0 97.42 97.79 44.24 84.95 93.70 94.58 77.66 92.66 81.92 91.10 95.27 95.65 85.70 93.73
SphereFace-Rv2 SFN 1.5 64 0.2 97.93 98.19 40.06 86.37 94.12 94.78 76.94 93.21 82.94 92.29 95.62 95.99 87.83 94.42
hyperparameters. We observe that CGD can effectively im- 1.8, and for larger s, we search m from 1.6 to 2.0. The
proveSphereFaceandSphereFace-RunderallFNstrategies. results in Table 8 well match our expectation that there
BecauseoftheconsistenteffectivenessofCGD,weuseCGD is only one optimal m for each s and the optimal m will
for both SphereFace and SphereFace-R by default and the increase with larger s. Under the same s, we discover that
resultsintheothersectionsarealsoobtainedwithCGD. as m deviates from its optimal value, the performance will
also become worse. The distribution of the performance
6.3 AblationandExplorationonMS-Celeb-1M for different m exhibits a strong unimodality, which can
largely benefit the hyperparameter tuning. The best mod-
In this section, we conduct ablation and exploration with
els of SphereFace, SphereFace-R v1 and SphereFace-R v2
a deeper network that is trained on a large-scale dataset.
achieve 91.03%, 90.78% and 91.58% with s = 32, 32, and
Specifically, we use SFNet-64 as the backbone network ar-
64, respectively. The performance on MS-Celeb-1M is also
chitecture and MS-Celeb-1M as the training set. We report
muchbetterthanthatonVGGFace2,whichshowsthatour
AUC-0.0005onthesamevalidationsetasSection6.2.
methods can easily enjoy the accuracy boost from larger
trainingsetanddeepernetwork.Moreover,theperformance
6.3.1 NoFeatureNormalization
of both SphereFace and SphereFace-R is not very sensitive
We evaluate SphereFace, SphereFace-R v1 and SphereFace-
tomandremainsstableforawiderangeofm.
R v2 without feature normalization. Note that SphereFace
with NFN is equivalent to the original SphereFace [2] with 6.3.3 SoftFeatureNormalization
CGD.TheresultsaregiveninTable7.Similartotheexperi-
Similar to Section 6.2.3, we adopt the best-performing set-
mentsonVGGFace2,NFNgenerallyworkswellwithsmall
tings (m and s) from HFN and vary the hyperparameter t
margins, achieving 79.89%, 84.66%, and 84.78% with m
inordertoevaluatetheperformanceofSFN.Theresultsare
being1.1,1.2,and1.2,respectively.Theincreasednumberof
reported in Table 9. With a properly tuned t, SFN achieves
trainingidentities(from8Kto86K)leadstosevereoptimiza-
87.70%, 87.19% and 86.10% AUC-0.0005 for SphereFace,
tion difficulty during training. This can be empirically ob-
SphereFace-R v1 and SphereFace-R v2, respectively. We
servedfromthesmalleroptimalmfromSphereFaceandthe
observe that the performance of SFN on MS-Celeb-1M are
dramatically decreased performance from both SphereFace
not as good as HFN, which contradicts the observation on
andSphereFace-Rwithlargermargins.
VGGFace2. This implies that SFN may be sensitive to the
distribution of the training data. We hypothesize that SFN
6.3.2 HardFeatureNormalization
is more sensitive to noisy samples (since MS-Celeb-1M has
Following our hyperparameter tuning strategy given in
muchmorelow-qualityandnoisyimagesthanVGGFace2).
Section 6.2.2, we search the optimal combination of s and
m.Sincetheperformanceisstableacrossawiderangeofs,
6.4 EvaluationonLarge-scaleBenchmarks
hereweusearelativelylargegap(i.e.,32).Asmentionedin
Section6.2.2,theoptimalmtendstoincreasewithlargers. 6.4.1 ExperimentswithSFNet-20andSFNet-64
WesearchtwofeaturescalehyperparametersforSphereFace In this section, we evaluate the performance of both
(i.e., s = 32,64), SphereFace-R v1 (i.e., s = 32,64) and SphereFace and SphereFace-R with three FN strategies
SphereFace-Rv2(i.e.,s=64,128).Basedonourobservation on popular large-scale benchmarks (i.e., IJB-B, IJB-C and
on VGGFace2, the optimal m for larger s also tends to be MegaFace). We also provide fair comparisons to state-of-
larger. Therefore for smaller s, we search m from 1.4 to the-art methods (with the same training set and backbone
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 14
TABLE12
EvaluationonMegaFace,IJB-BandIJB-C.WeuseIResNet-100asthebackbonearchitectureandMS-Celeb-1Masthetrainingset.Resultsare
in%andhighernumberindicatesbetterperformance.ForArcFace,wepresentresultsfromtheirpaperandourre-implementation.
MegaFace IJB-B IJB-C
(refined) 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR 1:1Veri.TAR@FAR 1:NIden.TPIR@FPIR
Method FN m s t Iden. Veri. 1e-6 1e-5 1e-4 top1 1e-2 1e-1 1e-6 1e-5 1e-4 top1 1e-2 1e-1
CosFace[3],[4] HFN 0.4 64 - 98.70 98.87 43.67 88.83 95.23 95.35 80.50 94.49 85.29 94.33 96.62 96.53 90.69 95.61
ArcFace(resultsin[5]) HFN 0.5 64 - 98.35 98.48 38.28 89.33 94.25 - - - 86.25 93.15 95.65 - - -
ArcFace [5] HFN 0.5 64 - 98.67 98.46 43.43 90.40 95.02 95.14 81.36 94.26 86.00 94.49 96.39 96.47 91.91 95.51
SphereFace[2] NFN 1.1 - - 94.95 95.76 43.02 73.79 90.19 92.67 64.09 87.80 68.83 85.77 92.82 93.89 76.83 89.93
SphereFace-Rv1 NFN 1.2 - - 96.49 97.22 38.01 81.31 92.58 94.15 70.49 91.20 77.94 90.23 94.83 95.34 84.81 92.91
SphereFace-Rv2 NFN 1.2 - - 97.14 97.56 41.73 82.60 93.00 94.42 70.93 91.44 78.64 90.70 95.03 95.45 84.75 93.11
SphereFace HFN 1.7 32 - 98.63 99.04 47.33 90.14 94.87 95.13 82.57 94.30 87.86 94.36 96.25 96.45 91.68 95.36
SphereFace-Rv1 HFN 1.6 32 - 98.61 98.61 47.82 89.06 94.89 95.18 82.69 94.09 86.30 93.91 96.21 96.38 91.16 95.19
SphereFace-Rv2 HFN 1.5 64 - 98.46 98.69 41.22 88.86 94.77 95.18 79.57 93.78 84.21 93.55 96.14 96.27 89.85 94.95
SphereFace SFN 1.7 32 1.0 98.23 98.50 45.35 84.86 94.20 94.90 76.38 93.32 80.83 92.17 95.70 95.91 86.44 94.37
SphereFace-Rv1 SFN 1.6 32 1.0 98.07 98.15 42.97 87.92 94.32 94.94 78.47 93.32 85.43 93.06 95.83 96.02 89.13 94.56
SphereFace-Rv2 SFN 1.5 64 0.2 98.26 98.58 45.64 86.55 94.51 95.10 76.53 93.65 80.19 93.01 95.96 96.19 87.39 94.88
network).WeusethesamemodelsfromSection6.2andSec- in our SphereFace family shows competitive results com-
tion 6.3 with the best-performing hyperparameters on the pared to the state-of-the-art methods. Both SphereFace and
validationset.Specifically,wetrainSFNet-20onVGGFace2 SphereFace-RperformparticularlywellunderthelowFAR,
and SFNet-64 on MS-Celeb-1M. We compare our models such as 1:1 verification TAR at 1e-6 and 1:N identification
to current state-of-the-art methods, i.e., NormFace [9], Cos- TPIR at 1e-1 FPIR. These metrics are very important in
Face [3], [4], ArcFace [5], circle loss [26] and Curricular- designingarobustfacerecognitionsysteminpractice.
Face[40].Thehyperparametersofthesemethodsaretuned
toachievetothebestvalidationperformance. 6.4.2 ExperimentswithIResNet-100
We make several useful observations from Table 10 and In order to have a comprehensive comparison with the
Table 11. First, the results on large-scale testing sets are published results, we conduct the experiments to train our
consistent with those on the validation set, especially the methods on MS-Celeb-1M [77] with IResNet-100 [5]. Com-
metrics at low false acceptance rate (FAR) or false posi- paring the results in Table 12 and Table 11, we observe
tive identification rates (FPIR). The consistent performance that IResNet100 achieves better performance than those
demonstrates the effectiveness of the selected validation using SFNet-64 (with the same set of hyperparameters),
set and metric. This indicates that the models that achieve establishing a higher baseline for SphereFace. For different
higher performance on the validation set usually show FNstrategies,IResNet100performssimilarlytoSFNet64in
betterresultsonMegaFaceandIJBaswell. the sense that HFN is slightly better than SFN and they
are both better than NFN. In general, both SphereFace
Second,differenttypesofmarginstendtoachievesimi-
and SphereFace-R are generally comparable to CosFace
larperformance,whiledifferenttypesofFNstrategieshave
and ArcFace. SphereFace with HFN achieves the best per-
significantly different results. In Fig. 6, we first show the
formance on MegaFace. More interestingly, we find that
training losses for different FN strategies. Fig. 6(a) shows
both SphereFace and SphereFace-R v1 with HFN achieve
that all the models equipped with NFN, HFN or SFN
significantlybetter1:1verificationperformanceatlowFAR
converge well on VGGFace2, a relatively small, clean and
thanallthecomparedmethodsonIJB.
high-quality training set. From Table 10, NFN and HFN
showcomparablegeneralizationability,whileSFNachieves
the best performance among all FN strategies. This implies 7 CONCLUDING REMARKS
thatmakinggooduseofthemagnitudeinformationduring Our paper proposes a novel framework that unifies hy-
trainingcaneffectivelyimprovetheresults.Fig.6(b)shows perspherical face recognition. This framework provides a
thatNFNisunabletoconvergetoasufficientlysmalltrain- general principle for a loss function to incorporate large
ing loss on MS-Celeb-1M, a large, noisy and low-quality angular margins. Under this framework, we substantially
dataset. From Table 11, we can observe that NFN indeed extendandimproveourpreviousworkonSphereFace[2]by
convergestoabadlocalminimathatgeneralizespoorly.By addressing training instability and significantly improving
introducingamagnituderegularizationtermtotheobjective empirical performance. Specifically, we propose two new
function, SFN can effectively help the models escaping types of multiplicative margins that effectively implement
from the bad local minima. In contrast to the results on theoriginalintuitionofSphereFace.Moreover,wealsocome
VGGFace2,wefindthatSFNperformsworsethanHFNon up with a novel implementation technique called charac-
MS-Celeb-1M,implyingthatSFNmaybemoresensitiveto teristic gradient detachment to further improve training
noisy samples in the training set and HFN may be more stability and generalization. Extensive experiments on a
robusttodifferenttrainingsetsthanNFNandSFN. number of popular benchmarks are conducted to validate
Finally, with our proposed modifications, all variants thesuperiorityofourSphereFacefamily.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 15
Based on the unified framework, our paper demon- [18] J.Lu,G.Wang,W.Deng,P.Moulin,andJ.Zhou,“Multi-manifold
strates strong flexibility and many unique advantages of deepmetriclearningforimagesetclassification,”inCVPR,2015.
[19] H. O. Song, Y. Xiang, S. Jegelka, and S. Savarese, “Deep metric
hypersphericalFR.Therestillexistanumberofexcitingyet
learningvialiftedstructuredfeatureembedding,”inCVPR,2016.
under-explored open problems in hyperspherical FR, such
[20] Y.Movshovitz-Attias,A.Toshev,T.K.Leung,S.Ioffe,andS.Singh,
as how to design better angular margin, how to effectively “Nofussdistancemetriclearningusingproxies,”inICCV,2017.
incorporate feature magnitude into training and testing, [21] C.-Y. Wu, R. Manmatha, A. J. Smola, and P. Krahenbuhl, “Sam-
howtolearnthelossfunctiondirectlyfromdata,etc.Wealso plingmattersindeepembeddinglearning,”inICCV,2017.
[22] W. Ge, “Deep metric learning with hierarchical triplet loss,” in
present a few useful characterizations for the loss function
ECCV,2018.
in hyperspherical FR, leading to multiple equivalent loss
[23] Y.Duan,W.Zheng,X.Lin,J.Lu,andJ.Zhou,“Deepadversarial
designspaces.Currentpopularlossfunctionsonlyrepresent metriclearning,”inCVPR,2018.
a very small and limited subset in the huge design space [24] Q.Qian,L.Shang,B.Sun,J.Hu,H.Li,andR.Jin,“Softtripleloss:
Deepmetriclearningwithouttripletsampling,”inICCV,2019.
of hyperspherical FR. We expect that more work can be
[25] X. Wang, Y. Hua, E. Kodirov, G. Hu, R. Garnier, and N. M.
devotedtothispromisinglineofresearchinthefuture.
Robertson,“Rankedlistlossfordeepmetriclearning,”inCVPR,
2019.
[26] Y. Sun, C. Cheng, Y. Zhang, C. Zhang, L. Zheng, Z. Wang, and
ACKNOWLEDGMENTS
Y.Wei,“Circleloss:Aunifiedperspectiveofpairsimilarityopti-
mization,”inCVPR,2020.
The authors would like to sincerely thank Haoran Sun,
[27] K.Musgrave,S.Belongie,andS.-N.Lim,“Ametriclearningreality
Yuyu Zhang and Will Powell for generously helping us
check,”inECCV,2020.
to schedule computing resources, and Hanchen Wang for [28] Y. Wen, K. Zhang, Z. Li, and Y. Qiao, “A comprehensive study
proofreading. Weiyang Liu is supported by a Cambridge- on center loss for deep face recognition,” International Journal of
Tu¨bingen Fellowship, an NVIDIA GPU grant, DeepMind ComputerVision,vol.127,no.6,pp.668–683,2019.
[29] R. Ranjan, C. D. Castillo, and R. Chellappa, “L2-constrained
and the Leverhulme Trust via CFI. Adrian Weller acknowl-
softmax loss for discriminative face verification,” arXiv preprint
edges support from a Turing AI Fellowship under grant arXiv:1703.09507,2017.
EP/V025379/1, The Alan Turing Institute under EPSRC [30] Y. Liu, H. Li, and X. Wang, “Rethinking feature discrimination
grant EP/N510129/1 and TU/B/000074, and the Lever- and polymerization for large-scale recognition,” arXiv preprint
arXiv:1710.00870,2017.
hulme Trust via CFI. This work is partially supported by
[31] W. Liu, Y.-M. Zhang, X. Li, Z. Yu, B. Dai, T. Zhao, and L. Song,
theDefenceScienceandTechnologyAgency(DSTA),Singa-
“Deephypersphericallearning,”inNIPS,2017.
pore under contract number A025959, and this paper does [32] W.Liu,R.Lin,Z.Liu,L.Liu,Z.Yu,B.Dai,andL.Song,“Learning
not reflect the position or policy of DSTA and no official towardsminimumhypersphericalenergy,”inNeurIPS,2018.
endorsementshouldbeinferred. [33] R. Ranjan, A. Bansal, H. Xu, S. Sankaranarayanan, J.-C. Chen,
C.D.Castillo,andR.Chellappa,“Crystallossandqualitypooling
forunconstrainedfaceverificationandrecognition,”arXivpreprint
arXiv:1804.01159,2018.
REFERENCES
[34] K.Zhao,J.Xu,andM.-M.Cheng,“Regularface:Deepfacerecog-
[1] W.Liu,Y.Wen,Z.Yu,andM.Yang,“Large-marginsoftmaxloss nitionviaexclusiveregularization,”inCVPR,2019.
forconvolutionalneuralnetworks,”inICML,2016. [35] Y.Duan,J.Lu,andJ.Zhou,“Uniformface:Learningdeepequidis-
[2] W.Liu,Y.Wen,Z.Yu,M.Li,B.Raj,andL.Song,“Sphereface:Deep tributedrepresentationforfacerecognition,”inCVPR,2019.
hypersphereembeddingforfacerecognition,”inCVPR,2017. [36] X. Zhang, R. Zhao, Y. Qiao, X. Wang, and H. Li, “Adacos:
[3] F.Wang,W.Liu,H.Liu,andJ.Cheng,“Additivemarginsoftmax Adaptivelyscalingcosinelogitsforeffectivelylearningdeepface
forfaceverification,”arXivpreprintarXiv:1801.05599,2018. representations,”inCVPR,2019.
[4] H. Wang, Y. Wang, Z. Zhou, X. Ji, D. Gong, J. Zhou, Z. Li, [37] H. Liu, X. Zhu, Z. Lei, and S. Z. Li, “Adaptiveface: Adaptive
and W. Liu, “Cosface: Large margin cosine loss for deep face marginandsamplingforfacerecognition,”inCVPR,2019.
recognition,”inCVPR,2018. [38] Y.Wu,Y.Wu,R.Gong,Y.Lv,K.Chen,D.Liang,X.Hu,X.Liu,and
[5] J. Deng, J. Guo, N. Xue, and S. Zafeiriou, “Arcface: Additive J. Yan, “Rotation consistent margin loss for efficient low-bit face
angularmarginlossfordeepfacerecognition,”inCVPR,2019. recognition,”inCVPR,2020.
[6] Y.Taigman,M.Yang,M.Ranzato,andL.Wolf,“Deepface:Closing [39] I. Kim, S. Han, S.-J. Park, J.-W. Baek, J. Shin, J.-J. Han, and
thegaptohuman-levelperformanceinfaceverification,”inCVPR, C.Choi,“Discface:Minimumdiscrepancylearningfordeepface
2014. recognition,”inACCV,2020.
[7] Y.Sun,X.Wang,andX.Tang,“Deeplearningfacerepresentation
[40] Y.Huang,Y.Wang,Y.Tai,X.Liu,P.Shen,S.Li,J.Li,andF.Huang,
frompredicting10,000classes,”inCVPR,2014.
“Curricularface: adaptive curriculum learning loss for deep face
[8] W. Liu, Z. Liu, Z. Yu, B. Dai, R. Lin, Y. Wang, J. M. Rehg, and
recognition,”inCVPR,2020.
L.Song,“Decouplednetworks,”inCVPR,2018.
[41] J. Deng, J. Guo, T. Liu, M. Gong, and S. Zafeiriou, “Sub-center
[9] F. Wang, X. Xiang, J. Cheng, and A. L. Yuille, “Normface: L2
arcface:Boostingfacerecognitionbylarge-scalenoisywebfaces,”
hypersphereembeddingforfaceverification,”inACM-MM,2017.
inECCV,2020.
[10] Y.Zheng,D.K.Pal,andM.Savvides,“Ringloss:Convexfeature
[42] Y. Kim, W. Park, M.-C. Roh, and J. Shin, “Groupface: Learning
normalizationforfacerecognition,”inCVPR,2018.
latent groups and constructing group-based representations for
[11] O.M.Parkhi,A.Vedaldi,andA.Zisserman,“Deepfacerecogni-
facerecognition,”inCVPR,2020.
tion,”inBMVC,2015.
[12] Y. Sun, Y. Chen, X. Wang, and X. Tang, “Deep learning face [43] Y. Zhong, W. Deng, J. Hu, D. Zhao, X. Li, and D. Wen, “Sface:
representationbyjointidentification-verification,”inNIPS,2014. sigmoid-constrained hypersphere loss for robust face recogni-
[13] F. Schroff, D. Kalenichenko, and J. Philbin, “Facenet: A unified tion,”IEEETransactionsonImageProcessing,vol.30,pp.2587–2598,
embeddingforfacerecognitionandclustering,”inCVPR,2015. 2021.
[14] Y. Wen, K. Zhang, Z. Li, and Y. Qiao, “A discriminative feature [44] S.Li,J.Xu,X.Xu,P.Shen,S.Li,andB.Hooi,“Sphericalconfidence
learningapproachfordeepfacerecognition,”inECCV,2016. learningforfacerecognition,”inCVPR,2021.
[15] Y.Sun,X.Wang,andX.Tang,“Sparsifyingneuralnetworkcon- [45] Q.Meng,S.Zhao,Z.Huang,andF.Zhou,“Magface:Auniversal
nectionsforfacerecognition,”inCVPR,2016. representation for face recognition and quality assessment,” in
[16] J.Liu,Y.Deng,andC.Huang,“Targetingultimateaccuracy:Face CVPR,2021.
recognitionviadeepembedding,”arXivpreprint:1506.07310,2015. [46] Y. Wen, W. Liu, A. Weller, B. Raj, and R. Singh, “Sphereface2:
[17] J. Hu, J. Lu, and Y.-P. Tan, “Discriminative deep metric learning Binary classification is all you need for deep face recognition,”
forfaceverificationinthewild,”inCVPR,2014. inICLR,2022.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 16
[47] W.-Y. Chen, Y.-C. Liu, Z. Kira, Y.-C. F. Wang, and J.-B. [77] Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao, “Ms-celeb-1m: A
Huang, “A closer look at few-shot classification,” arXiv preprint dataset and benchmark for large-scale face recognition,” in Eu-
arXiv:1904.04232,2019. ropeanconferenceoncomputervision. Springer,2016,pp.87–102.
[48] W. Liu, Z. Liu, J. M. Rehg, and L. Song, “Neural similarity [78] G.B.Huang,M.Ramesh,T.Berg,andE.Learned-Miller,“Labeled
learning,”inNeurIPS,2019. faces in the wild: A database for studying face recognition in
[49] P.Mettes,E.vanderPol,andC.Snoek,“Hypersphericalprototype unconstrainedenvironments,”TechnicalReport,Tech.Rep.,2007.
networks,”inNeurIPS,2019. [79] S. Moschoglou, A. Papaioannou, C. Sagonas, J. Deng, I. Kotsia,
[50] W. Liu, R. Lin, Z. Liu, L. Xiong, B. Scho¨lkopf, and A. Weller, andS.Zafeiriou,“Agedb:thefirstmanuallycollected,in-the-wild
“Learningwithhypersphericaluniformity,”inAISTATS,2021. agedatabase,”inCVPRWorkshops,2017.
[51] W.Liu,R.Lin,Z.Liu,J.M.Rehg,L.Paull,L.Xiong,L.Song,and [80] T. Zheng and W. Deng, “Cross-pose lfw: A database for study-
A. Weller, “Orthogonal over-parameterized training,” in CVPR, ing cross-pose face recognition in unconstrained environments,”
2021. TechnicalRepert,2018.
[52] B.YuandD.Tao,“Deepmetriclearningwithtupletmarginloss,” [81] T. Zheng, W. Deng, and J. Hu, “Cross-age lfw: A database for
inICCV,2019. studying cross-age face recognition in unconstrained environ-
[53] K.He,H.Fan,Y.Wu,S.Xie,andR.Girshick,“Momentumcontrast ments,”arXivpreprintarXiv:1708.08197,2017.
forunsupervisedvisualrepresentationlearning,”inCVPR,2020. [82] S.Sengupta,J.-C.Chen,C.Castillo,V.M.Patel,R.Chellappa,and
[54] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, “A simple D.W.Jacobs,“Frontaltoprofilefaceverificationinthewild,”in
frameworkforcontrastivelearningofvisualrepresentations,”in WACV,2016.
ICML,2020. [83] C.Whitelam,E.Taborsky,A.Blanton,B.Maze,J.Adams,T.Miller,
[55] J.-B. Grill, F. Strub, F. Altche´, C. Tallec, P. Richemond, N. Kalka, A. K. Jain, J. A. Duncan, K. Allen et al., “Iarpa janus
E. Buchatskaya, C. Doersch, B. Pires, Z. Guo, M. Azar et al., benchmark-bfacedataset,”inCVPRworkshops,2017.
“Bootstrap your own latent: A new approach to self-supervised [84] B. Maze, J. Adams, J. A. Duncan, N. Kalka, T. Miller, C. Otto,
learning,”inNeurIPS,2020. A. K. Jain, W. T. Niggel, J. Anderson, J. Cheney et al., “Iarpa
[56] T. Wang and P. Isola, “Understanding contrastive representation janus benchmark-c: Face dataset and protocol,” in International
learningthroughalignmentanduniformityonthehypersphere,” ConferenceonBiometrics,2018.
inICML,2020. [85] I.Kemelmacher-Shlizerman,S.M.Seitz,D.Miller,andE.Brossard,
[57] S.W.ParkandJ.Kwon,“Spheregenerativeadversarialnetwork “The megaface benchmark: 1 million faces for recognition at
basedongeometricmomentmatching,”inCVPR,2019. scale,”inCVPR,2016.
[86] D. Miller, E. Brossard, S. Seitz, and I. Kemelmacher-Shlizerman,
[58] T.R.Davidson,L.Falorsi,N.DeCao,T.Kipf,andJ.M.Tomczak,
“Megaface: A million faces for recognition at scale,” arXiv
“Hypersphericalvariationalauto-encoders,”inUAI,2018.
preprint:1505.02108,2015.
[59] T.S.Cohen,M.Geiger,J.Ko¨hler,andM.Welling,“Sphericalcnns,”
[87] C. Barra, B. Alvarez, S. Paul, A. Sette, B. Peters, M. Andreatta,
inICLR,2018.
S.Buus,andM.Nielsen,“Footprintsofantigenprocessingboost
[60] Y.Rao,J.Lu,andJ.Zhou,“Sphericalfractalconvolutionalneural
mhcclassiinaturalligandpredictions,”Genomemedicine,vol.10,
networksforpointcloudrecognition,”inCVPR,2019.
no.1,pp.1–15,2018.
[61] R.Lin,W.Liu,Z.Liu,C.Feng,Z.Yu,J.M.Rehg,L.Xiong,and
L. Song, “Regularizing neural networks via minimizing hyper-
sphericalenergy,”inCVPR,2020.
Weiyang Liu is currently conducting research
[62] X. Fan, W. Jiang, H. Luo, and M. Fei, “Spherereid: Deep hyper-
at the University of Cambridge, UK and the
spheremanifoldembeddingforpersonre-identification,”Journal
Max Planck Institute for Intelligent Systems,
ofVisualCommunicationandImageRepresentation,vol.60,pp.51–58,
Tu¨bingen, Germany under the Cambridge-
2019.
Tu¨bingen Fellowship Program. Prior to joining
[63] H.-X.Yu,W.-S.Zheng,A.Wu,X.Guo,S.Gong,andJ.-H.Lai,“Un-
thisprogram,hehasbeenwithCollegeofCom-
supervisedpersonre-identificationbysoftmultilabellearning,”in
puting,GeorgiaInstituteofTechnology,Atlanta,
CVPR,2019.
GA, USA. His research interests broadly lie in
[64] Y.Hao,N.Wang,J.Li,andX.Gao,“Hsme:hyperspheremanifold
deep learning, representation learning, interac-
embeddingforvisiblethermalpersonre-identification,”inAAAI,
tivemachinelearningandcausality.
2019.
[65] M. Hajibabaei and D. Dai, “Unified hypersphere embedding for
speakerrecognition,”arXivpreprintarXiv:1807.08312,2018.
[66] Y.Liu,L.He,andJ.Liu,“Largemarginsoftmaxlossforspeaker Yandong Wen received the B.S. and M.S. de-
verification,”inInterspeech,2019. grees from South China University of Technol-
[67] R. Li, N. Li, D. Tuo, M. Yu, D. Su, and D. Yu, “Boundary dis- ogy, Guangzhou, China in 2013 and 2016, re-
criminativelargemargincosinelossfortext-independentspeaker spectively.HeisaPh.D.candidateatCarnegie
verification,”inICASSP,2019. Mellon University, Pittsburgh, PA, USA, where
[68] Y. Fathullah, C. Zhang, and P. C. Woodland, “Improved large- heworkswithBhikshaRajandRitaSingh.His
marginsoftmaxlossforspeakerdiarisation,”inICASSP,2020. currentresearchinterestsaredeeplearningfor
[69] Y.Meng,J.Huang,G.Wang,C.Zhang,H.Zhuang,L.Kaplan,and facerecognition,audio-visualassociationlearn-
J.Han,“Sphericaltextembedding,”inNeurIPS,2019. ing,and3Dfacereconstruction.
[70] X. Wang, S. Wang, C. Chi, S. Zhang, and T. Mei, “Loss function
searchforfacerecognition,”inICML,2020.
[71] C. Li, X. Yuan, C. Lin, M. Guo, W. Wu, J. Yan, and W. Ouyang,
“Am-lfs:Automlforlossfunctionsearch,”inICCV,2019. BhikshaRaj(Fellow,IEEE)receivedthePh.D.
[72] B. Chen, W. Liu, Z. Yu, J. Kautz, A. Shrivastava, A. Garg, and degree in electrical and computer engineering
A.Anandkumar,“Angularvisualhardness,”inICML,2020. fromCarnegieMellonUniversity,Pittsburgh,PA,
[73] K.Zhang,Z.Zhang,Z.Li,andY.Qiao,“Jointfacedetectionand USA, in 2000. He is a Professor of the Com-
alignment using multi-task cascaded convolutional networks,” puter Science Department, Carnegie Mellon
arXivpreprint:1604.02878,2016. University where he leads the Machine Learn-
[74] J.Deng,J.Guo,E.Ververas,I.Kotsia,andS.Zafeiriou,“Retinaface: ing for Signal Processing Group. He joined the
Single-shot multi-level face localisation in the wild,” in CVPR, CarnegieMellonfacultyin2009,afterspending
2020. timeattheCompaqCambridgeResearchLabs
[75] S.IoffeandC.Szegedy,“Batchnormalization:Acceleratingdeep andMitsubishiElectricResearchLabs.Hehas
network training by reducing internal covariate shift,” in ICML, devoted his career to developing speech- and
2015. audio-processingtechnology.Hehashadseveralseminalcontributions
[76] Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, “Vg- in the areas of robust speech recognition, audio content analysis and
gface2: A dataset for recognising faces across pose and age,” in signalenhancement,andhaspioneeredtheareaofprivacy-preserving
IEEEinternationalconferenceonautomaticface&gesturerecognition, speechprocessing.HeisalsotheChiefArchitectofthepopularSphinx-
2018. 4speech-recognitionsystem.
IEEETRANSACTIONSONPATTERNANALYSISANDMACHINEINTELLIGENCE 17
Rita Singh received the B.Sc.(Hons.) degree
in physics and the M.Sc. degree in exploration
geophysics, both from the Banaras Hindu Uni-
versity, India. She received the Ph.D degree in
geophysicsin1996fromtheNationalGeophysi-
calResearchInstituteoftheCouncilofScientific
andIndustrialResearch,India.Sheiscurrently
aMemberoftheResearchFacultyattheSchool
of Computer Science, Carnegie Mellon Univer-
sity (CMU), Pittsburgh, PA, USA. From March
1996toNovember1997,shewasaPostdoctoral
Fellow with the Tata Institute of Fundamental Research, India, where
sheworkedwiththeCondensedMatterPhysicsandComputerSystems
andCommunicationsGroups.Duringthisperiod,sheworkedonnon-
lineardynamicalsystemsandsignalprocessingasanextensionofher
doctoral work on nonlinear geodynamics and chaos. Since November
1997, she has been affiliated with the Robust Speech Recognition
andSPHINXGroupsatCMU.Shecurrentlyworksoncorealgorithmic
aspectsofcomputervoicerecognition,andartificialintelligenceapplied
tovoiceforensics.Herfocusisonthedevelopmentoftechnologyforthe
automateddiscovery,measurement,representationandlearningofthe
informationencodedinvoicesignalforoptimalvoiceintelligence.
Adrian Weller received his undergraduate de-
greefromtheUniversityofCambridge,andhis
PhDfromColumbiaUniversityinNewYork.Heis
ProgrammeDirectorforAIatTheAlanTuringIn-
stitute,theUKnationalinstitutefordatascience
andAI,whereheisalsoaTuringFellowleading
work on safe and ethical AI. He is a Principal
Research Fellow in Machine Learning at Cam-
bridge, and at the Leverhulme Centre for the
Future of Intelligence where he is Programme
DirectorforTrustandSociety.Hisinterestsspan
AI, its commercial applications and helping to ensure beneficial out-
comes for society. He is Co-Director of the European Laboratory for
LearningandIntelligentSystems(ELLIS)programmeonHuman-centric
MachineLearning.Previously,heheldseniorrolesinfinance.
