Clever Hans or Neural Theory of Mind?
Stress Testing Social Reasoning in Large Language Models
NatalieShapira1 MoshLevy*1 SeyedHosseinAlavi*2,3 XuhuiZhou*4
YejinChoi5,6 YoavGoldberg1,5 MaartenSap4,5 VeredShwartz2,3
1 Bar-IlanUniversity 2 UniversityofBritishColumbia
3 VectorInstituteforAI 4 CarnegieMellonUniversity
5 AllenInstituteforArtificialIntelligence 6 UniversityofWashington
nd1234@gmail.com
Abstract TworecentpapersaddressedwhetherLargeLan-
guage Models (LLMs; Brown et al., 2020; Bom-
TheescalatingdebateonAI’scapabilitieswar-
masanietal.,2021;Zhaoetal.,2023)haveaToM,
rantsdevelopingreliablemetricstoassessma-
chine“intelligence.” Recently,manyanecdo- andcametooppositeconclusions: Sapetal.(2022)
talexampleswereusedtosuggestthatnewer shows they lack this ability and Kosinski (2023)
largelanguagemodels(LLMs)likeChatGPT claimsthisabilityhasemergedinthenewermod-
andGPT-4exhibitNeuralTheory-of-Mind(N- els spontaneously. The latter was criticized for
ToM);however,priorworkreachedconflicting
itsflawedmethodology(MarcusandDavis,2023).
conclusions regarding those abilities. We in-
Ullman(2023)furthershowedthatsimplechanges
vestigatetheextentofLLMs’N-ToMthrough
to the ToM questions break LLMs. But to para-
anextensiveevaluationon6tasksandfindthat
while LLMs exhibit certain N-ToM abilities, phrase the saying, hype gets halfway around the
this behavior is far from being robust. We world before rigorous experiments put on their
further examine the factors impacting perfor- boots; other researchers continue to spread the
manceonN-ToMtasksanddiscoverthatLLMs word about N-ToM, claiming that GPT-4 “has a
strugglewithadversarialexamples,indicating
veryadvancedleveloftheoryofmind”basedona
reliance on shallow heuristics rather than ro-
fewanecdotalexamples(Bubecketal.,2023).
bustToMabilities. Wecautionagainstdrawing
conclusionsfromanecdotalexamples,limited
DoLLMshaverobustN-ToM? Thispaperaims
benchmarktesting,andusinghuman-designed
toaddressthediscrepancyandlimitedscopeofpre-
psychologicalteststoevaluatemodels.
viouswork(thateachtested2tasks)byperforming
1 Introduction anextensiveevaluationon6taskstargetingvarious
aspects of ToM. We also experiment with differ-
TheoryofMind(ToM)istheabilitytounderstand
ent probing methods (i.e., generative QA format
thatotherpeoplehavethoughts,beliefs,andemo-
vs. probability of answer choices). We find that
tions that differ from one’s own (Wimmer and
contemporaryLLMsdemonstratecertainN-ToM
Perner,1983). AsToMisinherentlylinkedtohu-
abilities,buttheseabilitiesarenotrobust(§4).
mancognition,imbuingmachineswithcapabilities
that mimic or resemble ToM has the potential to
ToMorSpuriousCorrelations? Weinvestigate
lead to the “ELIZA effect” (Weizenbaum, 1976),
through a series of experiments the factors influ-
whereinhuman-likeintelligenceorevensentience
encing performance on N-ToM tasks. We show
andconsciousnessisincorrectlyascribedtothema-
thatLLMsperformworseondatasetsthatwerede-
chine(e.g.,Kosinski,2023;Bubecketal.,2023).
signedtopreventannotationartifacts. Wealsoen-
InlightofthesepossiblyillusoryToMabilities,
hancedthedatasetoriginallyproposedbyKosinski
thereisapressingneedtodeveloprobustmetrics
(2023)toincorporateadversarialexamplesinspired
for assessing Neural-ToM (N-ToM) in machines.
byUllman(2023). Wefindthattheperformanceof
This is particularly crucial given the escalating
LLMsdecreasesforadversarialexamples,suggest-
stakes of the debate on the extent to which ma-
ingthatLLMsdon’thaverobustToMabilitiesbut
chinespossessToM-likeabilitiesandthepotential
ratherrelyonshallowheuristics(§5).
ramificationsofoverblownclaimsinAI.1
Wesummarizethesefindingsandadditionalin-
*Theseauthorscontributedequallytothiswork. sightsin§6. Inparticular,wewarnagainstdrawing
1https://futureoflife.org/open-letter/
conclusions from anecdotal examples, testing on
pause-giant-ai-experiments/
https://amcs-community.org/open-letters/ a few benchmarks, and using psychological tests
3202
yaM
42
]LC.sc[
1v36741.5032:viXra
designedforhumanstotestmodels.2 the listener might not want to hear or know, and
which typically has negative consequences that
2 Background: ToMandClinicalTests thespeakerneverintended”(Baron-Cohenetal.,
1999). Anexampleofafauxpassituationiswhen
ToM has a long history starting in philosophy
aguesttellstheirhoststhatthey“likecakesexcept
(Lewis,1966)andlaterinpsychologyandcogni-
forapplepie”,withoutrealizingthatthehostshave
tivescience(PremackandWoodruff,1978). ToM
made an apple pie for them. The complexity of
involves understanding mental states, beliefs, de-
the situation depends not only on the content of
sires, intentions, and emotions of the self and of
thestatement(“exceptforapplepie”)butalsoon
others. Clinicalpsychologytestsweredeveloped
the context in which it was made (e.g., the host
to test ToM abilities in humans, such as the false
hadmadeanapplepieandtheguestwasunaware).
beliefandfauxpastestsdetailedhere.3
Faux pas is the “uh-oh!” emotion most people
wouldfeelwhentheyrevealtherealityofthecon-
2.1 FalseBeliefTest
text. In this context, the statement wouldn’t be
In a false belief test (Wimmer and Perner, 1983)
problematicifthehostsmadeacheesecakeinstead.
the examinee is told a story in which a character
Intheoriginaltest,thesubjectistold10stories
in the story is exposed to partial information and
that contain faux pas. At the end of each story,
thereforemistakenlybelievesinsomethingthatis
thesubjectisasked4questions: detection-Inthe
nottrue(“falsebelief”)incontrasttothelistener
storydidsomeonesaysomethingthattheyshould
whoisexposedtothefullstory.
nothavesaid?;identification-Whatdidtheysay
Awidelyusedclinicalpsychologytasktoassess
thattheyshouldnothavesaid?;Andtwoquestions
false belief understanding is the Sally–Anne Test
thatdifferbystory: comprehensive-e.g.,Where
(Baron-Cohenetal.,1985)orunexpectedtransfer.
does the event take place?, and false belief - did
Inthistest,Sallyhasabasket,andAnnehasabox.
theyknoworrememberthat?
Sally puts a marble in her basket and leaves the
room. Annetakesthemarbleoutofthebasketand 2.3 FromHumanTeststoMachineTests
puts it in her box. The examinee is asked about
StudieshaveexploredtheuseofNLPtechniques
first order belief, i.e. where will Sally look for
to model basic ToM skills. For example, in de-
her marble?; about the reality, i.e. where is the
tectingmentalstatesandemotions(Tausczikand
marble?;andabouttheirmemory,i.e. wherewas
Pennebaker, 2010; Guntuku et al., 2017; Gordon
themarbleinthebeginning?.
andHobbs,2017;Rashkinetal.,2018a,b;Shapira
TheanswersarethatSallywilllookinthebasket,
etal.,2021)orbygeneratingahumorousresponse
where she left the marble. Sally’s belief is false
whentheinterlocutorisinaplayfulmood(Shani
becausesheisunawareofthemarble’srelocation
etal.,2022;Shapiraetal.,2023a). Recentworkis
tothebox. However,alistenerexposedtotheentire
focused around creating datasets testing whether
storyknowsthatthemarbleisnolongerinSally’s
andtowhatextentmodelshaveToM(see§3). Itis
basketandthatSallywilllookinthewrongplace.
importanttonotethattheconsequencesofthe
Inmorecomplexversions,SecondOrderBelief
success of these tests do not straightforwardly
question would be, where does Anne think Sally
transferfromhumanstomodels(see§6).
willlookforhermarble?
Inadifferentversionofafalsebelieftask,known
3 Data
astheSmartiesTest(Perneretal.,1987),thepro-
tagonist is dealing with unexpected content, i.e., WeusedalldatasetslistedinTable1inourexperi-
unaware of the actual contents of a container be- ments. Belowisabriefdescriptionofeachdataset.
causeoffalselabeling. The creation of ToMi’ which is based on ToMi
is described immediately after the description of
2.2 FauxPasTest
ToMi (§3.1). The creation of Adv-CSFB (§3.2)
Faux Pas occurs when “a speaker says some- containsadescriptionofthedatasetsitisbasedon.
thing without considering if it is something that
3.1 ExistingBenchmarks&Variants
2Thecodeanddataisavailableat:https://github.com/
TriangleCOPA(Gordon,2016). Asetof100
salavi/Clever_Hans_or_N-ToM
3Foradetailedreviewsee(OsterhausandBosacki,2022). problems,eachdescribesashortsequenceofevents
2
Dataset InspiredbyTheory/Test Test Construc Example
Size -tion
Triangle Interpretingthesocialbe- 100 Experts Acircleisinthehousemovingaround.Atriangleburstsinthroughthedoor.Thecircle
COPA haviouroffictionalcharac- turnsaroundandfreezes.Howdoesthecirclefeel?
Gordon ters (a)Thecircleissurprisedbythetriangle’ssuddenentranceintotheroom.
(2016) (b)Thecircleisexcitedtoseethetriangle.
SocialIQa Reasoning about motiva- 400 Crowd- Intheschoolplay,Robinplayedaherointhestruggletothedeathwiththeangryvillain.
Sap et al. tions, what happens next random sourcing Howwouldothersfeelafterwards?
(2019) andemotionalreaction sample (a)sorryforthevillain
outof (b)hopefulthatRobinwillsucceed
37,588 (c)likeRobinshouldlose
ToMi Unexpected transfer task, 400 Synthetic Jacksonenteredthehall.Chloeenteredthehall.Thebootsisinthebathtub.Jacksonexited
Le et al. firstandsecondorderfalse random thehall.Jacksonenteredthedining_room.Chloemovedthebootstothepantry.
(2019) belief;(Baron-Cohenetal., sample (Memory)Wherewasthebootsatthebeginning?(bathtub)
1985) outof (Reality)Whereisthebootsreally?(pantry)
above (Firstorder)WherewillChloelookfortheboots?(pantry)
1000 (Secondorder)7WheredoesChloethinkthatJacksonsearchesfortheboots?(bathtub)
ToMi’ 180 Experts <SamestoryasinToMi>
This paper, questions (Memory)Atthebeginning,thebootswereinthe(bathtub)
based on 30 (Reality)Thebootsarereallyinthe(pantry)
ToMi ad- stories (Firstorder)Chloewilllookforthebootsinthe(pantry)
justments (Secondorder)ChloethinksthatJacksonsearchesforthebootsinthe(bathtub)
epistemic Verbs, factive and non- 2000 Experts Premise:JohnknowsthatAnnthinksthatthereismilkinthekitchen.
_reasoning factive,thatdescribeepis- with 10 Hypothesis:Annthinksthatthereismilkinthekitchen.(Entailment=1)
Cohen temicmentalstates; intra- templates Hypothesis:Johnthinksthatthereismilkinthekitchen.(Entailment=0)
(2021) personal,inter-personaland
inferencereasoning;(Wim- Premise:JohnthinksthatAnnknowsthatthereismilkinthekitchen.
merandPerner,1983;Hin- Hypothesis:Annthinksthatthereismilkinthekitchen.(Entailment=0)
tikka,1962) Hypothesis:Johnthinksthatthereismilkinthekitchen.(Entailment=1)
Adv-CSFB Unexpected content or 183 Experts Ontheshelf,thereisabottle.Itisfullofbeerandthelabelonthisbottlesays“beer”.Mark
This paper, transfer task, integrate questions walksintotheroomlookingforbeerandnoticesthebottle.Hehasneverseenitbefore.He
based on commonsense reasoning, 40 readsthelabel.
Kosinski first-order false belief; stories (a)Heopensthebottleandlooksinside,Hecanclearlyseethatitisfullof(beer)
& Ullman (Baron-Cohenetal.,1985; (b)Hebelievesthatitisfullof(beer)
(2023) Perneretal.,1987) (c)Hecallshisfriendtotellthemthathehasjustfoundabottlefullof(beer)
FauxPas Recognition of faux pas 176 Experts Jeffwasinaninterview.Whenhefinishedtheinterviewhesankintoacouchinthelobby.
-EAI (Baron-Cohenetal.,1999) questions__and SarahandTim,theexecutiveswhointerviewedhim,wentoutoftheroomandintothelobby
Shapira 44 AI+ExpertswhileSarahsaid:“Heaskedfor179K,couldhaveaskedformuchmore.Weneedtomake
et al. stories himanofferquicklyatthesalaryheaskedfor”.TimsawJeffandsaid“Oh,goodbye”.
(2023b) (FauxPas)Inthestorydidsomeonesaysomethingthattheyshouldnothavesaid?(Yes)
(Identification)Whatdidtheysaythattheyshouldnothavesaid?(“Heaskedfor..)
(Comprehensive)Whowasinterviewed?(Jeff)
(FalseBelief)DidSarahknowJeffissittingononeofthecouchesinthelobby?(No)
Table1: TheoryofMind(ToM)datasetsusedinthiswork.
involving the characters of the Heider and Sim- Nematzadehetal.,2018), comprisingover1,000
mel(1944)film: twotrianglesandacirclemoving distinct stories and questions regarding memory,
aroundaboxwithahingedopening. Thequestions reality,andfirstandsecond-orderfalsebelief. This
requireunderstandingtheactionsequenceandso- syntheticdatasetwasautomaticallygeneratedfor
cialreasoning,andtwoanswerchoicesaregiven. a range of essential objects and actions and was
furtherprocessedforartifactprevention.4
SocialIQa(Sapetal.,2019). Alarge-scale(38k)
dataset for commonsense reasoning about social ToMi Adjustments (ToMi’) ToMi stories are
situations. QuestionsinSocialIQarequirereason- inquestion-answeringformat. Werandomlysam-
ingaboutpeople’smotivationsandmentalstates, pled 30 stories (each story has 6 questions, 180
causes and effects. The questions in SocialIQa questionsintotal)fromtheToMidatasetandmod-
were crowdsourced along with correct and incor- ifiedthemtomatchasentencecompletionformat
rectanswers. Additionaldistractorswereaddedby withthesamemeaning.5 Forexamplethequestion:
usingthecorrectanswerforadifferentquestionon “WheredoesOliverthinkthatEmmasearchesfor
thesamecontext,usingaframeworkthatmitigates thegrapes?”. Wasadjustedtothefollowingsen-
stylisticartifacts. tencecompletiontask: “OliverthinksthatEmma
searchesforthegrapesinthe”.
ToMi (Le et al., 2019). Inspired by the Sally-
Anne test, ToMi is an improved iteration of prior 4SeeAppendix8.1foranexample.
datasets (Weston et al., 2015; Grant et al., 2017; 5Thiswasdonemanuallybyoneoftheauthors.
3
Ontheshelf,thereisabottle. Ontheshelfinthecompany’sheadquarters,thereisaharddrive
Itisfullofbeer;thereisnowineinit. thatcontainsonlyaudiofilesandnovideofiles.
Yet,thelabelonthisbottlesays‘wine’andnot‘beer’. Yet,confusingly,itslabelclearlystates‘videofiles’andnot‘audiofiles.’
Markwalksintotheroomandnoticesthebottle. Thenewlyhiredcomputerengineerfindstheharddriveontheshelf.
Hehasneverseenitbefore.Hereadsthelabel. Shehasneverseenthisharddrivebefore.Shereadsthelabel.
Table2: Variationsthatdemonstratethepatternsimilarity. Besidesthelexicalmatch(black)therearealsosemantic,
grammatical,andpragmaticmatchese.g.,“beer”and“audiofiles”bothsharethesamePOS-tagandplaceinthe
parsingtree;“fullof”and“contains”sharethesamesemanticmeaningforthepurposeofthequestion.
Epistemic Reasoning (Cohen, 2021). This False Belief. In the false-belief examples from
dataset is part of BIG bench (Srivastava et al., Kosinski(2023),theprotagonist’sbeliefaboutthe
2022). It combines ToM with natural language contentofthecontainerisdifferentfromitsactual
inference. The tests pertain to epistemic mental contents. The examples are variants of the corre-
states (Wimmer and Perner, 1983) and epistemic spondingoriginaltestsfrompsychology,e.g. the
logic(Hintikka,1962). Thisisdonebyusingspe- unexpectedcontentsexamplesarevariantsofthe
cificverbsrelatedtoknowledgeandbelief: factive Sally-Anne test. Notably, Kosinski only created
(i.e.,know,understand,recognize,see,remember, false-beliefscenarios.
learn), and non-factive (i.e., believe, think, sus-
TrueBelief. Foramorefairevaluationsetup,we
pect, assume). The dataset contains 3 types of
enhance the unexpected contents task with true
tests: (1)intra-personaltests: reasoningaboutthe
belief examples, i.e. in which the protagonist’s
mentalstatesofasingleagent;(2)inter-personal
beliefaboutthecontentofthecontaineristhesame
tests: reasoningaboutthementalstatesofmultiple
asitsactualcontents. Wedosobymodifyingeach
agents;and(3)inferencereasoning: recognizing
ofthefalsebelief examplessuchthatthelabelnow
thatotheragentsaremakinginferences(i.e.,ifX
indicatesthetruecontentofthecontainer,O . We
entails Y, and Bob believes that X, then, it is rea- 1
mention the alternative content O in a way that
sonabletoconcludethatBobbelievesY). 2
doesn’t change the answer, e.g. Mark walks into
FauxPas-EAI(Shapiraetal.,2023b). Basedon the room looking for O 2 but finds a bag with O 1
theclinicalfauxpastest(Baron-Cohenetal.,1999), labelledas“O 1”. Oneauthorofthispapercreated
the set contains 44 stories (22 faux pas and 22 avariationforeachapplicableexample,whichwas
equivalentcontrol)with4correspondingquestions. thenverifiedbyanotherauthor.
Thestoriesrequirebothsocialreasoningskillsand
AdversarialExamples. Ullman(2023)showed
detectingfalsebelief. Thestorieswerecreatedby
thatLLMsthatachievenear-perfectperformance
expertsandasmallpartofthestorieswascreated
onthefalsebelief examplesfailtosolveanumber
byChatGPTwithrephrasingandfixesbyexperts.
ofadversarialexampleswherenewinformationis
introduced. Inparticular,LLMsstillpredictfalse
3.2 CreationofAdv-CSFB
belief even when new information suggests that
Inspiredbythedisagreeingconclusionsreachedby theprotagonistshouldknowthetruth. Forexam-
priorwork,weintroducetheADVersarialCommon- ple, the LLM predicts that a protagonist looking
SensewithFalse-Belief (Adv-CSFB)dataset. Adv- atabagfullofpopcornthatislabelledas“choco-
CSFB contains 110 examples of the unexpected late”believesthebagisfullofchocolate, evenif
contentstaskand73examplesoftheunexpected thebagistransparentoriftheprotagonistcannot
transfer task (§2.1). Each manually-created ex- read. Ullman’scounterexamplesaresufficientin
ampleinthedatasetconsistsofashortparagraph showingthatLLMsdidnotrobustlyacquireToM
describingtwoobjectsO 1 andO 2,andisfollowed abilities. To further quantify the LLMs’ abilities,
by questions pertaining to reality, i.e. whether a wecreatedupto4additionalexamplesforeachof
certain container contains O 1 or O 2, and the pro- thefalsebelief examples,followingeachoftheal-
tagonist’sbeliefregardingthecontent. terationssuggestedbyUllman(2023): transparent
TheexamplesinAdv-CSFBarecategorizedto access,uninformativelabel,trustworthytestimony,
falsebelief,i.e. theoriginalexamplesfromToM- and late labels for the unexpected contents task,
k (Kosinski, 2023), true belief, and adversarial and transparent access, in→on, trustworthy testi-
examplesinspiredbyUllman(2023). mony,andotherpersonfortheunexpectedtransfer
4
LM MC CoT
davinci-003 55 60 68
GPT-3.5 - 67 69
GPT-4 - 79 72
davinci-003 67 67 71
GPT-3.5 - 70 73
GPT-4 - 70 73
Table3: AccuracyoftherecentGPTmodelsonaran-
domsampleof400instancesfromSocialIQa(Siqa)and
ToMi. Theprobingmethodaffectstheperformance.For
Figure1: Accuraciesoftop-performingmodelsoneach
example,inSiqathereisa7%differenceintheaccuracy
of the ToM tasks, compared to a most frequent class
ofGPT-4betweenMC-probingandCoT-probing.
(MFC) baseline. For several datasets, the best model
achievesperformancecomparabletotheMFCbaseline,
suggestingverylimitedToMability.
Our findings demonstrate that while some
LLMs achieve near perfect accuracies on some
task (see Appendix 8.2 for an example for each datasets (e.g., TriangleCOPA with 96% accuracy
variation). Again, the examples were created by byflan-t5-xxl),othersdatasetsremainchalleng-
oneauthorandverifiedbyanother. ingforLLMswithconsiderablylowerperformance.
For instance, the best performing LLM on the
4 Experiments&Results FauxPasEAIdatasetsisinferiortoasimplemost-
frequent-class baseline, indicating the difficulty
Toinvestigate theToM abilities of LLMs, we de-
levelofthesedatasets.
signed experiments that explore various aspects.
Notably,thebestLLMsperformanceseemscor-
The first experiment presents a meta-evaluation
related to the dataset’s age (i.e., the older the
of 15 LLMs evaluated on multiple ToM-related
dataset, the better the performance). This trend
datasetsinazero-shotmanner(§4.1). Wethenin-
could be attributed to the fact that the increasing
vestigatetowhatextentLLMsaresensitivetothe
sophistication of LLMs is driving the creation of
probingmethod(§4.2).
morechallengingdatasets,promptingresearchers
LLMs We examine the performance of 15 tosetahigherbar. AnotherpossibilityisthatLLMs
different LLMs of different sizes: FlanT5: havehadmoreopportunitiestotrainontheolder
flan-t5-{small, base, large, xl, xxl} (Chung datasets,resultinginbetterperformance(see§8.5).
et al., 2022), FlanUl2 (Tay et al., 2022), GPT- Basedonthismeta-evaluation, ourresultssug-
3 (text-davinci-002, text-davinci-003), GPT-3.5 / gestarethatwhilesomemodelsexhibitstrongToM
ChatGPT(gpt-3.5-turbo-0301),GPT-4(gpt-4-0314) abilitiesonsomedatasets,nomodelrobustlyex-
(Brownetal.,2020;Ouyangetal.,2022),andJuras- hibitsToMonalldatasets. Thesefindingsarecon-
sic2: j2-{jumbo-instruct, grande-instruct, jumbo, sistentwithSapetal.(2022)andUllman(2023).
grande, large}.6 We provide technical details re-
gardingpromptinganddecodingparametersinAp-
4.2 HowsensitiveareLLMstotheprobing
pendix8.3.
technique?
4.1 HowwelldoLLMsperformonToM Weexaminetheeffectofthedifferentprobingmeth-
tasks? Meta-Evaluation odsdetailedbelowonLLMperformance. Certain
techniques have shown to be superior to others
Weconductedanevaluationoftheperformanceof
(e.g.,Weietal.,2023). However,wearguethatto
15LLMsinazero-shotmanner(Liuetal.,2021)on
claimthatamodelhasN-ToMabilities,itisessen-
allToM-relateddatasetsconsidered(§3),andcom-
tialthatitperformswellacrossprobingtechniques.
paretoamost-frequent-class(MFC)baselinethat
Ononehand,themostefficientmethodcanpoten-
alwayspredictsthemostfrequentanswerineach
tiallyreveallatentcapabilities,whileontheother
dataset. Thesummaryoftheresultsispresentedin
hand,thereisareasonableexpectationforLLMs
Figure1,andthecompleteresultsinAppendix8.4.
to succeed in the tasks regardless of the probing
6 approachusedtoextractinformation.
https://www.ai21.com/blog/introducing-j2
5
aqiS
iMoT
Dataset ToMi’ ToM-k ToM-k contains only simple positive examples
Nosecond (variants of the original Sally-Annie test), ToMi
Subset Allquestion Allquestions
order
also contains simple alternations such as omis-
text-davinci-003 10 21 87
sionorduplicationofinformationthatcreatenega-
GPT-3.5 27 48 65
GPT-4 20 52 87 tiveexamples(seeexampleinAppendix8.1)and
second-orderquestions.
Table 4: Comparison of LLMs’ accuracy on ToM-k,
To ensure a fair comparison between the ques-
whichcontainspositiveexamplesonly,andonToMi’,
which contains both positive and negative examples tion answering format of ToMi and the sentence
(manuallyadjustedfromToMitobeofthesameprob- completionformatofToM-k(seetheeffectofprob-
ing type as ToM-k). ToM-k contains only first-order ingmethodsonperformancein§4.2),weadjusted
questions. Thesubset“Nosecondorder”wascreated ToMitomatchthesentencecompletionformat(de-
manuallytobettercomparetoToM-kdataset. Lower
tails about the adjustments can be found at §3.1).
accuracy might suggest the dataset is more robust to
Additionally,weanalyzedtheresultsseparatelyfor
spuriouscorrelations.
second-orderquestionsinordertofacilitateamore
accuratecomparisonwiththeToM-kdataset.
LM-probing predictstheoptionwiththehighest Table 4, shows significantly lower scores in
probability(Brownetal.,2020;Sapetal.,2022). ToMi’. Thenotablediscrepancybetweentheperfor-
manceofthetwodatasetssuggeststhatthemodel’s
MC-probing promptstheLLMwiththecontext,
abilities are not based on generalization. Instead
question,andanswerchoices,andasksittogener-
oftrueunderstandingoftheproblemathand,such
atetheanswerintheformof“a,b,c”. Thismethod
asaccuratelydeterminingone’sexactthoughts,the
isapplicableforLLMssuchasGPT-3.5andGPT-4
modelmightberecognizingpatternsfromtheSally-
thatdon’tproduceprobabilities(Huetal.,2022).
AnnestoryinotherToM-kexamplesandgenerat-
CoT-probing asks the model to first “reason” ingresponsesbasedonthosepatterns. Conversely,
about the question step-by-step and then give a the performance on ToMi’ is worse because it is
finalanswer,whichgenerallycontributestobetter morerobusttospuriouscorrelations.
performance(Weietal.,2023).7
Table3showsthattheprobingtechniquesinflu- 5.2 IsN-ToMRobusttoAdversarialChanges?
encetheLLMperformanceonbothdatasets. CoT
TotesttherobustnessoftheLLMs’N-ToM,wetest
generallydemonstratesenhancedperformance,as
theperformanceofGPTmodelsoneachofthecate-
supportedbypriorresearch(Camburuetal.,2018;
goriesinAdv-CSFB(§3.2),usingMC-probing. To
Shwartzetal.,2020;Weietal.,2023). Nonetheless,
ensurecorrectformattingandpreventunintended
therearecaseswherethistrenddoesnothold,since
outputs(e.g.,explanationofwhytheansweriscor-
thereasoningmayoccasionallyresultinerroneous
rect),weprependtothepromptoneout-of-domain
conclusions(Jungetal.,2022).
example from ToMi, which has a similar format.
Wereporttheaverageaccuracyofquestions2and
5 CleverHansvs. GeneralizedReasoning
3, both focusing on an agent’s belief rather than
Weconductedaseriesofexperimentsaimedtoen- objectivetruth. Finally,toensuremaximumrepro-
hanceourunderstandingofthefactorsinfluencing ducibilityoftheresults,wesetthetemperatureto0.
performanceinthecontextofN-ToMtasks. There- OurmainfindingisthatLLMsdon’texhibitro-
searchquestionthatguideduswas: Dothemodels bustperformanceacrossdifferentcategories. In
thatsolvethetaskspossessageneralabilityordo particular,laterLLMsexcelinsomecategories
theyrelyonmemorizationandshallowheuristics whilecompletelyfailingonothers. Weprovide
(“CleverHans”;Kavumbaetal.,2019)? Wedetail detailsbelow.
theexperimentsandfindingsbelow. Figure2illustratestheperformanceofarange
ofGPTmodelsondifferentcategorieswithinthe
5.1 DoLLMsRelyonSpuriousCorrelations?
unexpected transfer segment of Adv-CSFB. It is
ToMi and ToM-k are datasets that examine the evidentthatbothfalsebelief (i.e. theoriginalex-
unexpected transfer false belief problem. While amples from ToM-k) and trusted testimony (i.e.,
someone tells the protagonist that the object has
7Weusethezero-shotsetupwithoutprovidinganyreason-
ingexamples. beenmoved)haveimprovedinnewermodels. GPT-
6
Figure2: PerformanceofarangeofGPTmodelsonvariouscategorieswithintheunexpectedtransfersegmentof
Adv-CSFB.Theresultsaretheaverageaccuracyofquestion2(e.g. Mariathinksthatthebananasareinthe_)and
question3(e.g. WhenMariacomesback,shewillfirstlookforthebananasinthe_),whichspecificallyfocusonan
agent’sbeliefsratherthanobjectivetruth. Notably,GPT-4achievesanaccuracyof97%onthesubsetoffalsebelief
samples(theoriginalexamplesfromToM-k),whilefailingonadversarialsamplesthatinvolvetransparentaccessor
relationshipchange(in→on).
Figure3: PerformanceofarangeofGPTmodelsonvariouscategorieswithintheunexpectedcontentsegmentof
Adv-CSFB.Theresultsaretheaverageaccuracyofquestion2(e.g. Hebelievesthatitisfullof_)andquestion3
(e.g. Hecallshisfriendtotellthemthathehasjustfoundabottlefullof_),whichspecificallyfocusonanagent’s
beliefsratherthanobjectivetruth.
4 achieves 97.5% and 83.3% on the two cate- thelabel),anduninformativelabel(i.e.,theprotag-
goriesrespectively. Nevertheless,therehasbeena onistcan’treadthelabel).
gradualdeclineintheperformanceofsubsequent We regenerated the responses multiple times,
models onother categories, suchas other person consistently obtaining similar results, so we can
(from 93.8% by davinci-002 to 68.8% by GPT- concludethatthemodelsexhibitconfidenceintheir
4),in→on(from71.4%bydavinci-002to0%by predictions,eveniftheyareincorrect. Itisimpor-
GPT-4), and transparent access (from 66.7% by tanttonote,however,thattheresultsobtainedfrom
davinci-002to0%byGPT-4). LM-probingmayslightlydifferfromMC-probing.
In MC-probing, even with our 1-shot setup, the
Figure3showcasestheperformanceoftheGPT
modelmayproduceresponsesthatarenotapplica-
familyonvariouscategorieswithintheunexpected
ble, such as “none of the above” or “both”. This
contentssegment. Itbecomesapparentthat, akin
is particularly noticeable in verbose models like
to the unexpected transfer segment, newer mod-
GPT-3.5-Turbo and GPT-4. These models tend
elssuchasGPT-3.5-TurboandGPT-4demonstrate
tobecarefultoavoidprovidingincorrectanswers
improved performance in handling samples that
and,asaresult,generatelongerphrases. Withthat
involve false belief and transparent access (i.e.,
said,aswearguein§4.2,aLLMexhibitingrobust
thecontaineristransparent). Furthermore,nearly
N-ToMabilityshouldbeabletoanswerquestions
allmodelssincetext-davinci-002exhibitstrong
correctlyregardlessoftheprobingmethod.
performanceontruebelief samples. However,both
GPT-3.5-TurboandGPT-4experienceasubstantial
5.3 AreSpuriousCorrelationsaTrend?
decline in performance compared to their earlier
counterpartswhenitcomestotransparentaccess, In the previous experiment §5.2, we saw that the
latelabel(e.g.,theprotagonististheonewhowrote datasetscontainbothdifficultandeasyquestions.
7
isevenbelowthemajoritybaseline). Wealsocre-
atedAdv-CSFB,anewToMbenchmarkdesigned
touncoverwhetherLLMssolveToMquestionsfor
the right reasons, or merely rely on surface cues
andshallowheuristics.
So... DoLLMshaveToM? Ourresultsshowthat
whilesomedatasetshavebeensuccessfullysolved,
othersremainchallengingforLLMs. Thus,mod-
Figure4: ToMi’saccuracieswithdifferentsplitsofthe els do not have robust N-ToM abilities. These
dataset. While GPT-3.5 (the best-performing model)
findings are inconsistent with Kosinski (2023),
achievesatotalof0.7accuracyscore(seeFigure1),it
who claimed that ToM has emerged in LLMs as
achievesonly0.46onthesubsetquestions“falsebelief”.
abyproductoftheirdevelopment,aclaimfurther
echoed by Bubeck et al. (2023). We argue that
theseconclusionswereover-generalizedbasedon
aspecificaspectofToMandasmallnumberofex-
amples(40forKosinski(2023)and10forBubeck
etal.(2023)). FollowingUllman(2023),weempiri-
callyshowedthateventhebestmodelsfailonsmall
variationsoftheoriginaltasks, provingthateven
GPT-4doesnotdisplayrobustN-ToMabilities.
Figure5: SocialIQa’saccuraciesforthequestionsthat
focusonthemaincharactervs. others. WhileGPT-4
CleverHans,Heuristics&Shortcuts Theper-
(the best-performing model) achieves a total of 0.79
formance gaps between different question types
accuracyscore,itachievesonly0.61onthesubsetques-
tionsof“otherseffect”. suggests that LLMs rely on shortcuts, heuris-
tics,andspuriouscorrelations,whichoftenlead
themastray. InAdv-CSFB(§5.2),thebadperfor-
Here we show this recurring phenomenon across
manceonsomeoftheadversarialcategoriesmight
twoToMdatasets,inspiredbytheanalysesinSap
bepartlyattributedtoreportingbias(Gordonand
etal.(2022).
VanDurme,2013;ShwartzandChoi,2020). Peo-
Figure4describesToMiaccuraciesondifferent
ple don’t share obvious facts (Grice, 1975), so it
questiontypes;ToMicontainsquestionsaboutfacts
islikelythatLLMsarebiasedtowardsgenerating
vs. beliefs (mind), and specifically about true or
surprising rather than unsurprising continuations.
falsebeliefs. WhileGPT-3.5(thebest-performing
Inmostofthesecategories,theprotagonistbelief
model)achieves81%accuracy,onthesubsetques-
isthesameasthetruth,makingaboringstory.
tions“falsebelief”,itachievesonly46%,closeto
Furthermore, the newer models such as GPT-
randomperformance.
3.5 and GPT-4 are trained in addition to the LM
Figure 5 shows the SocialIQa accuracies for
objective to follow natural language instructions
questionsfocusingonthemaincharactervs. others.
and generate helpful answers. This might make
WhileGPT-4(thebest-performingmodel)achieves
themcooperativeandleadtoLLMsassumingthat
atotalof79%accuracyscore,onthesubsetques-
alldetailsareimportant,ratherthanthattheinput
tionsof“others”,itachievesonly74.5%.
is adversarial. For example, they might pay too
much attention to the mention of the false label
6 SummaryofFindingsandInsights
intheunexpectedcontentstask,failingtoseethat
We investigated whether modern LLMs robustly the label doesn’t matter if the person can’t read
displayN-ToMabilities. Byquantifyingtheirper- it or if the container is transparent. The fact that
formanceon6N-ToMbenchmarks,wefoundthat LLMsperformreasonablywellontruebeliefexam-
while some datasets have been nearly “solved” ples(Figure3)mightbeattributedtorecencybias
(e.g., TriangleCOPA with 96% accuracy by (O’ConnorandAndreas,2021), sincethecorrect
flan-t5-xxl), others remain challenging for contentistypicallythelastonetobementioned.
LLMswithconsiderablylowerperformance(e.g., Finally, we reassess the finding of Sap et al.
FauxPas-EAIwith27%accuracybyGPT-4,which (2022) that LLMs perform better on predicting
8
the mental states of the main character vs. oth- thattheyhaveToM).Instead,weneedtoconsider
ers(SIQA,§5.1);Sapetal.(2022)suggestedthat other explanations (e.g., that they are relying on
thismightbeduetocenteringtheory(Groszetal., heuristics). Thesameholdsintheotherdirection,
1995),accordingtowhichtextstendstofocuson whenanalyzinghowmodelsworkinordertolearn
describingasingleprotagonist. aboutthehumanbrain.
ELIZAEffect&AnecdotalGenerativevs. Au- Machine intelligence and Anthropomorphism
tomatic Large-Scale Multiple-Choice Testing Relatedly,ourresultsalsopointtoaneedforcau-
The impressive anecdotal examples produced by tion when discussing the abilities of machines in
LLMs in generative settings (e.g., observed with relationtoconceptsreferringtohumancognition,
ChatGPT and GPT4 web-demo; Bubeck et al., such as Theory of Mind. While it is common in
2023), tends to captivate non-expert individu- computer science to use human-related concepts
als. However, it is important to recognize that andmetaphorsforAIsystems,wecautionreaders
thesemodelsarespecificallydesignedtogenerate to interpret “neural ToM” carefully and without
textthatappearshigh-qualitytohumanobservers aimingtomakeclaimsabout“AIcognition,”espe-
(Ouyangetal.,2022). Thisinherentbiasintheirde- ciallysincegivenourpropensityforanthropomor-
signcanleadtothe“ELIZAeffect”(Weizenbaum, phizingnon-humananimalsandcomputers(Epley
1976;Shapiraetal.,2023b),i.e. thehumanassump- etal.,2007;KimandSundar,2012);ourmeasuring
tionthatcomputerbehaviorsareanalogoustohu- theperformanceonthesebenchmarksisnotmeant
manbehaviors. Thus,theillusionthataLLMhas asanendorsementofthepursuitofahuman-like
acquired human-like N-ToM often says more socialintelligenceforAIsystems.8 Instead,inlight
aboutthehumansreadingthetextthanabout of the hype around AI and it’s “intelligence,” we
themodelitself(Whang,2023). soughtouttoprovideamoresoberlookattheem-
Moreover, later models are by design trained pirical performance of LLMs on tasks related to
to practice “epistemic humility” (i.e., hedge and socialintelligenceandToM.
providemultiplepossibleanswers;Ouyangetal.,
“Solving” a ToM benchmark is necessary but
2022,p.17). Thisoftenleadsthemtoprovideratio-
notsufficient Methodologically,ifamodelfails
nalesforeachgivenanswerwithoutcommittingto
atleastoneToMtask,itdoesnothaveToMingen-
actuallyansweringthequestion. Buthumansmight
eral. Successononeexampleortaskisnotasound
fall prey to confirmation bias and simply see the
proof that a model has ToM. Future work will
rightansweranditsrationalandconcludethatthe
needtocontinuetodevelopbenchmarkstesting
model has gotten it correctly. We thus argue that
variousToMaspects,andthesebenchmarkswill
inordertoconcludewhetheracertainmodelpos-
needtobedesignedtoassessLLMsdirectlyrather
sessesacertainability,itiscrucialtoquantifythe
thanusingclinicaltestsdesignedforhumans.
performance across multiple large-scale datasets,
Additionally, reporting the aggregated perfor-
preferablyusinganautomaticevaluationmethod.
manceofLLMsonbenchmarksobscurestheper-
Usingpsychologicaltestsdesignedforhumans formancedifferencesacrossquestionsofdifferent
onLLMs Inclinicalpsychology,testsdesigned typesandcomplexities. Toovercomethis,oneap-
forhumansarecarefullyconstructedandvettedto proach is to pair a difficult question with an easy
ensurethattheyhaveexternalandinternalvalidity, question,requiringmodeltoanswerbothcorrectly.
i.e.,thattheyaremeasuringwhattheyaimtomea- Thismethodologyresemblesthe“jointscore”em-
sure(Franketal.,2023). Whilethereisevidence ployedinFauxPas-EAI,Adv-CSFB,andToMi. In
that a person’s success in one ToM task can indi- situations where pairing is challenging, a recom-
catetheirToMabilities(e.g.,Milliganetal.,2007), mendationforfutureworksisthatdatasetdifficulty
thisdoesnotnecessarilytransfertomodels. There- could be evaluated by calculating the final score
fore, it isimportanttobe cautiouswhendrawing acrossdifferentsplitsofthedataset. Thedifficulty
conclusions about ToM in models based on their levelofthedatasetcanthenbedeterminedbased
performance on a few tasks (Marcus and Davis, onthelowestscoreobtainedamongthesesplits.
2023). Ingeneral,whenasystemsucceedsonan
8WeleavethequestionofwhetherLLMs,AI,orevenany
instrumentdesignedforhumans,wecan’tdrawthe
non-biologicalentitycoulddevelophuman-likecognitionand
same conclusions as we would for humans (e.g., TheoryofMinduptophilosophers.
9
Emergence vs. Supervised Learning vs Train- parts of the datasets could be ambiguous, either
ingontheTestset PriorworkclaimedthatToM duetolackofcontextorinherentambiguity(Plank,
abilitiesemergedasabyproductoftheLLMtrain- 2022). Duetothispotentialambiguity,someLLMs
ing(Kosinski,2023). Wearguethatclaimsabout were safeguarded and refused to answer certain
emergenceare(i)unfounded,and(ii)unfalsifi- questions;whileweattemptedtoinstructthemto
ablewithoutaccesstotheLLMs’trainingdata. respondinthecorrectformat,someLLMsstilldid
To make a statement regarding emergent ToM, a notoutputtherightformat. Thiswasonlyanissue
careful experiment is needed to ensure that ToM forMC-probing,butprobabilitydistributionswere
did indeed appear spontaneously and not as a re- not available for all LLMs. Future work should
sult of other factors such as training on related investigatehowtomitigatethisissueviabetterin-
datasets,exposuretodescriptionsofclinicaltests structionsormethodsthatmapgeneratedanswers
online, interactions with users, and more.9 How- to multiple choice better (e.g., Niu et al., 2021;
ever,sincethedatausedtotraintheGPTmodels Bulianetal.,2022).
isnotpubliclyavailable, itisimpossibletoquan-
tifythedegreeofthepotentialdataleakage.10 We Limitedtext-onlyLLMs Ourexperimentswere
echo calls by Dodge et al. (2021) for increased conducted with a limited number of LLMs that
transparencyandopen-accesstothetrainingdata wereaccessibleatthetimeofwriting,andwedid
of LLMs, which is crucial for scientifically valid not explore the full spectrum of LLMs that are
andreproducibleexperiments(Rodgers,2023). currentlyavailable. Futureworkcouldexplorethe
N-ToM abilities displayed by other LLMs, and
Improving neural ToM abilities (with CoT or
additionally,exploremultimodalmodels.
other methods) Our objective in this study is
not to measure benchmark performance or climb
leaderboards. Itisfeasiblethattechniquessuchas EthicalStatement
chain-of-thoughtprompting(CoT;Weietal.,2022)
wouldenhancetheperformanceofGPT-4ontasks Data. Alltheexistingandnewdatasetsusedin
whereitcurrentlyperformspoorly. Nevertheless, this study are publicly available. The narratives
we need to exercise caution to ensure that the were evaluated by the authors to ensure that they
utilization of methods like CoT or others does donotcontainoffensivecontent.
notexcessivelyguidethemodelsbyessentiallyre-
vealingthetaskstructuretothem—justlikeClever Models. LLMsmaygenerateoffensivecontent
Hanswhoappearedproficientinmathmerelydue ifpromptedwithcertaininputs. However,weused
tosubtlehintsgivenbytheowner. themforevaluationonly,withnon-offensiveinputs,
andwedidnotrecordtheirresponses.
7 Conclusion
Basedonourresearchandreplicationstudies,we Acknowledgements
concludethatcontemporaryLLMsdemonstratean
enhanced yet limited degree of Theory of Mind We would like to thank Uri Katz, Royi Rassin,
abilities. WefindthattheirToMabilitiesareoften OriShapira,AlonJacoby,RotemDror,andAmir
notrobust,andinsomeinstances,weidentifyev- DNCohenforhelpfuldiscussions. WethankOpe-
idenceoftheirover-relianceonsimpleheuristics nAIforaccesstotheirAPIsincludingGPT-4,and
ratherthanrobustgeneralizedreasoning. AI21forthegenerousbudgetforusingtheirplat-
form API. This project was partially funded by
Limitations
the European Research Council (ERC) under the
EuropeanUnion’sHorizon 2020researchandin-
Benchmarkscopeandhumanambiguity The
novation program, grant agreement No. 802774
datasets used in this study were limited in scope
(iEXTRACT),theComputerScienceDepartment
andsize;ToMisrequiredinmosthumaninterac-
ofBar-IlanUniversity,theVectorInstituteforAI,
tion, and thus unbounded in scope. In addition,
Canada CIFAR AI Chairs program, an NSERC
9OpenAIacknowledgedthatGPT-4wastrainedontest
discovery grant, DARPA MCS program through
datafromBIGBench(OpenAI,2023,footnote5).
NIWCPacific(N66001-19-2-4031),andAI2.
10SeeAppendix8.5foranattempttoquantifysuchdata
leakage.
10
References Nicholas Epley, Adam Waytz, and John T Cacioppo.
2007. Onseeinghuman: athree-factortheoryofan-
Simon Baron-Cohen, Alan M Leslie, and Uta Frith.
thropomorphism. Psychologicalreview,114(4):864.
1985. Does the autistic child have a “theory of
mind”? Cognition,21(1):37–46.
Michael C Frank, Mika Braginsky, Julie Cachia,
NicholasColes, TomHardwicke, RobertHawkins,
SimonBaron-Cohen,MichelleO’riordan,ValerieStone,
MayaBMathur,andRondelineWilliams.2023. Ex-
RosieJones,andKatePlaisted.1999. Recognition
perimentology: Anopenscienceapproachtoexperi-
of faux pas by normally developing children and
mentalpsychologymethods.
childrenwithaspergersyndromeorhigh-functioning
autism. Journalofautismanddevelopmentaldisor-
Andrew Gordon. 2016. Commonsense interpretation
ders,29(5):407–418.
of triangle behavior. In Proceedings of the AAAI
Rishi Bommasani, Drew A Hudson, Ehsan Adeli, ConferenceonArtificialIntelligence,volume30.
Russ Altman, Simran Arora, Sydney von Arx,
MichaelSBernstein,JeannetteBohg,AntoineBosse- AndrewSGordonandJerryRHobbs.2017. Aformal
lut,EmmaBrunskill,etal.2021. Ontheopportuni- theory of commonsense psychology: How people
tiesandrisksoffoundationmodels. arXivpreprint thinkpeoplethink. CambridgeUniversityPress.
arXiv:2108.07258.
JonathanGordonandBenjaminVanDurme.2013. Re-
Tom Brown, Benjamin Mann, Nick Ryder, Melanie portingbiasandknowledgeacquisition. InProceed-
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind ingsofthe2013workshoponAutomatedknowledge
Neelakantan,PranavShyam,GirishSastry,Amanda baseconstruction,pages25–30.
Askell,etal.2020. Languagemodelsarefew-shot
learners. Advancesinneuralinformationprocessing ErinGrant,AidaNematzadeh,andThomasLGriffiths.
systems,33:1877–1901.
2017. Howcanmemory-augmentedneuralnetworks
passafalse-belieftask? InCogSci.
Sébastien Bubeck, Varun Chandrasekaran, Ronen El-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,
Herbert P Grice. 1975. Logic and conversation. In
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-
Speechacts,pages41–58.Brill.
berg,etal.2023. Sparksofartificialgeneralintelli-
gence: Earlyexperimentswithgpt-4. arXivpreprint
BarbaraJ.Grosz,AravindK.Joshi,andScottWeinstein.
arXiv:2303.12712.
1995. Centering:Aframeworkformodelingthelocal
JannisBulian,ChristianBuck,WojciechGajewski,Ben- coherenceofdiscourse. ComputationalLinguistics,
jaminBörschinger,andTalSchuster.2022. Tomayto, 21(2):203–225.
tomahto.beyondtoken-levelanswerequivalencefor
questionansweringevaluation. InProceedingsofthe SharathChandraGuntuku,DavidBYaden,MargaretL
2022ConferenceonEmpiricalMethodsinNatural Kern, Lyle H Ungar, and Johannes C Eichstaedt.
Language Processing, pages291–305, AbuDhabi, 2017. Detecting depression and mental illness on
United Arab Emirates. Association for Computa- socialmedia: anintegrativereview. CurrentOpinion
tionalLinguistics. inBehavioralSciences,18:43–49.
Oana-Maria Camburu, Tim Rocktäschel, Thomas Fritz Heider and Marianne Simmel. 1944. An exper-
Lukasiewicz,andPhilBlunsom.2018. e-snli: Natu- imentalstudyofapparentbehavior. TheAmerican
rallanguageinferencewithnaturallanguageexpla- journalofpsychology,57(2):243–259.
nations. AdvancesinNeuralInformationProcessing
Systems,31. Jaakko Hintikka. 1962. Knowledge and Belief: An
IntroductiontotheLogicoftheTwoNotions. Ithaca:
Hyung Won Chung, Le Hou, Shayne Longpre, Bar-
CornellUniversityPress.
ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
Wang,MostafaDehghani,SiddharthaBrahma,etal.
JenniferHu,SammyFloyd,OlessiaJouravlev,Evelina
2022. Scalinginstruction-finetunedlanguagemodels.
Fedorenko, and Edward Gibson. 2022. A fine-
arXivpreprintarXiv:2210.11416.
grained comparison of pragmatic language under-
standing in humans and language models. arXiv
Michael Cohen. 2021. Exploring roberta’s theory of
preprintarXiv:2212.06801.
mindthroughtextualentailment.
HalDaumé.2017. Acourseinmachinelearning. Hal JaehunJung,LianhuiQin,SeanWelleck,FaezeBrah-
DauméIII. man, Chandra Bhagavatula, Ronan Le Bras, and
Yejin Choi. 2022. Maieutic prompting: Logically
Jesse Dodge, Maarten Sap, Ana Marasovic´, William consistentreasoningwithrecursiveexplanations. In
Agnew,GabrielIlharco,DirkGroeneveld,Margaret Proceedings of the 2022 Conference on Empirical
Mitchell, and Matt Gardner. 2021. Documenting Methods in Natural Language Processing, pages
largewebtextcorpora: Acasestudyonthecolossal 1266–1279,AbuDhabi,UnitedArabEmirates.Asso-
cleancrawledcorpus. InEMNLP. ciationforComputationalLinguistics.
11
PrideKavumba,NaoyaInoue,BenjaminHeinzerling, Christopher Osterhaus and Sandra L Bosacki. 2022.
KeshavSingh,PaulReisert,andKentaroInui.2019. Lookingforthelighthouse: Asystematicreviewof
Whenchoosingplausiblealternatives,cleverhanscan advancedtheory-of-mindtestsbeyondpreschool. De-
beclever. InProceedingsoftheFirstWorkshopon velopmentalReview,64:101021.
CommonsenseInferenceinNaturalLanguagePro-
cessing,pages33–42,HongKong,China.Associa- LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car-
tionforComputationalLinguistics. rollLWainwright,PamelaMishkin,ChongZhang,
SandhiniAgarwal,KatarinaSlama,AlexRay,John
YoujeongKimandSShyamSundar.2012. Anthropo- Schulman,JacobHilton,FraserKelton,LukeMiller,
morphismofcomputers: Isitmindfulormindless? Maddie Simens, Amanda Askell, Peter Welinder,
ComputersinHumanBehavior,28(1):241–250. Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
Traininglanguagemodelstofollowinstructionswith
MichalKosinski.2023. Theoryofmindmayhavespon- humanfeedback. InNeurIPS.
taneouslyemergedinlargelanguagemodels. arXiv
preprintarXiv:2302.02083. Josef Perner, Susan R Leekam, and Heinz Wimmer.
1987. Three-year-olds’ difficulty with false belief:
MatthewLe,Y-LanBoureau,andMaximilianNickel. Thecaseforaconceptualdeficit. Britishjournalof
2019. Revisiting the evaluation of theory of mind developmentalpsychology,5(2):125–137.
throughquestionanswering. InProceedingsofthe
2019 Conference on Empirical Methods in Natu- BarbaraPlank.2022. The“problem”ofhumanlabel
ralLanguageProcessingandthe9thInternational variation: On ground truth in data, modeling and
JointConferenceonNaturalLanguageProcessing evaluation. InProceedingsofthe2022Conference
(EMNLP-IJCNLP),pages5872–5877. onEmpiricalMethodsinNaturalLanguageProcess-
ing,pages10671–10682,AbuDhabi,UnitedArab
David K Lewis. 1966. An argument for the identity Emirates.AssociationforComputationalLinguistics.
theory. TheJournalofPhilosophy,63(1):17–25.
David Premack and Guy Woodruff. 1978. Does the
chimpanzeehaveatheoryofmind? Behavioraland
PengfeiLiu,WeizheYuan,JinlanFu,ZhengbaoJiang,
brainsciences,1(4):515–526.
Hiroaki Hayashi, and Graham Neubig. 2021. Pre-
train, prompt, and predict: A systematic survey of
HannahRashkin,AntoineBosselut,MaartenSap,Kevin
promptingmethodsinnaturallanguageprocessing.
Knight,andYejinChoi.2018a. Modelingnaivepsy-
arXivpreprintarXiv:2107.13586.
chologyofcharactersinsimplecommonsensestories.
InACL.
GaryMarcusandErnestDavis.2023. Hownottotest
GPT-3. https://garymarcus.substack.com/p/
HannahRashkin,MaartenSap,EmilyAllaway,NoahA.
how-not-to-test-gpt-3. Accessed: 2023-2-19.
Smith,andYejinChoi.2018b. Event2mind: Com-
monsenseinferenceonevents,intents,andreactions.
KarenMilligan, JanetWildeAstington, andLisaAin
InACL.
Dack. 2007. Language and theory of mind: Meta-
analysis of the relation between language ability
AnnaRodgers.2023. Closedaimodelsmakebadbase-
andfalse-beliefunderstanding. Childdevelopment,
lines. TowardsDataScience. Accessed2023-05-23.
78(2):622–646.
MaartenSap, RonanLeBras, DanielFried, andYejin
Aida Nematzadeh, Kaylee Burns, Erin Grant, Alison Choi.2022. Neuraltheory-of-mind? onthelimitsof
Gopnik,andThomasLGriffiths.2018. Evaluating socialintelligenceinlargelms. InProceedingsofthe
theoryofmindinquestionanswering. arXivpreprint 2022ConferenceonEmpiricalMethodsinNatural
arXiv:1808.09352. LanguageProcessing(EMNLP).
Yilin Niu, Fei Huang, Jiaming Liang, Wenkai Chen, Maarten Sap, Hannah Rashkin, Derek Chen, Ronan
XiaoyanZhu,andMinlieHuang.2021. Asemantic- LeBras,andYejinChoi.2019. Socialiqa: Common-
basedmethodforunsupervisedcommonsenseques- sensereasoningaboutsocialinteractions. InAAAI.
tionanswering. InProceedingsofthe59thAnnual
Meeting of the Association for Computational Lin- Chen Shani, Alexander Libov, Sofia Tolmach, Liane
guisticsandthe11thInternationalJointConference Lewin-Eytan, Yoelle Maarek, and Dafna Shahaf.
onNaturalLanguageProcessing(Volume1: Long 2022. “alexa,doyouwanttobuildasnowman?”char-
Papers),pages3037–3049,Online.Associationfor acterizingplayfulrequeststoconversationalagents.
ComputationalLinguistics. InCHI2022.
JoeO’ConnorandJacobAndreas.2021. Whatcontext Natalie Shapira, Dana Atzil-Slonim, Daniel Juravski,
featurescantransformerlanguagemodelsuse? In MoranBaruch,DanaStolowicz-Melman,AdarPaz,
ACL,pages851–864,Online.AssociationforCom- TalAlfi-Yogev, RoyAzoulay, AdiSinger, Maayan
putationalLinguistics. Revivo,ChenDahbash,LimorDayan,TamarNaim,
LidarGez,BoazYanai,AdvaMaman,AdamNadaf,
OpenAI.2023. GPT-4technicalreport. Elinor Sarfati, Amna Baloum, Tal Naor, Ephraim
12
Mosenkis, Badreya Sarsour, Jany Gelfand Mor- JasonWei,XuezhiWang,DaleSchuurmans,Maarten
genshteyn, Yarden Elias, Liat Braun, Moria Ru- Bosma,FeiXia,EdHChi,QuocVLe,DennyZhou,
bin, Matan Kenigsbuch, Noa Bergwerk, Noam etal.2022. Chain-of-thoughtpromptingelicitsrea-
Yosef,SivanPeled,CoralAvigdor,RahavObercyger, soning in large language models. In Advances in
RachelMann,TomerAlper,InbalBeka,OriShapira, NeuralInformationProcessingSystems.
and Yoav Goldberg. 2021. Hebrew psychological
lexicons. InProceedingsoftheSeventhWorkshopon JosephWeizenbaum.1976. Computerpowerandhu-
ComputationalLinguisticsandClinicalPsychology: man reason: From judgment to calculation. WH
ImprovingAccess,pages55–69. Freeman&Co.
Natalie Shapira, Oren Kalinsky, Alex Libov, Chen JasonWeston,AntoineBordes,SumitChopra,Alexan-
Shani,andSofiaTolmach.2023a. Evaluatinghumor- derMRush,BartVanMerriënboer,ArmandJoulin,
ousresponsegenerationtoplayfulshoppingrequests. and Tomas Mikolov. 2015. Towards ai-complete
In Advances in Information Retrieval: 45th Euro- questionanswering: Asetofprerequisitetoytasks.
pean Conference on Information Retrieval, ECIR arXivpreprintarXiv:1502.05698.
2023,Dublin,Ireland,April2–6,2023,Proceedings,
PartII,pages617–626.Springer.
Oliver Whang. 2023. Can a machine know that we
knowwhatitknows? TheNewYorkTimes.
NatalieShapira,GuyZwirn,andYoavGoldberg.2023b.
Howwelldolargelanguagemodelsperformonfaux
HeinzWimmerandJosefPerner.1983. Beliefsabout
pastests. InFindingsoftheAssociationforCompu-
beliefs: Representationandconstrainingfunctionof
tationalLinguistics: ACL2023.
wrongbeliefsinyoungchildren’sunderstandingof
deception. Cognition,13(1):103–128.
Vered Shwartz and Yejin Choi. 2020. Do neural lan-
guagemodelsovercomereportingbias? InProceed-
ingsofthe28thInternationalConferenceonCom- Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
putationalLinguistics,pages6863–6870,Barcelona, XiaoleiWang,YupengHou,YingqianMin,Beichen
Spain(Online).InternationalCommitteeonCompu- Zhang,JunjieZhang,ZicanDong,YifanDu,Chen
tationalLinguistics. Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,
Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,
Vered Shwartz, Peter West, Ronan Le Bras, Chandra Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023.
Bhagavatula, andYejinChoi.2020. Unsupervised Asurveyoflargelanguagemodels. arXivpreprint
commonsensequestionansweringwithself-talk. In arXiv:2303.18223.
Proceedings of the 2020 Conference on Empirical
MethodsinNaturalLanguageProcessing(EMNLP), 8 Appendices
pages4615–4629,Online.AssociationforComputa-
tionalLinguistics.
8.1 ExampleofChatGPTFailure
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Table5showsanexamplefromtheTomidataset.
AbuAwalMdShoeb,AbubakarAbid,AdamFisch,
The unexpected transfer test discusses an unex-
Adam R Brown, Adam Santoro, Aditya Gupta,
pected(falsebelief)ratherthantrivial(truebelief)
Adrià Garriga-Alonso, et al. 2022. Beyond the
imitation game: Quantifying and extrapolating the case. ChatGPTsolvesthemorecomplextask(false
capabilities of language models. arXiv preprint belief)whilefailingonthetrivialtask,likelydue
arXiv:2206.04615.
toitsexposuretotheSalley-Annetask.
YlaRTausczikandJamesWPennebaker.2010. The
8.2 Ullman’sVariations
psychologicalmeaningofwords: Liwcandcomput-
erized text analysis methods. Journal of language
Figures6and7illustratethevariationsproposed
andsocialpsychology,29(1):24–54.
byUllmanfortheexamplesinToM-k.
YiTay, MostafaDehghani, VinhQTran, XavierGar-
cia,DaraBahri,TalSchuster,HuaixiuStevenZheng, 8.3 GenerativeLLMs
Neil Houlsby, and Donald Metzler. 2022. Unify-
ing language learning paradigms. arXiv preprint We provide the technical details regarding the
arXiv:2205.05131. prompts(§8.3.1)anddecodingparameters(§8.3.2).
TomerUllman.2023. Largelanguagemodelsfailon 8.3.1 Prompts
trivial alterations to theory-of-mind tasks. arXiv
preprintarXiv:2302.08399. AsinputtotheLLMs,weused(unlesswrittenoth-
erwise)anMC-probingsetup(§4.2),i.e.,concate-
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
nationoftheoriginaltestwithallpossibleanswers
Bosma,BrianIchter,FeiXia,EdChi,QuocLe,and
and an instruction to choose an option. Table 6
DennyZhou.2023. Chain-of-thoughtpromptingelic-
itsreasoninginlargelanguagemodels. exemplifiesthepromptforeachtask.
13
FalseBelief(PositiveExample) TrueBelief(NegativeExample)
NatalieandMichalareinthesameroom. NatalieandMichalareinthesameroom.
NatalieputsaringinboxA. NatalieputsaringinboxA.
Natalieleavestheroom. MichalopensboxA,
MichalopensboxA, takestheringfrominsideandtransfersittoboxB.
takestheringfrominsideandtransfersittoboxB. WherewillNatalielookforthering?
Natalieenterstheroom.
WherewillNatalielookforthering?
ChatGPT: ChatGPT:
NataliewilllookfortheringinboxA, NataliewillmostlikelylookinboxA,
wheresheinitiallyputit. wheresheinitiallyputthering.
Sheisnotawareof SinceNataliedidnotwitness
Michal’sactions MichalmovingtheringtoboxB,
andassumesthattheringisstillintheoriginalbox. shewouldassumethattheringisstillinboxA.
Therefore,hernaturalinclinationwouldbe ItispossiblethatNataliemayeventuallycheckboxB,
tolookintheplacewheresheleftit. butherinitialinstinctwouldbetolookinboxA.
Table5: AnexampleofChatGPTfailureonaninstancefromToMi.
Dataset ExamplePrompt
Acircleknocksonthedoor.Atrianglegoestothedoor,buthesitatestoopenit.
Whydoesthetrianglehesitatetoopenthedoor?
Triangle a.Thetrianglehesitatestoopenthedoorbecauseitisunsureifitwantstoletthecirclein.
COPA b.Thetrianglehesitatestoopenthedoorbecauseitisexcitedtoseethecircle.
Answerwith“a”or“b”.
Answer:
Premise:OliviasuspectsthatEvelynunderstandsthatamanplaysapianopaintedwithan
imageofawomanonit.
epistemic
Hypothesis:Evelynunderstandsthatamanplaysapianopaintedwithanimageofawomanonit.
reasoning
Isentailment?answerwith“0”or“1”.
Answer:
Abby’sfatherpublishesshortstoriesinthenewspapereveryweek.
Shetoldhim“Dad,Iwanttolearnhowtowritejustlikeyou!”
andhereplied:“Wellthenmydearwhydon’tyougotoawritingclass?”
AbbygoestoafirstlessoninaclassshefoundandDavidtheteachersays:
“Todaywe’lllookatsomebadandgoodexamplesofstory-writing”.
FauxPas
HeshowstheclassastoryAbby’sfatherwrotelastweekandsays:
EAI
“AndnowI’llgiveyouagoodexampleofthewriterPichnikandyouwillsaywhatthedifferencesare.”
Inthestorydidsomeonesaysomethingthattheyshouldnothavesaid?
Answerwith“Yes”or“No”only,withoutexplanations.
Incaseofdoubt,answeraccordingtothemostprobableanswer.
Answer:
Table6: Anexamplepromptusedforeachtask.
8.3.2 DecodingParameters google/flan-t5-xl, google/flan-t5-xxl; tempera-
ture=0.0001
Asinglesample(thefirst)wasselectedfromeach
modelfortheanalysisofthestories. Weusedthe
hyperparametersdetailedbelow. Wechosehyper-
FlanUl2 (Tay et al., 2022). Python
parametersthatminimizerandomnessandpredict package transformers implementation
the most probable answer (i.e., low temperature,
(T5ForConditionalGeneration, AutoTok-
samplingmethod),andallowforsufficientnumber enizer); torch; Generation by generate function;
oftokens.
do_sample=True; max_length=50; tempera-
ture=0.0001
FlanT5 (Chung et al., 2022). Python pack-
age transformers implementation (AutoMod-
elForSeq2SeqLM, AutoTokenizer); torch; Gen- GPT (Brown et al., 2020). Python package
eration by generate function; do_sample=True; openaimodel=text-davinci-002,text-davinci-003;
max_length=50, from_pretrained:google/flan-t5- GenerationbyCompletion.createfunction;temper-
small, google/flan-t5-base, google/flan-t5-large, ature=0,max_tokens=50
14
ChatGPT.11 Pythonpackageopenaimodel=gpt-
3.5-turbo-0301,gpt-4-0314;GenerationbyChat-
Completion.createfunction;temperature=0
AI21.12 Pythonpackageai21model=j2-jumbo-
instruct, j2-grande-instruct, j2-jumbo, j2-grande,
j2-large;GenerationbyCompletion.executefunc-
tion; temperature=0, max_tokens=50, topKRe-
turn=0,topP=1,withoutanypanalty
8.4 CompleteResults
Table7containstheexhaustiveaccuracyresultsfor
allLLMsonalldatasets.
Running the well-organized code provided by
Kosinski(2023)wefoundthattask2(Unexpected
TransferTask)scoredlowerthanreportedforGPT
3.5. Specifically, two samples resulted in clear
mispredictionsandonesamplehadborderlinepre-
dictionsthatprovidedthecorrectanswerbutina
formatthatdifferedfromtheexpectedanswer(i.e.,
the first word was not the expected answer). As
a result, the score for task 2 was either 85% or
Figure6: AnillustrationofUllman’sVariationsforthe
90%, and the average score across the two tasks
unexpected contents task. Image taken from Ullman
waseither85%or87.5%,whichislowerthanthe
(2023).
reportedaverageof93%.
8.5 “Emergence”ortestdatacontamination?
WewouldliketodeterminewhetherLLMsgener-
alizeormemorizewhentheysolvetheToMtasks
(Daumé, 2017). We explored the possibility that
theincreaseinperformanceisaresultoftraining
on the test data itself. for that purpose we used
a second, secret, test set for SocialIQa that was
purposefullykepthiddentoavoiddatacontamina-
tionandisonlyavailabletotheoriginalSocialIQa
authorsaswellasthroughtheAI2leaderboard.13
Foreachtestset(i.e.,thestandardandsecrettest
sets)werandomlysample11subsetsof100ques-
tions on which we evaluate gpt3.5-turbo-0301
andgpt-4-0314. Comparingtheperformanceof
bothmodelsonbothtestsetssampleswithaT-test,
wefoundnosignificantdifferences,makingitin-
conclusivewhetherthemodelsweretrainedonthe
normaltestsetornot. AswediscussinSec6,this
doesn’t mean that ToM has “emerged” in LLMs,
sincetheymayhavebeenexposedtotrainingdata
Figure7: AnillustrationofUllman’sVariationsforthe orsimilarexamples.
unexpected transfer task. Image taken from Ullman
(2023). 11https://chat.openai.com/chat
12https://www.ai21.com/blog/introducing-j2
13https://leaderboard.allenai.org/socialiqa/
submissions/public
15
TheoryofMindDatasets
Model Triangle SocialIQa ToMi Epistemic Adv-CSFB FauxPas
COPA Reasoning EAI
MFC 52 36 56 63 – 55,30
Flan-ul2 95 – – 60 – 60,07
Flan-T5-xxl 96 – – 57 – 68,18
Flan-T5-xl 92 – – 61 – 68,14
Flan-T5-large 92 – – 44 – 53,07
Flan-T5-base 84 – – 52 – 52,07
Flan-T5-small 58 – – 54 – 58,07
gpt4-0314 94 79 70 43 75,57 74,27
gpt-3.5-turbo-0301 84 67 70 45 70,42 73,25
text-davinci-003 95 60 67 59 79,61 67,07
text-davinci-002 92 19 39 58 76,53 63,14
j2-grande-instruct 06 – – 37 – 58,0
j2-jumbo-instruct 48 – – 47 – 45,0
j2-grande 75 – – 63 – 45,0
j2-jumbo 68 – – 63 – 38,0
j2-large 58 – – 63 – 31,0
Table7: AccuracyofLLMsondifferentdatasetscomparedtoamostfrequentclassbaseline. ForAdv-CSFBand
FauxPas-EAIwereporttwometrics: questionlevelandstorylevel.
Averagescore Jointscore thestory,itmightstillfailtoanswermorecomplex
First Second w.o questions.
Reality Memory Second All
order order
order
Devinci003 100 96.6 61.6 25.0 20.6 10.3
Turbo-0301 100 90.0 73.3 40.0 41.3 17.2
Table8: ToMi’zero-shotsubsetscomparison. Allnum-
bersarepercentages.
8.6 ToMi’subsetsanalysis
Table8providesthecompleteresultsfromtheeval-
uationofGPT-3.5ontheToMi’dataset. Thesame
overall conclusion can be drawn from this table
aswell: althoughthemodelcancorrectlyanswer
simplereadingcomprehensionquestions,itdoesn’t
answerquestionsthatrequireToMskill(firstand
secondorder)withsimilaraccuracy.
Wedividedtheresultsintotheaveragescoreand
joint score. The average score is calculated as a
simpleaverageonthedifferenttypesofquestions,
whilethejointscoreisconsidersthepredictionas
correct only if the model answered correctly all
thequestionsfromthesamestory(withatotalof
30stories). Theaverageresultsemphasizethema-
jorgapsbetweenthemodel’saccuracyonreading
comprehension questions to first order questions
(“Chloe will look for the boots in the”) and be-
tweenthefirstorderquestionstothesecondorder
questions(“ChloethinkthatJacksonsearchesfor
thebootsinthe”). Thejointscorerevealsthateven
whenthemodelcorrectlyanswersquestionsabout
16
