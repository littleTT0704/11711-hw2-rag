Understanding Political Polarisation using Language Models:
A dataset and method
SamiranGode,1 SupreethBare,1 BhikshaRaj,1 HyungonYoo,1
CarnegieMellonUniversity
Abstract calsystem,themethodswesuggestformeasuringpolariza-
tionwouldbeusefulforothercountrieswithsimilardemo-
OurpaperaimstoanalyzepoliticalpolarizationinUSpolit-
craticelectionsindetermininghowpolazisedacandidateis.
icalsystemusingLanguageModels,andtherebyhelpcandi-
We first try classical methods such as Word2Vec(Mikolov
datesmakeaninformeddecision.Theavailabilityofthisin-
et al. 2013) and Doc2Vec(Le and Mikolov 2014) to under-
formationwillhelpvotersunderstandtheircandidates’views
stand if we can find polarization using the data we have
on the economy, healthcare, education and other social is-
sues. Our main contributions are a dataset extracted from and gain more insights. We find that words that are politi-
Wikipedia that spans the past 120 years and a Language callysensitive(Center2019)arerelatedtootherwordswhich
model-basedmethodthathelpsanalyzehowpolarizedacan- are politically sensitive(Center 2019). We thus move on to
didateis.Ourdataisdividedinto2parts,backgroundinfor- morerecentandsophisticatedmodelsbuiltusingTransform-
mationandpoliticalinformationaboutacandidate,sinceour ers(Vaswani et al. 2017) to gain more insight into the data.
hypothesisisthatthepoliticalviewsofacandidateshouldbe We then use these, in particular, longformers(Beltagy, Pe-
basedonreasonandbeindependentoffactorssuchasbirth-
ters,andCohan2020)toprojectcandidate-specificdatainto
place,almamater,etc.Wefurthersplitthisdatainto4phases
a particular embedding space and then use this data to find
chronologically,tohelpunderstandifandhowthepolariza-
the nearest neighbors of each candidate and provide one
tionamongstcandidateschanges.Thisdatahasbeencleaned
metrictofindhowpolarizedacandidateis.
to remove biases. To understand the polarization we begin
by showing results from some classical language models in
Word2VecandDoc2Vec.Andthenusemorepowerfultech- RelatedWork
niquesliketheLongformer,atransformer-basedencoder,to
(KhudaBukhsh et al. 2021) talks about political polariza-
assimilatemoreinformationandfindthenearestneighborsof
tion online and uses machine translation to interpret politi-
eachcandidatebasedontheirpoliticalviewandtheirback-
calpolarizationontheinternet.(Bhattetal.2018)discusses
ground.
theimpactsofhyper-partisanwebsitesoninfluencingpublic
opinionasillustratedbytheirabilitytoaffectcertainevents
Introduction inthe2016USgeneralelections.Theauthorsthengoonto
show how certain political biases are assumed for the pur-
PolarizationamongthetwomainpartiesintheUS,Republi-
poseoftheirstudy,namelyovertsupportforeitheraDemo-
canandDemocratic,hasbeenstudiedforalongtime((Poole
cratorRepublicanistakentobeanindicatorofthesitebeing
and Rosenthal 1984),(KhudaBukhsh et al. 2021)). A lot of
eitherLiberalorConservative.Thispaperisfundamentalto
the discussion online has become polarized(Jiang, Robert-
our research as it looks into the political division and lays
son, and Wilson 2020), and this discussion gets the most
thefoundationforanyfollowingworkinthedomainofus-
tractiononline(Jiang,Robertson,andWilson2020).Thispo-
ingspecificfeaturestoclassifyanentityasbeingLiberalor
larizationcanaffectthedecision-makingabilityofacandi-
Conservative.Thefeaturestheyconsideredweretranscripts
dateifselected(Chen,Li,andLiu2022).Insuchscenarios,it
ofthecontentbeingpublishedorsharedonthesesites.Inour
isimportantforuserstobeabletoseparatetherhetoricand
case,thefeatureswillsimplybetheWikipediapagecontent
understandhowpolaracandidateis.Withthiswork,weset
of the people. (KhudaBukhsh et al. 2022) shows the polar-
outtoaskexactlythesequestions,”Canwemeasurehowpo-
izationinTVmediaandfringenewnetworksandusesLan-
larizing a candidate is?”, ”Can we measure how much this
guage model-based techniques to understand them further.
polarity has changed over time?”, We try to answer these
However, this polarization visible in the electorate stems
questions using Natural Language based techniques and in
from the candidates. (DeSilver 2022) claims that the can-
the process, create a dataset that will be useful for the re-
didates become polarized and moved away from the center
searchcommunityintryingtounderstandpoliticalpolariza-
over the years. With this paper, we release a dataset and a
tion in the US. Though we have worked on the US politi-
fewmetricsthatwillhelpusunderstandifpoliticalpolariza-
Copyright©2023,AssociationfortheAdvancementofArtificial tionexistsinpoliticalcandidatesandhowwemightbeable
Intelligence(www.aaai.org).Allrightsreserved. tomeasurethispoliticalpolarization.Theaimofthisstudy
3202
naJ
2
]LC.sc[
1v19800.1032:viXra
istoaidvoterstomakeinformeddecisionsbeforeelections. are easily learnable. The Authors also demonstrate the us-
And we use language-based techniques on a dataset that is ageofothermodels(unidirectionalandbi-directional)inthe
classifiedinto4erasanddividedinto3parts,mainlyback- study, namely ’fariseq-fconv’ and ’Transformer-XL’. They
ground,politicalandother. concludebyshowingthatBERT-Largeisabletooutperform
(Belcastroetal.2020)DemonstratesthatPoliticalPolar- othermodelsandcompeteevenwithsupervisedmodelsfor
ization can be mapped with the help of Neural Networks. thesameTask.
Thisisalmostabaselineideaasweareusingattentionnet- (Palakodety,KhudaBukhsh,andCarbonell2020)demon-
worksandLongformermodelsforthesame.Thekeydiffer- strates the ability of BERT and similar LM’s to track com-
enceliesinthedataextractionandmethodology. munityperception,aggregateopinionsandcomparethepop-
(Khadilkar, KhudaBukhsh, and Mitchell 2022) goes in ularityofpoliticalpartiesandcandidates.Thisisdemonstra-
depthtowardsfindinggenderandracialbiasinalargesam- tiveofourworkasweintendtouseBERTforthepurpose
pleofBollywood(andHollywood)movies.Theauthorhas of sentiment analysis. The authors conclude by stating that
amalgamated several known NLP models while he tries to theLMcanbeusedasapipelineforextractingDatainthe
createareasonablyrobustmodelofhisown.Theportionsin future.
whichthisparticularstudydiffersfromthosebeforeisthat In (Hamilton, Leskovec, and Jurafsky 2016) the authors
thesamplesizeisfairlylarge.Itthendivergesfurtherwithits try to counter the problem of word meaning changing se-
ratherinnovativeuseofdiachronic-wordembeddingassoci- mantically with context. They propose a robust method by
ationtests(WEAT).Othertechniquesthatareimplemented using embeddings. These are then evaluated with the ’Law
include count-based statistics dependent on a highly popu- ofConformity’and’TheLawofInnovation’.Thesedisplay
larlexiconclozetestusingBERTasabasemodel(anidea the role of frequency and polysemy in the building struc-
wecouldconsiderafterdataattention)andbiasrecognition tural blocks of language. These blocks will be crucial for
usingWEAT.Thefinalmodelisacombinationoftheabove 2 reasons, (1) The meaning changes may adversely affect
three.Thispaperishighlyrelevanttoourprojectasituses sentiment analysis and thus affect results. Thus frequency
a similar idea of our own. It uses aforementioned models and polysemy must be duly curtailed. (2) The embedding
to predict bias, i.e. sentiment prediction. In our project, we research is fundamental as we are using embedding-based
usedatatopredictpoliticalsentimentandattempttoclassify models.SpecificallyWord2vec.
certainfeaturesasbeingprecursorstoclassification.
(Rajanietal.2019)triedtoimprovespeech-basedmodels DatasetDescription
on their ability to verbalize the reasoning that they learned
Source
during training. It uses the CAGE framework (Common-
SenseAuto-GeneratedExplanations)onthecommonsense Our data is sourced from the individual pages of politi-
explanation dataset to increase the effectiveness by 10 per- cians(SenatorsandCongressmembers)fromthe58th tothe
cent.ItintroducesimprovementsovertheuseofBiDAF++ 117th congress. We divide these into 4 phases, chronolog-
(augmented with self-attention layer) in these newer mod- ically, with each phase consisting of about 14 congresses.
els. It further uses NLE as rationale generalization within Foreachcongressmember,wescrapethesection-wisedata.
thesecondphaseprimarilyasmeansforsentimentanalysis.
DataCollectionandProcessing
Inthispaper,Mturk(fromAmazon)isusedtogenerateex-
planationsforthedataset.CAGEprimarilyusesaquestion- We scrape Wikipedia based on the list of politicians from
answer format with 3 options, a label and the best expla- the Wikipedia page for each congress. For each congress
nation for that label. Furthermore, other evaluation param- member in the list, we store the label, their party and the
eters affecting performance are tested and may be used in metadata.Foreachinstance,thisincludestheirpersonalde-
ourprojecteitherasverificationmodelsorotherwise.CAGE tails and all the information from their page as a dictio-
is certainly an interesting choice for verification given the nary, with the heading being the keys and the content be-
higher accuracy it attains. A factor to be considered how- ing the value. This information helps with the downstream
ever is that the types of datasets and models are very dif- task of cleaning. We annotate this data based on the exper-
ferent.Thuscertainmodificationswillbemadetotheabove iment, in our case we have manually annotated the data to
framework. classify these keys into three separate categories. 1) Back-
(Devlin et al. 2018) is the introduction paper for BERT, ground data, 2) Political data, 3) Other; in our release, we
a model that will be used extensively. It also shows the re- will be releasing both the annotated and raw versions to
sults of fine-tuning BERT. These indirectly or directly will facilitate custom use. Wikipedia page sections don’t have
be used either as pre-trained constraints or as tuning meth- a fixed format, each politician has different key sections.
ods.petroni2019language For instance, Early Life and Background can be split into
(Petroni et al. 2019) Demonstrates the ability of pre- many sections such as Education, Career, Family, Personal
trained high-capacity models like BERT and ELMo to be History, etc. So all these sections are grouped into a sin-
used as knowledge repositories. This is mainly based on 3 glecategoryBackground.Similarly,anythingrelatedtotheir
observations,(1)Therelationalknowledgeofthesemodels politicalaffiliation,elections,campaignsandpositionsheld
iscompetitivetothatofanNLPwithaccesstocertainoracle during their tenure are categorized into a single annotation
knowledge. (2) The effectiveness of BERT in an open do- Political Career. All other categories such as Awards, Con-
mainquestionanswertestand(3)Thefactthatcertainfacts troversies,Businessrelatedactivity,Postpoliticalcareerare
clubbed under the Others category. This way, only relevant
data is selected under each category by manually chang-
ing the annotation based on the content inside each cate-
gory. To conclude, for just Phase 4, a total of 1656 cate-
gories were merged into 3 categories for 1631 instances in
thefirstpassspreadoverroughly26years(1995-2021).This
data still contains information names, organizations, loca-
tions, numbers, etc. which need to be cleaned. We first run
aNERmodelonthedatatoremovethenamesandorgani-
zation. However, we remove location names only from the
politicalsection.Thereasoningbehindthisis,tomakesure
information from the political section is not influenced by
locationinformation.However,forbackground,wewantto
understandwhereapersonwasbornandraisedaffectstheir
politicalviewsandforthisonlythiswaskeptbutotherswere
deleted. This information, after the NER, is passed to re- Figure3:Political
movenumbersandotherirrelevantregularexpressions.This
makessurethedatabeingpassedforotherdownstreamtasks
iscleanandgivesunbiasedanswers. et al. 2019) have been state of the art since 2018 but when
itcomestoourdataset,thesemodelshaveadrawback,that
is,theirabilitytoprocesslongersequencessincethecostof
attentiongrowsontheorderofO(N2).Longformer(Beltagy,
Peters, and Cohan 2020) and other variants are useful for
this task, they accept 4096 input tokens as opposed to 512
forBERT.Itreducesmodelcomplexitybyreformulatingthe
self-attentioncomputation.TheperformanceofLongformer
againstthecurrentSOTAisrepresentedbythetablepresent
belowontherawdata.
Experiments
PreliminaryExperiments
Ourinitialexperimentswereaimedatgaininginsightsabout
patterns or trends that might be present in our data, and
Figure1:WebscrapingbasedoneachTag
alsoquestioningifpolarizationexists.Wedotheseprelimi-
naryexperimentsusingtheDoc2Vec(LeandMikolov2014)
and Word2Vec(Mikolov et al. 2013) models. The Doc2Vec
modelwasbuiltfromscratchwiththerawdata,whereeach
Wikipedia page is considered to be a document. We first
use the Doc2Vec model with K-means clustering and get
a classification accuracy of 59.52% with political data and
61.846% with background data. We then used the same
Doc2VecmodelwithbinarySVMclassifierandachievedan
accuracy of 72.872% with political data and 63.564% with
background data. These results are summarized in the ta-
ble presented below. The Word2Vec tests were run on pre-
trainedmodelsaswellasmodelswebuiltfromscratchand
trainedusingthedatawecollected.WeusedtheWord2Vec
approach to find approximate nearest neighbors and exact
nearestneighborsforcertainwordsonboththeDemocratic
and the Republican sides. This nearest-neighbor approach
led to some interesting insights. We expected to see some
Figure2:Background
disparity in the nearest neighbor searches for the Repub-
lican data and Democratic data basis the assumption that
there is polarization. However using the simple Word2Vec
LanguageModel
models the 15 nearest neighbors we got were quite simi-
Natural Language Processing based applications have been lar but as there were certain words for whom the order of
dominated by transformer-based language models where the neighbors changed based on the party, for example, for
models like BERT(Devlin et al. 2018) and RoBERTa(Liu the word ’GUN’ , ’VIOLENCE’ is the 2nd nearest neigh-
bor(approximatenearestneighborusingspotify’sannoyal-
gorithm)fordemocraticdatahoweverthesamewordis9th
for the republican case, similarly the word ’CHECKS’ is
the 3rd nearest neighbor for democrats while it is the 8th
for republicans. There are more such interesting examples
whichcoupledwiththeresultsfromtheDoc2Vecclassifica-
tion results, prove that political polarization exists and can
be learned using Natural Language Processing based tech-
niques.
Mainanalysis Figure 4: Nearest neighboring words to the word immigrant in the
democraticcorpusacrosstimefromlefttoright,aswecansee,words
As part of our preliminary analysis, we use RoBERTa,
likeamericanswerecloselyassociatedintheearly20thcentury.
we notice the removal of the words ”Democratic”, ”Re-
publican” etc. causing a drop in classification. This is ex-
pected as we lose obvious information and classifying just
based on the first 512 tokens is challenging. We hence
use Longformer since it can consider 4096 tokens at a
time. As expected, this increases the score significantly, as
can be seen in the table. There are two versions of Long-
former - ”longformer-base-4096” and ”longformer-large-
4096.Longformerbaseprovidesasignificantimprovement
overthepreviousmodelRoBERTaandsimplermodelssuch
as Doc2Vec. However Longformer large provided a better
scoreandhasbeenthebestperformingmodelwhenitcomes
Figure5:Nearestneighboringwordstothewordimmigrantinthere-
toclassifyingagivencandidate’spoliticalparty.Wealsoan-
publican corpus, the words are similar in the 1st era, the early 20th
alyze using BigBird which is yet another model which can
century,butinthemostrecenteraitisrelatedtootherpoliticallysen-
consider tokens with lengths of 4096, the results of these
sitivewords.
experimentsareinthetable.Weusethisinformationtoun-
derstandhowdifferentscoresareaffectedbydifferentwords
andrelatethiswithourbroaderaimofPoliticalpolarization.
background dataset to get insight into the factors that in-
Forthat,wecalculatetheglobalattentionscoresofthelast
fluence political polarization. The obtained results are pre-
layer and then find the words that have the highest atten-
sentedinthefollowingtable.
tion scores for self-attention with the < s > token. This
Apartfromtheseaccuracytests,wealsoleveragetheat-
has shown some interesting results, for example, for Ted
tention mechanism of the Longformer model. We find the
Stevens, a Republican, some obvious words like, ”public”,
words with the highest attention scores to correlate them
”federal”,”legislature”,”Wisconsin”showuphigherwhich
with our theory of political polarization. We have also de-
isexpectedsincethemaininformationfromthepoliticaltext
signedaninteractivewebsitethathelpsyoutounderstandif
isrelatedtotheirwork,buttheword”abortion”showedup
polarizationexists.Thewebsitefindsthenearestneighbors
in the top 10 percentile words, more such analysis is being
oftheselectedpoliticiansfromtheLongformeroutput.Then
donewhichwebelievewillgivemoreinterestingresults,the
depending on the ratio of Republicans to Democrats in the
above analysis for simpler models like BERT isn’t as im-
nearestneighbors,weestimatethepolitician’spolarization.
pressive since the information is local and for Longformer
Onesuchexampleisshownbelow-
thisnottrivialsinceLongformerlooksascontextusingslid-
Inthegraph,thex-axisistherankofthe20closestneigh-
ing windows, however, the Longformer architecture allows
borsforthepoliticianyouchoosegiventhedatasetandthe
forcertaintokenstohaveglobalattentionandchoosingthe
y-axis shows their respective closeness scores. The color
CLStokenallowsustolookattheattentionofall4096to-
blue is for Democrats and red for Republicans. The ratio
kenswiththisword.Anotherhypothesisthatwehavebeen
is Blue vs Red points in this graph, so one of our hypothe-
testingisthatthebackgroundofacandidatecanalsohelpus
ses is that if a politician isn’t polarized this ratio should be
identifythepoliticalleaningofapersonwhichiftheworld
0.5(democrat/total) if we just look at the background data.
was not polarized would not be the case and only the po-
litical information would help us classify, however as can
beseeninthetablethebackgroundmatterssignificantlyas
Model Data Accuracy
well.
Doc2Vec Political 59.520
Doc2Vec Background 61.846
Results
Allenai/longformer-large-4096 Political 52.128
We tested different models with the annotated raw dataset Allenai/longformer-large-4096 Background 56.383
to understand the polarization in the text. The three mod-
Table1:K-meansClassificationResults
elsweretestedwithboththepoliticalcareerdatasetandthe
Model Data Accuracy standtheviewsofacandidateandmeasurehowpolarizing
Doc2Vec Political 72.872 their views are. We also hope that the spread of this data
Doc2Vec Background 63.564 acrossmultipledecadeswillhelpusunderstandhowpoliti-
Allenai/longformer-large-4096 Political 76.862 calideashavechangedovertime.
Allenai/longformer-large-4096 Background 69.681
FutureWork
Table2:BinarySVMClassificationResults
Forfuturework,weaimtouseothermetricsforfindingthe
political polarization of individuals and communities again
usingtheWikipediadataset.Specifically,wewanttousethe
attentiontokensmentionedabovetolookattheratioofto-
kensfromthebackgroundtothepoliticalgiventextfroma
candidate that is equally distributed across the background
andpolitical.
Acknowledgments
WewouldliketothankYashJainandVirajRanadefortheir
contributions.
References
Belcastro,L.;Cantini,R.;Marozzo,F.;Talia,D.;andTrun-
Figure 6: Nearest neighbors for political data belonging
fio,P.2020. Learningpoliticalpolarizationonsocialmedia
toMitchMcConnell(Republican)
usingneuralnetworks. IEEEAccess,8:47177–47187.
Beltagy, I.; Peters, M. E.; and Cohan, A. 2020. Long-
former: The long-document transformer. arXiv preprint
arXiv:2004.05150.
Bhatt, S.; Joglekar, S.;Bano, S.;and Sastry,N. 2018. Illu-
minatinganecosystemofpartisanwebsites. InCompanion
ProceedingsoftheTheWebConference2018,545–554.
Center, P. R. 2019. In a politically polarized era, sharp di-
vides in both partisan coalitions. In a Politically Polarized
Era,SharpDividesinBothPartisanCoalitions.
Chen,Z.;Li,Z.;andLiu,S.2022. Thepriceofpoliticalpo-
larization:Evidencefrommunicipalissuersduringthecoro-
naviruspandemic. FinanceResearchLetters,102781.
DeSilver,D.2022. Thepolarizationintoday’sCongresshas
rootsthatgobackdecades.
Figure7:Nearestneighborsforbackgrounddatabelong- Devlin,J.;Chang,M.-W.;Lee,K.;andToutanova,K.2018.
ingtoAyennaPresley(Democrat) Bert:Pre-trainingofdeepbidirectionaltransformersforlan-
guageunderstanding. arXivpreprintarXiv:1810.04805.
Hamilton, W. L.; Leskovec, J.; and Jurafsky, D. 2016. Di-
TheabovegraphinFigure10showstheneighborsforMitch achronicwordembeddingsrevealstatisticallawsofseman-
McConnell(Republican)anditisveryevidentthatmajority ticchange. arXivpreprintarXiv:1605.09096.
of the neighbors are Republican (red in color) whereas the
Jiang,S.;Robertson,R.E.;andWilson,C.2020. Reasoning
Democratcountisonly2outof20.Soonecaninferthatthe
aboutpoliticalbiasincontentmoderation.InProceedingsof
polarization ratio is 0.9 for Mitch McConnell. Similarly, in
the AAAI Conference on Artificial Intelligence, volume 34,
Figure11,wecanseethatAyennaPresleywhoisaDemo-
13669–13672.
crathas16neighborsbelongingtothesamepartyresulting
Khadilkar, K.; KhudaBukhsh, A. R.; and Mitchell, T. M.
inaratioof0.8forbackgrounddata.Scaled-upversionsof
2022. Genderbias,socialbias,andrepresentation:70years
suchwebsiteswithmoremetricsthathighlightthepolitical
ofBHollywood. Patterns,3(2):100409.
viewsofamemberasradicalormoderatewillbebeneficial
tothevoters. KhudaBukhsh, A. R.; Sarkar, R.; Kamlet, M. S.; and
Also, we show the worthiness of this data and hope that Mitchell,T.2021. WeDon’tSpeaktheSameLanguage:In-
thiswillbeusefultotheresearchcommunityinexamining terpretingPolarizationthroughMachineTranslation.InPro-
theideaofpoliticalpolarizationincandidatesandhowitis ceedings of the AAAI Conference on Artificial Intelligence,
linked to other attributes of the candidate. Also, to under- volume35,14893–14901.
KhudaBukhsh, A. R.; Sarkar, R.; Kamlet, M. S.; and
Mitchell, T. M. 2022. Fringe news networks: dynamics of
US news viewership following the 2020 presidential elec-
tion. In14thACMWebScienceConference2022,269–278.
Le, Q.; and Mikolov, T. 2014. Distributed representations
ofsentencesanddocuments. InInternationalconferenceon
machinelearning,1188–1196.PMLR.
Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;
Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V.
2019. Roberta: A robustly optimized bert pretraining ap-
proach. arXivpreprintarXiv:1907.11692.
Mikolov,T.;Chen,K.;Corrado,G.;andDean,J.2013. Ef-
ficient estimation of word representations in vector space.
arXivpreprintarXiv:1301.3781.
Palakodety, S.; KhudaBukhsh, A. R.; and Carbonell, J. G.
2020. Mininginsightsfromlarge-scalecorporausingfine-
tuned language models. In ECAI 2020, 1890–1897. IOS
Press.
Petroni,F.;Rockta¨schel,T.;Lewis,P.;Bakhtin,A.;Wu,Y.;
Miller, A. H.; and Riedel, S. 2019. Language models as
knowledgebases? arXivpreprintarXiv:1909.01066.
Poole, K. T.; and Rosenthal, H. 1984. The polarization of
American politics. The journal of politics, 46(4): 1061–
1079.
Rajani,N.F.;McCann,B.;Xiong,C.;andSocher,R.2019.
Explainyourself!leveraginglanguagemodelsforcommon-
sensereasoning. arXivpreprintarXiv:1906.02361.
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.;Gomez,A.N.;Kaiser,Ł.;andPolosukhin,I.2017. At-
tentionisallyouneed. Advancesinneuralinformationpro-
cessingsystems,30.
