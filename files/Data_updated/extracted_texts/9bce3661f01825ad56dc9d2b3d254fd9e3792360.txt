Solving NLP Problems through Human-System Collaboration: A
Discussion-based Approach
MasahiroKaneko1 GrahamNeubig2 NaoakiOkazaki1
1TokyoInstituteofTechnology 2CarnegieMellonUniversity
masahiro.kaneko@nlp.c.titech.ac.jp
gneubig@cs.cmu.edu okazaki@c.titech.ac.jp
Abstract
Humansworktogethertosolvecommonprob-
lems by having discussions, explaining, and
agreeingordisagreeingwitheachother. Sim-
ilarly, if a system can have discussions with
humanpartnerswhensolvingtasks,ithasthe
potentialtoimprovethesystem’sperformance
andreliability. Inpreviousresearchonexplain-
ability,ithasonlybeenpossibleforsystemsto
makepredictionsandforhumanstoaskques-
tionsaboutthem,ratherthanhavingamutual
exchange of opinions. This research aims to
create a dataset1 and a computational frame-
workforsystemsthatdiscussandrefinetheir
predictionsthroughdialogue. Throughexperi-
Figure1: Human-systemdiscussionsinNLI.
ments,weshowthattheproposedsystemcan
havebeneficialdiscussionswithhumans, im-
provingtheaccuracybyupto25pointsona
naturallanguageinferencetask. urallanguage(Lingetal.,2017;Raffeletal.,2020;
Brownetal.,2020;Wiegreffeetal.,2022;Duetal.,
1 Introduction
2023) and give instructions and feedback to sys-
Today’sdeeplearningsystemsareperformantbut tems through natural language (Abramson et al.,
opaque,leadingtoawidevarietyofexplainability 2022;Sharmaetal.,2022;Murtyetal.,2022;Cam-
techniquesthatattempttotakeinasystempredic- posandShern,2022;Bowmanetal.,2022;Loem
tionandoutputanexplanationjustifyingthepredic- etal.,2023). Chain-of-Thought(CoT)prompting
tion(Ribeiroetal.,2016;Shwartz-ZivandTishby, hasshownthatnaturallanguagecontributestoper-
2017; Fong and Vedaldi, 2017; Kim et al., 2018; formanceimprovementsincomplexmultistepinfer-
Lipton,2018;Wiegreffeetal.,2022). Manysuch ence(Weietal.,2022;Wangetal.,2022b;Zhang
explainabilitytechniquesrequiresignificantexper- et al., 2022). Step-by-step reasoning in CoT re-
tise in deep learning to use effectively, requiring liessolelyonthesystemtomakepredictionswith-
consumersoftheexplanationstoanalyzethedata, out human involvement. There is also work that
internalstates,andoutputtrendsofthesystemof allows users to ask questions about the system’s
interest(Ribeiroetal.,2016;Kanekoetal.,2022d; predictionsandtasks(Slacketal.,2022)inacon-
KanekoandOkazaki,2023). However, manypo- versationalformat. Comparedtothemorestandard
tential system users lack this expertise, such as learningandexplanationparadigms,thisapproach
medical or legal professionals who want to use allows humans to understand and teach the sys-
machinelearningmodelsandneedtoconfirmthe temintuitively. However,intheseworks,thecom-
veracityofthegeneratedresultsorrectifyanymis- municationtendstobeone-sided,fromhuman-to-
takenpredictions. systemorsystem-to-human,whichstillfallsshort
Toaddressthisissue,researchersareworkingto ofthefullinteractiveproblemsolvingprocessex-
findwaystobothexplainsystempredictionsinnat- periencedbyhumaninterlocutors(Lakkarajuetal.,
2022).
1Ourdatasetispubliclyavailableat:https://github.
com/kanekomasahiro/discussion_nlp Inthisstudy,wetakethefirststepstowardses-
4202
naJ
03
]LC.sc[
3v98711.5032:viXra
tablishingaframeworkforhuman-systemcollabo- example,giventhepremise“Thecatissittingon
rationonpredictionproblemsthroughdiscussion the mat” and the hypothesis "The mat is empty",
(illustration in Figure 1). If such a system is re- thetaskwouldinvolveclassifyingtherelationship
alized, it will allow both humans and the system asacontradiction. NLItasksrequiredeepassimila-
toengageinexplanationsofpredictions,askques- tionoffinenuancesofcommonsenseknowledge,
tions about unclear points, refine their thoughts, andmuchworkhasbeendonetoexplainthiswith
andsolveproblems. naturallanguageasapredictionreason(Camburu
First,wecreateadatasetofhuman-humandis- et al., 2018; Kumar and Talukdar, 2020). There-
cussionsregardingapredictiontask(Section2). In fore,wealsotargettheNLItaskandbuildasystem
particular,weusethetaskofnaturallanguageinfer- thatpredictsentailment,contradiction,orneutrality
ence(NLI):predictionoftherelationshipbetween throughdiscussion.
a“premise”sentenceanda“hypothesis”sentence Totrainasystemthatcanengageinadiscussion,
is entailment, contradiction, or neutral (Bowman wecreateadatasetofhumanannotatorsdiscussing
etal.,2015). Wespecificallychooserelativelydiffi- NLI problems. We use the Stanford NLI (SNLI)
cultorambiguouscasestospurdiscussionbetween dataset(Bowmanetal.,2015), acommonbench-
theparticipants. markdatasetinNLP,tocreatethediscussiondata.
Second, we train and evaluate a system that is Collectinghigh-qualitydiscussiondataamonghu-
capable of discussing an NLI problem with a hu- mansiscostly,asitrequiresknowledgeableannota-
man(Sections3,4). Itisachievedbyconstructing torsaboutthetaskandmultipledialogueturnsfor
prompts with manually created discussion exam- eachproblem. Fourteenannotatorswithknowledge
plessothesystemcanlearnfromhumanshowto ofNLPwereaskedtoannotatethedata.2
discuss,accept,orobjecttotheprovidedopinions First,theannotatorswerepresentedwithpremise
aboutthetopic. and hypothesis sentences and asked to predict la-
Theresultsofbothquantitativeandhumaneval- bels such as entailment, contradiction, or neutral.
uation demonstrate that a system could perform Werandomlypairedtwoannotatorstohavethem
more informative discussions by training to have assign labels for the same premise and hypothe-
a discussion with few-shot learning (Section 5). sis. Then, theydiscussedthelabelsthattheyhad
We also found that providing the system with in- assigned differently and decided on the final la-
formationaboutthediscussiontopicimprovedits belsbasedonthosediscussions. Thepremiseand
performanceinmanycasescomparedtothesystem hypothesissentencesweresampledfrom300prob-
that did not have access to such information. On lemsfromthedevelopmentdataand750problems
theotherhand,thediscussionrevealedthatthesys- fromtheevaluationdataofSNLI.Thesewereused
temtendstobetoocompliantwithhumanopinions. asdevelopmentandevaluationdatainthediscus-
Therefore,addressingtheriskoftransmittingincor- siondata,respectively. Eachannotatorpairisasked
rectknowledgeormaliciouslyalteringthesystem’s topredictthelabelsof150problems. SNLIdevel-
knowledgeofhumansisnecessary. Wealsoshow opmentdataoriginallyconsistsofproblemswith
thatfew-shotusageofdiscussiondatacanenable labels from five crowd workers, and the majority
thesystemtocounterhumanargumentscorrectly vote of these labels determines the golden label.
(Section6). Finally,wedemonstratethatusingdis- Tofindrelativelyhardcasesthatmightspurmore
cussiondatageneratedbythesystem(Wangetal., discussion, we sampled problems for annotation
2022b;Huangetal.,2022)canachieveequivalent fromthoseinwhichthreeofthefivehadthesame
results to those of the system that used manually label.
createddiscussiondatainfew-shotlearningorfine- Ourannotatorswerethenpairedwitheachother
tuningcases. and discussed the questions for which they had
given different labels. They discussed in a free-
2 DiscussionDatasetCreation formmanneruntiltheyagreedonafinaldecision.3
Preliminaryexperimentalresultsshowedthatthe
The NLI task aims to determine the logical re-
lationship between a hypothesis sentence and a 2Annotationworkwasrequestedat$25perhour.Thedata
premisesentence(Bowmanetal.,2015). Thetask collectionfromhumanparticipantswasconductedunderan
institutionalreviewboardprotocol.
involves classifying whether the hypothesis sen-
3Theywerealsoinstructednottoincludepersonalinfor-
tenceisentailment,contradiction,orneutral. For mationandinappropriateutterances.
Figure2: Promptwithasingleexampleforfew-shotlearning.
numberofdiscussionturnstendedtobehigherfor examples’taskdescriptionandpremise,hypothe-
oralratherthantext-baseddiscussions. Therefore, sis, and gold labels are given as prompts. In the
we created discussion data by transcribing oral few-shot-discussionsystem,inadditiontothetask
discussionsamongtheannotators,usingWhisper description and examples, human discussion ex-
(medium.en)(Radfordetal.,2022)4 fortranscrip- amplesaboutthelabelsoftheexamplesaregiven
tion. The text transcribed by Whisper was manu- asprompts. Thesepromptsareconcatenatedwith
allycorrectedfortranscriptionerrorsandmanually theproblemtobesolvedandgivenasinputtothe
separatedintospeechsegments. system to perform inference. Examples of each
Then, for each utterance, we assigned the evi- prompt are shown in Figure 2. The discussion
dentialutterancesforthefinallabelandthelabels exampledistinguisheshumanutterancesbetween
of“supportive”,“unsupportive”,or“irrelevant”to “Human1:” and“Human2:”.
each utterance. For example, for Figure 1, “Both Theexamplesusedinthepromptsarethesame
haveapersonsittinginthechair,buttheyareneu- forboththefew-shotandthefew-shot-discussion
tralbecausenogenderisspecified.” islabeledas systems. We use the same examples for all prob-
supportive,“Itisentailmentbecausethepersonsits lems. Allmethodsdonotupdatetheparametersof
inachair.” isunsupportive,and“Yes.” islabeled thesystems. WeuseGPT-3.55 (Brownetal.,2020)
asirrelevant. Theselabelsarenotusedinthefew- and ChatGPT6 (OpenAI, 2023)for thezero-shot,
shotlearningprocessbutareusedtoevaluatethe few-shot,andfew-shot-discussionsystems.
discussionabilityofthesystemautomatically.
In this annotation work, discussion data were 4 EvaluationMethod
collectedfor102problems. Ofthese,10problems
Weevaluateasystem’sdiscussionabilityfromthe
wereusedaspromptsforfew-shotlearning,27for
following three perspectives: (1) Can the system
validation data, and 65 for evaluation data. The
generateutterancecontentthatcontributestothefi-
averagenumberofutterancesforeachproblemin
nallabel? (2)Canthesystemagreewithstatements
theprompt,validation,andevaluationdatais4.4,
thatsupportthecorrectlabelandrefutestatements
6.3,and5.1respectively. Forvalidationandevalu-
that support the incorrect label? (3) Does discus-
ationdata,thenumberofsupportive/unsupportive
sionwithhumansimprovetaskperformance? To
utterancesare85/23and133/72respectively.
examine these discussion abilities, we compare
3 DiscussionSystem eachsystembyperformingautomaticandmanual
evaluations.
Weusethreetypesofsystemsintheexperiments:
We investigate utterances generated from the
zero-shot,few-shot,andfew-shot-discussion. In
the zero-shot system, only the task description is 5text-davinci-003: https://beta.openai.com/
given as a prompt. In the few-shot system, the docs/models/gpt-3
6gpt-3.5-turbo:https://platform.openai.com/
4https://github.com/openai/whisper docs/guides/gpt/chat-completions-api
systemstodetermineiftheycontributetotheauto- pre-trained language model for BERTScore. We
maticevaluation’sfinallabel. Forthat,weusethe conductasignificancetestusingt-test(p < 0.01).
utterances generated by the system for the given WesetthetemperatureparameterofGPT-3.5and
problemsandevaluatehowwelltheymatchtheref- ChatGPTto0.7andgeneratetenoutputsforeach
erenceutterancesbetweenhumansfromdiscussion input. WecalculateBERTScoreforeachoftheten
evaluationdata. Eachutteranceinourdiscussion outputsandtestforsignificanceamongthecalcu-
evaluationdataisannotatedaseithersupportiveor latedtenscores.
unsupportiveofthegoldlabel. Ifasystemismore Next, we use human evaluation to examine
likely to generate a supportive utterance than an whetherthesystemcanagreewithsupportivehu-
unsupportiveutteranceforthegoldlabel,thesys- manutterancesandrefuteunsupportivehumanut-
temcanbeconsideredcapableofmakingcorrect terances. Thehumanparticipantsandthesystem
discussions that lead to the correct answers. For predictdifferentlabelsforthesameproblem. Then,
example, “I think it is also better to consider the theyengageinadiscussion,andthefinallabelre-
general cases.” is the supportive utterance, and sult is demonstrated to be in agreement with the
“Isthephoneinthehypothesisnecessarilyacell-
labelsassignedintheSNLIdatathroughthecon-
phone? Itcouldbealandlinephone.” istheunsup- sistencyoftheagreementrate. Inthisprocess,we
portive utterance in Figure 2. Therefore, we also evaluate the ability of the system to accept a hu-
investigatewhetherthesystemisbetteratgenerat- man’sopinionwhenthesystem’slabelisincorrect,
ingsupportiveutterancesoverunsupportiveones. andwhenthehuman’slabeliscorrect,andtheabil-
Specifically,weevaluatethesimilaritybetweenthe ity of the system to object to a human’s opinion
system-generatedutterancesandtheactualhuman when the human’s label is incorrect, and the sys-
utterances for supportive and unsupportive utter- tem’slabeliscorrect.
ances,respectively.
Similarlytoabove,weselectedthosedatawith
We concatenate the input problem and the dis-
thesamelabel3times(e.g.,entailment,entailment,
cussion utterance up to the target utterance and
neutral,entailment,neutral). Asaresult,wesam-
generatethenexttargetutterance. Forexample,if
pled 140 problems that differ from the problems
thesecondhuman’sutteranceinthediscussionis
collected in section 2. During this process, if the
thetargetutterance, thenthepromptis“Premise:
system’slabelwascorrect,humansengagedinad-
A nun is taking a picture outside. Hypothesis: A
versarialdiscussionstochangethesystem’slabel.
nun is taking a selfie. Label: entailment or neu-
If the system’s label was incorrect, humans en-
tralDiscussion: Human1: Ithinkitisentailment,
gagedindiscussionstoguidethesystemtowardthe
becausethenunistakingapicture,soitmightbe
correctlabel. Here,thediscussionwastext-based
aselfie. Human2:”,andthesystemshouldgener-
ratherthanverbal,asthesystemtakestextualinput.
ate an utterance that would be evaluated against
To conduct a discussion with the system, we
thefollowingutterancemadebyahuman“Sinceit
input the prompt and problem shown in Figure 2
isoutside,itisconceivablethatthenunistaking
tothesystemandtheninputtedadditionalhuman
somescenery.”. Atthispoint,theproblemhastwo
utteranceexamplesrelatedtothediscussionafter
opposinglabelsinthepromptbecausewewantit
eachsystempredictedthelabel. Intheadditional
todiscusstwodifferentlabels.
input,thebeginningofhumanutteranceisprefixed
We use actual human utterances as references
with"Human:"andtheendisprefixedwith"Sys-
andcomputetheBERTScore(Zhangetal.,2020)
tem:" to indicate that the next is a system’s utter-
ofthesystem’soutputsforevaluation. BERTScore
ance. Specifically,thefirstpromptfordiscussion
leveragesthepre-trainedlanguagemodelsuchas
is"Human: Let’sdiscussitmore. Ithinkneutral,
BERT (Vaswani et al., 2017) and RoBERTa (Liu
because there may be a kitchen in the barn. Sys-
et al., 2019) and matches words in candidate
tem:". Thesystempredictsthefinallabelwhenthe
and reference sentences by cosine similarity.
discussionisfinished.
BERTScore computes precision, recall, and F1
Weinvestigatehowdiscussionwithhumansim-
measures. Therefore, BERTScore can be used
provesNLItaskperformance. Thesystempredicts
tocomparethesystem’scontentandhumanutter-
anceswitheachother. Weuseroberta-large7forthe the label, then the human and the system discuss
and decide on the final label. We compare the
7https://huggingface.co/roberta-large performanceofeachlabelbeforeandafterthedis-
supportive↑ unsupportive↓ diff. Before After
zero-shot 82.0/83.1 81.8/82.5 0.2/0.6 zero-shot 54.2/60.0 65.6/60.0
few-shot 82.7/83.6 82.3/82.9 0.4/0.7 few-shot 60.0/65.6 60.0/70.0
few-shot-dis. 84.8†/86.3† 79.1†/78.6† 5.7/7.7 few-shot-dis. 60.0/65.6 85.0†/90.0†
Table 1: BERTScore of supportive and unsupportive Table 3: The accuracy for the predicted label before
utterances. TheleftscoresarebyGPT-3.5,andtheright and after the discussion. The left scores are by GPT-
scoresarebyChatGPT.†indicatesstatisticallysignifi- 3.5, and the right scores are by ChatGPT. † indicates
cantscoresforsupportiveandunsupportiveaccording statisticallysignificantscoresaccordingtoMcNemar’s
tothet-test(p<0.01). test(p<0.01).
Acceptancerate Objectionrate SNLI R1 R2 R3
zero-shot 75.0/80.0 58.9/55.0 zero-shot 49.74 47.40 39.10 41.33
few-shot 80.0/80.0 55.0/55.0 few-shot 69.45 53.50 48.00 48.50
few-shot-dis. 90.0†/95.0† 80.0†/80.0† few-shot-dis. 66.14 53.90† 50.40† 50.42†
zero-shot 51.83 48.63 41.70 40.52
Table 2: Human evaluation of the system’s ability to few-shot 70.31 55.08 52.31 52.18
accept and object to human opinion. The left scores few-shot-dis. 70.15 57.24† 55.63† 55.19†
arebyGPT-3.5,andtherightscoresarebyChatGPT.
†indicatesstatisticallysignificantscoresaccordingto Table 4: The accuracy on SNLI and ANLI (R1, R2,
McNemar’stest(p<0.01). R3)evaluationdata. UpperscoresarebyGPT-3.5,and
lowerscoresarebyChatGPT.†indicatesstatistically
significant scores according to McNemar’s test (p <
cussion. Here, the data for the acceptance and 0.01).
objection settings are half and half. Therefore, if
thediscussionisnotproperlyconducted, suchas
that few-shot-discussion can generate discussion
byacceptingallhumanlabelsorrefutingallhuman
utteranceswithhigheraccuracythanzero-shotand
labels,theperformancewillnotimprove.
few-shot, which do not use discussion examples
WealsoinvestigatetheperformanceoftheNLI
data. Theperformanceofzero-shotandfew-shot
whenusingargumentationprompts. Wecompared
is almost the same, suggesting that just showing
theperformanceofNLIinzero-shot,few-shot,and
examplesdoesnotimprovethediscussionability.
few-shot-discussionsystems. Thepredictedlabel
Also,thedifferencebetweensupportiveandunsup-
after “Label:” in the prompt of Figure 2 is con-
portiveutteranceaccuraciesisgreaterinfew-shot-
sideredastheprediction,anddiscussionbetween
discussionthaninzero-shotandfew-shotsystems.
humansandsystemsisnotperformed. Intheeval-
Therefore, because the few-shot-discussion can
uation of NLI performance, in addition to SNLI
generatemoresupportiveutterances,itisthought
data, we also use Adversarial NLI (ANLI) data
thatsuchdiscussionscanresultinmoreappropriate
(Nieetal.,2020). ANLIcreatesdatabyrepeatedly
labels.
performingadversarialannotationagainstNLIsys-
Table 2 shows the accuracy of the label deter-
tems;thus,theresultingNLIexamplesarepartic-
minedbydiscussioninthesettingsforevaluating
ularly difficult for the system to solve. There are
theacceptanceabilityandobjectionability,respec-
three data sets R1, R2, and R3 with differences
tively. In terms of the objection, it can be seen
in the number of iterations, and the evaluation is
thatthefew-shot-discussionsystemhandledobjec-
performedusingeachevaluationdatapoint.
tions well in comparison to the zero-shot system.
In addition, Table 3 shows the accuracy8 of the
5 Experiments
predicted label without discussion, and the accu-
5.1 DiscussionAbilityEvaluationResults racy of the final label reached as a result of the
discussionbetweenhumansandsystems. Further-
Table1representsBERTScoreforsupportiveand
more,thefew-shotsystemhasasimilarobjection
unsupportive utterances and the difference be-
abilityasthezero-shotsystem,andthereisapos-
tween them in zero-shot, few-shot, and few-shot-
discussionsystems. TheBERTScoreoffew-shot- 8Tofacilitatediscussion,thisevaluationislimitedtoin-
stanceswherethreeofthefivecloudworkershavethesame
discussionisgenerallyhigherthanthatofthezero-
labelinSNLIdata.Thismakesitmorechallengingthanusing
shot and the few-shot systems. It can be seen theentireSNLIdata.
SNLI R1 R2 R3 SNLI R1 R2 R3
GPT-3.5dis. 66.14 53.90 50.40 50.42 MPT 85.2 67.4† 55.2† 55.0†
GPT-3.5pseudo 65.67 54.00 49.60 50.50 MPT-inst. 87.7† 68.2† 56.1† 55.3†
w/dis.
ChatGPTdis. 68.51 53.90 52.82 52.33 Falcon 86.2† 67.6 55.5† 54.9
ChatGPTpseudo 68.66 54.00 52.51 52.10 Falcon-inst. 90.3† 71.7† 58.4† 57.6†
MPT 85.4 65.2 53.9 52.4
MPT-inst. 85.1 64.0 51.1 50.7
Table5: TheaccuracyonSNLIandANLI(R1,R2,R3) w/odis.
Falcon 84.6 67.9 54.7 54.2
testdataforfew-shotsystemsusingmanuallycreated
Falcon-inst. 85.3 66.2 53.1 53.0
discussionexamplesandpseudo-discussionexamples.
MPT 86.7† 68.3† 55.2† 55.0†
UpperscoresarebyGPT-3.5,andlowerscoresareby
MPT-inst. 86.9 68.8† 56.1† 55.3†
ChatGPT. w/dis.
Falcon 88.1 68.1 55.5 54.9
Falcon-inst. 90.7† 71.9† 58.4† 57.6†
MPT 85.4 65.2 53.9 52.4
sibilitythattheperformanceoflabelpredictionby MPT-inst. 86.0 64.0 51.1 50.7
w/odis.
thesesystemsisnotnecessarilydirectlyrelatedto Falcon 88.5 67.9 54.7 54.2
Falcon-inst. 89.7 67.8 55.5 56.4
the ability to discuss. In comparison with accep-
tance, itisnecessarytobecarefulofpeoplewho
Table6: AccuracyonSNLIandANLI(R1,R2,R3)test
manipulatepredictionswithmalicearguments,as data for fine-tuned systems with and without pseudo-
the system tends to be weak at objecting to hu- discussion data. Additional fine-tuning with pseudo
mans. Furthermore,fromthefactthattheaccuracy discussiondataforinstructiontunedandnon-instruction
of the few-shot-discussion system has improved tuned models for MPT and Falcon. The upper and
lower scores are the results using pseudo discussion
themost,itisclearthattheproposeddatacanbe
datageneratedbyGPT-3.5andChatGPT,respectively.
usedtohavediscussionswithhumansthatleadto
†indicatesstatisticallysignificantscoresforw/dis. and
improvedperformance.
w/odis. accordingtoMcNemar’stest(p<0.01).
Table4showstheaccuracyofeachsystemfor
theevaluationdataofSNLIandANLI.InSNLI,the
few-shot-discussion system performs worse than et al., 2021; Honovich et al., 2022; Wang et al.,
the few-shot system, but in the three datasets of 2022b). Therefore,weproposetouseGPT-3.5and
ANLI, we find that the performance is the best. ChatGPTtogeneratediscussiondatainazero-shot
This is because ANLI is more difficult data com- andusethemasdiscussionexamplesforafew-shot
pared to SNLI, and we hypothesize that through toinvestigateifitispossibletoachievethesame
discussion,systemsgetamoredetailedunderstand- levelofimprovementasfromusingmanuallycre-
ingofproblems,whichinturncontributestoper- ated data. If a system can automatically produce
formanceimprovement. high-qualitydata, itcanproduceenoughdatafor
From the results of previous experiments, we fine-tuningatalowcost. Therefore,wealsoinves-
foundthatdiscussionbetweenhumansandsystems tigatetheeffectivenessofpseudo-discussiondata
is beneficial for improving performance.9 There- infine-tuning.
fore, the few-shot-discussion system, in which a Ingeneratinghumandiscussions,thesystemis
discussion example is also given as a prompt, is givenpromptsintheformofthepremise,hypoth-
expectedtoachieveadeeperunderstandingofNLI esis, gold label, and the labels from each human.
problems and improve performance through the The human labels are randomly chosen to be the
discussionexampleintheprompt. gold label or the other incorrect label. For exam-
ple, given the premise “A nun is taking a picture
6 Analysis
outside.” andhypothesis“Anunistakingaselfie.”
with the gold label of neutral, the prompt would
6.1 Pseudo-DiscussionData
be“Reproduceamulti-turninteractivediscussion
Onedrawbackofusingdiscussiondataisthatitcan
inwhichthefollowingpremiseandhypothesisare
becostlytocreatecomparedtodatasetsthatonly
entailment,contradiction,orneutral,withthehu-
havegoldlabels. Usingpre-trainedmodelstoan-
mans agreeing with each other on the final label.
notateunlabeleddataandusethisdatafortraining
Human1’slabelisneutral,andHuman2’slabelisa
has been shown to improve performance (Wang
contradiction. Intheend,theyagreeonthelabelof
neutral. Premise: Anunistakingapictureoutside.
9Weshowexamplesofhuman-systemdiscussioninAp-
pendixA. Hypothesis: Anunistakingaselfie.”.
TheGPT-3.5andChatGPTgeneratehumandis- SNLI R1 R2 R3
cussionsfor10problemsusedinthefew-shotand
Randomdis. -2.91 -2.10 -3.30 -3.42
2,000 problems used in the fine-tuning, respec- Cuttingdis. -2.40 -1.60 -2.60 -2.25
Randomlabel -3.43 -2.50 -3.50 -3.17
tively. Theaveragenumberofutterancesinhuman-
createddiscussionswas4.4,andtheaveragenum- Randomdis. -3.32 -3.59 -3.77 -3.62
Cuttingdis. -2.88 -2.79 -2.32 -2.15
berofutterancesinsystem-generateddiscussions
Randomlabel -3.22 -3.76 -3.89 -3.58
was4.7. Regardingthenumberofutterances,hu-
manandsystemargumentsarealmostthesame. Table 7: Difference for the few-shot-discussion accu-
We used instruction tuned and non-instruction racyfromwhenthenoisyexamplesareprovidedinthe
tuned models for MPT10 (Team, 2023) and Fal- promptonSNLIandANLI.Thehigherthedifference,
thestrongerthenoise. UpperdifferencesarebyGPT-
con11 (Penedoetal.,2023)aspre-trainedmodels
3.5,andlowerdifferencesarebyChatGPT.
forfine-tuning. Weusedhyperparametersfromex-
istingstudies(Taorietal.,2023)asareferenceand
fine-tunedthebatchsizeto128,thelearningrate ofproducinghigh-qualitydiscussiondatathatcan
to 2e-5, and the epoch to 3. We used five nodes, beusedfortrainingsystemstobeabletodiscuss
eachcontainingeightNVIDIAA100GPUs. The givenproblems.12 Therefore,onecansignificantly
systemisgivenboththelabelsanddiscussionsas lowerthecostofcreatingdiscussiondatamanually
goldsduringtraining,andweevaluateusingonly byusingsystems.
labelsduringinference. Wetrainmodelswithout
pseudo-discussiondataasabaseline. Thebaseline 6.2 DoDiscussionExamplesinthePrompts
modelsaretrainedwithonlythelabels. Matter?
Table5showstheresultsoftheautomaticevalu- It is known that pre-trained models can ob-
ationofperformanceinSNLIandANLIforeach tain good results even with irrelevant or noisy
ofthemanuallygenerateddiscussionexampledata prompts (Khashabi et al., 2022; Webson and
andsystem-generatedpseudo-discussionexample Pavlick, 2022; Min et al., 2022). Therefore, we
dataforfew-shotlearning,respectively. Intwoof investigatethesensitivityandrobustnessofthesys-
the four datasets, the system’s performance with tem with respect to the discussion examples con-
pseudo-discussiondataoutperformsthatofthesys- tained in the prompts. We provide three types of
temwithmanuallycreateddata. Moreover,thereis noiseintheprompts: (1)assigningarandomdis-
nosignificantdifferencebetweenthescoresofthe cussionthatisirrelevanttotheexampleproblem,
LLMsusingthehuman-createdandpseudo-discus- (2)cuttingtheoriginaldiscussionexamplesshortat
sion by McNemar’s test (p < 0.01). It is possible randomtimes,and(3)assigningalabelatrandom
to achieve performance comparable to manually fortheexampleproblems.
createddata,evenwithpseudo-discussiondata. Table 7 shows the difference in accuracy com-
Table6showstheresultsoftheautomaticevalu- pared to the few-shot-discussion accuracy from
ationofperformanceinSNLIandANLIforfine- Table4foreachofthethreenoises. Itcanbeseen
tuned MPT and Falcon with pseudo-discussion thatperformancedeterioratesforalltypesofnoises.
data. The model with pseudo-discussion data Noisethatrandomlyreplacesdiscussionsandnoise
performs better than the model without pseudo- thatrandomlyreplaceslabelsbothhavethesame
discussion data in most cases for both MPT and degreeofreducedaccuracy. Oppositely,thediscus-
Falcon. We find that fine-tuning with pseudo- sionsthatwerecutshort,showtobeaweakernoise
discussion data is more effective for instruction than discussion substitution and have performed
tunedmodels. Itimpliesthatinstructiontuningim- better. Theseindicatethatthesystemproperlycon-
provesthelinguisticunderstandingofthesystem sidersdiscussionexamplesintheprompts.
andenhancestheunderstandingofthediscussion.
7 RelatedWork
Theseresultsindicatethatthesystemiscapable
Inthisstudy,systemsandhumansdiscussaprob-
10https://huggingface.co/mosaicml/
lem through dialogue. Dialogue systems can be
mpt-7b and https://huggingface.co/
mosaicml/mpt-7b-instruct broadly classified into two types: task-oriented
11https://huggingface.co/tiiuae/
falcon-7b and https://huggingface.co/ 12Weshowcomparisonsofexamplescreatedbyhumans
tiiuae/falcon-7b-instruct andsystemsrespectivelyinAppendixB.
systemsthatperformspecifictasks,andnon-task- beusedtoseekadditionalexplanationsorspecific
orientedsystemsthatdonothavethegoaloftask explanations,theinterpretabilityisnotsufficientin
completion,suchascasualconversation. Thisstudy practiceaspointedoutbyLakkarajuetal.(2022).
aims to conduct appropriate predictions in NLP Instead of directly predicting answers, CoT
tasksthroughdiscussionsbetweenhumansandthe uses natural language to derive answers step-by-
systemandisclassifiedasatask-orientedsystem. step(Weietal.,2022). Thisleadstocomplexmulti-
Many existing dialogue systems target daily life stepinferences. Byaddingthephrase“Let’sthink
taskssuchashotelreservationsandtransportation step by step” before each answer, Kojima et al.
inquiries(Budzianowskietal.,2018). Pre-trained (2022)demonstratethatlanguagemodelsarecom-
models such as BERT (Devlin et al., 2019) and petent zero-shot CoT. On the other hand, Wang
GPT-2(BudzianowskiandVulic´,2019;Hametal., et al. (2022a) shows that CoT can achieve com-
2020)arealsoutilizedindialoguesystemsfordaily petitive performance even with invalid reasoning
lifetasks. Recently,ChatGPT(OpenAI,2023)has stepsintheprompt. CoT’sstep-by-stepapproach
beenproposedformoregenericinteractionbased isbasedonthesystemonly,whereasourproposed
on a pre-trained model. We similarly use a pre- methodincorporateshumaninvolvementinthesys-
trainedmodelforoursystem. temtofacilitatecollaborationbetweenhumansand
the system. Additionally, our approach utilizes
Asfarasweknow,fewstudiesusediscussionfor
discussionsforastep-by-stepthinkingprocess.
NLPtaskssimilartoours. Changetal.(2017)pro-
Research is also being conducted on the use
posed the TalkToModel, which explains through
ofnaturallanguagebyhumanstoprovideinstruc-
dialogue three tasks of loan, diabetes, and recidi-
tionsandfeedbacktothesystem. Abramsonetal.
vism prediction. The user can talk to the TalkTo-
(2022) has developed multi-modal grounded lan-
Model in five categories: prediction explanation,
guageagentsthatperformreinforcementlearning
datamodification,erroranalysis,dialoguehistory
on human dialogue-based instructions. Sharma
reference, and experimental setting explanation.
etal.(2022)proposedamethodtointegratehuman-
DataforlearningandevaluatingtheTalkToModel
provided feedback in natural language to update
aregeneratedbyinstructingtheannotatortocon-
arobot’splanningcostappliedtosituationswhen
verse about these categories. However, the cate-
the planner fails. Murty et al. (2022) proposed
gories were not determined based on interviews
a method to modify a model by natural language
or data but were defined subjectively by the au-
patchesandachievedperformanceimprovementin
thors. Therefore,itispossiblethatthecategoriesdo
sentimentanalysisandrelationshipextractiontasks.
notreflectactualconversationsthathumansneed.
CamposandShern(2022)proposedamethodfor
Ontheotherhand,ourstudywasconductedinan
trainingamodeltobehaveinlinewithhumanpref-
open-endeddialoguetogeneratedata. Additionally,
erences, by learning from natural language feed-
ourstudyaimsformutualunderstandingthrougha
back, in text summarization. On the other hand,
bidirectionaldialoguewherebothhumansandthe
thesestudiescannotbeexplainedorquestionedby
systemexpressopinionsandquestions,unlikethe
thesystemtohumans.
systemsthatonlyrespondtohumanquestionsina
unidirectionaldialogue.
8 Conclusion
Thereisresearchongeneratingexplanatorytext
for predictions as a way to transfer information Whiledeeplearningsystemshavebeenhighlyef-
fromsystemstohumansthroughnaturallanguage. fectiveinvarioustasks,theirlackofinterpretability
For example, research regarding natural science posesachallengetotheiruseinreal-worldapplica-
tests (Ling et al., 2017), image recognition and tions. Toaddressthis,weproposedasystemthat
imagequestionanswering(Parketal.,2018),math- engagesinadialoguewithhumansintheformof
ematicstests(Jansenetal.,2018),andNLI(Cam- discussingpredictions,whichallowsbothhumans
buru et al., 2018) have been studied. Addition- andthesystemtoengageinexplanations,askques-
ally,systemsforgeneratingexplanationsusingpre- tions, refine their thoughts, and solve problems.
trainedmodelssuchasT5(Raffeletal.,2020)and Our experimental results showed that the system
GPT-3.5(Brownetal.,2020)havealsobeenpro- trainedwithfew-shotlearningfordiscussioncould
posed(Narangetal.,2020;Wiegreffeetal.,2022). perform moreuseful discussionsthan the system
However,asthesegeneratedexplanationscannot that was not trained for discussion and provided
insightsonthechallengesandopportunitiesofthis Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou,
approach. Thisresearchprovidesanewavenuefor VenkateshSaligrama,andAdamTaumanKalai.2016.
Man is to computer programmer as woman is to
developingmoreinteractivedeep-learningsystems.
homemaker? debiasingwordembeddings. InNeural
InformationProcessingSystems.
Limitations
SamuelRBowman,GaborAngeli,ChristopherPotts,
Compared to the original system that uses only
and Christopher D Manning. 2015. A large anno-
inputsandlabels,ourmethodusesadditionaldis-
tatedcorpusforlearningnaturallanguageinference.
cussion data, resulting in longer sequences. This In Proceedings of the 2015 Conference on Empiri-
leadstoanincreaseintrainingorinferencecosts. calMethodsinNaturalLanguageProcessing,pages
632–642,Lisbon,Portugal.AssociationforCompu-
Wehaveconductedexperimentsonpre-trained
tationalLinguistics.
modelswithlargemodelsizestoverifytheireffec-
tiveness. Ontheotherhand,itisnecessarytoverify SamuelRBowman,JeeyoonHyun,EthanPerez,Edwin
theeffectivenessoflearningbyargumentationon Chen,CraigPettit,ScottHeiner,KamileLukosuite,
AmandaAskell,AndyJones,AnnaChen,etal.2022.
smallerpre-trainedmodels(Wuetal.,2023;Team,
Measuringprogressonscalableoversightforlarge
2023;Touvronetal.,2023). Ourmanuallycreated languagemodels. arXivpreprintarXiv:2211.03540.
discussiondataisrelativelysmallinscale. There-
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
fore,itisnecessarytoexpandthedatasettoalarger
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
scaletomorerobustlytesttheeffectivenessofthe
Neelakantan,PranavShyam,GirishSastry,Amanda
proposedmethod. Askell,etal.2020. Languagemodelsarefew-shot
learners. Advancesinneuralinformationprocessing
EthicsStatement systems,33:1877–1901.
Pre-trained models have serious levels of social PawełBudzianowskiandIvanVulic´.2019. Hello,it’s
biasesregardinggender,race,andreligion(Boluk- GPT-2-howcanIhelpyou? towardstheuseofpre-
trainedlanguagemodelsforTask-Orienteddialogue
basi et al., 2016; Kaneko and Bollegala, 2019,
systems. InProceedingsofthe3rdWorkshoponNeu-
2021b,a,c;Mayetal.,2019;Caliskanetal.,2022;
ralGenerationandTranslation,pages15–22,Hong
Zhouetal.,2022;LucyandBamman,2021;Anan- Kong.AssociationforComputationalLinguistics.
taprayoon et al., 2023; Kaneko et al., 2022c,b,a,
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang
2023b,a, 2024; Oba et al., 2023). Therefore, we
Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ra-
have to be careful that systems discussing with
madan, and Milica Gašic´. 2018. MultiWOZ - a
humansamplifysuchbiases. Large-Scale Multi-Domain Wizard-of-Oz dataset
Annotationworkwasrequestedat$25perhour. forTask-Orienteddialoguemodelling. pages5016–
5026.
Workersareemployedatappropriatepay. Annota-
torswerewarnedinadvancenottogivepersonal
Aylin Caliskan, Pimparkar Parth Ajay, Tessa
informationorinappropriateutterancesduringthe Charlesworth, Robert Wolfe, and Mahzarin R
dialogue. Wehaveverifiedthatthedataproduced Banaji.2022. Genderbiasinwordembeddings: a
comprehensive analysis of frequency, syntax, and
does not contain any personal information or in-
semantics. InProceedingsofthe2022AAAI/ACM
appropriate utterances. The data collection from
Conference on AI, Ethics, and Society, pages
humanparticipantswasconductedunderaninstitu- 156–170.
tionalreviewboardprotocol.
Oana-Maria Camburu, Tim Rocktäschel, Thomas
Lukasiewicz,andPhilBlunsom.2018. E-SNLI:Nat-
urallanguageinferencewithnaturallanguageexpla-
References
nations.
JoshAbramson,ArunAhuja,FedericoCarnevale,Petko
Georgiev,AlexGoldin,AldenHung,JessicaLandon, JonAnderCamposandJunShern.2022. Traininglan-
JirkaLhotka,TimothyLillicrap,AlistairMuldal,etal. guagemodelswithlanguagefeedback. InACLWork-
2022. Improvingmultimodalinteractiveagentswith shop on Learning with Natural Language Supervi-
reinforcementlearningfromhumanfeedback. arXiv sion.2022.
preprintarXiv:2211.11602.
JosephCheeChang,SaleemaAmershi,andEceKamar.
PanatchakornAnantaprayoon,MasahiroKaneko,and 2017. Revolt: Collaborativecrowdsourcingforlabel-
Naoaki Okazaki. 2023. Evaluating gender bias ingmachinelearningdatasets. InProceedingsofthe
of pre-trained language models in natural lan- 2017CHIConferenceonHumanFactorsinComput-
guage inference by considering all labels. ArXiv, ingSystems,CHI’17,pages2334–2346,NewYork,
abs/2309.09697. NY,USA.AssociationforComputingMachinery.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Masahiro Kaneko and Danushka Bollegala. 2021c.
Kristina Toutanova. 2019. BERT: Pre-training of Unmasking the mask - evaluating social biases in
deepbidirectionaltransformersforlanguageunder- masked language models. In AAAI Conference on
standing. InProceedingsofthe2019Conferenceof ArtificialIntelligence.
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech- MasahiroKaneko, DanushkaBollegala, andTimothy
nologies,Volume1(LongandShortPapers),pages Baldwin. 2024. The gaps between pre-train and
4171–4186,Minneapolis,Minnesota.Associationfor downstreamsettingsinbiasevaluationanddebiasing.
ComputationalLinguistics.
Masahiro Kaneko, Danushka Bollegala, and Naoaki
YilunDu,ShuangLi,AntonioTorralba,JoshuaBTenen- Okazaki.2022a. Debiasingisn’tenough! –onthe
baum,andIgorMordatch.2023. Improvingfactual- effectiveness of debiasing MLMs and their social
ityandreasoninginlanguagemodelsthroughmultia- biasesindownstreamtasks. InProceedingsofthe
gentdebate. arXivpreprintarXiv:2305.14325. 29thInternationalConferenceonComputationalLin-
guistics,pages1299–1310,Gyeongju,Republicof
RuthCFongandAndreaVedaldi.2017. Interpretable Korea. International Committee on Computational
explanations of black boxes by meaningful pertur- Linguistics.
bation. In Proceedings of the IEEE international
conferenceoncomputervision,pages3429–3437. Masahiro Kaneko, Danushka Bollegala, and Naoaki
Okazaki.2022b. Genderbiasinmeta-embeddings.
DonghoonHam,Jeong-GwanLee,YoungsooJang,and
In Findings of the Association for Computational
Kee-Eung Kim. 2020. End-to-End neural pipeline
Linguistics: EMNLP2022,pages3118–3133,Abu
forGoal-OrienteddialoguesystemsusingGPT-2. In
Dhabi,UnitedArabEmirates.AssociationforCom-
Proceedingsofthe58thAnnualMeetingoftheAssoci-
putationalLinguistics.
ationforComputationalLinguistics,pages583–592,
Online.AssociationforComputationalLinguistics. Masahiro Kaneko, Danushka Bollegala, and Naoaki
Okazaki. 2023a. Comparing intrinsic gender bias
OrHonovich,ThomasScialom,OmerLevy,andTimo
evaluationmeasureswithoutusinghumanannotated
Schick. 2022. Unnatural instructions: Tuning lan-
examples. ArXiv,abs/2301.12074.
guagemodelswith(almost)nohumanlabor. arXiv
preprintarXiv:2212.09689.
Masahiro Kaneko, Danushka Bollegala, and Naoaki
Okazaki. 2023b. The impact of debiasing on the
JiaxinHuang,ShixiangShaneGu,LeHou,YuexinWu,
performanceoflanguagemodelsindownstreamtasks
XuezhiWang,HongkunYu,andJiaweiHan.2022.
isunderestimated. ArXiv,abs/2309.09092.
Large language models can self-improve. arXiv
preprintarXiv:2210.11610.
MasahiroKaneko,AizhanImankulova,DanushkaBol-
legala,andNaoakiOkazaki.2022c. Genderbiasin
Peter Jansen, Elizabeth Wainwright, Steven Mar-
maskedlanguagemodelsformultiplelanguages. In
morstein,andClaytonMorrison.2018. WorldTree:
Proceedings of the 2022 Conference of the North
Acorpusofexplanationgraphsforelementarysci-
AmericanChapteroftheAssociationforComputa-
ence questions supporting multi-hop inference. In
tionalLinguistics: HumanLanguageTechnologies,
Proceedings of the Eleventh International Confer-
pages2740–2750,Seattle,UnitedStates.Association
enceonLanguageResourcesandEvaluation(LREC
forComputationalLinguistics.
2018), Miyazaki, Japan. European Language Re-
sourcesAssociation(ELRA).
Masahiro Kaneko and Naoaki Okazaki. 2023. Con-
Masahiro Kaneko and Danushka Bollegala. 2019. trolledgenerationwithpromptinsertionfornatural
Gender-preserving debiasing for pre-trained word languageexplanationsingrammaticalerrorcorrec-
embeddings. In Proceedings of the 57th Annual tion. ArXiv,abs/2309.11439.
Meeting of the Association for Computational Lin-
MasahiroKaneko,ShoTakase,AyanaNiwa,andNaoaki
guistics,pages1641–1650,Florence,Italy.Associa-
Okazaki.2022d. Interpretabilityforlanguagelearn-
tionforComputationalLinguistics.
ers using example-based grammaticalerror correc-
MasahiroKanekoandDanushkaBollegala.2021a. De- tion. InProceedingsofthe60thAnnualMeetingof
biasing pre-trained contextualised embeddings. In theAssociationforComputationalLinguistics(Vol-
Proceedingsofthe16thConferenceoftheEuropean ume 1: Long Papers), pages 7176–7187, Dublin,
Chapter of the Association for Computational Lin- Ireland.AssociationforComputationalLinguistics.
guistics: Main Volume, pages 1256–1266, Online.
AssociationforComputationalLinguistics. Daniel Khashabi, Xinxi Lyu, Sewon Min, Lianhui
Qin,KyleRichardson,SeanWelleck,HannanehHa-
Masahiro Kaneko and Danushka Bollegala. 2021b. jishirzi, Tushar Khot, Ashish Sabharwal, Sameer
Dictionary-baseddebiasingofpre-trainedwordem- Singh, and Yejin Choi. 2022. Prompt wayward-
beddings. InProceedingsofthe16thConferenceof ness: Thecuriouscaseofdiscretizedinterpretation
theEuropeanChapteroftheAssociationforCompu- ofcontinuousprompts. InProceedingsofthe2022
tationalLinguistics: MainVolume,pages212–223, Conference of the North American Chapter of the
Online.AssociationforComputationalLinguistics. AssociationforComputationalLinguistics: Human
LanguageTechnologies,pages3631–3643,Seattle, SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,
United States. Association for Computational Lin- MikeLewis,HannanehHajishirzi,andLukeZettle-
guistics. moyer. 2022. Rethinking the role of demonstra-
tions: Whatmakesin-contextlearningwork? arXiv
Been Kim, Martin Wattenberg, Justin Gilmer, Carrie preprintarXiv:2202.12837.
Cai,JamesWexler,FernandaViegas,etal.2018. In-
terpretabilitybeyondfeatureattribution: Quantitative Shikhar Murty, Christopher D Manning, Scott Lund-
testingwithconceptactivationvectors(tcav). InIn- berg,andMarcoTulioRibeiro.2022. Fixingmodel
ternationalconferenceonmachinelearning,pages bugswithnaturallanguagepatches. arXivpreprint
2668–2677.PMLR. arXiv:2211.03318.
TakeshiKojima,ShixiangShaneGu,MachelReid,Yu- Sharan Narang, Colin Raffel, Katherine Lee, Adam
takaMatsuo,andYusukeIwasawa.2022. Largelan- Roberts,NoahFiedel,andKarishmaMalkan.2020.
guagemodelsarezero-shotreasoners. arXivpreprint WT5?! trainingText-to-Textmodelstoexplaintheir
arXiv:2205.11916. predictions.
SawanKumarandParthaTalukdar.2020. NILE:Natu- YixinNie,AdinaWilliams,EmilyDinan,MohitBansal,
rallanguageinferencewithfaithfulnaturallanguage JasonWeston,andDouweKiela.2020. Adversarial
explanations. In Proceedings of the 58th Annual NLI:Anewbenchmarkfornaturallanguageunder-
Meeting of the Association for Computational Lin- standing. InProceedingsofthe58thAnnualMeet-
guistics,pages8730–8742,Online.Associationfor ingoftheAssociationforComputationalLinguistics,
ComputationalLinguistics. pages4885–4901,Online.AssociationforComputa-
tionalLinguistics.
HimabinduLakkaraju,DylanSlack,YuxinChen,Chen-
hao Tan, and Sameer Singh. 2022. Rethinking ex- DaisukeOba,MasahiroKaneko,andDanushkaBolle-
plainabilityasadialogue: Apractitioner’sperspec- gala.2023. In-contextualbiassuppressionforlarge
tive. languagemodels. ArXiv,abs/2309.07251.
WangLing,DaniYogatama,ChrisDyer,andPhilBlun- OpenAI.2023. IntroducingChatGPT.
som.2017. Programinductionbyrationalegenera-
tion: Learningtosolveandexplainalgebraicword DongHukPark,LisaAnneHendricks,ZeynepAkata,
problems. InProceedingsofthe55thAnnualMeet- AnnaRohrbach,BerntSchiele,TrevorDarrell,and
ingoftheAssociationforComputationalLinguistics MarcusRohrbach.2018. Multimodalexplanations:
(Volume1:LongPapers),pages158–167,Vancouver, Justifyingdecisionsandpointingtotheevidence.
Canada.AssociationforComputationalLinguistics.
GuilhermePenedo,QuentinMalartic,DanielHesslow,
ZacharyCLipton.2018. Themythosofmodelinter- Ruxandra Cojocaru, Alessandro Cappelli, Hamza
pretability: Inmachinelearning, theconceptofin- Alobeidli, Baptiste Pannier, Ebtesam Almazrouei,
terpretabilityisbothimportantandslippery. Queue, andJulienLaunay.2023. TheRefinedWebdataset
16(3):31–57. for Falcon LLM: outperforming curated corpora
with web data, and web data only. arXiv preprint
YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man- arXiv:2306.01116.
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019. AlecRadford,JongWookKim,TaoXu,GregBrock-
Roberta: A robustly optimized bert pretraining ap- man,ChristineMcLeavey,andIlyaSutskever.2022.
proach. arXivpreprintarXiv:1907.11692. Robustspeechrecognitionvialarge-scaleweaksu-
pervision. arXivpreprintarXiv:2212.04356.
MengsayLoem,MasahiroKaneko,andNaoakiOkazaki.
2023. Saieframework: Supportaloneisn’tenough ColinRaffel,NoamShazeer,AdamRoberts,Katherine
- advancing llm training with adversarial remarks. Lee,SharanNarang,MichaelMatena,YanqiZhou,
ArXiv,abs/2311.08107. WeiLi,PeterJLiu,etal.2020. Exploringthelimits
oftransferlearningwithaunifiedtext-to-texttrans-
Li Lucy and David Bamman. 2021. Gender and rep- former. J.Mach.Learn.Res.,21(140):1–67.
resentationbiasinGPT-3generatedstories. InPro-
ceedings of the Third Workshop on Narrative Un- Marco Tulio Ribeiro, Sameer Singh, and Carlos
derstanding, pages48–55, Virtual.Associationfor Guestrin.2016. "whyshoulditrustyou?"explaining
ComputationalLinguistics. thepredictionsofanyclassifier. InProceedingsof
the22ndACMSIGKDDinternationalconferenceon
ChandlerMay,AlexWang,ShikhaBordia,SamuelR. knowledgediscoveryanddatamining,pages1135–
Bowman,andRachelRudinger.2019. Onmeasuring 1144.
socialbiasesinsentenceencoders. InProceedings
ofthe2019ConferenceoftheNorthAmericanChap- Pratyusha Sharma, Balakumar Sundaralingam, Valts
teroftheAssociationforComputationalLinguistics: Blukis,ChrisPaxton,TuckerHermans,AntonioTor-
HumanLanguageTechnologies,Volume1(Longand ralba, Jacob Andreas, and Dieter Fox. 2022. Cor-
Short Papers), pages 622–628, Minneapolis, Min- rectingrobotplanswithnaturallanguagefeedback.
nesota.AssociationforComputationalLinguistics. arXivpreprintarXiv:2204.05186.
RavidShwartz-ZivandNaftaliTishby.2017. Opening of the North American Chapter of the Association
theblackboxofdeepneuralnetworksviainforma- for Computational Linguistics: Human Language
tion. arXivpreprintarXiv:1703.00810. Technologies,pages632–658,Seattle,UnitedStates.
AssociationforComputationalLinguistics.
DylanSlack,SatyapriyaKrishna,HimabinduLakkaraju,
andSameerSingh.2022. Talktomodel: Explaining MinghaoWu,AbdulWaheed,ChiyuZhang, Muham-
machinelearningmodelswithinteractivenaturallan- mad Abdul-Mageed, and Alham Fikri Aji. 2023.
guageconversations. Lamini-lm: A diverse herd of distilled mod-
els from large-scale instructions. arXiv preprint
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann arXiv:2304.14402.
Dubois, Xuechen Li, Carlos Guestrin, Percy
Liang, and Tatsunori B. Hashimoto. 2023. Stan- Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
ford alpaca: An instruction-following llama Weinberger,andYoavArtzi.2020. Bertscore: Eval-
model. https://github.com/tatsu-lab/ uating text generation with bert. In International
stanford_alpaca. ConferenceonLearningRepresentations.
MosaicMLNLPTeam.2023. Introducingmpt-7b: A Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex
newstandardforopen-source,lyusablellms. Smola. 2022. Automatic chain of thought prompt-
ing in large language models. arXiv preprint
HugoTouvron,ThibautLavril,GautierIzacard,Xavier arXiv:2210.03493.
Martinet,Marie-AnneLachaux,TimothéeLacroix,
BaptisteRozière,NamanGoyal,EricHambro,Faisal YiZhou,MasahiroKaneko,andDanushkaBollegala.
Azhar,AurelienRodriguez,ArmandJoulin,Edouard 2022. Senseembeddingsarealsobiased–evaluating
Grave,andGuillaumeLample.2023. Llama: Open socialbiasesinstaticandcontextualisedsenseem-
and efficient foundation language models. arXiv beddings. InProceedingsofthe60thAnnualMeet-
preprintarXiv:2302.13971. ingoftheAssociationforComputationalLinguistics
(Volume1: LongPapers),pages1924–1935,Dublin,
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Ireland.AssociationforComputationalLinguistics.
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser,andIlliaPolosukhin.2017. Attentionisall
youneed. Advancesinneuralinformationprocessing
systems,30.
BoshiWang,SewonMin,XiangDeng,JiamingShen,
You Wu, Luke Zettlemoyer, and Huan Sun. 2022a.
Towardsunderstandingchain-of-thoughtprompting:
Anempiricalstudyofwhatmatters. arXivpreprint
arXiv:2212.10001.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc
Le,EdChi,SharanNarang,AakankshaChowdhery,
andDennyZhou.2022b. Self-consistencyimproves
chainofthoughtreasoninginlanguagemodels. arXiv
preprintarXiv:2203.11171.
ZiruiWang,AdamsWeiYu,OrhanFirat,andYuanCao.
2021. Towardszero-labellanguagelearning. arXiv
preprintarXiv:2109.09193.
Albert Webson and Ellie Pavlick. 2022. Do prompt-
basedmodelsreallyunderstandthemeaningoftheir
prompts? InProceedingsofthe2022Conferenceof
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
nologies, pages 2300–2344, Seattle, United States.
AssociationforComputationalLinguistics.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.
Chainofthoughtpromptingelicitsreasoninginlarge
languagemodels. arXivpreprintarXiv:2201.11903.
Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta,
Mark Riedl, and Yejin Choi. 2022. Reframing
human-AIcollaborationforgeneratingfree-textex-
planations. InProceedingsofthe2022Conference
A ExamplesofHuman-SystemDiscussion
Here we examine whether humans and systems
canengageineffectivediscussionsbylookingat
actualdiscussions. Table8showstwoexamplesof
discussions with humans in each of the few-shot
andfew-shot-discussion. Thefirstisthatbothfew-
shot and few-shot-discussion can accept human
opinions and change their labels. However, the
discussionsdifferfromeachother. Infew-shot,the
system is not concerned with the content of the
premiseandhypothesis,butwiththedefinitionof
neutral and contradiction labels. In the few-shot-
discussion,thesystemcandiscusstherelationship
betweenawideplainofsnowandablizzardinthe
contentsofthepremiseandhypothesis.
In the second case, both few-shot and few-
shot-discussionpredictthesamecontradictionla-
bel. Still, the discussion results differ in the
wrong acceptance and the correct refutation, re-
spectively. Thefew-shothasacceptedahuman’s
erroneousopinionwithoutdiscussingit. Thefew-
shot-discussion refutes a human’s opinion by ap-
propriatelyreferringtotheman’sbehaviorinthe
premiseandthehypothesis. Theseresultsindicate
thatthemodeltrainedwiththediscussiondatacan
arguemoreappropriately.
B DiscussionExamplesCreatedby
HumansandSystems
Table 9 shows discussion examples made by hu-
mansandsystems,respectively. Inbothdiscussion
examples,thesystemcanassignlabelstoHuman1
andHuman2asindicatedbytheprompts. Thefirst
system example can derive a label that matches
the gold label and can discuss the differences be-
tweenthepremiseandhypothesisinthesameway
ashumans. Inthesecondsystemexample,thefinal
predictedlabeldiffersfromthegoldlabel. Onthe
otherhand,boththesystemandhumandiscussions
refertothemeaningofapictureandaphotograph.
While humans determine the final label from the
generalcase,thesystemdeterminesthefinallabel
in terms of lexical ambiguity. Therefore, the sys-
tem’sdiscussion,althoughdifferentfromthegold
label,isnotnecessarilyincorrect.
Premise Asnowboarderonawideplainofsnow
Hypothesis Asnowmobileinablizzard
Goldlabel Neutral
Label:Contradiction
Human:Let’sdiscussitmore.Whyisitacontradiction?Itmaybeneutralbecausethepremiseandthe
hypothesisaretalkingaboutdifferentsituations.
System:Thepremiseandhypothesisaretalkingaboutdifferentsituationsthatarenotrelated,soitisa
contradiction.
Human:Ifthesesituationsarenotatthesametime,doesnotitmeanitisneutral?
System:Itisstillconsideredacontradictionbecausethepremiseandhypothesisareunrelatedand
cannotbetrueatthesametime.
Few-shot Human:Isnotthatadefinitionofneutral?
System:Aneutralstatementisoneinwhichthepremiseandhypothesisarenotrelatedanddonotimply
eachother.
Acontradictioniswhenthepremiseandhypothesisarerelatedandcannotbetrueatthesametime.
Human:Itisnothappeningatthesametimebecausethesnowboardercannotbeinablizzard.Butthe
snowboardercanbeonawideplainofsnow.Sothesearetotallydifferentsituationshappeningat
differenttimes.Soitisneutral.
System:Yes,youarecorrect.Thepremiseandhypothesisareunrelatedanddonotimplyeachother,so
itisconsideredtobeaneutralstatement.
Label:Contradiction
Human:Let’sdiscussitmore.Whyisitacontradiction?Itmaybeneutralbecausethepremiseandthe
hypothesis
aretalkingaboutdifferentsituations.
System:Thepremiseandthehypothesisaresemanticallycontradictingeachother.Thesnowboarderis
onawideplainofsnow,whilethesnowmobileisinablizzard.
Therefore,itisacontradiction.
Human:Buthowthesnowboarderbethereifthereisablizzard?Itisveryunlikely.
System:Thatistrue.Itishighlyunlikelythatthereisawideplainofsnowandablizzardatthesametime.
Few-shot-dis. Therefore,itisacontradiction.
Human:Ifthesesituationsarenotatthesametime,doesnotitmeanitisneutral?
System:Itcanbeneutralifitisnotspecifiedwheneachsituationhappens.However,inthiscase,itisnot
specifiedwhetherthesituationsarehappeningatthesametimeornot,soitisbettertoconsiderthemasa
contradiction.
Human:Itisnothappeningatthesametimebecausethesnowboarder
cannotbeinablizzard.Butthesnowboardercanbeonawideplainofsnow.Sothesearetotally
differentsituationshappeningatdifferenttimes.Soitisneutral.
System:Thatistrue.Sinceitisnotspecifiedwhethertheyarehappeningatthesametimeornot,itis
bettertoconsiderthemasneutral.
Amanlookingoverabicycle’srearwheelinthemaintenancegaragewithvarioustoolsvisibleinthe
Premise
background.
Hypothesis Amanwaitsoutsideagarage.
Goldlabel Contradiction
Label:Contradiction
Human:Let’sdiscussitmore.Isnotitneutral?Becauselookingoverabicycle’srearwheeldoesnot
Few-shot necessarily
meanheiswaiting.
System:That’strue.Thepremiseandhypothesisareneutral.
Label:Contradiction
Human:Let’sdiscussitmore.Isnotitneutral?Becauselookingoverabicycle’srearwheeldoesnot
necessarily
meanheiswaiting.
Few-shot-dis. System:Yes,youareright.Thepremiseisdescribingthatthemanisactivelyworkingwhilethe
hypothesisisdescribingapassivestate.Therefore,thelabelshouldbecontradiction.
Human:Heisjustlookingoverabicycle’srearwheel,whyisheconsideredtobeactivelyworking?
System:Lookingoverabicycle’srearwheelsuggeststhatheisinspectingthewheel,possiblytorepair
orreplaceit.Thatisanactiveprocess,andthusisconsideredasactivelyworking.
Table8: Examplesofhumandiscussioninfew-shotandfew-shot-discussion(dis.) respectively.
Premise Twodogsplaytogetheronthebed.
Hypothesis Dogslayingdownonthefloor,motionless.
Goldlabel Contradiction
Human1:Thepremiseandhypothesisseemtobeacontradiction.Twodogsplayingtogetheronthebedis
anactivesituation,whiledogslayingdownonthefloor,motionlessisapassivesituation.
Human2:Iagreethatthepremiseandhypothesisaredifferent,butIdon’tthinktheyarenecessarily
contradictory.It’spossiblethatthetwodogscouldbeplayingtogetheronthebedandthenmovetothefloor
System
andlaydown,motionless.
Human1:That’strue,butIstillthinkthepremiseandhypothesisarecontradictory.Thepremiseimplies
activity,whilethehypothesisimpliespassivity.
Human2:Iseeyourpoint.Ithinkthepremiseandhypothesisareacontradiction.
Human1:Ithinkthepremiseandthehypothesisaretellingaboutdifferentthings.That’swhyIthinkitis
neutral.
Human2:Itiscontradictionbecausethewordsaresemanticallycontradicteachother.Forexample,black
Human
andwhite,sitandrunning.
Human1:Youarerightinthatterms.However,generally,theyaretotallydifferentsituations.
Human2:Isee,youareright.
Premise Amanwearingahornedhatposesforapicture.
Hypothesis Amanwearingahornedhatposesforaphotograph
Goldlabel neutral
Human1:Ithinkthepremiseandhypothesisareentailment.
Human2:Ithinkthepremiseandhypothesisarecontradiction.
Human1:Whydoyouthinkthat?
Human2:Becausethepremisestatesthatthemanisposingforapicture,whilethehypothesisstatesthat
System heisposingforaphotograph.
Human1:Ah,Isee.So,you’resayingthatapictureandaphotographaredifferentthings?
Human2:Yes,that’sright.Apictureisageneraltermforanyimage,whileaphotographisaspecifictypeof
image.
Human1:Okay,soIagreewithyouthatthepremiseandhypothesisareacontradiction.
Human2:Ithinkitisentailment.Becausetheonlydifferenceispictureorphotograph,butbothmean
photography.
Human1:Ithinkitiscontradiction,becauseapicturecouldmeanapainting.Sothemancaneitherposefor
Human aphotographorforapainting.
Human2:Butisn’tpicturegenerallymeanaphotograph?Anditismorecommontotakeapictureof
apersonthantodrawapersonasapicture,isn’tit?
Human1:Youareright.
Table9: Discussionexamplescreatedbyhumansandthesystem,respectively. Inthefirstproblem,thesystem
assignscontradictionforHuman1andentailmentforHuman2. Inthesecondproblem,thesystemassignsentailment
forHuman1andcontradictionforHuman2.
