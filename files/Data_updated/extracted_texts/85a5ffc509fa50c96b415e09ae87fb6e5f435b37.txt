BIASX: “Thinking Slow” in Toxic Content Moderation
with Explanations of Implied Social Biases
Warning:contentinthispapermaybeupsettingoroffensive.
YimingZhang♢ SravaniNanduri♠ LiweiJiang♠ TongshuangWu♡ MaartenSap♡
♢UniversityofChicago ♠UniversityofWashington ♡CarnegieMellonUniversity
yimingz0@uchicago.edu, maartensap@cmu.edu
Abstract
No, can you get one of the boys to carry that out?
It’s too heavy for you.
Toxicityannotatorsandcontentmoderatorsof-
ten default to mental shortcuts when making
"Thinking fast" Targeted group: women
decisions.Thiscanleadtosubtletoxicitybeing
- no explanations Implies women are physically weak
missed,andseeminglytoxicbutharmlesscon-
tentbeingover-detected. WeintroduceBIASX, : Allow ❌ "Thinking slow" (BiasX) : Moderate
a framework that enhances content modera-
tionsetupswithfree-textexplanationsofstate- Figure1: Tocombat“thinkingfast”inonlinecontent
ments’impliedsocialbiases,andexploreitsef- moderation,weproposetheBIASXframeworktohelp
fectivenessthroughalarge-scalecrowdsourced moderatorsthinkthroughthebiasedorprejudicedim-
userstudy. Weshowthatindeed,participants plicationsofstatementswithfree-textexplanations,in
substantiallybenefitfromexplanationsforcor- contrasttomostexistingmoderationparadigmswhich
rectly identifying subtly (non-)toxic content. providelittletonoexplanations.
Thequalityofexplanationsiscritical: imper-
fect machine-generated explanations (+2.4% sionmakingwithfree-textexplanationsofapoten-
on hard toxic examples) help less compared tiallytoxicstatement’stargetedgroupandsubtle
toexpert-writtenhumanexplanations(+7.2%). biased or prejudiced implication (Figure 1). In-
Ourresultsshowcasethepromiseofusingfree-
spired by cognitive science’s dual process theory
textexplanationstoencouragemorethoughtful
(Jamesetal.,1890),BIASXismeanttoencourage
toxicitymoderation.
moreconsciousreasoningaboutstatements(“think-
1 Introduction ing slow”; Kahneman, 2011), to circumvent the
mentalshortcutsandcognitiveheuristicsresulting
Online content moderators often resort to mental
fromautomaticprocessing(“thinkingfast”)thatof-
shortcuts,cognitivebiases,andheuristicswhensift-
tenleadtoadropinmodelandhumanperformance
ingthroughpossiblytoxic,offensive,orprejudiced alike(Malaviyaetal.,2022).2
content,duetoincreasinglyhighpressuretomod-
Importantly, in contrast with prior work in
eratecontent(Roberts,2019). Forexample,moder-
human-AI collaboration (e.g., Lai et al., 2022;
atorsmightassumethatstatementswithouthateful
Bansal et al., 2021) that generate explanations in
orprofanewordsarenotprejudicedortoxic(such
task-agnostic manners, we design BIASX to be
asthesubtlysexiststatementinFigure1),without
grounded in SOCIAL BIAS FRAMES, a linguis-
deeperreasoningaboutpotentiallybiasedimplica-
ticframeworkthatspellsoutbiasesandoffensive-
tions(Sapetal.,2022). Suchshortcutsincontent
nessimpliedinlanguage. Thisallowsustomake
moderation would easily allow subtle prejudiced
explicit the implied toxicity and social biases of
statements and suppress harmless speech by and
statementsthatmoderatorsotherwisemightmiss.
aboutminoritiesand,asaresult,cansubstantially
We evaluate the usefulness of BIASX explana-
hinderequitableexperiencesinonlineplatforms.1
tions for helping content moderators think thor-
(Sapetal.,2019;Gillespieetal.,2020).
oughlythroughbiasedimplicationsofstatements,
Tomitigatesuchshortcuts,weintroduceBIASX,
via a large-scale crowdsourcing user study with
aframeworktoenhancecontentmoderators’deci-
over450participantsonacuratedsetofexamples
1Here,wedefine“minority”associalanddemographic
groupsthathistoricallyhavebeenandoftenstillaretargets 2Note,“thinkingslow”refersadeeperandmorethought-
of oppression and discrimination in the U.S. sociocultural ful reasoning about statements and their implications, not
context(NietoandBoyer,2006;RWJF,2017). necessarilyslowerintermsofreadingordecisiontime.
3202
yaM
32
]LC.sc[
1v98531.5032:viXra
of varying difficulties. We explore three primary AI-generatedfree-textexplanationsofanauthor’s
researchquestions: (1)Whendofree-textexplana- likelyintenttohelpusersidentifymisinformation
tionshelpimprovethecontentmoderationquality, innewsheadlines,weproposetofocusonfree-text
andhow? (2)Istheexplanationformatin BIASX explanationsofoffensiveness,whichhasthepoten-
effective? and (3) How might the quality of the tialofcommunicatingrichinformationtohumans.
explanationsaffecttheirhelpfulness? Ourresults
Implied Social Biases. To maximize its utility,
showthat BIASX indeedhelpsmoderatorsbetter
detecthard,subtlytoxicinstances,asreflectedboth
wefurtherdesign BIASX tooptimizeforcontent
moderation,bygroundingtheexplanationformatin
inincreasedmoderationperformanceandsubjec-
tivefeedback. Contrastingpriorworkthatuseother
theestablished SOCIAL BIAS FRAMES(SBF;Sap
etal.,2020)formalism. SBFisaframeworkthat
forms of explanation (e.g., highlighted spans in
distillsbiasesandoffensivenessthatareimpliedin
theinputtext,classifierconfidencescores)(Carton
language,anditsdefinitionanddemonstrationof
et al., 2020; Lai et al., 2022; Bansal et al., 2021),
impliedstereotypenaturallyallowsusforexplain-
ourresultsdemonstratethatdomain-specificfree-
ingsubtlytoxicstatements. Specifically,fortoxic
textexplanations(inourcase,impliedsocialbias)
isapromisingformofexplanationtosupply.
posts, BIASX explanations take the same format
Notably, we also find that explanation quality
asSOCIAL BIAS FRAMES,whichspellsoutboth
the targeted group and the implied stereotype, as
matters: modelssometimesmisstheveiledbiases
showninFigure1.
thatarepresentintext,makingtheirexplanations
unhelpfulorevencounterproductiveforusers. Our On the other hand, moderators also need help
findingsshowcase thepromiseoffree-textexpla-
toavoidblockingbenignpoststhatareseemingly
nationsinimprovingcontentmoderationfairness, toxic (e.g., positive posts with expletives, state-
and serves as a proof-of-concept of the effective- mentsdenouncingbiases,orinnocuousstatements
nessofBIASX,whilehighlightingtheneedforAI mentioningminorities). Toaccommodatethisneed,
systems that are more capable of identifying and we extend SOCIAL BIAS FRAMES-style implica-
explainingsubtlebiasesintext. tionstoprovideexplanationsofwhyapostmight
benon-toxic. Foranon-toxicstatement,theexpla-
2 Explaining(Non-)Toxicitywith BIASX nationacknowledgesthe(potential)aggressiveness
ofthestatementwhilenotingthelackofprejudice
The goal of our work is to help content modera-
againstminoritygroups: giventhestatement“This
tors reason through whether statements could be
is fucking annoying because it keeps raining in
biased,prejudiced,oroffensive—wewouldlike
mycountry”,BIASXcouldprovideanexplanation
toexplicitlycalloutmicroaggressionsandsocial
“Usesprofanitywithoutprejudiceorhate”.3
biasesprojectedbyastatement,andalleviateover-
moderation of deceivingly non-toxic statements.
3 ExperimentDesign
To do so, we propose BIASX, a framework for
assisting content moderators with free-text expla- Weconductauserstudytomeasuretheeffective-
nations of implied social biases. There are two nessof BIASX.Weareinterestedinexploring:
primarydesigndesiderata: Q.1 DoesBIASXimprovethecontentmoderation
quality,especiallyonchallenginginstances?
Free-textexplanations. Identifyingandexplain-
Q.2 IsBIASX’sexplanationformatdesignedeffec-
ingimplicitbiasesinonlinesocialinteractionsis
tivelytoallowmoderatorsthinkcarefullyabout
difficult, as the underlying stereotypes are rarely
moderationdecisions?
stated explicitlyby definition; thisis nonetheless
Q.3 Arehigherqualityexplanationmoreeffective?
important due to the risk of harm to individu-
Toanswerthesequestions,wedesignacrowd-
als (Williams, 2020). Psychologists have argued
sourced user study that simulates a real con-
that common types of explanation in literature,
tentmoderationenvironment: crowdworkersare
such as highlights and rationales (e.g., Lai et al.,
askedtoplaytheroleofcontentmoderators,andto
2020;Vasconcelosetal.,2023)orclassifierconfi-
judgethetoxicityofaseriesof30onlineposts,po-
dencescores(e.g.,Bansaletal.,2021)areoflim-
tentiallywithexplanationsfromBIASX.Ourstudy
ited utility to humans (Miller, 2019). This moti-
vatestheneedforexplanationsthatgobeyondwhat
3Anon-toxicstatementbydefinitiondoesnottargetany
iswritten. InspiredbyGabrieletal.(2022)whouse minoritygroup,andweuse“N/A”asafiller.
2
overall hard-toxicset hard-non-toxicset easyset
No-Expl 61.8 44.1 56.0 85.4 10.6
Light-Expl 61.7 45.9 57.7 81.5 14.6
Model-Expl 61.8 46.5 53.9 85.1 15.0
Human-Expl 66.5 51.3 63.7 84.4 14.9
40 60 80 40 60 80 40 60 80 40 60 80 0 5 10 15
(a)Averageannotator(4-way)accuracy(%). (b)Medianlabelingtime(s).
Figure 2: Accuracy and efficiency results for the user study across evaluation sets and conditions. Error bars
represent95%confidenceintervals.
incorporates examples of varying difficulties and correctlyclassified.5 Amongthese,wefurtherre-
differentformsofexplanationsasdetailedbelow. movedmislabeledexamples,andselected20exam-
plesthatatleasttwoauthorsagreedwerehardbut
3.1 ExperimentSetup
couldbeunambiguouslylabeled.
Conditions. Participantsindifferentconditions
Explanation generation. To generate explana-
haveaccesstodifferentkindsofexplanationassis-
tions for MODEL-EXPL, the authors manually
tance. To answer Q.1 and Q.2, we set two base-
wrote explanations for a prompt of 6 training ex-
lineconditions: (1)NO-EXPL,whereparticipants
amplesfromSBIC(3toxicand3non-toxic),and
make decisions without seeing any explanations;
promptedGPT-3.5(Ouyangetal.,2022)forexpla-
(2) LIGHT-EXPL, where we provide only the tar-
nationgeneration.6 Wereportadditionaldetailson
geted group as the explanation. This can be con-
explanationgenerationinAppendixA.1. Forthe
sidered an ablation of BIASX with the detailed
HUMAN-EXPLcondition,theauthorscollectively
impliedstereotypeontoxicpostsandjustification
wroteexplanationsafterdeliberation.
onnon-toxicpostsremoved,andhelpsusverifythe
effectivenessofourexplanationformat. Further,to Moderation labels. Granularity is desirable in
answerQ.3,weaddtwo BIASX conditions,with
contentmoderation(DíazandHecht-Felella,2021).
varyingqualitiesofexplanationsfollowingBansal
We design our labels such that certain posts are
etal.(2021): (3)HUMAN-EXPLwithhighquality
blockedfromallusers(e.g.,forincitingviolence
explanationsmanuallywrittenbyexperts,and(4)
againstmarginalizedgroups),whileothersarepre-
MODEL-EXPL with possibly imperfect machine-
sentedwithwarnings(e.g.,forprojectingasubtle
generatedexplanations.
stereotype). InspiredbyRottgeretal.(2022),our
studyfollowsasetofprescriptiveparadigmsinthe
Data selection and curation. As argued in §2,
designofthemoderationlabels,whichispredomi-
webelieve BIASX wouldbemorehelpfulonchal-
nantlythecaseinsocialmediaplatforms’moder-
lenging cases where moderators may make mis-
ation guidelines. Loosely following the modera-
takes without deep reasoning — including toxic
tionoptionsavailabletoRedditcontentmoderators,
posts that contain subtle stereotypes, and benign
weprovideparticipantswithfouroptions: Allow,
poststhataredeceivinglytoxic. Tomeasurewhen
Lenient, Moderate, andBlock. Theydifferboth
andhowBIASXhelpsmoderators,wecarefullyse-
in the severity of toxicity, and the corresponding
lect30blogpostsfromtheSBICdataset(Sapetal.,
effect(e.g.,Lenientproducesawarningtousers,
2020)astaskexamplesthatcrowdworkersannotate.
whereasBlockprohibitsanyuserfromseeingthe
SBICcontains45kpostsandtoxicitylabelsfroma
post). AppendixBshowsthelabeldefinitionspro-
mixofsources(e.g.,Reddit,Twitter,varioushate
videdtoworkers.
sites),manyofwhichprojecttoxicstereotypes. The
datasetprovidestoxicitylabels,aswellastargeted
3.2 StudyProcedure
minorityandstereotypeannotations. Wechoose10
Our study consists of a qualification stage and a
simpleexamples,10hard-toxicexamples,and10
hard-non-toxicexamplesfromit.4 FollowingHan taskstage. Duringqualification,wedeployedHu-
manIntelligenceTasks(HITs)onAmazonMechan-
andTsvetkov(2020),weidentifyhardexamplesby
icalTurk(MTurk)inwhichworkersgothrough4
usingafine-tunedDeBERTatoxicityclassifier(He
et al., 2021) to find misclassified instances from
5WeuseHuggingFace(Wolfetal.,2020)tofine-tuneapre-
thetestset,whicharelikelytobeharderthanthose traineddeberta-v3-largemodel. Themodelachieves
anF1scoreof87.5%ontheSBICtestset.
4ThefulllistofexamplescanbefoundinTable3. 6Weusetext-davinci-003inourexperiments.
3
Mentaldemand After you strip off his makeup and
A (No-Expl: 39.7%)
No-Expl Response clothes, biologically he's still a man.
Light-Expl s dt isro an gg rely edisagree T Imar pg le iet se d
th
g ar to tu rp a:
n
t sr ga en ns dg ee rn pd ee or
p
p lee o ap rele
n ot
(Light-Expl: 54.5%)
Model-Expl neutral their true gender and are just pretending. (Model-Expl: 60.2%)
Human-Expl agree
−100% 0% 100% stronglyagree T Imar pg le iet se d th g ar to tu rp a: n t sr wan os mge en n d ae rr e w noo tm re en a l women. (Human-Expl: 58.1%)
Percentage of participants
Usefulforsubtle Alabama where eharmony and (No-Expl: 55.4%)
B
ancestry are the same website
Light-Expl
Model-Expl Targeted group: N/A (Light-Expl: 52.7%)
Human-Expl Makes a joke about two unrelated websites. (Model-Expl: 39.8%)
−100% 0% 100% Targeted group: people from Alabama (Human-Expl: 60.0%)
Percentage of participants Implies that people from Alabama marry their family.
Figure3: Usersurveyresultsonmentaldemand,and Figure 4: Explanations and worker performances for
whetherexplanationsareusefulforsubtlestereotypes. twoexamplesinthehard-toxicset.
roundsoftrainingtofamiliarizewiththetaskand stance. Thisshowcasesthepotentialof(evenim-
theuserinterface. Then,workersareaskedtolabel perfect)explanationsinspellingoutsubtlestereo-
twostraightforwardpostswithoutassistance. typesinstatements. Thesubjectivefeedbackfrom
Workers who labeled both posts correctly are moderators further corroborates this observation
recruited into the task stage. A total of N=454 (Figure 3): the majority of moderators agreed or
participants are randomly assigned to one of the stronglyagreedthattheBIASXexplanationsmade
four conditions, in which they provide labels for themmoreawareofsubtlestereotypes(77.1%in
30 selected examples. Upon completion, partic- MODEL-EXPL;78.1%in HUMAN-EXPL).
ipants also complete a post-study survey which
collects their demographics information and sub- Ourdesignedexplanationformatefficientlypro-
jectivefeedbackontheusefulnessoftheprovided motesmorethoroughdecisions. While BIASX
explanations and the mental demand of the mod- helps raise moderators’ awareness of implied bi-
eration task. Additional details on user interface ases,itincreasestheamountoftextthatmoderators
designareinAppendixC.3. readandprocess,potentiallyleadingtoincreased
mentalloadandreadingtime. Thus,wecompare
4 ResultsandDiscussion
ourproposedexplanationagainsttheLIGHT-EXPL
condition,inwhichmoderatorsonlyhaveaccessto
We analyze the usefulness of BIASX, examining
themodel-generatedtargetedgroup,thusreducing
workermoderationaccuracy(Figure2a),efficiency
theamountoftexttoread.
(Figure2b),andsubjectivefeedback(Figure3).
Following Bansal et al. (2021), we report me-
BIASXimprovesmoderationquality,especially dianlabelingtimesoftheparticipantsacrosscon-
onhard-toxicexamples. ShowninFigure2a,we ditions in Figure 2b. We indeed see a sizable in-
findthat HUMAN-EXPL leadstosubstantialgains crease (4–5s) in labeling time for MODEL-EXPL
in moderation accuracy over the NO-EXPL base- and HUMAN-EXPL. Interestingly, LIGHT-EXPL
lineonbothhard-toxic(+7.2%)andhard-non-toxic sharesasimilarincreaseinlabelingtime(∼4s). As
examples(+7.7%),whichasaresultisreflectedas LIGHT-EXPL has brief explanations (1-2 words),
a+4.7%accuracyimprovementoverall. Thisindi- this increase is unlikely to be due to reading, but
catesthatexplicitlycallingoutstatements’implied ratherpointstoadditionalmentalprocessing. This
stereotypesorprejudicesdoesencouragecontent extra mental processing is further evident from
moderatorstothinkmorethoroughlyaboutthetox- users’subjectiveevaluationinFigure3: 56%par-
icityofposts. ticipants agreed or strongly agreed that the task
Illustratingthiseffect,weshowanexampleofa wasmentallydemandinginthe LIGHT-EXPLcon-
hard-toxicstatementinFigure4a. Thestatement dition,comparedto41%in MODEL-EXPL andin
projects a stereotype against transgender people, HUMAN-EXPL. Thisresultsuggeststhatproviding
which the majority of moderators (60.3%) in the thetargetedgroupexclusivelycouldmisleadmod-
NO-EXPLconditionfailedtoflag. Incontrast,BI- eratorswithoutimprovingaccuracyorefficiency.
ASX assistance in both MODEL-EXPL (+20.5%)
andHUMAN-EXPL(+18.4%)conditionssubstan- Explanation quality matters. Compared to
tiallyimprovedmoderatorperformanceonthisin- expert-written explanations, the effect of model-
4
MODEL-EXPL HUMAN-EXPL ing task-specific difficulty (subtle biases) in free
Evaluationset E U E U text. Subsequentstudiescouldinvestigatevarious
hardtoxic 60.0 56.4 100.0 64.1 formsoffree-textexplanationsandobjectives,e.g.,
hardnon-toxic 90.0 77.7 100.0 80.1
reasoningaboutintent(Gabrieletal.,2022)ordis-
easy 100.0 98.0 100.0 97.0
overall 83.3 77.4 100.0 80.4 tillingpossibleharmstothetargetedgroups(e.g.,
CobraFrames;Zhouetal.,2023). Ourlesssignifi-
Table1: Binaryaccuracyofexplanations(E)andusers cantresultonhard-non-toxicexamplesalsosound
(U)inMODEL-EXPLandHUMAN-EXPLconditions. a cautionary note, and shows the need for inves-
tigatingmorecarefuldefinitionsandframeworks
aroundnon-toxicexamples(e.g.,byextendingSo-
generatedexplanationsonmoderatorperformance
cialBiasFrame),orexploringalternativedesigns
ismixed. Akeyreasonbehindthismixedresultis
fortheirexplanations.
thatmodelexplanationsareimperfect. InTable1,
Further,goingfromproof-of-concepttopractical
wecomparethecorrectnessofexplanationstothe
accuracy of participants.7 On the hard toxic set, usage,wenotetwoadditionalnuancesthatdeserve
carefulconsideration. Ontheonehand,ourstudy
60% of model explanations are accurate, which
showsthatwhileexplanationshavebenefits,they
leadsto56.4%workeraccuracy,a-7.7%dropfrom
come at the cost of a sizable increase in labeling
the HUMAN-EXPL condition where workers al-
time. Weargueforthesehigh-stakestasks,thein-
wayshaveaccesstocorrectexplanations. Figure4b
crease in labeling time and cost is justifiable to a
showsanexamplewherethemodelexplainsanim-
degree (echoing our intend of pushing people to
plicitlytoxic statementas harmlessand misleads
“think slow”). However, we do hope future work
content moderators (39.8% in MODEL-EXPL vs.
could look more into potential ways to improve
55.4%in NO-EXPL).
performancewhilereducingtimethrough,e.g.,se-
Onapositivenote,expert-writtenexplanations
lectively introducing explanations on hard exam-
still improve moderator performance over base-
ples(Laietal.,2023). Thisapproachcouldaidin
lines, highlighting the potential of our frame-
scalingourframeworkforeverydayuse,wherethe
work with higher quality explanations and serv-
delicatebalancebetweenswiftannotationandcare-
ing as a proof-of-concept of BIASX, while moti-
ful moderation is more prominent. On the other
vating future work to explore methods to gener-
hand,ourstudyfollowsasetofprescriptivemod-
ate higher-quality explanations using techniques
eration guidelines (Rottger et al., 2022), written
such as chain-of-thought (Camburu et al., 2018;
based on the researchers’ definitions of toxicity.
Weietal.,2022)andself-consistency(Wangetal.,
Whiletheyaresimilartoactualplatforms’termsof
2023)prompting.
serviceandmoderationrules,theymaynotreflect
5 ConclusionandFutureWork thenormsofallonlinecommunities. Customized
labeling might be essential to accommodate for
In this work, we propose BIASX, a collaborative
platform needs. We are excited to see more ex-
frameworkthatprovidesAI-generatedexplanations
plorationsaroundouralreadypromisingproof-of-
toassistusersincontentmoderation,withtheob-
concept.
jectiveofenablingmoderatorstothinkmorethor-
oughly about their decisions. In an online user
6 Limitations,EthicalConsiderations&
study,wefindthatbyaddingexplanations,humans
BroaderImpact
performbetteronhard-toxicexamples. Theeven
greatergaininperformancewithexpert-writtenex- Whileouruserstudyoftoxiccontentmoderation
planationsfurtherhighlightsthepotentialoffram- is limited to examples in English and to a US-
ingcontentmoderationunderthelensofhuman-AI centricperspective,hatespeechishardlyamono-
collaborativedecisionmaking. lingual(Rossetal.,2016)oramonocultural(Ma-
Ourworkservesasaproof-of-conceptforfuture ronikolakisetal.,2022)issue,andfutureworkcan
investigationinhuman-AIcontentmoderation,un- investigate the extension of BIASX to languages
dermoredescriptiveparadigms. Mostimportantly, andcommunitiesbeyondEnglish.
ourresearchhighlightstheimportanceofexplain- In addition, our study uses a fixed sample of
30 curated examples. The main reason for using
7BinarizinginstanceswithmoderationlabelsAllowand
Lenientasnon-toxic,andModerateandBlockastoxic. a small set of representative examples is that it
5
enables us to conduct the user study with a large Ribeiro, and Daniel Weld. 2021. Does the whole
number of participants to demonstrate salient ef- exceed its parts? the effect of ai explanations on
complementaryteamperformance. InProceedings
fectsacrossgroupsofparticipants. Anotherreason
ofthe2021CHIConferenceonHumanFactorsin
forthefixedsamplingisthedifficultyofidentify-
ComputingSystems,pages1–16.
inghigh-qualityexamplesandgeneratinghuman
explanations: toxicitylabelsandimplicationanno- Oana-Maria Camburu, Tim Rocktäschel, Thomas
Lukasiewicz,andPhilBlunsom.2018. e-snli: Natu-
tationsinexistingdatasetsarenoisy. Additionalre-
rallanguageinferencewithnaturallanguageexpla-
searcheffortsintobuildinghigher-qualitydatasets
nations. AdvancesinNeuralInformationProcessing
in implicit hate speech could enable larger-scale Systems,31.
explorationsofmodel-assistedcontentmoderation.
SamuelCarton,QiaozhuMei,andPaulResnick.2020.
Justascommunitieshavedivergingnorms,anno-
Feature-basedexplanationsdon’thelppeopledetect
tatorshavediverseidentitiesandbeliefs,whichcan misclassificationsofonlinetoxicity. InICWSM.
shifttheirindividualperceptionoftoxicity(Rottger
etal.,2022). SimilartoSapetal.(2022),wefind Ángel Díaz and Laura Hecht-Felella. 2021. Dou-
bleStandardsinSocialMediaContentModeration.
annotator performance varies greatly depending
Technicalreport,BrennanCenterforJustice.
ontheannotator’spoliticalorientation. Asshown
inFigure9(Appendix),amoreliberalparticipant FranzFaul,EdgarErdfelder,AxelBuchner,andAlbert-
achieveshigherlabelingaccuraciesonhard-toxic, GeorgLang.2009. Statisticalpoweranalysesusing
G*Power 3.1: Tests for correlation and regression
hard-non-toxicandeasyexamplesthanamorecon-
analyses. BehaviorResearchMethods,41(4):1149–
servativeone. Thisresulthighlightsthatthedesign
1160.
ofamoderationschemeshouldtakeintoaccount
Saadia Gabriel, Skyler Hallinan, Maarten Sap, Pemi
the varying backgrounds of annotators, cover a
Nguyen,FranziskaRoesner,EunsolChoi,andYejin
broadspectrumofpoliticalviews,andraisesinter-
Choi. 2022. Misinfo reaction frames: Reasoning
estingquestionsaboutwhetherannotatorvariation aboutreaders’reactionstonewsheadlines. InACL.
can be mitigated by explanations, which future
TarletonGillespie,PatriciaAufderheide,ElinorCarmi,
workshouldexplore.
YsabelGerrard,RobertGorwa,AriadnaMatamoros-
Due to the nature of our user study, we ex-
Fernandez, Sarah T Roberts, Aram Sinnreich, and
posecrowdworkerstotoxiccontentthatmaycause SarahMyersWest.2020. Expandingthedebateabout
harm (Roberts, 2019). To mitigate the potential contentmoderation: Scholarlyresearchagendasfor
thecomingpolicydebates. InternetPolicyReview.
risks,wedisplaycontentwarningsbeforethetask,
and our study was approved by the Institutional
XiaochuangHanandYuliaTsvetkov.2020. Fortifying
ReviewBoard(IRB)attheresearchers’institution. toxic speech detectors against veiled toxicity. In
Finally,weensurethatstudyparticipantsarepaid EMNLP.
fairwages(> $10/hr). SeeAppendixCforfurther
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and
informationregardingtheuserstudy.
Weizhu Chen. 2021. DEBERTA: DECODING-
ENHANCEDBERTWITHDISENTANGLEDAT-
Acknowledgments
TENTION. InInternationalConferenceonLearning
Representations.
WethankworkersonAmazonMturkwhopartic-
ipatedinouronlineuserstudyformakingourre- WilliamJames,FrederickBurkhardt,FredsonBowers,
search possible. We thank Karen Zhou, people and Ignas K Skrupskelis. 1890. The principles of
psychology,volume1. MacmillanLondon.
fromvariouspaperclinicsandanonymousreview-
ersforinsightfulfeedbackandfruitfuldiscussions. DanielKahneman.2011. Thinking,fastandslow.
ThisresearchwassupportedinpartbyMetaFun-
VivianLai, SamuelCarton, RajatBhatnagar, Q.Vera
damentalAIResearchLaboratories(FAIR)“Dyn-
Liao, Yunfeng Zhang, and Chenhao Tan. 2022.
abench Data Collection and Benchmarking Plat-
Human-AIcollaborationviaconditionaldelegation:
form”award“ContExTox: Context-AwareandEx- Acasestudyofcontentmoderation. InProceedings
plainableToxicityDetection.” ofthe2022CHIConferenceonHumanFactorsin
ComputingSystems,CHI’22,NewYork,NY,USA.
AssociationforComputingMachinery.
References
Vivian Lai, Han Liu, and Chenhao Tan. 2020. "Why
Gagan Bansal, Tongshuang Wu, Joyce Zhou, Ray- is ’Chicago’ Deceptive?" towards building model-
mondFok,BesmiraNushi,EceKamar,MarcoTulio driven tutorials for humans. In Proceedings of the
6
2020CHIConferenceonHumanFactorsinComput- HelenaVasconcelos,MatthewJörke,MadeleineGrunde-
ingSystems, CHI’20, pages1–13, NewYork, NY, McLaughlin,TobiasGerstenberg,MichaelBernstein,
USA.AssociationforComputingMachinery. and Ranjay Krishna. 2023. Explanations Can Re-
duceOverrelianceonAISystemsDuringDecision-
VivianLai,YimingZhang,ChachaChen,Q.VeraLiao, Making.
and Chenhao Tan. 2023. Selective Explanations:
LeveragingHumanInputtoAlignExplainableAI. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc
Le,EdChi,SharanNarang,AakankshaChowdhery,
ChaitanyaMalaviya,SudeepBhatia,andMarkYatskar.
andDennyZhou.2023. Self-ConsistencyImproves
2022. Cascadingbiases: Investigatingtheeffectof
ChainofThoughtReasoninginLanguageModels.
heuristicannotationstrategiesondataandmodels. In
EMNLP. JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,BrianIchter,FeiXia,EdChi,QuocLe,and
Antonis Maronikolakis, Axel Wisiorek, Leah Nann,
Denny Zhou. 2022. Chain of Thought Prompting
HarisJabbar,SahanaUdupa,andHinrichSchuetze.
ElicitsReasoninginLargeLanguageModels.
2022. ListeningtoAffectedCommunitiestoDefine
ExtremeSpeech: DatasetandExperiments. MonnicaT.Williams.2020. Microaggressions: Clari-
fication,evidence,andimpact. PerspectivesonPsy-
TimMiller.2019. Explanationinartificialintelligence:
chologicalScience,15(1):3–26.
Insights from the social sciences. Artificial intelli-
gence. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond,ClementDelangue,AnthonyMoi,Pier-
Leticia Nieto and Margot Boyer. 2006. Understand-
ricCistac,TimRault,RemiLouf,MorganFuntowicz,
ingoppression: Strategiesinaddressingpowerand
JoeDavison,SamShleifer,PatrickvonPlaten,Clara
privilege. ColorsNW,pages30–33.
Ma, YacineJernite, JulienPlu, CanwenXu, Teven
LeScao,SylvainGugger,MariamaDrame,Quentin
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car-
Lhoest, and Alexander Rush. 2020. Transformers:
rollL.Wainwright,PamelaMishkin,ChongZhang,
State-of-the-Art Natural Language Processing. In
SandhiniAgarwal,KatarinaSlama,AlexRay,John
Proceedings of the 2020 Conference on Empirical
Schulman,JacobHilton,FraserKelton,LukeMiller,
Methods in Natural Language Processing: System
Maddie Simens, Amanda Askell, Peter Welinder,
Demonstrations,pages38–45,Online.Association
Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
forComputationalLinguistics.
Traininglanguagemodelstofollowinstructionswith
humanfeedback.
XuhuiZhou,HaoZhu,AkhilaYerukola,ThomasDavid-
SarahTRoberts.2019. Behindthescreen. son, Jena D. Hwang, Swabha Swayamdipta, and
MaartenSap.2023. Cobraframes: Contextualrea-
BjörnRoss, MichaelRist, GuillermoCarbonell, Ben- soning about effects and harms of offensive state-
jaminCabrera,NilsKurowsky,andMichaelWojatzki. ments. InFindingsofACL.
2016. MeasuringtheReliabilityofHateSpeechAn-
notations: TheCaseoftheEuropeanRefugeeCrisis.
PaulRottger,BertieVidgen,DirkHovy,andJanetPier-
rehumbert. 2022. Two contrasting data annotation
paradigmsforsubjectiveNLPtasks. InProceedings
ofthe2022ConferenceoftheNorthAmericanChap-
ter of the Association for Computational Linguis-
tics:HumanLanguageTechnologies,pages175–190,
Seattle,UnitedStates.AssociationforComputational
Linguistics.
RWJF.2017. Discriminationinamerica: experiences
andviews.
MaartenSap,DallasCard,SaadiaGabriel,YejinChoi,
andNoahASmith.2019. Theriskofracialbiasin
hatespeechdetection. InACL.
MaartenSap,SaadiaGabriel,LianhuiQin,DanJuraf-
sky, Noah A Smith, and Yejin Choi. 2020. Social
biasframes: Reasoningaboutsocialandpowerim-
plicationsoflanguage. InACL.
Maarten Sap, Swabha Swayamdipta, Laura Vianna,
XuhuiZhou,YejinChoi,andNoahA.Smith.2022.
Annotatorswithattitudes: Howannotatorbeliefsand
identitiesbiastoxiclanguagedetection. InNAACL.
7
A ImplementationDetails • Lenient: thepostmightbeaggressive,angry,or
useprofanity/swearwords,butisnotoffensive
A.1 ExplanationGenerationwithLLMs
or prejudiced and does not use slurs in hateful
Weuselargelanguagemodels(Ouyangetal.,2022) ways.
to generate free-text explanations. Given a state-
• Moderate: the post is offensive, prejudiced,
ments,weuseapatternF toencodeoffensiveness
stereotypical,orusesgeneralizationsaboutmi-
ofthestatementw ,thelightexplanatione
[off] group
noritydemographicgroups,butisnotcallingfor
andthefullexplanatione inthesimpleformat
full
violenceorhateagainstthem.
below:
• Block: thepostqualifiesashatespeech, oren-
F(s) = {s,[SEP],
couragesviolencetowardsminorityindividuals
Offensive: w [off],[SEP], or groups and should be blocked, such that no
Targeted group: e ,[SEP], userswillbeabletoviewthiscontentatall.
group
Explanation: e },
full
C HumanEvaluation
where[SEP]isanewlinecharacter. Whilewedo
not provide the predicted offensiveness as a part WeobtainedanInstitutionalReviewBoard(IRB)
of explanation to assist humans, we nevertheless approvalforouruserstudy. Priortotheuserstudy,
includeitinsidetheprompt,sothatthegeneration we conduted a power analysis to determine the
ofgroupandexplanationisconditionedonwhether scaleoftheexperiment. Weensuredthatrecruited
thegivenstatementisoffensive. workersarepaidfairly,andconductedanoptional
Thepromptconsistsof6examples(3toxicand post-studydemographicssurvey.
3non-toxic)fromSBICwithmanuallywrittenex-
planations. Duringevaluation,wefeedtheprompt C.1 PowerAnalysis
to GPT-3.5 (Ouyang et al., 2022) and extract the
WeusedG*Power(Fauletal.,2009)toconductan
targetedgroupandexplanationfromitscompletion.
aprioripoweranalysisforone-wayANOVA.With
Wegreedilydecodetheoffensivenesstokenw ,
[off] thegoalofhaving80%powertodetectamoderate
andsamplethetargetedgroupe andexplana-
group effect size of 0.15 at a significance level of 0.05,
tione withatemperatureof0.3.
full weyieldatargetnumberof492participants.
A.2 Hyperparametersforfine-tuning
C.2 MTurkSetupandParticipant
DeBERTa
Compensation
Hyperparameter value Inboththequalificationphaseandthetaskphase,
we use the following MTurk qualifications: HIT
Batchsize 16
Learningrate 10−5 ApprovalRate≥ 98%,NumberofHITsApproved
≥ 5000,andlocationisUS.Amongthe731work-
Trainingsteps 8000
erswhoparticipatedinthequalificationphase,603
Optimizer AdamW
passed,andtheworkerswerepaidamedianhourly
Table2: DeBERTafine-tuninghyperparameters. wage of $10.23/h. Among the workers passing
qualification,490participatedinthetaskphase,in
whichtheywerefurtherpaidamedianhourlywage
For the fine-tuning of the DeBERTa classifier,
of$14.4/h. Afterfilteringoutworkerswhofailed
weusedthehyperparameters reportedinTable2.
the qualification questions during the task stage,
Nohyperparametersearchwasperformed,andwe
ouruserstudyhas454remainingparticipants.
usedearlystoppingbasedonclassificationperfor-
mance on a validation set. All experiments were
C.3 HumanEvaluationUserInterface
performedonasingleNVIDIAA40GPU,taking
<5GPUhoursintotal. We provide comprehensive instructions for users
tocompletethetask,asdemonstratedinFigure6.
B ModerationLabels
Figure 7 shows the interface for one of 4 rounds
• Allow: the post is not offensive or prejudiced of user training, and Figure 8 shows the labeling
andanyoneshouldbeabletoviewit. interface,bothundertheMODEL-EXPLcondition.
8
C.4 ParticipantDemographics
In the post-study survey, we included a optional
demographics survey. Among users who self-
identified gender, 53.4% were male, 46.1% were
female and 0.4% were non-binary. The majority
ofparticipantsidentifiedasWhite(79.9%),6.5%
asBlack/AfricanAmerican,6.0%asAsian/Asian
American, 3.6% as Hispanic/Latinx, 3.1% as
Mixed/Other,0.4%asNativeHawaiian/PacificIs-
lander,0.2%asMiddleEasternand0.2%asSouth
Asian/Indian American. Most participants were
aged25-50(72.6%).
9
Figure5: Theconsentpageavailabletoparticipants.
10
Figure6: Theinstructionspageavailabletoparticipants.
11
Figure7: ExampleofatrainingroundundertheMODEL-EXPLcondition.
Figure8: ExampleofalabelingroundundertheMODEL-EXPLcondition.
overall hard-toxicset hard-non-toxicset easyset
90
85.685.887.7 political orientation
74.380.5 Strongly conservative
80 Conservative
Neutral
67 00 54.959.562.164.967.3
53.5
50.856.557.358.860.5 L Si tb re or na gl ly liberal
50.1
50 39.541.543.4
40
30
Figure9: Averagehumanperformancegroupedbypoliticalorientation,with95%confidenceintervalsreportedas
errorbars.
12
)%(
ycaruccA
Warning:thetablecontainscontentthatmaybeupsettingoroffensive.
Post Classification
YourmomisBrazilianisn’tshe?Maybeshecouldcometotheschoolsometimeforgymandteach hardtoxic
theclasshowtodancesamba!
No,canyougetoneoftheboystocarrythatout?It’stooheavyforyou. hardtoxic
What’sthebestwaytowashdownfivehundredchocolates?Katrina. hardtoxic
Afteryoustripoffhismakeupandclothes,biologicallyhe’sstillaman. hardtoxic
Bisexualisatermthatgayguysinhighschoolusewhentheywanttoholdhandswithgirlsandfeel hardtoxic
likeanormalpersonforachange.
Isitjustacoincidencethatblackiceisthemostdangerous? hardtoxic
alabamawhereeharmonyandancestryarethesamewebsite. hardtoxic
WhenIlookattheZimbawee’sMugabe,Ithink"Ape"or"Gorilla". hardtoxic
JusthowAmericansdrawthemselvesslimmer.Japandoesthesame,theymakeanimehavegianteyes hardtoxic
whileinrealitytheycan’tseewhattheirdrawing
Youmeanyourboyfriendcodeditupinaweek! hardtoxic
YALL MOTHERFUCKER NORMIES WILL GET SPOILERS ON SEASON 8 OF GAME OF hardnon-toxic
THRONESIFYOUDONTLEAVENOW
RT@n0iratre:hookupculturecansuckmyfuckingtoe hardnon-toxic
DONOTGOAROUNDMYFUCKINGCHILDIFYOUDONTEXPECTTOHAVEFUCKING hardnon-toxic
WORDSWITHME.ThatisMYsonMINNNE.
Thereasonpeoplebecomehomebodies...theyaretiredofbeingsurroundedbyidiots hardnon-toxic
Sick of seeing liberalism/conservatism is cancer. No, extremism on both sides is cancer and ur hardnon-toxic
incompetenceatrealizingthisisdisgusting
IHAVETHEWORSTAUTUMNEVERINMYCOUNTRYITSFUCKINGAUTUMNANDTHIS hardnon-toxic
ISFUCKINGANNOYINGBECAUSEITSKEEPSRAININGINMYCOUNTRY
buyingpussyorsmokingweedcouldgetyoumorejailtimethanbeingatraitortoyourcountrymen hardnon-toxic
apparently
FellaswegottainvadeIranforfeminismandgayrights. hardnon-toxic
What’sJesus’sfavoritegun?Anailgun. hardnon-toxic
WhoistheonlysuperherothatcouIdbeatCaptainAmerica?Captainvietnam hardnon-toxic
I’mnotweird,you’rejustafaggot easy
Whyisthemonkeysad?Justlearnedthatitwillbeaniggerinamillionyears. easy
Aredbulladaykeepstheniggersaway easy
IhonestlyhateIndians,Muslims,reallyanythingwithbrown,blackoryellowcolouredskinIhate. easy
WhatwasAdolfHitler’sbiggestmistake?Notkillingthe9,000,001thJew. easy
Disclaimer:NoneofthesethingsI’mabouttotellyouare100%accurate. Just*mostly*accurate. easy
Therearealwaysexceptions.
countdowntomorecompaniesfollowingsuitafterseeingthewaythatwashandled. easy
Thanksforthe#RT!@marshawright@PrettyFru@cgm807@poesravenlady@axelmojave@wal- easy
labemu7_62Haveagreatweek!
thatmomentwhenyousilenceamageandtheystartbackpedallingandyoujustKNOWit’saboutto easy
godown
IstillhaveoneortwohuntingknivesfromwhenIusedtofishandshootincaseofselfdefenceat easy
home.
Table3: 30postsusedintheonlineuserstudy.
13
